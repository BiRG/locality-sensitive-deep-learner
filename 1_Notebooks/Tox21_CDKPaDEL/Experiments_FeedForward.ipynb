{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments for FeedForward networks, as a baseline comparison against AttentionModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMPDIR=/tmp/temp\n"
     ]
    }
   ],
   "source": [
    "%env TMPDIR=/tmp/temp \n",
    "#For joblib multi-threading\n",
    "\n",
    "import os, sys\n",
    "code_folder=os.path.join(os.getcwd(), \"..\", \"..\", \"0_code\")\n",
    "sys.path.append(code_folder)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['dark_background'])\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing (If re-running code, skip to load data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY_Tox21_CDKPaDEL_processed.csv has data type 'Training', 'Testing' and 'Score'. Training and Testing (leaderboard) data are reflected in train while Score (Final Evaluation) data is in test.\n"
     ]
    }
   ],
   "source": [
    "# Load Tox21 data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset_name=\"XY_Tox21_CDKPaDEL_processed.csv\"\n",
    "df=pd.read_csv(os.path.join(\"..\", \n",
    "                            \"..\",\n",
    "                            \"rawdata\", \n",
    "                            dataset_name))\n",
    "\n",
    "label_columns=range(5,17) #12 Tox21 labels\n",
    "data_columns=range(17,1504) #1487 CDK+PaDEL descriptors (after filtering)\n",
    "id_columns=range(5)  \n",
    "\n",
    "training_ind=np.where(np.isin(df['Type'], ['Training', 'Testing']))[0]\n",
    "testing_ind=np.where(df['Type']==\"Score\")[0]\n",
    "print(f\"{dataset_name} has data type 'Training', 'Testing' and 'Score'. Training and Testing (leaderboard) data are reflected in train while Score (Final Evaluation) data is in test.\")\n",
    "\n",
    "X_train=df.iloc[training_ind, data_columns].values\n",
    "X_test=df.iloc[testing_ind, data_columns].values\n",
    "y_train=df.iloc[training_ind, label_columns]\n",
    "y_test=df.iloc[testing_ind, label_columns]\n",
    "train_id_df=df.iloc[training_ind, id_columns]\n",
    "test_id_df=df.iloc[testing_ind, id_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tanimoto similarity\n",
    "\n",
    "dataset_sim_name=\"XY_Tox21_CDKPaDEL_processed_tanimoto.csv\"\n",
    "df_sim=pd.read_csv(os.path.join(\"..\", \n",
    "                                \"..\",\n",
    "                                \"rawdata\", \n",
    "                                dataset_sim_name\n",
    "                               ), \n",
    "                   index_col=0\n",
    "                  )\n",
    "\n",
    "sim_train_df=df_sim.iloc[training_ind, training_ind+len(id_columns)]\n",
    "sim_test_df=df_sim.iloc[testing_ind, training_ind+len(id_columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values (as most ML can't deal with missing feature values)\n",
    "Retain features with only 1 missing value. Drop features with only 1 unique value. Do median imputation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_imputation(X_train, X_test):\n",
    "    for col in range(len(X_train[0])):\n",
    "        med=np.nanmedian(X_train[:,col])\n",
    "        \n",
    "        train_nanind=np.where(np.isnan(X_train[:,col]))[0]\n",
    "        test_nanind=np.where(np.isnan(X_test[:,col]))[0]\n",
    "        \n",
    "        if len(train_nanind)>0:\n",
    "            X_train[train_nanind,col]=med\n",
    "        if len(test_nanind)>0:\n",
    "            X_test[test_nanind,col]=med\n",
    "    return X_train, X_test\n",
    "\n",
    "def zero_imputation(y):\n",
    "    for col in range(len(y[0])):\n",
    "        nan_ind=np.where(np.isnan(y[:,col]))[0]\n",
    "        if len(nan_ind)>0:\n",
    "            y[nan_ind,col]=0\n",
    "    return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_feat_ind=np.where(np.sum(np.isnan(X_train),axis=0)<2)[0]\n",
    "\n",
    "X_train, X_test=median_imputation(X_train[:, retain_feat_ind], X_test[:, retain_feat_ind])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_impute=zero_imputation(y_train.values)\n",
    "# y_test_impute=zero_imputation(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove features that are almost identical to each other (R>0.95)\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "m=X_train.shape[1]\n",
    "R_mat=np.empty((m,m))\n",
    "for (i,j) in combinations(range(m), 2):\n",
    "    r=pearsonr(X_train[:,i], X_train[:,j])\n",
    "    R_mat[i,j]=r[0]\n",
    "    R_mat[j,i]=r[0]\n",
    "for i in range(m):\n",
    "    R_mat[i,i]=0.    \n",
    "    \n",
    "import seaborn as sns\n",
    "ax= sns.heatmap(R_mat, center=0, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 comparisons with R=1.00\n",
      "6948 comparisons with R>0.95\n"
     ]
    }
   ],
   "source": [
    "R_mat=np.nan_to_num(R_mat, nan=1.)\n",
    "\n",
    "arr=pd.Series(np.abs(R_mat.flatten()))\n",
    "\n",
    "print(f\"{np.count_nonzero(arr==1)} comparisons with R=1.00\")\n",
    "print(f\"{np.count_nonzero(arr>0.95)} comparisons with R>0.95\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr=np.where(R_mat==1.)\n",
    "\n",
    "def split_ind(arr):\n",
    "    # Given 2D array of pairs of indices, return the lowest index of connected groups of indices\n",
    "    retain_list=[]\n",
    "    omit_list=[]\n",
    "    for i in range(len(arr[0])):\n",
    "        head, tail=arr[0][i], arr[1][i]\n",
    "        if head in retain_list:\n",
    "            omit_list=np.append(omit_list,tail)\n",
    "        elif tail in retain_list:\n",
    "            omit_list=np.append(omit_list,head)\n",
    "        else:\n",
    "            retain_list=np.append(retain_list, head)\n",
    "            omit_list=np.append(omit_list,tail)\n",
    "        retain_list=np.setdiff1d(retain_list, omit_list)\n",
    "        omit_list=np.unique(omit_list)\n",
    "    return retain_list, omit_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_list2, omit_list2=split_ind(np.where(np.abs(R_mat)>0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(omit_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We omit comparisons with R>0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 out of 1290 features retained.\n"
     ]
    }
   ],
   "source": [
    "filtered_features=np.setdiff1d(range(m), omit_list2)\n",
    "X_train_filtered=X_train[:,filtered_features]\n",
    "X_test_filtered=X_test[:,filtered_features]\n",
    "\n",
    "print(f\"{len(filtered_features)} out of {m} features retained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Fweights (by fitting COSA model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on outer iteration 1; beta/eta:0.220\n",
      "Wchange:0.598, Crit:-401030.862\n",
      "Wchange:0.142, Crit:-394108.120\n",
      "Inner loop converged in (or maxed out) at 2 steps\n",
      "Starting on outer iteration 2; beta/eta:0.240\n",
      "Wchange:0.061, Crit:-392041.416\n",
      "Inner loop converged in (or maxed out) at 1 steps\n",
      "Starting on outer iteration 3; beta/eta:0.260\n",
      "Wchange:0.032, Crit:-391472.136\n",
      "Inner loop converged in (or maxed out) at 1 steps\n",
      "Starting on outer iteration 4; beta/eta:0.280\n"
     ]
    }
   ],
   "source": [
    "from algorithms import COSA\n",
    "from importlib import reload\n",
    "reload(COSA)\n",
    "cosa_mdl=COSA.NNCosa(Fweight_init=\"uniform\", lam=0.2, n_iter=100,\n",
    "                                distance_measure=\"inv_exp_dist\",\n",
    "                     calc_D_ijk=False, threads=-1\n",
    "                    )\n",
    "cosa_mdl.fit(X_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosa_mdl.fit_OOS(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fweights=cosa_mdl.output_Fweight()\n",
    "# cosa_dist=cosa_mdl.output_Dmat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder=os.path.join(\"processed_data\"\n",
    "                        )\n",
    "new_data_columns=np.array(data_columns)[filtered_features]\n",
    "\n",
    "processed_df_columns=np.concatenate([id_columns, \n",
    "                                     label_columns, \n",
    "                                     new_data_columns\n",
    "                                    ])\n",
    "processed_df=df\n",
    "processed_df.iloc[training_ind, new_data_columns]=X_train_filtered\n",
    "processed_df.iloc[testing_ind, new_data_columns]=X_test_filtered\n",
    "processed_df=processed_df.iloc[:, processed_df_columns]\n",
    "\n",
    "processed_df.to_csv(os.path.join(\n",
    "    save_folder,\n",
    "    \"XY_Tox21_CDKPaDEL_processedFiltered.csv\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Fweights\n",
    "import pandas as pd\n",
    "Fweights=cosa_mdl.output_Fweight()\n",
    "df= pd.DataFrame(Fweights)\n",
    "df.to_csv(os.path.join(save_folder,\n",
    "                       \"Tox21_CDKPaDEL_Fweights_train.csv\"), \n",
    "          index=False)\n",
    "\n",
    "# import pandas as pd\n",
    "# Fweights=pd.read_csv(\"Tox21_Fweights_train.txt\")\n",
    "# cosa_mdl.Fweight=Fweights.values\n",
    "\n",
    "cosa_dist=cosa_mdl.output_Dmat()\n",
    "df=pd.DataFrame(cosa_dist)\n",
    "df.to_csv(os.path.join(save_folder,\n",
    "                       \"Tox21_CDKPaDEL_cosa_dist_train.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fweights_OOS=cosa_mdl.output_Fweight(OOS=True)\n",
    "df= pd.DataFrame(Fweights_OOS)\n",
    "df.to_csv(os.path.join(save_folder,\n",
    "                       \"Tox21_CDKPaDEL_Fweights_test.csv\"), \n",
    "          index=False)\n",
    "\n",
    "cosa_dist_OOS=cosa_mdl.output_Dmat(OOS=True)\n",
    "df=pd.DataFrame(cosa_dist_OOS)\n",
    "df.to_csv(os.path.join(save_folder,\n",
    "                       \"Tox21_CDKPaDEL_cosa_dist_test.csv\"),\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed data \n",
    "To be updated again when COSA fitting is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XY_Tox21_CDKPaDEL_processedFiltered.csv has data type 'Training', 'Testing' and 'Score'. Training and Testing (leaderboard) data are reflected in train while Score (Final Evaluation) data is in test.\n"
     ]
    }
   ],
   "source": [
    "load_folder=os.path.join(\"processed_data\"\n",
    "                        )\n",
    "dataset_name=\"XY_Tox21_CDKPaDEL_processedFiltered.csv\"\n",
    "load_df=pd.read_csv(os.path.join(load_folder, \n",
    "                                 dataset_name\n",
    "                                ), \n",
    "                    index_col=0\n",
    "                   )\n",
    "\n",
    "label_columns=range(5,17) #12 Tox21 labels\n",
    "data_columns=range(17,load_df.shape[1]) #945/1487 filtered CDK+PaDEL descriptors (after filtering)\n",
    "id_columns=range(5)  \n",
    "\n",
    "training_ind=np.where(np.isin(load_df['Type'], ['Training', 'Testing']))[0]\n",
    "testing_ind=np.where(load_df['Type']==\"Score\")[0]\n",
    "print(f\"{dataset_name} has data type 'Training', 'Testing' and 'Score'. Training and Testing (leaderboard) data are reflected in train while Score (Final Evaluation) data is in test.\")\n",
    "\n",
    "X_train=load_df.iloc[training_ind, data_columns].values\n",
    "X_test=load_df.iloc[testing_ind, data_columns].values\n",
    "y_train=load_df.iloc[training_ind, label_columns]\n",
    "y_test=load_df.iloc[testing_ind, label_columns]\n",
    "train_id_df=load_df.iloc[training_ind, id_columns]\n",
    "test_id_df=load_df.iloc[testing_ind, id_columns]\n",
    "\n",
    "\n",
    "Fweights_df=pd.read_csv(os.path.join(load_folder, \n",
    "                                     \"Tox21_CDKPaDEL_Fweights_train.csv\"\n",
    "                                    ))\n",
    "Fweights_train=Fweights_df[load_df.columns[data_columns]].values\n",
    "\n",
    "Fweights_OOS_df=pd.read_csv(os.path.join(load_folder,\n",
    "                                          \"Tox21_CDKPaDEL_Fweights_test.csv\"\n",
    "                                         ))\n",
    "Fweights_test=Fweights_OOS_df[load_df.columns[data_columns]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train deep feed forward networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Updated 6th Jan 2021 (Edited Line 71 to Line 72. Reduce_mean instead of mean, to preserve the required rank)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "epsilon=K.epsilon\n",
    "\n",
    "def get_weights_dicts(Y):\n",
    "    weights_dicts=[]\n",
    "    for j in range(Y.shape[1]):\n",
    "        weight_zero, weight_one = _get_label_weights(Y[:,j])\n",
    "        d={'weight_zero':weight_zero,\n",
    "           'weight_one':weight_one\n",
    "          }\n",
    "        weights_dicts.append(d)\n",
    "    return weights_dicts\n",
    "def _get_label_weights(y):\n",
    "    #Get label weights for majority and minority class using the following:\n",
    "        #major_weight=n/(n_major*2)\n",
    "        #minor_weight=n*(n_major/n_minor)/(n_major*2)\n",
    "        #NaN weights are set to zero\n",
    "    y1=y[~np.isnan(y)]\n",
    "    n=len(y1)\n",
    "    n_zero=np.count_nonzero(np.isclose(y1,0))\n",
    "    n_one=np.count_nonzero(np.isclose(y1,1))\n",
    "    if n_zero>n_one:\n",
    "        weight_zero=n/(n_zero*2)\n",
    "        weight_one=n*(n_zero/n_one)/(n_zero*2)\n",
    "    else:\n",
    "        weight_zero=n*(n_one/n_zero)/(n_one*2)\n",
    "        weight_one=n/(n_one*2)\n",
    "    return weight_zero, weight_one    \n",
    "\n",
    "class BinaryCrossEntropyIgnoreNaN(tf.keras.losses.Loss):\n",
    "    def __init__(self, weights_dicts=None, axis=0, **kwargs):\n",
    "        super(BinaryCrossEntropyIgnoreNaN, self).__init__(**kwargs)\n",
    "        self.weights_dicts=weights_dicts\n",
    "        self.axis=axis        \n",
    "\n",
    "    def __call__(self, target, output, sample_weight=None):\n",
    "        #Binary cross entropy that ignores Nan and replaces with mini-batch Nan with 0\n",
    "        #modified from tf.python.keras.backend.binary_crossentropy\n",
    "        \n",
    "        ##NEED TO TEST THIS CODE MORE THOROUGHLY\n",
    "        target=tf.convert_to_tensor(target)\n",
    "        output=tf.convert_to_tensor(output)\n",
    "        if len(target.shape)==1:\n",
    "            target=tf.expand_dims(target, 1)\n",
    "            output=tf.expand_dims(output, 1)\n",
    "        epsilon_ = tf.constant(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output=tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "\n",
    "        #Compute cross entropy from probabilities\n",
    "        bce=target * tf.math.log(output+epsilon_)\n",
    "        bce+=(1-target)* tf.math.log(1-output+epsilon_)\n",
    "\n",
    "        bce=tf.where(tf.math.is_nan(-bce), epsilon(), -bce)\n",
    "        if self.weights_dicts is not None:\n",
    "            sample_weight=tf.cast(tf.where(target==0.,1.,0.)*[self.weights_dicts[i]['weight_zero'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            sample_weight+=tf.cast(tf.where(target==1., 1., 0.)*[self.weights_dicts[i]['weight_one'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            bce=tf.multiply(sample_weight, bce)\n",
    "#         return tf.keras.backend.mean(bce, axis=self.axis)  \n",
    "        return tf.math.reduce_mean(bce)\n",
    "\n",
    "    def call(self, target, output, sample_weight=None):\n",
    "        return self(target, output, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label='NR-AR'\n",
    "\n",
    "train_inds=~np.isnan(y_train[label])\n",
    "test_inds=~np.isnan(y_test[label])\n",
    "\n",
    "train_data=X_train[train_inds,:]\n",
    "train_targets=y_train[label][train_inds].astype(np.float32)\n",
    "test_data=X_test[test_inds,:]\n",
    "test_targets=y_test[label][test_inds].astype(np.float32)\n",
    "#train_Fweights\n",
    "#test_Fweights\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Temporarily use this file first. \n",
    "#There are fewer chemicals in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_folder=os.path.join(\"ARE_v2\"\n",
    "                        )\n",
    "\n",
    "#Load Tox21 processed data (ARE)\n",
    "processed_data_df=pd.read_csv(os.path.join(load_folder, \n",
    "                                           \"Tox21_CDKPaDEL_processedData_AREv2.csv\"\n",
    "                                          ), index_col=0\n",
    "                             )\n",
    "label_ind=processed_data_df.shape[1]-2 \n",
    "\n",
    "feat_ind=range(processed_data_df.shape[1]-2)\n",
    "\n",
    "X_train_ARE2=(processed_data_df.query(\"Type=='Training'\")\n",
    "             .iloc[:,feat_ind]).values\n",
    "X_test_ARE2=(processed_data_df.query(\"Type=='Testing'\")\n",
    "            .iloc[:,feat_ind]).values\n",
    "y_train_ARE2=(processed_data_df.query(\"Type=='Training'\")\n",
    "             .iloc[:,label_ind]).values\n",
    "y_test_ARE2=(processed_data_df.query(\"Type=='Testing'\")\n",
    "            .iloc[:,label_ind]).values\n",
    "\n",
    "#Load COSA feature weights and distances for Tox21 processed data (ARE)\n",
    "Fweights_train_df=pd.read_csv(os.path.join(load_folder,\n",
    "                                     \"Tox21_CDKPaDEL_Fweights_ARE_train2.csv\",                                 \n",
    "                                    )\n",
    "                       )\n",
    "Fweights_train=Fweights_train_df.iloc[:,:-1].values\n",
    "\n",
    "\n",
    "Fweights_test_df=pd.read_csv(os.path.join(load_folder, \n",
    "                                          \"Tox21_CDKPaDEL_FweightsOOS_ARE_test2.csv\"\n",
    "                                         ))\n",
    "Fweights_test=Fweights_test_df.iloc[:,:-1]\n",
    "\n",
    "# temp_ind=Fweights_df['ind']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingDeep'\n",
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingDeep\\\\Dense_NR-AR'\n"
     ]
    }
   ],
   "source": [
    "# n_feat = train_data.shape[1]\n",
    "# n_attention = 20 #Reduced from 20 to 10. 10 works better\n",
    "# n_attention_hidden=20\n",
    "# n_attention_out=1\n",
    "# n_concat_hidden=2048\n",
    "# n_hidden1 =512\n",
    "# n_hidden2 = 64 #Added 2nd hidden layer\n",
    "# momentum=0.8\n",
    "# learning_rate=0.001\n",
    "\n",
    "# n_batch=32\n",
    "\n",
    "n_feat = train_tensor.shape[1]\n",
    "n_attention = 20 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=20\n",
    "n_attention_out=1\n",
    "n_concat_hidden=4096\n",
    "n_hidden1 =1024\n",
    "n_hidden2 = 128 #Added 2nd hidden layer\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=32\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingDeep\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"Dense_{}\".format(label),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dense_model=Sequential()\n",
    "dense_model.add(Dense(n_attention*n_attention_hidden, \n",
    "                      activation=\"gelu\",\n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5),\n",
    "#                  input_shape=(n_feat,),\n",
    "                ))\n",
    "dense_model.add(Dropout(0.1))\n",
    "dense_model.add(Dense(n_attention*n_feat, activation=\"gelu\",\n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5),\n",
    "                     ))\n",
    "# dense_model.add(LeakyReLU())\n",
    "dense_model.add(Dense(n_concat_hidden, activation=\"gelu\",  \n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5),   \n",
    "#                       activity_regularizer=l1(1E-5)                      \n",
    "                     ))\n",
    "# dense_model.add(LeakyReLU())\n",
    "dense_model.add(Dropout(0.1))\n",
    "dense_model.add(Dense(n_hidden1, activation=\"gelu\",\n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5),\n",
    "                     ))\n",
    "# dense_model.add(LeakyReLU())\n",
    "dense_model.add(Dropout(0.1))\n",
    "dense_model.add(Dense(n_hidden2, activation=\"gelu\",\n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5),\n",
    "                     ))\n",
    "# dense_model.add(LeakyReLU())\n",
    "dense_model.add(Dropout(0.1))\n",
    "dense_model.add(Dense(1, activation=\"sigmoid\",\n",
    "                      kernel_initializer=VarianceScaling(),\n",
    "                      kernel_regularizer=l1(1E-5),\n",
    "                      bias_regularizer=l1(1E-5)\n",
    "                     ))\n",
    "\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "dense_model.compile(tf.optimizers.Adam(learning_rate=learning_rate,),\n",
    "                   loss=loss_fn, \n",
    "                    metrics=['accuracy', 'AUC'],\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "292/292 - 8s - loss: 3.6190 - accuracy: 0.7750 - auc: 0.7640 - val_loss: 1.7328 - val_accuracy: 0.9009 - val_auc: 0.6670\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.66704, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 2/100\n",
      "292/292 - 6s - loss: 1.2129 - accuracy: 0.9214 - auc: 0.7988 - val_loss: 0.8358 - val_accuracy: 0.9635 - val_auc: 0.6767\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.66704 to 0.67673, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 3/100\n",
      "292/292 - 6s - loss: 0.8040 - accuracy: 0.8857 - auc: 0.8220 - val_loss: 0.6600 - val_accuracy: 0.9200 - val_auc: 0.6929\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.67673 to 0.69287, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 4/100\n",
      "292/292 - 7s - loss: 0.6567 - accuracy: 0.8992 - auc: 0.8352 - val_loss: 0.5816 - val_accuracy: 0.9496 - val_auc: 0.7131\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.69287 to 0.71307, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 5/100\n",
      "292/292 - 7s - loss: 0.6917 - accuracy: 0.8927 - auc: 0.8266 - val_loss: 0.6610 - val_accuracy: 0.7357 - val_auc: 0.7116\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.71307\n",
      "Epoch 6/100\n",
      "292/292 - 6s - loss: 0.6446 - accuracy: 0.8991 - auc: 0.8212 - val_loss: 0.5981 - val_accuracy: 0.8678 - val_auc: 0.7115\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.71307\n",
      "Epoch 7/100\n",
      "292/292 - 6s - loss: 0.5865 - accuracy: 0.8771 - auc: 0.8422 - val_loss: 0.5381 - val_accuracy: 0.9026 - val_auc: 0.7067\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.71307\n",
      "Epoch 8/100\n",
      "292/292 - 6s - loss: 0.6900 - accuracy: 0.8837 - auc: 0.8270 - val_loss: 0.5782 - val_accuracy: 0.9113 - val_auc: 0.7325\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.71307 to 0.73253, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 9/100\n",
      "292/292 - 6s - loss: 0.6004 - accuracy: 0.8987 - auc: 0.8432 - val_loss: 0.5383 - val_accuracy: 0.9704 - val_auc: 0.7090\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.73253\n",
      "Epoch 10/100\n",
      "292/292 - 6s - loss: 0.5615 - accuracy: 0.8969 - auc: 0.8437 - val_loss: 0.5382 - val_accuracy: 0.9670 - val_auc: 0.5949\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.73253\n",
      "Epoch 11/100\n",
      "292/292 - 6s - loss: 0.5426 - accuracy: 0.9128 - auc: 0.8424 - val_loss: 0.5257 - val_accuracy: 0.9513 - val_auc: 0.6499\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.73253\n",
      "Epoch 12/100\n",
      "292/292 - 6s - loss: 0.5335 - accuracy: 0.9196 - auc: 0.8531 - val_loss: 0.6715 - val_accuracy: 0.6174 - val_auc: 0.7373\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.73253 to 0.73734, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 13/100\n",
      "292/292 - 6s - loss: 0.5462 - accuracy: 0.9093 - auc: 0.8454 - val_loss: 0.4958 - val_accuracy: 0.9443 - val_auc: 0.7303\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.73734\n",
      "Epoch 14/100\n",
      "292/292 - 6s - loss: 0.5269 - accuracy: 0.8904 - auc: 0.8530 - val_loss: 0.4970 - val_accuracy: 0.9670 - val_auc: 0.7251\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.73734\n",
      "Epoch 15/100\n",
      "292/292 - 6s - loss: 0.5176 - accuracy: 0.8731 - auc: 0.8593 - val_loss: 0.5533 - val_accuracy: 0.5913 - val_auc: 0.7137\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.73734\n",
      "Epoch 16/100\n",
      "292/292 - 6s - loss: 0.6241 - accuracy: 0.8856 - auc: 0.8352 - val_loss: 0.5852 - val_accuracy: 0.9200 - val_auc: 0.7167\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.73734\n",
      "Epoch 17/100\n",
      "292/292 - 6s - loss: 0.6418 - accuracy: 0.8830 - auc: 0.8460 - val_loss: 1.8254 - val_accuracy: 0.7217 - val_auc: 0.7007\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.73734\n",
      "Epoch 18/100\n",
      "292/292 - 6s - loss: 0.8483 - accuracy: 0.8677 - auc: 0.8388 - val_loss: 0.9714 - val_accuracy: 0.7009 - val_auc: 0.7448\n",
      "\n",
      "Epoch 00018: val_auc improved from 0.73734 to 0.74482, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 19/100\n",
      "292/292 - 6s - loss: 0.7536 - accuracy: 0.8595 - auc: 0.8435 - val_loss: 0.7408 - val_accuracy: 0.9739 - val_auc: 0.7356\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.74482\n",
      "Epoch 20/100\n",
      "292/292 - 6s - loss: 0.6557 - accuracy: 0.9056 - auc: 0.8343 - val_loss: 0.5841 - val_accuracy: 0.8991 - val_auc: 0.7006\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.74482\n",
      "Epoch 21/100\n",
      "292/292 - 6s - loss: 0.6177 - accuracy: 0.8804 - auc: 0.8368 - val_loss: 0.5784 - val_accuracy: 0.9235 - val_auc: 0.6072\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.74482\n",
      "Epoch 22/100\n",
      "292/292 - 6s - loss: 0.5823 - accuracy: 0.8989 - auc: 0.8447 - val_loss: 0.5375 - val_accuracy: 0.9287 - val_auc: 0.7076\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.74482\n",
      "Epoch 23/100\n",
      "292/292 - 6s - loss: 0.5679 - accuracy: 0.8990 - auc: 0.8498 - val_loss: 0.5692 - val_accuracy: 0.9478 - val_auc: 0.7072\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.74482\n",
      "Epoch 24/100\n",
      "292/292 - 6s - loss: 0.6256 - accuracy: 0.8881 - auc: 0.8580 - val_loss: 1.1001 - val_accuracy: 0.9774 - val_auc: 0.7342\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.74482\n",
      "Epoch 25/100\n",
      "292/292 - 6s - loss: 0.8388 - accuracy: 0.8341 - auc: 0.8330 - val_loss: 0.7405 - val_accuracy: 0.9357 - val_auc: 0.7214\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.74482\n",
      "Epoch 26/100\n",
      "292/292 - 6s - loss: 0.6927 - accuracy: 0.8863 - auc: 0.8422 - val_loss: 0.6671 - val_accuracy: 0.8678 - val_auc: 0.6680\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.74482\n",
      "Epoch 27/100\n",
      "292/292 - 6s - loss: 0.5999 - accuracy: 0.8829 - auc: 0.8621 - val_loss: 0.5651 - val_accuracy: 0.9687 - val_auc: 0.6456\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.74482\n",
      "Epoch 28/100\n",
      "292/292 - 6s - loss: 0.6291 - accuracy: 0.9056 - auc: 0.8454 - val_loss: 0.5505 - val_accuracy: 0.9478 - val_auc: 0.7663\n",
      "\n",
      "Epoch 00028: val_auc improved from 0.74482 to 0.76628, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 29/100\n",
      "292/292 - 6s - loss: 0.5693 - accuracy: 0.9036 - auc: 0.8544 - val_loss: 0.8039 - val_accuracy: 0.9757 - val_auc: 0.6174\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.76628\n",
      "Epoch 30/100\n",
      "292/292 - 6s - loss: 0.6352 - accuracy: 0.9018 - auc: 0.8470 - val_loss: 0.5931 - val_accuracy: 0.8417 - val_auc: 0.7259\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.76628\n",
      "Epoch 31/100\n",
      "292/292 - 6s - loss: 0.5347 - accuracy: 0.9192 - auc: 0.8599 - val_loss: 0.5841 - val_accuracy: 0.8122 - val_auc: 0.7208\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.76628\n",
      "Epoch 32/100\n",
      "292/292 - 6s - loss: 0.6093 - accuracy: 0.8968 - auc: 0.8381 - val_loss: 0.5205 - val_accuracy: 0.9200 - val_auc: 0.7565\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.76628\n",
      "Epoch 33/100\n",
      "292/292 - 6s - loss: 0.5286 - accuracy: 0.9063 - auc: 0.8723 - val_loss: 0.5576 - val_accuracy: 0.9026 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.76628\n",
      "Epoch 34/100\n",
      "292/292 - 6s - loss: 0.5860 - accuracy: 0.9026 - auc: 0.8349 - val_loss: 0.5500 - val_accuracy: 0.8487 - val_auc: 0.6839\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.76628\n",
      "Epoch 35/100\n",
      "292/292 - 6s - loss: 0.5224 - accuracy: 0.8907 - auc: 0.8618 - val_loss: 0.5451 - val_accuracy: 0.8017 - val_auc: 0.7325\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.76628\n",
      "Epoch 36/100\n",
      "292/292 - 6s - loss: 0.5266 - accuracy: 0.8818 - auc: 0.8678 - val_loss: 0.7413 - val_accuracy: 0.5739 - val_auc: 0.7463\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.76628\n",
      "Epoch 37/100\n",
      "292/292 - 6s - loss: 0.6386 - accuracy: 0.9103 - auc: 0.8533 - val_loss: 0.5261 - val_accuracy: 0.9583 - val_auc: 0.7262\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.76628\n",
      "Epoch 38/100\n",
      "292/292 - 6s - loss: 0.5286 - accuracy: 0.9169 - auc: 0.8594 - val_loss: 0.5416 - val_accuracy: 0.9722 - val_auc: 0.6889\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.76628\n",
      "Epoch 39/100\n",
      "292/292 - 6s - loss: 0.5187 - accuracy: 0.9090 - auc: 0.8609 - val_loss: 0.4999 - val_accuracy: 0.9496 - val_auc: 0.7460\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.76628\n",
      "Epoch 40/100\n",
      "292/292 - 6s - loss: 0.5678 - accuracy: 0.9036 - auc: 0.8659 - val_loss: 0.6127 - val_accuracy: 0.8313 - val_auc: 0.7423\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.76628\n",
      "Epoch 41/100\n",
      "292/292 - 6s - loss: 0.5983 - accuracy: 0.9034 - auc: 0.8608 - val_loss: 0.5536 - val_accuracy: 0.9304 - val_auc: 0.7033\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.76628\n",
      "Epoch 42/100\n",
      "292/292 - 6s - loss: 0.6403 - accuracy: 0.8921 - auc: 0.8673 - val_loss: 0.6289 - val_accuracy: 0.9739 - val_auc: 0.7920\n",
      "\n",
      "Epoch 00042: val_auc improved from 0.76628 to 0.79204, saving model to 210120_TrainingDeep\\Dense_NR-AR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "292/292 - 6s - loss: 0.5706 - accuracy: 0.9078 - auc: 0.8721 - val_loss: 0.5181 - val_accuracy: 0.9374 - val_auc: 0.7285\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.79204\n",
      "Epoch 44/100\n",
      "292/292 - 6s - loss: 0.5129 - accuracy: 0.9098 - auc: 0.8751 - val_loss: 0.6038 - val_accuracy: 0.8365 - val_auc: 0.7448\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.79204\n",
      "Epoch 45/100\n",
      "292/292 - 6s - loss: 0.5392 - accuracy: 0.9018 - auc: 0.8772 - val_loss: 0.5358 - val_accuracy: 0.9113 - val_auc: 0.7388\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.79204\n",
      "Epoch 46/100\n",
      "292/292 - 7s - loss: 0.6074 - accuracy: 0.8923 - auc: 0.8663 - val_loss: 1.3972 - val_accuracy: 0.8817 - val_auc: 0.7557\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.79204\n",
      "Epoch 47/100\n",
      "292/292 - 7s - loss: 0.9042 - accuracy: 0.8627 - auc: 0.8415 - val_loss: 0.6388 - val_accuracy: 0.9687 - val_auc: 0.6503\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.79204\n",
      "Epoch 48/100\n",
      "292/292 - 7s - loss: 0.6723 - accuracy: 0.9099 - auc: 0.8713 - val_loss: 0.7127 - val_accuracy: 0.8000 - val_auc: 0.6865\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.79204\n",
      "Epoch 49/100\n",
      "292/292 - 6s - loss: 0.6001 - accuracy: 0.8932 - auc: 0.8830 - val_loss: 0.7302 - val_accuracy: 0.9548 - val_auc: 0.6932\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.79204\n",
      "Epoch 50/100\n",
      "292/292 - 6s - loss: 0.7340 - accuracy: 0.8924 - auc: 0.8473 - val_loss: 0.7646 - val_accuracy: 0.8174 - val_auc: 0.7556\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.79204\n",
      "Epoch 51/100\n",
      "292/292 - 7s - loss: 0.6840 - accuracy: 0.8841 - auc: 0.8681 - val_loss: 0.8030 - val_accuracy: 0.9409 - val_auc: 0.6870\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.79204\n",
      "Epoch 52/100\n",
      "292/292 - 6s - loss: 0.6574 - accuracy: 0.9064 - auc: 0.8645 - val_loss: 0.6978 - val_accuracy: 0.4174 - val_auc: 0.6205\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.79204\n",
      "Epoch 53/100\n",
      "292/292 - 6s - loss: 0.6058 - accuracy: 0.9022 - auc: 0.8767 - val_loss: 0.6782 - val_accuracy: 0.9583 - val_auc: 0.6782\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.79204\n",
      "Epoch 54/100\n",
      "292/292 - 6s - loss: 0.6248 - accuracy: 0.9129 - auc: 0.8885 - val_loss: 0.5743 - val_accuracy: 0.8922 - val_auc: 0.6806\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.79204\n",
      "Epoch 55/100\n",
      "292/292 - 6s - loss: 0.5938 - accuracy: 0.8927 - auc: 0.8830 - val_loss: 0.5768 - val_accuracy: 0.9235 - val_auc: 0.6870\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.79204\n",
      "Epoch 56/100\n",
      "292/292 - 7s - loss: 0.5426 - accuracy: 0.9013 - auc: 0.8790 - val_loss: 0.5303 - val_accuracy: 0.8991 - val_auc: 0.7161\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.79204\n",
      "Epoch 57/100\n",
      "292/292 - 6s - loss: 0.4794 - accuracy: 0.9112 - auc: 0.8942 - val_loss: 0.5183 - val_accuracy: 0.9339 - val_auc: 0.6978\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.79204\n",
      "Epoch 58/100\n",
      "292/292 - 6s - loss: 0.5308 - accuracy: 0.9179 - auc: 0.8700 - val_loss: 0.5626 - val_accuracy: 0.8591 - val_auc: 0.6679\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.79204\n",
      "Epoch 59/100\n",
      "292/292 - 7s - loss: 0.5340 - accuracy: 0.9102 - auc: 0.8820 - val_loss: 0.5379 - val_accuracy: 0.9026 - val_auc: 0.7199\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.79204\n",
      "Epoch 60/100\n",
      "292/292 - 6s - loss: 0.4831 - accuracy: 0.9092 - auc: 0.8975 - val_loss: 0.5424 - val_accuracy: 0.9652 - val_auc: 0.6963\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.79204\n",
      "Epoch 61/100\n",
      "292/292 - 6s - loss: 0.5245 - accuracy: 0.9173 - auc: 0.8828 - val_loss: 0.5164 - val_accuracy: 0.8522 - val_auc: 0.7416\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.79204\n",
      "Epoch 62/100\n",
      "292/292 - 7s - loss: 0.5105 - accuracy: 0.8983 - auc: 0.8900 - val_loss: 0.5298 - val_accuracy: 0.9670 - val_auc: 0.7246\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.79204\n",
      "Epoch 63/100\n",
      "292/292 - 7s - loss: 0.5787 - accuracy: 0.9034 - auc: 0.8765 - val_loss: 0.6178 - val_accuracy: 0.9096 - val_auc: 0.8449\n",
      "\n",
      "Epoch 00063: val_auc improved from 0.79204 to 0.84488, saving model to 210120_TrainingDeep\\Dense_NR-AR\n",
      "Epoch 64/100\n",
      "292/292 - 6s - loss: 0.5516 - accuracy: 0.8928 - auc: 0.8948 - val_loss: 0.5452 - val_accuracy: 0.8713 - val_auc: 0.7284\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.84488\n",
      "Epoch 65/100\n",
      "292/292 - 6s - loss: 0.5650 - accuracy: 0.8855 - auc: 0.8771 - val_loss: 0.6599 - val_accuracy: 0.9687 - val_auc: 0.7536\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.84488\n",
      "Epoch 66/100\n",
      "292/292 - 6s - loss: 0.5600 - accuracy: 0.9057 - auc: 0.8807 - val_loss: 0.8463 - val_accuracy: 0.5339 - val_auc: 0.7817\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.84488\n",
      "Epoch 67/100\n",
      "292/292 - 6s - loss: 0.5133 - accuracy: 0.9074 - auc: 0.8852 - val_loss: 0.5266 - val_accuracy: 0.8365 - val_auc: 0.7262\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.84488\n",
      "Epoch 68/100\n",
      "292/292 - 7s - loss: 0.4558 - accuracy: 0.9094 - auc: 0.9052 - val_loss: 0.5216 - val_accuracy: 0.9270 - val_auc: 0.6915\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.84488\n",
      "Epoch 69/100\n",
      "292/292 - 7s - loss: 0.4657 - accuracy: 0.9053 - auc: 0.8995 - val_loss: 0.5025 - val_accuracy: 0.9096 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.84488\n",
      "Epoch 70/100\n",
      "292/292 - 7s - loss: 0.4414 - accuracy: 0.9154 - auc: 0.9045 - val_loss: 0.5338 - val_accuracy: 0.8157 - val_auc: 0.7284\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.84488\n",
      "Epoch 71/100\n",
      "292/292 - 6s - loss: 0.4646 - accuracy: 0.9090 - auc: 0.8963 - val_loss: 0.5157 - val_accuracy: 0.8991 - val_auc: 0.7036\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.84488\n",
      "Epoch 72/100\n",
      "292/292 - 6s - loss: 0.4597 - accuracy: 0.9088 - auc: 0.9068 - val_loss: 0.5474 - val_accuracy: 0.7861 - val_auc: 0.7113\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.84488\n",
      "Epoch 73/100\n",
      "292/292 - 6s - loss: 0.5298 - accuracy: 0.8932 - auc: 0.8840 - val_loss: 0.5855 - val_accuracy: 0.9600 - val_auc: 0.6630\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.84488\n",
      "Epoch 74/100\n",
      "292/292 - 7s - loss: 0.6669 - accuracy: 0.8830 - auc: 0.8846 - val_loss: 0.7201 - val_accuracy: 0.9774 - val_auc: 0.7761\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.84488\n",
      "Epoch 75/100\n",
      "292/292 - 6s - loss: 0.6457 - accuracy: 0.9158 - auc: 0.8634 - val_loss: 0.5619 - val_accuracy: 0.8817 - val_auc: 0.7043\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.84488\n",
      "Epoch 76/100\n",
      "292/292 - 6s - loss: 0.6033 - accuracy: 0.9086 - auc: 0.8775 - val_loss: 0.5764 - val_accuracy: 0.9009 - val_auc: 0.7123\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.84488\n",
      "Epoch 77/100\n",
      "292/292 - 6s - loss: 0.5149 - accuracy: 0.9138 - auc: 0.9022 - val_loss: 0.5491 - val_accuracy: 0.8522 - val_auc: 0.7086\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.84488\n",
      "Epoch 78/100\n",
      "292/292 - 6s - loss: 0.4671 - accuracy: 0.9167 - auc: 0.8981 - val_loss: 0.5301 - val_accuracy: 0.8626 - val_auc: 0.7468\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.84488\n",
      "Epoch 79/100\n",
      "292/292 - 7s - loss: 0.4596 - accuracy: 0.9166 - auc: 0.9081 - val_loss: 0.4989 - val_accuracy: 0.8800 - val_auc: 0.7481\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.84488\n",
      "Epoch 80/100\n",
      "292/292 - 7s - loss: 0.4804 - accuracy: 0.9301 - auc: 0.8971 - val_loss: 0.5554 - val_accuracy: 0.9739 - val_auc: 0.6672\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.84488\n",
      "Epoch 81/100\n",
      "292/292 - 6s - loss: 0.5113 - accuracy: 0.9238 - auc: 0.8945 - val_loss: 0.5081 - val_accuracy: 0.9200 - val_auc: 0.6952\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.84488\n",
      "Epoch 82/100\n",
      "292/292 - 6s - loss: 0.5367 - accuracy: 0.9280 - auc: 0.8741 - val_loss: 0.5714 - val_accuracy: 0.8957 - val_auc: 0.7162\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.84488\n",
      "Epoch 83/100\n",
      "292/292 - 7s - loss: 0.4949 - accuracy: 0.9176 - auc: 0.9026 - val_loss: 0.5167 - val_accuracy: 0.9235 - val_auc: 0.7186\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.84488\n",
      "Epoch 84/100\n",
      "292/292 - 6s - loss: 0.4861 - accuracy: 0.9204 - auc: 0.9078 - val_loss: 0.5607 - val_accuracy: 0.8661 - val_auc: 0.6960\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.84488\n",
      "Epoch 85/100\n",
      "292/292 - 6s - loss: 0.5499 - accuracy: 0.9124 - auc: 0.8948 - val_loss: 0.5827 - val_accuracy: 0.8400 - val_auc: 0.7390\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.84488\n",
      "Epoch 86/100\n",
      "292/292 - 6s - loss: 0.5343 - accuracy: 0.9090 - auc: 0.8935 - val_loss: 0.6718 - val_accuracy: 0.7096 - val_auc: 0.6265\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.84488\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 - 6s - loss: 0.5357 - accuracy: 0.8950 - auc: 0.8990 - val_loss: 0.5362 - val_accuracy: 0.8870 - val_auc: 0.7420\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.84488\n",
      "Epoch 88/100\n",
      "292/292 - 6s - loss: 0.5020 - accuracy: 0.9074 - auc: 0.9066 - val_loss: 0.6150 - val_accuracy: 0.9496 - val_auc: 0.7490\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.84488\n",
      "Epoch 89/100\n",
      "292/292 - 6s - loss: 0.5532 - accuracy: 0.9305 - auc: 0.8829 - val_loss: 0.5763 - val_accuracy: 0.9374 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.84488\n",
      "Epoch 90/100\n",
      "292/292 - 6s - loss: 0.5193 - accuracy: 0.9069 - auc: 0.9118 - val_loss: 0.5677 - val_accuracy: 0.9391 - val_auc: 0.7297\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.84488\n",
      "Epoch 91/100\n",
      "292/292 - 7s - loss: 0.5012 - accuracy: 0.9140 - auc: 0.9178 - val_loss: 0.5172 - val_accuracy: 0.9548 - val_auc: 0.7080\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.84488\n",
      "Epoch 92/100\n",
      "292/292 - 7s - loss: 0.7062 - accuracy: 0.9060 - auc: 0.9017 - val_loss: 0.6335 - val_accuracy: 0.9409 - val_auc: 0.6659\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.84488\n",
      "Epoch 93/100\n",
      "292/292 - 7s - loss: 0.5417 - accuracy: 0.9219 - auc: 0.9028 - val_loss: 0.6331 - val_accuracy: 0.9809 - val_auc: 0.5817\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.84488\n",
      "Epoch 94/100\n",
      "292/292 - 7s - loss: 0.5308 - accuracy: 0.9256 - auc: 0.8995 - val_loss: 0.6035 - val_accuracy: 0.8696 - val_auc: 0.7595\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.84488\n",
      "Epoch 95/100\n",
      "292/292 - 7s - loss: 0.4728 - accuracy: 0.9197 - auc: 0.9121 - val_loss: 0.4864 - val_accuracy: 0.9217 - val_auc: 0.7403\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.84488\n",
      "Epoch 96/100\n",
      "292/292 - 7s - loss: 0.4609 - accuracy: 0.9295 - auc: 0.9014 - val_loss: 0.5018 - val_accuracy: 0.9513 - val_auc: 0.7177\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.84488\n",
      "Epoch 97/100\n",
      "292/292 - 7s - loss: 0.4791 - accuracy: 0.9207 - auc: 0.9096 - val_loss: 0.5332 - val_accuracy: 0.9635 - val_auc: 0.7390\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.84488\n",
      "Epoch 98/100\n",
      "292/292 - 7s - loss: 0.5012 - accuracy: 0.9205 - auc: 0.9071 - val_loss: 0.5496 - val_accuracy: 0.9583 - val_auc: 0.6388\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.84488\n",
      "Epoch 99/100\n",
      "292/292 - 7s - loss: 0.4987 - accuracy: 0.9121 - auc: 0.9115 - val_loss: 0.5497 - val_accuracy: 0.9357 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.84488\n",
      "Epoch 100/100\n",
      "292/292 - 7s - loss: 0.4749 - accuracy: 0.9123 - auc: 0.9148 - val_loss: 0.6064 - val_accuracy: 0.9687 - val_auc: 0.6968\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.84488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be874e0520>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_auc',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "\n",
    "n_epoch=100\n",
    "\n",
    "dense_model.fit(train_data,\n",
    "                train_targets,\n",
    "                epochs=n_epoch, \n",
    "                batch_size=n_batch, \n",
    "                validation_data=(test_data, test_targets),\n",
    "                verbose=2,\n",
    "                shuffle=True,\n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop training for all single-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(weights_dicts,\n",
    "                     n_attention=n_attention, \n",
    "                     n_attention_hidden=n_attention_hidden, \n",
    "                     n_feat=n_feat,\n",
    "                     n_concat_hidden=n_concat_hidden,\n",
    "                     n_hidden1=n_hidden1, \n",
    "                     n_hidden2=n_hidden2,\n",
    "                    ):\n",
    "    dense_model=Sequential()\n",
    "    dense_model.add(Dense(n_attention*n_attention_hidden, \n",
    "                          activation=\"gelu\",\n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5),\n",
    "    #                  input_shape=(n_feat,),\n",
    "                    ))\n",
    "    dense_model.add(Dense(n_attention*n_feat*n_attention_out, activation=\"gelu\",\n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5),\n",
    "                         ))\n",
    "    # dense_model.add(LeakyReLU())\n",
    "    dense_model.add(Dense(n_concat_hidden, activation=\"gelu\",  \n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5),   \n",
    "    #                       activity_regularizer=l1(1E-5)                      \n",
    "                         ))\n",
    "    # dense_model.add(LeakyReLU())\n",
    "    dense_model.add(Dropout(0.1))\n",
    "    dense_model.add(Dense(n_hidden1, activation=\"gelu\",\n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5),\n",
    "                         ))\n",
    "    # dense_model.add(LeakyReLU())\n",
    "    dense_model.add(Dropout(0.1))\n",
    "    dense_model.add(Dense(n_hidden2, activation=\"gelu\",\n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5),\n",
    "                         ))\n",
    "    # dense_model.add(LeakyReLU())\n",
    "    dense_model.add(Dropout(0.1))\n",
    "    dense_model.add(Dense(1, activation=\"sigmoid\",\n",
    "                          kernel_initializer=VarianceScaling(),\n",
    "                          kernel_regularizer=l1(1E-5),\n",
    "                          bias_regularizer=l1(1E-5)\n",
    "                         ))\n",
    "\n",
    "    loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "    dense_model.compile(tf.optimizers.Adam(learning_rate=learning_rate,),\n",
    "                       loss=loss_fn, \n",
    "                        metrics=['accuracy', 'AUC'],\n",
    "                  )\n",
    "    return dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingDeep\\\\210120_Dense_NR-AR'\n",
      "Epoch 1/100\n",
      "292/292 - 9s - loss: 4.3231 - accuracy: 0.7380 - auc: 0.7148 - val_loss: 2.4061 - val_accuracy: 0.9565 - val_auc: 0.6796\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.67962, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 2/100\n",
      "292/292 - 7s - loss: 1.7785 - accuracy: 0.8925 - auc: 0.8014 - val_loss: 1.2416 - val_accuracy: 0.9722 - val_auc: 0.7288\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.67962 to 0.72876, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 3/100\n",
      "292/292 - 7s - loss: 1.0809 - accuracy: 0.9184 - auc: 0.8234 - val_loss: 0.8635 - val_accuracy: 0.9722 - val_auc: 0.7126\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.72876\n",
      "Epoch 4/100\n",
      "292/292 - 7s - loss: 0.8160 - accuracy: 0.9388 - auc: 0.8261 - val_loss: 0.7276 - val_accuracy: 0.9722 - val_auc: 0.7349\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.72876 to 0.73490, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 5/100\n",
      "292/292 - 7s - loss: 0.7098 - accuracy: 0.9367 - auc: 0.8170 - val_loss: 0.6412 - val_accuracy: 0.8835 - val_auc: 0.7360\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.73490 to 0.73601, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 6/100\n",
      "292/292 - 7s - loss: 0.6267 - accuracy: 0.9212 - auc: 0.8512 - val_loss: 0.6215 - val_accuracy: 0.9739 - val_auc: 0.5071\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.73601\n",
      "Epoch 7/100\n",
      "292/292 - 7s - loss: 0.6623 - accuracy: 0.8956 - auc: 0.8245 - val_loss: 0.6069 - val_accuracy: 0.9600 - val_auc: 0.7106\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.73601\n",
      "Epoch 8/100\n",
      "292/292 - 7s - loss: 0.5924 - accuracy: 0.9290 - auc: 0.8382 - val_loss: 0.5965 - val_accuracy: 0.6904 - val_auc: 0.7155\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.73601\n",
      "Epoch 9/100\n",
      "292/292 - 7s - loss: 0.5715 - accuracy: 0.8907 - auc: 0.8415 - val_loss: 0.5283 - val_accuracy: 0.9600 - val_auc: 0.7259\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.73601\n",
      "Epoch 10/100\n",
      "292/292 - 7s - loss: 0.5503 - accuracy: 0.9013 - auc: 0.8508 - val_loss: 0.5365 - val_accuracy: 0.8609 - val_auc: 0.7396\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.73601 to 0.73964, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 11/100\n",
      "292/292 - 7s - loss: 0.5421 - accuracy: 0.8871 - auc: 0.8524 - val_loss: 0.5083 - val_accuracy: 0.9339 - val_auc: 0.7320\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.73964\n",
      "Epoch 12/100\n",
      "292/292 - 7s - loss: 0.5336 - accuracy: 0.9134 - auc: 0.8490 - val_loss: 0.5103 - val_accuracy: 0.9287 - val_auc: 0.7185\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.73964\n",
      "Epoch 13/100\n",
      "292/292 - 7s - loss: 0.5526 - accuracy: 0.9091 - auc: 0.8324 - val_loss: 0.5508 - val_accuracy: 0.9652 - val_auc: 0.6732\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.73964\n",
      "Epoch 14/100\n",
      "292/292 - 7s - loss: 0.5266 - accuracy: 0.9136 - auc: 0.8538 - val_loss: 0.5134 - val_accuracy: 0.9478 - val_auc: 0.7699\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.73964 to 0.76991, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 15/100\n",
      "292/292 - 7s - loss: 0.5531 - accuracy: 0.8938 - auc: 0.8568 - val_loss: 0.5969 - val_accuracy: 0.9148 - val_auc: 0.7240\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.76991\n",
      "Epoch 16/100\n",
      "292/292 - 7s - loss: 0.6063 - accuracy: 0.9066 - auc: 0.8327 - val_loss: 0.5185 - val_accuracy: 0.9704 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.76991\n",
      "Epoch 17/100\n",
      "292/292 - 7s - loss: 0.5272 - accuracy: 0.9210 - auc: 0.8546 - val_loss: 0.5114 - val_accuracy: 0.9530 - val_auc: 0.7061\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.76991\n",
      "Epoch 18/100\n",
      "292/292 - 7s - loss: 0.5157 - accuracy: 0.9274 - auc: 0.8522 - val_loss: 0.5253 - val_accuracy: 0.8452 - val_auc: 0.7612\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.76991\n",
      "Epoch 19/100\n",
      "292/292 - 7s - loss: 0.5108 - accuracy: 0.9088 - auc: 0.8631 - val_loss: 0.4844 - val_accuracy: 0.9357 - val_auc: 0.7638\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.76991\n",
      "Epoch 20/100\n",
      "292/292 - 7s - loss: 0.5074 - accuracy: 0.9035 - auc: 0.8658 - val_loss: 0.5034 - val_accuracy: 0.9774 - val_auc: 0.7360\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.76991\n",
      "Epoch 21/100\n",
      "292/292 - 7s - loss: 0.5137 - accuracy: 0.9086 - auc: 0.8562 - val_loss: 0.5070 - val_accuracy: 0.9443 - val_auc: 0.6981\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.76991\n",
      "Epoch 22/100\n",
      "292/292 - 7s - loss: 0.5054 - accuracy: 0.9022 - auc: 0.8669 - val_loss: 0.5137 - val_accuracy: 0.9461 - val_auc: 0.6955\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.76991\n",
      "Epoch 23/100\n",
      "292/292 - 7s - loss: 0.4950 - accuracy: 0.9033 - auc: 0.8675 - val_loss: 0.4932 - val_accuracy: 0.9409 - val_auc: 0.7444\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.76991\n",
      "Epoch 24/100\n",
      "292/292 - 7s - loss: 0.5060 - accuracy: 0.9119 - auc: 0.8648 - val_loss: 0.5053 - val_accuracy: 0.9565 - val_auc: 0.6576\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.76991\n",
      "Epoch 25/100\n",
      "292/292 - 7s - loss: 0.5186 - accuracy: 0.9126 - auc: 0.8698 - val_loss: 0.5186 - val_accuracy: 0.9391 - val_auc: 0.6801\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.76991\n",
      "Epoch 26/100\n",
      "292/292 - 7s - loss: 0.6208 - accuracy: 0.8840 - auc: 0.8525 - val_loss: 0.6213 - val_accuracy: 0.9774 - val_auc: 0.7510\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.76991\n",
      "Epoch 27/100\n",
      "292/292 - 7s - loss: 0.5492 - accuracy: 0.9185 - auc: 0.8615 - val_loss: 0.4996 - val_accuracy: 0.9009 - val_auc: 0.7744\n",
      "\n",
      "Epoch 00027: val_auc improved from 0.76991 to 0.77442, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 28/100\n",
      "292/292 - 7s - loss: 0.5173 - accuracy: 0.9086 - auc: 0.8671 - val_loss: 0.5826 - val_accuracy: 0.9774 - val_auc: 0.6701\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.77442\n",
      "Epoch 29/100\n",
      "292/292 - 7s - loss: 0.6844 - accuracy: 0.8905 - auc: 0.8541 - val_loss: 0.5398 - val_accuracy: 0.9548 - val_auc: 0.7200\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.77442\n",
      "Epoch 30/100\n",
      "292/292 - 7s - loss: 0.7805 - accuracy: 0.8795 - auc: 0.8640 - val_loss: 0.6461 - val_accuracy: 0.8609 - val_auc: 0.7645\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.77442\n",
      "Epoch 31/100\n",
      "292/292 - 7s - loss: 0.5451 - accuracy: 0.8916 - auc: 0.8809 - val_loss: 0.5526 - val_accuracy: 0.7652 - val_auc: 0.7361\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.77442\n",
      "Epoch 32/100\n",
      "292/292 - 7s - loss: 0.5163 - accuracy: 0.8970 - auc: 0.8732 - val_loss: 0.5348 - val_accuracy: 0.8383 - val_auc: 0.7100\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.77442\n",
      "Epoch 33/100\n",
      "292/292 - 7s - loss: 0.4878 - accuracy: 0.8835 - auc: 0.8918 - val_loss: 0.5297 - val_accuracy: 0.9061 - val_auc: 0.7158\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.77442\n",
      "Epoch 34/100\n",
      "292/292 - 7s - loss: 0.4838 - accuracy: 0.8833 - auc: 0.8876 - val_loss: 0.5242 - val_accuracy: 0.9183 - val_auc: 0.6644\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.77442\n",
      "Epoch 35/100\n",
      "292/292 - 7s - loss: 0.4687 - accuracy: 0.9028 - auc: 0.8956 - val_loss: 0.5237 - val_accuracy: 0.9061 - val_auc: 0.6662\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.77442\n",
      "Epoch 36/100\n",
      "292/292 - 7s - loss: 0.4929 - accuracy: 0.8809 - auc: 0.8929 - val_loss: 0.5194 - val_accuracy: 0.9270 - val_auc: 0.7373\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.77442\n",
      "Epoch 37/100\n",
      "292/292 - 7s - loss: 0.4716 - accuracy: 0.8875 - auc: 0.9010 - val_loss: 0.5030 - val_accuracy: 0.8904 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.77442\n",
      "Epoch 38/100\n",
      "292/292 - 7s - loss: 0.4642 - accuracy: 0.8989 - auc: 0.8992 - val_loss: 0.5029 - val_accuracy: 0.7861 - val_auc: 0.7727\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.77442\n",
      "Epoch 39/100\n",
      "292/292 - 7s - loss: 0.4933 - accuracy: 0.8827 - auc: 0.8984 - val_loss: 0.4986 - val_accuracy: 0.9548 - val_auc: 0.7051\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.77442\n",
      "Epoch 40/100\n",
      "292/292 - 7s - loss: 0.4923 - accuracy: 0.8830 - auc: 0.9066 - val_loss: 0.6610 - val_accuracy: 0.9739 - val_auc: 0.6946\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.77442\n",
      "Epoch 41/100\n",
      "292/292 - 7s - loss: 0.5527 - accuracy: 0.8697 - auc: 0.8918 - val_loss: 0.5740 - val_accuracy: 0.7252 - val_auc: 0.6798\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.77442\n",
      "Epoch 42/100\n",
      "292/292 - 7s - loss: 0.4572 - accuracy: 0.9026 - auc: 0.9057 - val_loss: 0.5329 - val_accuracy: 0.9183 - val_auc: 0.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_auc did not improve from 0.77442\n",
      "Epoch 43/100\n",
      "292/292 - 7s - loss: 0.4521 - accuracy: 0.8786 - auc: 0.9120 - val_loss: 0.5806 - val_accuracy: 0.6957 - val_auc: 0.6780\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.77442\n",
      "Epoch 44/100\n",
      "292/292 - 7s - loss: 0.4348 - accuracy: 0.8857 - auc: 0.9145 - val_loss: 0.5047 - val_accuracy: 0.8017 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.77442\n",
      "Epoch 45/100\n",
      "292/292 - 7s - loss: 0.4260 - accuracy: 0.8721 - auc: 0.9226 - val_loss: 0.5671 - val_accuracy: 0.9026 - val_auc: 0.6089\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.77442\n",
      "Epoch 46/100\n",
      "292/292 - 7s - loss: 0.4301 - accuracy: 0.8806 - auc: 0.9190 - val_loss: 0.5174 - val_accuracy: 0.8609 - val_auc: 0.6955\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.77442\n",
      "Epoch 47/100\n",
      "292/292 - 7s - loss: 0.4080 - accuracy: 0.8740 - auc: 0.9321 - val_loss: 0.6631 - val_accuracy: 0.6748 - val_auc: 0.6881\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.77442\n",
      "Epoch 48/100\n",
      "292/292 - 7s - loss: 0.4296 - accuracy: 0.8762 - auc: 0.9227 - val_loss: 0.5755 - val_accuracy: 0.9357 - val_auc: 0.6943\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.77442\n",
      "Epoch 49/100\n",
      "292/292 - 7s - loss: 0.4284 - accuracy: 0.8641 - auc: 0.9231 - val_loss: 0.5001 - val_accuracy: 0.8417 - val_auc: 0.7346\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.77442\n",
      "Epoch 50/100\n",
      "292/292 - 7s - loss: 0.4433 - accuracy: 0.8865 - auc: 0.9215 - val_loss: 0.7150 - val_accuracy: 0.8852 - val_auc: 0.6578\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.77442\n",
      "Epoch 51/100\n",
      "292/292 - 7s - loss: 0.5249 - accuracy: 0.8761 - auc: 0.9201 - val_loss: 0.6313 - val_accuracy: 0.8748 - val_auc: 0.6397\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.77442\n",
      "Epoch 52/100\n",
      "292/292 - 7s - loss: 0.7673 - accuracy: 0.8712 - auc: 0.9061 - val_loss: 0.9991 - val_accuracy: 0.9270 - val_auc: 0.6932\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.77442\n",
      "Epoch 53/100\n",
      "292/292 - 7s - loss: 0.5989 - accuracy: 0.8695 - auc: 0.8958 - val_loss: 0.5393 - val_accuracy: 0.9478 - val_auc: 0.7288\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.77442\n",
      "Epoch 54/100\n",
      "292/292 - 7s - loss: 0.4638 - accuracy: 0.8714 - auc: 0.9198 - val_loss: 0.5269 - val_accuracy: 0.8661 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.77442\n",
      "Epoch 55/100\n",
      "292/292 - 7s - loss: 0.4410 - accuracy: 0.8806 - auc: 0.9209 - val_loss: 0.5535 - val_accuracy: 0.8470 - val_auc: 0.6950\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.77442\n",
      "Epoch 56/100\n",
      "292/292 - 7s - loss: 0.4358 - accuracy: 0.8771 - auc: 0.9237 - val_loss: 0.5532 - val_accuracy: 0.8783 - val_auc: 0.7170\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.77442\n",
      "Epoch 57/100\n",
      "292/292 - 7s - loss: 0.4199 - accuracy: 0.8847 - auc: 0.9292 - val_loss: 0.5409 - val_accuracy: 0.9096 - val_auc: 0.7268\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.77442\n",
      "Epoch 58/100\n",
      "292/292 - 7s - loss: 0.4128 - accuracy: 0.8990 - auc: 0.9323 - val_loss: 0.5467 - val_accuracy: 0.9252 - val_auc: 0.7595\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.77442\n",
      "Epoch 59/100\n",
      "292/292 - 7s - loss: 0.4082 - accuracy: 0.8827 - auc: 0.9322 - val_loss: 0.5069 - val_accuracy: 0.8922 - val_auc: 0.7792\n",
      "\n",
      "Epoch 00059: val_auc improved from 0.77442 to 0.77916, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 60/100\n",
      "292/292 - 7s - loss: 0.4050 - accuracy: 0.8710 - auc: 0.9346 - val_loss: 0.5098 - val_accuracy: 0.9061 - val_auc: 0.7749\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.77916\n",
      "Epoch 61/100\n",
      "292/292 - 7s - loss: 0.4435 - accuracy: 0.8821 - auc: 0.9318 - val_loss: 0.5836 - val_accuracy: 0.8661 - val_auc: 0.7213\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.77916\n",
      "Epoch 62/100\n",
      "292/292 - 7s - loss: 0.3928 - accuracy: 0.8763 - auc: 0.9422 - val_loss: 0.5157 - val_accuracy: 0.8852 - val_auc: 0.7974\n",
      "\n",
      "Epoch 00062: val_auc improved from 0.77916 to 0.79744, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR\n",
      "Epoch 63/100\n",
      "292/292 - 7s - loss: 0.4161 - accuracy: 0.8562 - auc: 0.9317 - val_loss: 0.6196 - val_accuracy: 0.9409 - val_auc: 0.6986\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.79744\n",
      "Epoch 64/100\n",
      "292/292 - 7s - loss: 0.4043 - accuracy: 0.8776 - auc: 0.9358 - val_loss: 0.5817 - val_accuracy: 0.8939 - val_auc: 0.6944\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.79744\n",
      "Epoch 65/100\n",
      "292/292 - 7s - loss: 2.4911 - accuracy: 0.6833 - auc: 0.7630 - val_loss: 4.8034 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.79744\n",
      "Epoch 66/100\n",
      "292/292 - 7s - loss: 7.5691 - accuracy: 0.9556 - auc: 0.5083 - val_loss: 1.4396 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.79744\n",
      "Epoch 67/100\n",
      "292/292 - 7s - loss: 1.0042 - accuracy: 0.8642 - auc: 0.7666 - val_loss: 0.9705 - val_accuracy: 0.9130 - val_auc: 0.6601\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.79744\n",
      "Epoch 68/100\n",
      "292/292 - 7s - loss: 0.6637 - accuracy: 0.8747 - auc: 0.9100 - val_loss: 0.5968 - val_accuracy: 0.8870 - val_auc: 0.7573\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.79744\n",
      "Epoch 69/100\n",
      "292/292 - 7s - loss: 1.4361 - accuracy: 0.8332 - auc: 0.8526 - val_loss: 2.9853 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.79744\n",
      "Epoch 70/100\n",
      "292/292 - 7s - loss: 1.6743 - accuracy: 0.9597 - auc: 0.5002 - val_loss: 1.0549 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.79744\n",
      "Epoch 71/100\n",
      "292/292 - 7s - loss: 1.1172 - accuracy: 0.9598 - auc: 0.4858 - val_loss: 0.8495 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.79744\n",
      "Epoch 72/100\n",
      "292/292 - 7s - loss: 0.9704 - accuracy: 0.9597 - auc: 0.4874 - val_loss: 0.7527 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.79744\n",
      "Epoch 73/100\n",
      "292/292 - 7s - loss: 0.8943 - accuracy: 0.9598 - auc: 0.4975 - val_loss: 0.7006 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.79744\n",
      "Epoch 74/100\n",
      "292/292 - 7s - loss: 0.8572 - accuracy: 0.9514 - auc: 0.5055 - val_loss: 0.6686 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.79744\n",
      "Epoch 75/100\n",
      "292/292 - 7s - loss: 0.8644 - accuracy: 0.9062 - auc: 0.5224 - val_loss: 0.7953 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.79744\n",
      "Epoch 76/100\n",
      "292/292 - 7s - loss: 0.8530 - accuracy: 0.9489 - auc: 0.4799 - val_loss: 0.6476 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.79744\n",
      "Epoch 77/100\n",
      "292/292 - 7s - loss: 0.8023 - accuracy: 0.9340 - auc: 0.4935 - val_loss: 0.6288 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.79744\n",
      "Epoch 78/100\n",
      "292/292 - 6s - loss: 0.7868 - accuracy: 0.9597 - auc: 0.4828 - val_loss: 0.6199 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.79744\n",
      "Epoch 79/100\n",
      "292/292 - 6s - loss: 0.7791 - accuracy: 0.9594 - auc: 0.4863 - val_loss: 0.6142 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.79744\n",
      "Epoch 80/100\n",
      "292/292 - 7s - loss: 0.7745 - accuracy: 0.9551 - auc: 0.4851 - val_loss: 0.6102 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.79744\n",
      "Epoch 81/100\n",
      "292/292 - 7s - loss: 0.7701 - accuracy: 0.9595 - auc: 0.5014 - val_loss: 0.6075 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.79744\n",
      "Epoch 82/100\n",
      "292/292 - 7s - loss: 0.7661 - accuracy: 0.9585 - auc: 0.4938 - val_loss: 0.6045 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.79744\n",
      "Epoch 83/100\n",
      "292/292 - 7s - loss: 0.7648 - accuracy: 0.6257 - auc: 0.4995 - val_loss: 0.6033 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.79744\n",
      "Epoch 84/100\n",
      "292/292 - 7s - loss: 0.7621 - accuracy: 0.2772 - auc: 0.4882 - val_loss: 0.6015 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.79744\n",
      "Epoch 85/100\n",
      "292/292 - 7s - loss: 2.8601 - accuracy: 0.6750 - auc: 0.6146 - val_loss: 1.3394 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.79744\n",
      "Epoch 86/100\n",
      "292/292 - 7s - loss: 0.9821 - accuracy: 0.8969 - auc: 0.7284 - val_loss: 0.7221 - val_accuracy: 0.9635 - val_auc: 0.6138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: val_auc did not improve from 0.79744\n",
      "Epoch 87/100\n",
      "292/292 - 7s - loss: 0.8122 - accuracy: 0.8896 - auc: 0.7853 - val_loss: 0.7152 - val_accuracy: 0.8991 - val_auc: 0.7308\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.79744\n",
      "Epoch 88/100\n",
      "292/292 - 7s - loss: 0.9021 - accuracy: 0.9099 - auc: 0.8053 - val_loss: 0.9310 - val_accuracy: 0.9287 - val_auc: 0.7395\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.79744\n",
      "Epoch 89/100\n",
      "292/292 - 7s - loss: 0.8585 - accuracy: 0.9093 - auc: 0.8303 - val_loss: 0.6901 - val_accuracy: 0.9235 - val_auc: 0.6002\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.79744\n",
      "Epoch 90/100\n",
      "292/292 - 7s - loss: 0.8519 - accuracy: 0.9454 - auc: 0.4984 - val_loss: 0.6183 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.79744\n",
      "Epoch 91/100\n",
      "292/292 - 6s - loss: 0.6907 - accuracy: 0.9267 - auc: 0.8006 - val_loss: 0.5488 - val_accuracy: 0.9583 - val_auc: 0.7408\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.79744\n",
      "Epoch 92/100\n",
      "292/292 - 7s - loss: 0.7028 - accuracy: 0.8485 - auc: 0.8365 - val_loss: 0.8825 - val_accuracy: 0.9791 - val_auc: 0.5112\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.79744\n",
      "Epoch 93/100\n",
      "292/292 - 7s - loss: 0.8777 - accuracy: 0.9334 - auc: 0.6143 - val_loss: 0.7982 - val_accuracy: 0.9374 - val_auc: 0.6369\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.79744\n",
      "Epoch 94/100\n",
      "292/292 - 7s - loss: 0.7863 - accuracy: 0.8299 - auc: 0.8011 - val_loss: 0.6408 - val_accuracy: 0.9530 - val_auc: 0.7211\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.79744\n",
      "Epoch 95/100\n",
      "292/292 - 7s - loss: 0.7383 - accuracy: 0.8881 - auc: 0.8013 - val_loss: 0.6330 - val_accuracy: 0.9043 - val_auc: 0.6934\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.79744\n",
      "Epoch 96/100\n",
      "292/292 - 7s - loss: 0.7180 - accuracy: 0.9077 - auc: 0.7629 - val_loss: 0.6460 - val_accuracy: 0.9635 - val_auc: 0.6887\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.79744\n",
      "Epoch 97/100\n",
      "292/292 - 7s - loss: 0.5925 - accuracy: 0.9256 - auc: 0.8392 - val_loss: 0.7512 - val_accuracy: 0.9791 - val_auc: 0.6223\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.79744\n",
      "Epoch 98/100\n",
      "292/292 - 7s - loss: 0.6274 - accuracy: 0.9158 - auc: 0.8495 - val_loss: 0.5187 - val_accuracy: 0.9148 - val_auc: 0.6993\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.79744\n",
      "Epoch 99/100\n",
      "292/292 - 7s - loss: 0.5635 - accuracy: 0.8961 - auc: 0.8675 - val_loss: 0.5339 - val_accuracy: 0.9478 - val_auc: 0.7809\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.79744\n",
      "Epoch 100/100\n",
      "292/292 - 7s - loss: 0.5637 - accuracy: 0.9087 - auc: 0.8464 - val_loss: 0.6082 - val_accuracy: 0.9461 - val_auc: 0.6894\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.79744\n",
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingDeep\\\\210120_Dense_NR-AhR'\n",
      "Epoch 1/100\n",
      "257/257 - 8s - loss: 2.4662 - accuracy: 0.6807 - auc: 0.7903 - val_loss: 1.0022 - val_accuracy: 0.5503 - val_auc: 0.8756\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.87560, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 2/100\n",
      "257/257 - 6s - loss: 0.7580 - accuracy: 0.7466 - auc: 0.8484 - val_loss: 0.6648 - val_accuracy: 0.6980 - val_auc: 0.8861\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.87560 to 0.88614, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 3/100\n",
      "257/257 - 6s - loss: 0.6078 - accuracy: 0.7660 - auc: 0.8653 - val_loss: 0.6143 - val_accuracy: 0.7836 - val_auc: 0.8892\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.88614 to 0.88921, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 4/100\n",
      "257/257 - 6s - loss: 0.5714 - accuracy: 0.7820 - auc: 0.8722 - val_loss: 0.6419 - val_accuracy: 0.8792 - val_auc: 0.8905\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.88921 to 0.89048, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 5/100\n",
      "257/257 - 6s - loss: 0.5440 - accuracy: 0.7743 - auc: 0.8784 - val_loss: 0.5410 - val_accuracy: 0.6779 - val_auc: 0.8908\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.89048 to 0.89076, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 6/100\n",
      "257/257 - 6s - loss: 0.5200 - accuracy: 0.7877 - auc: 0.8864 - val_loss: 0.5814 - val_accuracy: 0.7030 - val_auc: 0.8934\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.89076 to 0.89336, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 7/100\n",
      "257/257 - 6s - loss: 0.5056 - accuracy: 0.8104 - auc: 0.8930 - val_loss: 0.4975 - val_accuracy: 0.8020 - val_auc: 0.8956\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.89336 to 0.89564, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 8/100\n",
      "257/257 - 6s - loss: 0.4924 - accuracy: 0.8026 - auc: 0.8971 - val_loss: 0.5709 - val_accuracy: 0.7366 - val_auc: 0.8938\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.89564\n",
      "Epoch 9/100\n",
      "257/257 - 6s - loss: 1.0413 - accuracy: 0.7666 - auc: 0.8537 - val_loss: 0.7720 - val_accuracy: 0.6040 - val_auc: 0.8923\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.89564\n",
      "Epoch 10/100\n",
      "257/257 - 6s - loss: 0.6040 - accuracy: 0.8074 - auc: 0.8926 - val_loss: 0.6049 - val_accuracy: 0.8658 - val_auc: 0.9003\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.89564 to 0.90029, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 11/100\n",
      "257/257 - 6s - loss: 0.5395 - accuracy: 0.7953 - auc: 0.8977 - val_loss: 0.5551 - val_accuracy: 0.7617 - val_auc: 0.8946\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.90029\n",
      "Epoch 12/100\n",
      "257/257 - 6s - loss: 0.5174 - accuracy: 0.8189 - auc: 0.9009 - val_loss: 0.5569 - val_accuracy: 0.8523 - val_auc: 0.8956\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.90029\n",
      "Epoch 13/100\n",
      "257/257 - 6s - loss: 0.5005 - accuracy: 0.8097 - auc: 0.9042 - val_loss: 0.5163 - val_accuracy: 0.8440 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.90029 to 0.90153, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 14/100\n",
      "257/257 - 6s - loss: 0.4797 - accuracy: 0.8169 - auc: 0.9098 - val_loss: 0.5479 - val_accuracy: 0.6795 - val_auc: 0.8972\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.90153\n",
      "Epoch 15/100\n",
      "257/257 - 6s - loss: 0.4738 - accuracy: 0.8292 - auc: 0.9123 - val_loss: 0.5480 - val_accuracy: 0.8591 - val_auc: 0.8988\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.90153\n",
      "Epoch 16/100\n",
      "257/257 - 6s - loss: 0.4814 - accuracy: 0.8241 - auc: 0.9094 - val_loss: 0.4941 - val_accuracy: 0.8205 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.90153\n",
      "Epoch 17/100\n",
      "257/257 - 6s - loss: 0.4563 - accuracy: 0.8349 - auc: 0.9174 - val_loss: 0.5145 - val_accuracy: 0.8255 - val_auc: 0.8980\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.90153\n",
      "Epoch 18/100\n",
      "257/257 - 6s - loss: 0.4892 - accuracy: 0.8147 - auc: 0.9070 - val_loss: 0.5449 - val_accuracy: 0.8591 - val_auc: 0.8965\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.90153\n",
      "Epoch 19/100\n",
      "257/257 - 6s - loss: 0.4766 - accuracy: 0.8172 - auc: 0.9111 - val_loss: 0.5216 - val_accuracy: 0.8272 - val_auc: 0.8892\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.90153\n",
      "Epoch 20/100\n",
      "257/257 - 6s - loss: 0.4681 - accuracy: 0.8284 - auc: 0.9108 - val_loss: 0.5394 - val_accuracy: 0.8356 - val_auc: 0.8909\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.90153\n",
      "Epoch 21/100\n",
      "257/257 - 6s - loss: 0.4587 - accuracy: 0.8128 - auc: 0.9134 - val_loss: 0.5291 - val_accuracy: 0.8423 - val_auc: 0.8922\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.90153\n",
      "Epoch 22/100\n",
      "257/257 - 6s - loss: 0.4552 - accuracy: 0.8208 - auc: 0.9153 - val_loss: 0.5145 - val_accuracy: 0.8372 - val_auc: 0.8962\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.90153\n",
      "Epoch 23/100\n",
      "257/257 - 6s - loss: 0.4476 - accuracy: 0.8351 - auc: 0.9174 - val_loss: 0.5143 - val_accuracy: 0.8423 - val_auc: 0.8948\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.90153\n",
      "Epoch 24/100\n",
      "257/257 - 6s - loss: 0.4407 - accuracy: 0.8246 - auc: 0.9191 - val_loss: 0.5029 - val_accuracy: 0.7886 - val_auc: 0.8945\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.90153\n",
      "Epoch 25/100\n",
      "257/257 - 6s - loss: 0.4292 - accuracy: 0.8402 - auc: 0.9257 - val_loss: 0.5140 - val_accuracy: 0.7869 - val_auc: 0.8887\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.90153\n",
      "Epoch 26/100\n",
      "257/257 - 6s - loss: 0.4298 - accuracy: 0.8390 - auc: 0.9238 - val_loss: 0.5209 - val_accuracy: 0.7299 - val_auc: 0.8844\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.90153\n",
      "Epoch 27/100\n",
      "257/257 - 6s - loss: 0.4232 - accuracy: 0.8427 - auc: 0.9277 - val_loss: 0.5535 - val_accuracy: 0.7584 - val_auc: 0.8861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_auc did not improve from 0.90153\n",
      "Epoch 28/100\n",
      "257/257 - 6s - loss: 0.4145 - accuracy: 0.8493 - auc: 0.9306 - val_loss: 0.5497 - val_accuracy: 0.8138 - val_auc: 0.8921\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.90153\n",
      "Epoch 29/100\n",
      "257/257 - 6s - loss: 0.4324 - accuracy: 0.8328 - auc: 0.9259 - val_loss: 0.6034 - val_accuracy: 0.8641 - val_auc: 0.8904\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.90153\n",
      "Epoch 30/100\n",
      "257/257 - 6s - loss: 0.4255 - accuracy: 0.8421 - auc: 0.9281 - val_loss: 0.5127 - val_accuracy: 0.7903 - val_auc: 0.8847\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.90153\n",
      "Epoch 31/100\n",
      "257/257 - 6s - loss: 0.4292 - accuracy: 0.8474 - auc: 0.9304 - val_loss: 0.5040 - val_accuracy: 0.8188 - val_auc: 0.8964\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.90153\n",
      "Epoch 32/100\n",
      "257/257 - 6s - loss: 0.4382 - accuracy: 0.8389 - auc: 0.9235 - val_loss: 0.5436 - val_accuracy: 0.8389 - val_auc: 0.8880\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.90153\n",
      "Epoch 33/100\n",
      "257/257 - 6s - loss: 0.4184 - accuracy: 0.8504 - auc: 0.9318 - val_loss: 0.6312 - val_accuracy: 0.6242 - val_auc: 0.8866\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.90153\n",
      "Epoch 34/100\n",
      "257/257 - 6s - loss: 0.4178 - accuracy: 0.8240 - auc: 0.9307 - val_loss: 0.5400 - val_accuracy: 0.8138 - val_auc: 0.8874\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.90153\n",
      "Epoch 35/100\n",
      "257/257 - 6s - loss: 0.4098 - accuracy: 0.8504 - auc: 0.9345 - val_loss: 0.5515 - val_accuracy: 0.8205 - val_auc: 0.8939\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.90153\n",
      "Epoch 36/100\n",
      "257/257 - 6s - loss: 0.4106 - accuracy: 0.8425 - auc: 0.9336 - val_loss: 0.5262 - val_accuracy: 0.7550 - val_auc: 0.8893\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.90153\n",
      "Epoch 37/100\n",
      "257/257 - 6s - loss: 0.4072 - accuracy: 0.8549 - auc: 0.9372 - val_loss: 0.5215 - val_accuracy: 0.8255 - val_auc: 0.8931\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.90153\n",
      "Epoch 38/100\n",
      "257/257 - 6s - loss: 0.3958 - accuracy: 0.8494 - auc: 0.9385 - val_loss: 0.5354 - val_accuracy: 0.7752 - val_auc: 0.8842\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.90153\n",
      "Epoch 39/100\n",
      "257/257 - 6s - loss: 0.3859 - accuracy: 0.8543 - auc: 0.9415 - val_loss: 0.5454 - val_accuracy: 0.7517 - val_auc: 0.8862\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.90153\n",
      "Epoch 40/100\n",
      "257/257 - 6s - loss: 0.3898 - accuracy: 0.8480 - auc: 0.9411 - val_loss: 0.5323 - val_accuracy: 0.7953 - val_auc: 0.8862\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.90153\n",
      "Epoch 41/100\n",
      "257/257 - 6s - loss: 0.3831 - accuracy: 0.8606 - auc: 0.9427 - val_loss: 0.5473 - val_accuracy: 0.7886 - val_auc: 0.8844\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.90153\n",
      "Epoch 42/100\n",
      "257/257 - 6s - loss: 0.3874 - accuracy: 0.8559 - auc: 0.9418 - val_loss: 0.5526 - val_accuracy: 0.8289 - val_auc: 0.8863\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.90153\n",
      "Epoch 43/100\n",
      "257/257 - 6s - loss: 0.3763 - accuracy: 0.8595 - auc: 0.9444 - val_loss: 0.5771 - val_accuracy: 0.8171 - val_auc: 0.8844\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.90153\n",
      "Epoch 44/100\n",
      "257/257 - 6s - loss: 0.3912 - accuracy: 0.8572 - auc: 0.9451 - val_loss: 0.5348 - val_accuracy: 0.7718 - val_auc: 0.8939\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.90153\n",
      "Epoch 45/100\n",
      "257/257 - 6s - loss: 0.3898 - accuracy: 0.8505 - auc: 0.9428 - val_loss: 0.5696 - val_accuracy: 0.8440 - val_auc: 0.8908\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.90153\n",
      "Epoch 46/100\n",
      "257/257 - 6s - loss: 0.3731 - accuracy: 0.8640 - auc: 0.9468 - val_loss: 0.5732 - val_accuracy: 0.7450 - val_auc: 0.8730\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.90153\n",
      "Epoch 47/100\n",
      "257/257 - 6s - loss: 0.3784 - accuracy: 0.8544 - auc: 0.9447 - val_loss: 0.5601 - val_accuracy: 0.7685 - val_auc: 0.8917\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.90153\n",
      "Epoch 48/100\n",
      "257/257 - 6s - loss: 0.3931 - accuracy: 0.8559 - auc: 0.9432 - val_loss: 0.6231 - val_accuracy: 0.8507 - val_auc: 0.8763\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.90153\n",
      "Epoch 49/100\n",
      "257/257 - 6s - loss: 0.4409 - accuracy: 0.8548 - auc: 0.9416 - val_loss: 0.6100 - val_accuracy: 0.7232 - val_auc: 0.8824\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.90153\n",
      "Epoch 50/100\n",
      "257/257 - 6s - loss: 0.3783 - accuracy: 0.8635 - auc: 0.9467 - val_loss: 0.5421 - val_accuracy: 0.8121 - val_auc: 0.8955\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.90153\n",
      "Epoch 51/100\n",
      "257/257 - 6s - loss: 0.3663 - accuracy: 0.8627 - auc: 0.9472 - val_loss: 0.5284 - val_accuracy: 0.7768 - val_auc: 0.8811\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.90153\n",
      "Epoch 52/100\n",
      "257/257 - 6s - loss: 0.3583 - accuracy: 0.8600 - auc: 0.9479 - val_loss: 0.5335 - val_accuracy: 0.7785 - val_auc: 0.8869\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.90153\n",
      "Epoch 53/100\n",
      "257/257 - 6s - loss: 0.3560 - accuracy: 0.8683 - auc: 0.9512 - val_loss: 0.5343 - val_accuracy: 0.8138 - val_auc: 0.8937\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.90153\n",
      "Epoch 54/100\n",
      "257/257 - 6s - loss: 0.3740 - accuracy: 0.8645 - auc: 0.9464 - val_loss: 0.6060 - val_accuracy: 0.7148 - val_auc: 0.8913\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.90153\n",
      "Epoch 55/100\n",
      "257/257 - 6s - loss: 0.3811 - accuracy: 0.8605 - auc: 0.9460 - val_loss: 0.6693 - val_accuracy: 0.6158 - val_auc: 0.8817\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.90153\n",
      "Epoch 56/100\n",
      "257/257 - 6s - loss: 0.3807 - accuracy: 0.8613 - auc: 0.9482 - val_loss: 0.6715 - val_accuracy: 0.7852 - val_auc: 0.8699\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.90153\n",
      "Epoch 57/100\n",
      "257/257 - 6s - loss: 0.3625 - accuracy: 0.8628 - auc: 0.9515 - val_loss: 0.6653 - val_accuracy: 0.7349 - val_auc: 0.8628\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.90153\n",
      "Epoch 58/100\n",
      "257/257 - 6s - loss: 0.3573 - accuracy: 0.8618 - auc: 0.9511 - val_loss: 0.6057 - val_accuracy: 0.8104 - val_auc: 0.8850\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.90153\n",
      "Epoch 59/100\n",
      "257/257 - 6s - loss: 0.3698 - accuracy: 0.8663 - auc: 0.9505 - val_loss: 0.8082 - val_accuracy: 0.8289 - val_auc: 0.8757\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.90153\n",
      "Epoch 60/100\n",
      "257/257 - 6s - loss: 0.3527 - accuracy: 0.8605 - auc: 0.9531 - val_loss: 0.5335 - val_accuracy: 0.7668 - val_auc: 0.8842\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.90153\n",
      "Epoch 61/100\n",
      "257/257 - 6s - loss: 0.3873 - accuracy: 0.8610 - auc: 0.9475 - val_loss: 0.9268 - val_accuracy: 0.8406 - val_auc: 0.8534\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.90153\n",
      "Epoch 62/100\n",
      "257/257 - 6s - loss: 0.4700 - accuracy: 0.8460 - auc: 0.9380 - val_loss: 0.6623 - val_accuracy: 0.8087 - val_auc: 0.8853\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.90153\n",
      "Epoch 63/100\n",
      "257/257 - 6s - loss: 0.3648 - accuracy: 0.8707 - auc: 0.9545 - val_loss: 0.6057 - val_accuracy: 0.7399 - val_auc: 0.8870\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.90153\n",
      "Epoch 64/100\n",
      "257/257 - 6s - loss: 0.3595 - accuracy: 0.8668 - auc: 0.9535 - val_loss: 0.6576 - val_accuracy: 0.6913 - val_auc: 0.8684\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.90153\n",
      "Epoch 65/100\n",
      "257/257 - 6s - loss: 0.3451 - accuracy: 0.8705 - auc: 0.9570 - val_loss: 0.6208 - val_accuracy: 0.7819 - val_auc: 0.8847\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.90153\n",
      "Epoch 66/100\n",
      "257/257 - 6s - loss: 0.3434 - accuracy: 0.8618 - auc: 0.9546 - val_loss: 0.5886 - val_accuracy: 0.7198 - val_auc: 0.8755\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.90153\n",
      "Epoch 67/100\n",
      "257/257 - 6s - loss: 0.3408 - accuracy: 0.8595 - auc: 0.9553 - val_loss: 0.6932 - val_accuracy: 0.7483 - val_auc: 0.8751\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.90153\n",
      "Epoch 68/100\n",
      "257/257 - 6s - loss: 0.3484 - accuracy: 0.8599 - auc: 0.9544 - val_loss: 0.6022 - val_accuracy: 0.7550 - val_auc: 0.8825\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.90153\n",
      "Epoch 69/100\n",
      "257/257 - 6s - loss: 0.3885 - accuracy: 0.8733 - auc: 0.9543 - val_loss: 0.6859 - val_accuracy: 0.7081 - val_auc: 0.8806\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.90153\n",
      "Epoch 70/100\n",
      "257/257 - 6s - loss: 0.3332 - accuracy: 0.8731 - auc: 0.9582 - val_loss: 0.6734 - val_accuracy: 0.8154 - val_auc: 0.8578\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.90153\n",
      "Epoch 71/100\n",
      "257/257 - 6s - loss: 0.3419 - accuracy: 0.8710 - auc: 0.9546 - val_loss: 0.6787 - val_accuracy: 0.7752 - val_auc: 0.8809\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.90153\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 6s - loss: 0.3294 - accuracy: 0.8765 - auc: 0.9581 - val_loss: 0.6565 - val_accuracy: 0.7483 - val_auc: 0.8643\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.90153\n",
      "Epoch 73/100\n",
      "257/257 - 6s - loss: 0.6633 - accuracy: 0.7836 - auc: 0.9188 - val_loss: 0.9384 - val_accuracy: 0.7886 - val_auc: 0.8822\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.90153\n",
      "Epoch 74/100\n",
      "257/257 - 6s - loss: 0.4929 - accuracy: 0.8556 - auc: 0.9503 - val_loss: 0.6608 - val_accuracy: 0.7852 - val_auc: 0.8737\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.90153\n",
      "Epoch 75/100\n",
      "257/257 - 6s - loss: 0.3768 - accuracy: 0.8727 - auc: 0.9599 - val_loss: 0.6288 - val_accuracy: 0.7785 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00075: val_auc improved from 0.90153 to 0.90305, saving model to 210120_TrainingDeep\\210120_Dense_NR-AhR\n",
      "Epoch 76/100\n",
      "257/257 - 6s - loss: 0.3498 - accuracy: 0.8740 - auc: 0.9609 - val_loss: 0.7538 - val_accuracy: 0.7752 - val_auc: 0.8811\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.90305\n",
      "Epoch 77/100\n",
      "257/257 - 6s - loss: 0.3670 - accuracy: 0.8573 - auc: 0.9520 - val_loss: 0.7339 - val_accuracy: 0.8020 - val_auc: 0.8595\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.90305\n",
      "Epoch 78/100\n",
      "257/257 - 6s - loss: 0.3272 - accuracy: 0.8733 - auc: 0.9614 - val_loss: 0.7467 - val_accuracy: 0.7886 - val_auc: 0.8697\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.90305\n",
      "Epoch 79/100\n",
      "257/257 - 6s - loss: 0.3289 - accuracy: 0.8662 - auc: 0.9597 - val_loss: 0.6973 - val_accuracy: 0.7785 - val_auc: 0.8725\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.90305\n",
      "Epoch 80/100\n",
      "257/257 - 6s - loss: 0.3195 - accuracy: 0.8811 - auc: 0.9638 - val_loss: 0.6929 - val_accuracy: 0.8104 - val_auc: 0.8683\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.90305\n",
      "Epoch 81/100\n",
      "257/257 - 6s - loss: 0.3205 - accuracy: 0.8698 - auc: 0.9608 - val_loss: 0.8713 - val_accuracy: 0.8020 - val_auc: 0.8547\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.90305\n",
      "Epoch 82/100\n",
      "257/257 - 6s - loss: 0.3276 - accuracy: 0.8712 - auc: 0.9593 - val_loss: 0.7228 - val_accuracy: 0.7735 - val_auc: 0.8783\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.90305\n",
      "Epoch 83/100\n",
      "257/257 - 6s - loss: 0.3362 - accuracy: 0.8638 - auc: 0.9581 - val_loss: 0.6707 - val_accuracy: 0.7349 - val_auc: 0.8727\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.90305\n",
      "Epoch 84/100\n",
      "257/257 - 6s - loss: 0.3211 - accuracy: 0.8773 - auc: 0.9600 - val_loss: 0.6643 - val_accuracy: 0.7953 - val_auc: 0.8739\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.90305\n",
      "Epoch 85/100\n",
      "257/257 - 6s - loss: 0.3218 - accuracy: 0.8781 - auc: 0.9596 - val_loss: 0.6705 - val_accuracy: 0.8221 - val_auc: 0.8807\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.90305\n",
      "Epoch 86/100\n",
      "257/257 - 6s - loss: 0.3219 - accuracy: 0.8709 - auc: 0.9587 - val_loss: 0.6056 - val_accuracy: 0.7265 - val_auc: 0.8784\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.90305\n",
      "Epoch 87/100\n",
      "257/257 - 6s - loss: 0.3423 - accuracy: 0.8727 - auc: 0.9573 - val_loss: 0.6827 - val_accuracy: 0.8272 - val_auc: 0.8825\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.90305\n",
      "Epoch 88/100\n",
      "257/257 - 6s - loss: 0.3135 - accuracy: 0.8789 - auc: 0.9617 - val_loss: 0.8483 - val_accuracy: 0.8272 - val_auc: 0.8636\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.90305\n",
      "Epoch 89/100\n",
      "257/257 - 6s - loss: 0.3180 - accuracy: 0.8819 - auc: 0.9624 - val_loss: 0.6753 - val_accuracy: 0.8054 - val_auc: 0.8765\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.90305\n",
      "Epoch 90/100\n",
      "257/257 - 6s - loss: 0.3331 - accuracy: 0.8784 - auc: 0.9590 - val_loss: 0.6189 - val_accuracy: 0.7852 - val_auc: 0.8900\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.90305\n",
      "Epoch 91/100\n",
      "257/257 - 6s - loss: 0.3247 - accuracy: 0.8799 - auc: 0.9627 - val_loss: 0.8695 - val_accuracy: 0.8154 - val_auc: 0.8432\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.90305\n",
      "Epoch 92/100\n",
      "257/257 - 6s - loss: 0.3143 - accuracy: 0.8773 - auc: 0.9632 - val_loss: 0.8446 - val_accuracy: 0.8104 - val_auc: 0.8577\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.90305\n",
      "Epoch 93/100\n",
      "257/257 - 6s - loss: 0.3500 - accuracy: 0.8524 - auc: 0.9544 - val_loss: 0.8119 - val_accuracy: 0.7970 - val_auc: 0.8739\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.90305\n",
      "Epoch 94/100\n",
      "257/257 - 6s - loss: 0.3361 - accuracy: 0.8706 - auc: 0.9584 - val_loss: 0.6233 - val_accuracy: 0.7198 - val_auc: 0.8883\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.90305\n",
      "Epoch 95/100\n",
      "257/257 - 6s - loss: 0.3164 - accuracy: 0.8743 - auc: 0.9624 - val_loss: 0.6154 - val_accuracy: 0.8020 - val_auc: 0.8861\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.90305\n",
      "Epoch 96/100\n",
      "257/257 - 6s - loss: 0.3157 - accuracy: 0.8842 - auc: 0.9640 - val_loss: 0.7059 - val_accuracy: 0.7332 - val_auc: 0.8742\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.90305\n",
      "Epoch 97/100\n",
      "257/257 - 6s - loss: 0.3247 - accuracy: 0.8810 - auc: 0.9621 - val_loss: 0.7843 - val_accuracy: 0.8037 - val_auc: 0.8779\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.90305\n",
      "Epoch 98/100\n",
      "257/257 - 6s - loss: 0.3388 - accuracy: 0.8771 - auc: 0.9605 - val_loss: 0.6941 - val_accuracy: 0.7601 - val_auc: 0.8590\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.90305\n",
      "Epoch 99/100\n",
      "257/257 - 6s - loss: 0.3025 - accuracy: 0.8869 - auc: 0.9665 - val_loss: 0.7208 - val_accuracy: 0.6711 - val_auc: 0.8725\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.90305\n",
      "Epoch 100/100\n",
      "257/257 - 6s - loss: 0.3040 - accuracy: 0.8837 - auc: 0.9663 - val_loss: 0.8931 - val_accuracy: 0.8188 - val_auc: 0.8662\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.90305\n",
      "Epoch 1/100\n",
      "269/269 - 10s - loss: 6.9092 - accuracy: 0.7688 - auc: 0.4993 - val_loss: 3.1074 - val_accuracy: 0.0141 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.50000, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 2/100\n",
      "269/269 - 6s - loss: 1.8217 - accuracy: 0.0853 - auc: 0.4972 - val_loss: 1.0199 - val_accuracy: 0.0141 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.50000\n",
      "Epoch 3/100\n",
      "269/269 - 6s - loss: 1.0499 - accuracy: 0.0513 - auc: 0.4926 - val_loss: 0.7516 - val_accuracy: 0.0141 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.50000\n",
      "Epoch 4/100\n",
      "269/269 - 6s - loss: 0.9217 - accuracy: 0.4341 - auc: 0.5300 - val_loss: 0.6654 - val_accuracy: 0.9859 - val_auc: 0.4415\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.50000\n",
      "Epoch 5/100\n",
      "269/269 - 6s - loss: 3.1380 - accuracy: 0.5923 - auc: 0.5518 - val_loss: 1.0103 - val_accuracy: 0.9859 - val_auc: 0.3971\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.50000\n",
      "Epoch 6/100\n",
      "269/269 - 6s - loss: 0.8791 - accuracy: 0.8860 - auc: 0.8100 - val_loss: 0.9385 - val_accuracy: 0.9051 - val_auc: 0.6236\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.50000 to 0.62355, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 7/100\n",
      "269/269 - 6s - loss: 0.7608 - accuracy: 0.9376 - auc: 0.8241 - val_loss: 0.6001 - val_accuracy: 0.9684 - val_auc: 0.6954\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.62355 to 0.69541, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 8/100\n",
      "269/269 - 6s - loss: 0.5849 - accuracy: 0.9609 - auc: 0.8352 - val_loss: 0.5701 - val_accuracy: 0.9613 - val_auc: 0.6820\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.69541\n",
      "Epoch 9/100\n",
      "269/269 - 6s - loss: 0.5551 - accuracy: 0.9594 - auc: 0.8354 - val_loss: 0.5509 - val_accuracy: 0.9754 - val_auc: 0.6500\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.69541\n",
      "Epoch 10/100\n",
      "269/269 - 6s - loss: 0.5192 - accuracy: 0.9624 - auc: 0.8499 - val_loss: 0.5272 - val_accuracy: 0.9613 - val_auc: 0.7348\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.69541 to 0.73485, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 11/100\n",
      "269/269 - 6s - loss: 0.4907 - accuracy: 0.9656 - auc: 0.8709 - val_loss: 0.5511 - val_accuracy: 0.8858 - val_auc: 0.7013\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.73485\n",
      "Epoch 12/100\n",
      "269/269 - 6s - loss: 0.4993 - accuracy: 0.9440 - auc: 0.8640 - val_loss: 0.4922 - val_accuracy: 0.9754 - val_auc: 0.7394\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.73485 to 0.73942, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 13/100\n",
      "269/269 - 6s - loss: 0.5416 - accuracy: 0.9560 - auc: 0.8581 - val_loss: 0.6148 - val_accuracy: 0.8049 - val_auc: 0.7308\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.73942\n",
      "Epoch 14/100\n",
      "269/269 - 6s - loss: 0.4772 - accuracy: 0.9493 - auc: 0.8938 - val_loss: 0.4903 - val_accuracy: 0.9631 - val_auc: 0.7912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_auc improved from 0.73942 to 0.79122, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 15/100\n",
      "269/269 - 6s - loss: 0.4574 - accuracy: 0.9443 - auc: 0.8886 - val_loss: 0.5655 - val_accuracy: 0.9807 - val_auc: 0.7143\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.79122\n",
      "Epoch 16/100\n",
      "269/269 - 6s - loss: 0.4339 - accuracy: 0.9481 - auc: 0.9066 - val_loss: 0.4595 - val_accuracy: 0.9508 - val_auc: 0.7486\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.79122\n",
      "Epoch 17/100\n",
      "269/269 - 6s - loss: 0.4561 - accuracy: 0.9272 - auc: 0.9042 - val_loss: 0.5736 - val_accuracy: 0.9772 - val_auc: 0.7367\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.79122\n",
      "Epoch 18/100\n",
      "269/269 - 6s - loss: 0.4461 - accuracy: 0.9574 - auc: 0.9050 - val_loss: 0.4533 - val_accuracy: 0.9578 - val_auc: 0.8230\n",
      "\n",
      "Epoch 00018: val_auc improved from 0.79122 to 0.82297, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 19/100\n",
      "269/269 - 6s - loss: 0.4256 - accuracy: 0.9585 - auc: 0.9140 - val_loss: 0.4546 - val_accuracy: 0.9455 - val_auc: 0.8187\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.82297\n",
      "Epoch 20/100\n",
      "269/269 - 6s - loss: 0.4077 - accuracy: 0.9472 - auc: 0.9209 - val_loss: 0.5105 - val_accuracy: 0.9473 - val_auc: 0.7715\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.82297\n",
      "Epoch 21/100\n",
      "269/269 - 6s - loss: 0.5457 - accuracy: 0.9397 - auc: 0.8805 - val_loss: 0.4813 - val_accuracy: 0.9666 - val_auc: 0.8568\n",
      "\n",
      "Epoch 00021: val_auc improved from 0.82297 to 0.85684, saving model to 210120_TrainingDeep\\210120_Dense_NR-AR-LBD\n",
      "Epoch 22/100\n",
      "269/269 - 6s - loss: 0.6108 - accuracy: 0.9388 - auc: 0.8714 - val_loss: 0.5553 - val_accuracy: 0.9473 - val_auc: 0.7238\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.85684\n",
      "Epoch 23/100\n",
      "269/269 - 6s - loss: 0.4795 - accuracy: 0.9504 - auc: 0.8651 - val_loss: 0.5210 - val_accuracy: 0.9754 - val_auc: 0.5391\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.85684\n",
      "Epoch 24/100\n",
      "269/269 - 6s - loss: 0.4553 - accuracy: 0.9613 - auc: 0.8813 - val_loss: 0.5148 - val_accuracy: 0.9772 - val_auc: 0.5687\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.85684\n",
      "Epoch 25/100\n",
      "269/269 - 6s - loss: 0.4523 - accuracy: 0.9471 - auc: 0.8884 - val_loss: 0.5354 - val_accuracy: 0.9736 - val_auc: 0.5916\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.85684\n",
      "Epoch 26/100\n",
      "269/269 - 6s - loss: 0.4842 - accuracy: 0.9480 - auc: 0.8857 - val_loss: 0.5183 - val_accuracy: 0.9666 - val_auc: 0.6475\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.85684\n",
      "Epoch 27/100\n",
      "269/269 - 6s - loss: 0.4447 - accuracy: 0.9524 - auc: 0.8780 - val_loss: 0.4859 - val_accuracy: 0.9631 - val_auc: 0.7369\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.85684\n",
      "Epoch 28/100\n",
      "269/269 - 6s - loss: 0.5821 - accuracy: 0.9316 - auc: 0.8842 - val_loss: 0.8296 - val_accuracy: 0.9420 - val_auc: 0.5459\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.85684\n",
      "Epoch 29/100\n",
      "269/269 - 6s - loss: 0.5239 - accuracy: 0.9581 - auc: 0.8798 - val_loss: 0.4963 - val_accuracy: 0.8998 - val_auc: 0.7396\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.85684\n",
      "Epoch 30/100\n",
      "269/269 - 6s - loss: 0.4388 - accuracy: 0.9499 - auc: 0.8990 - val_loss: 0.5541 - val_accuracy: 0.9736 - val_auc: 0.4764\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.85684\n",
      "Epoch 31/100\n",
      "269/269 - 6s - loss: 0.4355 - accuracy: 0.9449 - auc: 0.8916 - val_loss: 0.5169 - val_accuracy: 0.9631 - val_auc: 0.5670\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.85684\n",
      "Epoch 32/100\n",
      "269/269 - 6s - loss: 0.4206 - accuracy: 0.9519 - auc: 0.9099 - val_loss: 0.4900 - val_accuracy: 0.9385 - val_auc: 0.7037\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.85684\n",
      "Epoch 33/100\n",
      "269/269 - 6s - loss: 0.8602 - accuracy: 0.9423 - auc: 0.6375 - val_loss: 0.6038 - val_accuracy: 0.9859 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.85684\n",
      "Epoch 34/100\n",
      "269/269 - 6s - loss: 0.8340 - accuracy: 0.8414 - auc: 0.8111 - val_loss: 0.9360 - val_accuracy: 0.9789 - val_auc: 0.7452\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.85684\n",
      "Epoch 35/100\n",
      "269/269 - 6s - loss: 0.6722 - accuracy: 0.9473 - auc: 0.8838 - val_loss: 0.6313 - val_accuracy: 0.9578 - val_auc: 0.6373\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.85684\n",
      "Epoch 36/100\n",
      "269/269 - 6s - loss: 0.4893 - accuracy: 0.9414 - auc: 0.8974 - val_loss: 0.5566 - val_accuracy: 0.9666 - val_auc: 0.7781\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.85684\n",
      "Epoch 37/100\n",
      "269/269 - 6s - loss: 0.5398 - accuracy: 0.9408 - auc: 0.9020 - val_loss: 0.6209 - val_accuracy: 0.9684 - val_auc: 0.5839\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.85684\n",
      "Epoch 38/100\n",
      "269/269 - 6s - loss: 0.4642 - accuracy: 0.9333 - auc: 0.9126 - val_loss: 0.5299 - val_accuracy: 0.9385 - val_auc: 0.6934\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.85684\n",
      "Epoch 39/100\n",
      "269/269 - 6s - loss: 0.4653 - accuracy: 0.9517 - auc: 0.9073 - val_loss: 0.5253 - val_accuracy: 0.9490 - val_auc: 0.6716\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.85684\n",
      "Epoch 40/100\n",
      "269/269 - 6s - loss: 0.4207 - accuracy: 0.9574 - auc: 0.9158 - val_loss: 0.5080 - val_accuracy: 0.9332 - val_auc: 0.6815\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.85684\n",
      "Epoch 41/100\n",
      "269/269 - 6s - loss: 0.4246 - accuracy: 0.9552 - auc: 0.9175 - val_loss: 0.4935 - val_accuracy: 0.9315 - val_auc: 0.7391\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.85684\n",
      "Epoch 42/100\n",
      "269/269 - 6s - loss: 0.4026 - accuracy: 0.9560 - auc: 0.9202 - val_loss: 0.5870 - val_accuracy: 0.9649 - val_auc: 0.5462\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.85684\n",
      "Epoch 43/100\n",
      "269/269 - 6s - loss: 0.4062 - accuracy: 0.9429 - auc: 0.9271 - val_loss: 0.4463 - val_accuracy: 0.8928 - val_auc: 0.8117\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.85684\n",
      "Epoch 44/100\n",
      "269/269 - 6s - loss: 0.3969 - accuracy: 0.9460 - auc: 0.9298 - val_loss: 0.5144 - val_accuracy: 0.9332 - val_auc: 0.7211\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.85684\n",
      "Epoch 45/100\n",
      "269/269 - 6s - loss: 0.4034 - accuracy: 0.9551 - auc: 0.9249 - val_loss: 0.5894 - val_accuracy: 0.9684 - val_auc: 0.5294\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.85684\n",
      "Epoch 46/100\n",
      "269/269 - 6s - loss: 0.7165 - accuracy: 0.9286 - auc: 0.9047 - val_loss: 0.8236 - val_accuracy: 0.9596 - val_auc: 0.6700\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.85684\n",
      "Epoch 47/100\n",
      "269/269 - 6s - loss: 0.5172 - accuracy: 0.9558 - auc: 0.9263 - val_loss: 0.6557 - val_accuracy: 0.9736 - val_auc: 0.4401\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.85684\n",
      "Epoch 48/100\n",
      "269/269 - 6s - loss: 0.4664 - accuracy: 0.9495 - auc: 0.9117 - val_loss: 0.5655 - val_accuracy: 0.8998 - val_auc: 0.7529\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.85684\n",
      "Epoch 49/100\n",
      "269/269 - 6s - loss: 0.4087 - accuracy: 0.9606 - auc: 0.9358 - val_loss: 0.5439 - val_accuracy: 0.9262 - val_auc: 0.6905\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.85684\n",
      "Epoch 50/100\n",
      "269/269 - 6s - loss: 0.3991 - accuracy: 0.9514 - auc: 0.9311 - val_loss: 0.4983 - val_accuracy: 0.9156 - val_auc: 0.6888\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.85684\n",
      "Epoch 51/100\n",
      "269/269 - 6s - loss: 0.3766 - accuracy: 0.9594 - auc: 0.9422 - val_loss: 0.5897 - val_accuracy: 0.9701 - val_auc: 0.5504\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.85684\n",
      "Epoch 52/100\n",
      "269/269 - 6s - loss: 0.3955 - accuracy: 0.9529 - auc: 0.9370 - val_loss: 0.5138 - val_accuracy: 0.9367 - val_auc: 0.6981\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.85684\n",
      "Epoch 53/100\n",
      "269/269 - 6s - loss: 0.4114 - accuracy: 0.9507 - auc: 0.9299 - val_loss: 0.5163 - val_accuracy: 0.9209 - val_auc: 0.7063\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.85684\n",
      "Epoch 54/100\n",
      "269/269 - 6s - loss: 0.5694 - accuracy: 0.9329 - auc: 0.9205 - val_loss: 0.6753 - val_accuracy: 0.8805 - val_auc: 0.6844\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.85684\n",
      "Epoch 55/100\n",
      "269/269 - 6s - loss: 0.4600 - accuracy: 0.9521 - auc: 0.9414 - val_loss: 0.6199 - val_accuracy: 0.9666 - val_auc: 0.5343\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.85684\n",
      "Epoch 56/100\n",
      "269/269 - 6s - loss: 0.4428 - accuracy: 0.9459 - auc: 0.9370 - val_loss: 0.6232 - val_accuracy: 0.9613 - val_auc: 0.6031\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.85684\n",
      "Epoch 57/100\n",
      "269/269 - 6s - loss: 0.4915 - accuracy: 0.9513 - auc: 0.9385 - val_loss: 1.3693 - val_accuracy: 0.0246 - val_auc: 0.6864\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.85684\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 - 6s - loss: 0.5450 - accuracy: 0.9538 - auc: 0.9436 - val_loss: 0.5591 - val_accuracy: 0.8840 - val_auc: 0.7311\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.85684\n",
      "Epoch 59/100\n",
      "269/269 - 6s - loss: 0.4090 - accuracy: 0.9519 - auc: 0.9372 - val_loss: 0.6067 - val_accuracy: 0.9455 - val_auc: 0.7058\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.85684\n",
      "Epoch 60/100\n",
      "269/269 - 6s - loss: 0.5192 - accuracy: 0.9365 - auc: 0.9188 - val_loss: 0.6096 - val_accuracy: 0.9561 - val_auc: 0.6058\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.85684\n",
      "Epoch 61/100\n",
      "269/269 - 6s - loss: 0.4017 - accuracy: 0.9614 - auc: 0.9390 - val_loss: 0.5753 - val_accuracy: 0.9613 - val_auc: 0.5827\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.85684\n",
      "Epoch 62/100\n",
      "269/269 - 6s - loss: 0.3990 - accuracy: 0.9532 - auc: 0.9434 - val_loss: 0.5415 - val_accuracy: 0.9578 - val_auc: 0.6639\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.85684\n",
      "Epoch 63/100\n",
      "269/269 - 6s - loss: 0.3762 - accuracy: 0.9581 - auc: 0.9429 - val_loss: 0.6139 - val_accuracy: 0.9649 - val_auc: 0.5625\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.85684\n",
      "Epoch 64/100\n",
      "269/269 - 6s - loss: 0.3478 - accuracy: 0.9650 - auc: 0.9563 - val_loss: 0.6798 - val_accuracy: 0.9631 - val_auc: 0.6599\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.85684\n",
      "Epoch 65/100\n",
      "269/269 - 6s - loss: 0.3370 - accuracy: 0.9374 - auc: 0.9605 - val_loss: 0.5639 - val_accuracy: 0.9438 - val_auc: 0.7649\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.85684\n",
      "Epoch 66/100\n",
      "269/269 - 6s - loss: 0.4412 - accuracy: 0.9475 - auc: 0.9254 - val_loss: 0.5741 - val_accuracy: 0.9631 - val_auc: 0.4931\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.85684\n",
      "Epoch 67/100\n",
      "269/269 - 6s - loss: 0.4523 - accuracy: 0.9540 - auc: 0.9043 - val_loss: 0.5252 - val_accuracy: 0.9736 - val_auc: 0.6064\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.85684\n",
      "Epoch 68/100\n",
      "269/269 - 6s - loss: 0.4462 - accuracy: 0.9615 - auc: 0.9017 - val_loss: 0.5247 - val_accuracy: 0.9772 - val_auc: 0.5869\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.85684\n",
      "Epoch 69/100\n",
      "269/269 - 6s - loss: 0.4234 - accuracy: 0.9742 - auc: 0.9135 - val_loss: 0.5000 - val_accuracy: 0.9561 - val_auc: 0.7015\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.85684\n",
      "Epoch 70/100\n",
      "269/269 - 6s - loss: 0.5340 - accuracy: 0.9593 - auc: 0.8803 - val_loss: 0.5153 - val_accuracy: 0.9772 - val_auc: 0.6781\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.85684\n",
      "Epoch 71/100\n",
      "269/269 - 6s - loss: 0.5270 - accuracy: 0.9215 - auc: 0.9016 - val_loss: 0.7880 - val_accuracy: 0.9754 - val_auc: 0.3456\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.85684\n",
      "Epoch 72/100\n",
      "269/269 - 6s - loss: 0.8470 - accuracy: 0.9515 - auc: 0.8590 - val_loss: 0.8113 - val_accuracy: 0.9754 - val_auc: 0.5574\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.85684\n",
      "Epoch 73/100\n",
      "269/269 - 6s - loss: 0.5532 - accuracy: 0.9653 - auc: 0.8926 - val_loss: 0.5634 - val_accuracy: 0.9789 - val_auc: 0.6073\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.85684\n",
      "Epoch 74/100\n",
      "269/269 - 6s - loss: 0.4618 - accuracy: 0.9409 - auc: 0.9156 - val_loss: 0.5494 - val_accuracy: 0.9736 - val_auc: 0.6658\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.85684\n",
      "Epoch 75/100\n",
      "269/269 - 6s - loss: 0.4481 - accuracy: 0.9492 - auc: 0.9105 - val_loss: 0.6040 - val_accuracy: 0.9490 - val_auc: 0.7169\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.85684\n",
      "Epoch 76/100\n",
      "269/269 - 6s - loss: 0.5465 - accuracy: 0.9618 - auc: 0.8667 - val_loss: 0.5433 - val_accuracy: 0.9649 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.85684\n",
      "Epoch 77/100\n",
      "269/269 - 6s - loss: 0.4465 - accuracy: 0.9579 - auc: 0.9165 - val_loss: 0.5402 - val_accuracy: 0.8699 - val_auc: 0.6344\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.85684\n",
      "Epoch 78/100\n",
      "269/269 - 6s - loss: 0.4331 - accuracy: 0.9340 - auc: 0.9241 - val_loss: 0.5695 - val_accuracy: 0.9736 - val_auc: 0.6320\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.85684\n",
      "Epoch 79/100\n",
      "269/269 - 6s - loss: 0.4594 - accuracy: 0.9454 - auc: 0.9027 - val_loss: 0.7577 - val_accuracy: 0.9789 - val_auc: 0.5816\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.85684\n",
      "Epoch 80/100\n",
      "269/269 - 6s - loss: 0.5332 - accuracy: 0.9328 - auc: 0.8988 - val_loss: 0.5206 - val_accuracy: 0.9754 - val_auc: 0.6717\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.85684\n",
      "Epoch 81/100\n",
      "269/269 - 6s - loss: 0.5402 - accuracy: 0.9358 - auc: 0.8636 - val_loss: 0.6838 - val_accuracy: 0.9719 - val_auc: 0.5339\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.85684\n",
      "Epoch 82/100\n",
      "269/269 - 6s - loss: 0.5129 - accuracy: 0.9369 - auc: 0.8948 - val_loss: 0.5452 - val_accuracy: 0.9736 - val_auc: 0.6534\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.85684\n",
      "Epoch 83/100\n",
      "269/269 - 6s - loss: 0.4893 - accuracy: 0.9714 - auc: 0.8487 - val_loss: 0.5431 - val_accuracy: 0.9754 - val_auc: 0.5329\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.85684\n",
      "Epoch 84/100\n",
      "269/269 - 6s - loss: 0.4610 - accuracy: 0.9429 - auc: 0.9115 - val_loss: 0.5842 - val_accuracy: 0.8717 - val_auc: 0.5843\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.85684\n",
      "Epoch 85/100\n",
      "269/269 - 6s - loss: 0.5524 - accuracy: 0.9297 - auc: 0.8867 - val_loss: 0.6005 - val_accuracy: 0.9701 - val_auc: 0.7260\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.85684\n",
      "Epoch 86/100\n",
      "269/269 - 6s - loss: 0.4514 - accuracy: 0.9251 - auc: 0.9240 - val_loss: 0.5651 - val_accuracy: 0.9772 - val_auc: 0.6261\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.85684\n",
      "Epoch 87/100\n",
      "269/269 - 6s - loss: 0.4526 - accuracy: 0.9145 - auc: 0.9145 - val_loss: 0.5858 - val_accuracy: 0.9473 - val_auc: 0.2545\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.85684\n",
      "Epoch 88/100\n",
      "269/269 - 6s - loss: 0.5705 - accuracy: 0.9611 - auc: 0.8136 - val_loss: 0.5329 - val_accuracy: 0.9772 - val_auc: 0.5226\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.85684\n",
      "Epoch 89/100\n",
      "269/269 - 6s - loss: 0.4916 - accuracy: 0.9699 - auc: 0.8509 - val_loss: 0.5094 - val_accuracy: 0.9596 - val_auc: 0.5463\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.85684\n",
      "Epoch 90/100\n",
      "269/269 - 6s - loss: 0.5318 - accuracy: 0.9571 - auc: 0.8419 - val_loss: 1.0782 - val_accuracy: 0.9807 - val_auc: 0.5811\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.85684\n",
      "Epoch 91/100\n",
      "269/269 - 6s - loss: 0.7224 - accuracy: 0.9617 - auc: 0.8474 - val_loss: 0.5954 - val_accuracy: 0.9754 - val_auc: 0.6244\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.85684\n",
      "Epoch 92/100\n",
      "269/269 - 6s - loss: 0.5259 - accuracy: 0.9642 - auc: 0.8964 - val_loss: 0.6592 - val_accuracy: 0.9859 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.85684\n",
      "Epoch 93/100\n",
      "269/269 - 6s - loss: 0.8668 - accuracy: 0.9229 - auc: 0.6374 - val_loss: 0.7615 - val_accuracy: 0.9772 - val_auc: 0.5528\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.85684\n",
      "Epoch 94/100\n",
      "269/269 - 6s - loss: 0.7596 - accuracy: 0.9516 - auc: 0.8693 - val_loss: 0.6392 - val_accuracy: 0.9772 - val_auc: 0.5775\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.85684\n",
      "Epoch 95/100\n",
      "269/269 - 6s - loss: 0.6049 - accuracy: 0.9764 - auc: 0.8468 - val_loss: 0.5834 - val_accuracy: 0.9719 - val_auc: 0.4993\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.85684\n",
      "Epoch 96/100\n",
      "269/269 - 6s - loss: 0.5764 - accuracy: 0.9695 - auc: 0.8372 - val_loss: 0.6202 - val_accuracy: 0.9807 - val_auc: 0.5582\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.85684\n",
      "Epoch 97/100\n",
      "269/269 - 6s - loss: 0.5535 - accuracy: 0.9756 - auc: 0.8430 - val_loss: 0.5725 - val_accuracy: 0.9807 - val_auc: 0.6564\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.85684\n",
      "Epoch 98/100\n",
      "269/269 - 6s - loss: 0.5181 - accuracy: 0.9774 - auc: 0.8435 - val_loss: 0.5420 - val_accuracy: 0.9807 - val_auc: 0.6329\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.85684\n",
      "Epoch 99/100\n",
      "269/269 - 6s - loss: 0.5831 - accuracy: 0.9587 - auc: 0.8459 - val_loss: 0.7776 - val_accuracy: 0.9772 - val_auc: 0.5578\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.85684\n",
      "Epoch 100/100\n",
      "269/269 - 6s - loss: 0.5378 - accuracy: 0.9710 - auc: 0.8439 - val_loss: 0.6411 - val_accuracy: 0.9736 - val_auc: 0.6349\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.85684\n",
      "Epoch 1/100\n",
      "242/242 - 8s - loss: 2.9879 - accuracy: 0.5958 - auc: 0.6214 - val_loss: 1.2509 - val_accuracy: 0.6312 - val_auc: 0.7541\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.75407, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 - 6s - loss: 0.9812 - accuracy: 0.7663 - auc: 0.7317 - val_loss: 0.7673 - val_accuracy: 0.6410 - val_auc: 0.7871\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.75407 to 0.78707, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 3/100\n",
      "242/242 - 5s - loss: 0.7488 - accuracy: 0.8010 - auc: 0.7567 - val_loss: 0.6567 - val_accuracy: 0.7357 - val_auc: 0.7879\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.78707 to 0.78790, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 4/100\n",
      "242/242 - 5s - loss: 0.7011 - accuracy: 0.7958 - auc: 0.7571 - val_loss: 0.6150 - val_accuracy: 0.8166 - val_auc: 0.7968\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.78790 to 0.79683, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 5/100\n",
      "242/242 - 5s - loss: 0.6827 - accuracy: 0.7928 - auc: 0.7523 - val_loss: 0.6002 - val_accuracy: 0.8185 - val_auc: 0.8000\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.79683 to 0.79996, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 6/100\n",
      "242/242 - 5s - loss: 0.6460 - accuracy: 0.8208 - auc: 0.7699 - val_loss: 0.6247 - val_accuracy: 0.9231 - val_auc: 0.7914\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.79996\n",
      "Epoch 7/100\n",
      "242/242 - 5s - loss: 0.6358 - accuracy: 0.8174 - auc: 0.7780 - val_loss: 0.5683 - val_accuracy: 0.8540 - val_auc: 0.7930\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.79996\n",
      "Epoch 8/100\n",
      "242/242 - 5s - loss: 0.6267 - accuracy: 0.8263 - auc: 0.7753 - val_loss: 0.5630 - val_accuracy: 0.8481 - val_auc: 0.8008\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.79996 to 0.80081, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 9/100\n",
      "242/242 - 5s - loss: 0.6227 - accuracy: 0.8265 - auc: 0.7825 - val_loss: 0.5818 - val_accuracy: 0.9073 - val_auc: 0.7905\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.80081\n",
      "Epoch 10/100\n",
      "242/242 - 5s - loss: 0.6181 - accuracy: 0.8230 - auc: 0.7819 - val_loss: 0.5733 - val_accuracy: 0.7554 - val_auc: 0.7963\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.80081\n",
      "Epoch 11/100\n",
      "242/242 - 5s - loss: 0.6262 - accuracy: 0.8095 - auc: 0.7751 - val_loss: 0.5697 - val_accuracy: 0.7791 - val_auc: 0.8015\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.80081 to 0.80147, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 12/100\n",
      "242/242 - 5s - loss: 0.6161 - accuracy: 0.8195 - auc: 0.7825 - val_loss: 0.5718 - val_accuracy: 0.8698 - val_auc: 0.7854\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.80147\n",
      "Epoch 13/100\n",
      "242/242 - 5s - loss: 0.6115 - accuracy: 0.8283 - auc: 0.7868 - val_loss: 0.5578 - val_accuracy: 0.8284 - val_auc: 0.7987\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.80147\n",
      "Epoch 14/100\n",
      "242/242 - 6s - loss: 0.6104 - accuracy: 0.8263 - auc: 0.7890 - val_loss: 0.5815 - val_accuracy: 0.8067 - val_auc: 0.7948\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.80147\n",
      "Epoch 15/100\n",
      "242/242 - 5s - loss: 0.6131 - accuracy: 0.8182 - auc: 0.7926 - val_loss: 0.5571 - val_accuracy: 0.8679 - val_auc: 0.7987\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.80147\n",
      "Epoch 16/100\n",
      "242/242 - 5s - loss: 0.6040 - accuracy: 0.8236 - auc: 0.7897 - val_loss: 0.5761 - val_accuracy: 0.8757 - val_auc: 0.7774\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.80147\n",
      "Epoch 17/100\n",
      "242/242 - 5s - loss: 0.5982 - accuracy: 0.8214 - auc: 0.7970 - val_loss: 0.5644 - val_accuracy: 0.8481 - val_auc: 0.7925\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.80147\n",
      "Epoch 18/100\n",
      "242/242 - 5s - loss: 0.5973 - accuracy: 0.8240 - auc: 0.7983 - val_loss: 0.5652 - val_accuracy: 0.8521 - val_auc: 0.7907\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.80147\n",
      "Epoch 19/100\n",
      "242/242 - 5s - loss: 0.6050 - accuracy: 0.8334 - auc: 0.7943 - val_loss: 0.5647 - val_accuracy: 0.8442 - val_auc: 0.8017\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.80147 to 0.80173, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 20/100\n",
      "242/242 - 5s - loss: 0.6015 - accuracy: 0.8288 - auc: 0.7957 - val_loss: 0.5653 - val_accuracy: 0.8323 - val_auc: 0.7908\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.80173\n",
      "Epoch 21/100\n",
      "242/242 - 5s - loss: 0.5941 - accuracy: 0.8261 - auc: 0.8030 - val_loss: 0.5634 - val_accuracy: 0.8718 - val_auc: 0.7835\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.80173\n",
      "Epoch 22/100\n",
      "242/242 - 5s - loss: 0.5985 - accuracy: 0.8174 - auc: 0.7940 - val_loss: 0.6327 - val_accuracy: 0.6607 - val_auc: 0.8019\n",
      "\n",
      "Epoch 00022: val_auc improved from 0.80173 to 0.80188, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 23/100\n",
      "242/242 - 5s - loss: 0.6133 - accuracy: 0.8182 - auc: 0.8027 - val_loss: 0.6574 - val_accuracy: 0.6154 - val_auc: 0.8038\n",
      "\n",
      "Epoch 00023: val_auc improved from 0.80188 to 0.80376, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 24/100\n",
      "242/242 - 5s - loss: 0.5932 - accuracy: 0.8166 - auc: 0.8057 - val_loss: 0.5694 - val_accuracy: 0.8442 - val_auc: 0.7937\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.80376\n",
      "Epoch 25/100\n",
      "242/242 - 6s - loss: 0.6233 - accuracy: 0.8052 - auc: 0.8041 - val_loss: 0.5678 - val_accuracy: 0.8205 - val_auc: 0.8006\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.80376\n",
      "Epoch 26/100\n",
      "242/242 - 5s - loss: 0.5979 - accuracy: 0.8197 - auc: 0.8070 - val_loss: 0.5838 - val_accuracy: 0.6864 - val_auc: 0.8049\n",
      "\n",
      "Epoch 00026: val_auc improved from 0.80376 to 0.80495, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 27/100\n",
      "242/242 - 5s - loss: 0.5858 - accuracy: 0.8305 - auc: 0.8075 - val_loss: 0.5891 - val_accuracy: 0.9073 - val_auc: 0.7951\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.80495\n",
      "Epoch 28/100\n",
      "242/242 - 5s - loss: 0.5917 - accuracy: 0.8153 - auc: 0.8050 - val_loss: 0.5543 - val_accuracy: 0.8225 - val_auc: 0.8026\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.80495\n",
      "Epoch 29/100\n",
      "242/242 - 6s - loss: 0.5760 - accuracy: 0.8372 - auc: 0.8119 - val_loss: 0.6093 - val_accuracy: 0.6864 - val_auc: 0.8120\n",
      "\n",
      "Epoch 00029: val_auc improved from 0.80495 to 0.81204, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 30/100\n",
      "242/242 - 6s - loss: 0.5845 - accuracy: 0.8184 - auc: 0.8114 - val_loss: 0.5747 - val_accuracy: 0.8639 - val_auc: 0.7758\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.81204\n",
      "Epoch 31/100\n",
      "242/242 - 6s - loss: 0.6141 - accuracy: 0.8215 - auc: 0.8060 - val_loss: 0.5594 - val_accuracy: 0.8462 - val_auc: 0.7869\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.81204\n",
      "Epoch 32/100\n",
      "242/242 - 6s - loss: 0.5882 - accuracy: 0.8162 - auc: 0.8111 - val_loss: 0.5632 - val_accuracy: 0.7909 - val_auc: 0.8070\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.81204\n",
      "Epoch 33/100\n",
      "242/242 - 6s - loss: 0.6037 - accuracy: 0.8140 - auc: 0.8092 - val_loss: 0.6573 - val_accuracy: 0.7219 - val_auc: 0.7821\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.81204\n",
      "Epoch 34/100\n",
      "242/242 - 6s - loss: 0.6095 - accuracy: 0.8255 - auc: 0.8129 - val_loss: 0.5557 - val_accuracy: 0.8343 - val_auc: 0.8039\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.81204\n",
      "Epoch 35/100\n",
      "242/242 - 6s - loss: 0.5914 - accuracy: 0.8262 - auc: 0.8184 - val_loss: 0.5539 - val_accuracy: 0.8126 - val_auc: 0.7984\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.81204\n",
      "Epoch 36/100\n",
      "242/242 - 6s - loss: 0.5852 - accuracy: 0.8263 - auc: 0.8179 - val_loss: 0.5769 - val_accuracy: 0.8935 - val_auc: 0.7993\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.81204\n",
      "Epoch 37/100\n",
      "242/242 - 6s - loss: 0.5856 - accuracy: 0.8281 - auc: 0.8161 - val_loss: 0.5454 - val_accuracy: 0.7968 - val_auc: 0.8118\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.81204\n",
      "Epoch 38/100\n",
      "242/242 - 6s - loss: 0.5677 - accuracy: 0.8325 - auc: 0.8217 - val_loss: 0.5415 - val_accuracy: 0.8402 - val_auc: 0.7974\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.81204\n",
      "Epoch 39/100\n",
      "242/242 - 6s - loss: 0.5895 - accuracy: 0.8122 - auc: 0.8157 - val_loss: 0.5692 - val_accuracy: 0.7653 - val_auc: 0.8029\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.81204\n",
      "Epoch 40/100\n",
      "242/242 - 6s - loss: 0.5596 - accuracy: 0.8232 - auc: 0.8341 - val_loss: 0.5472 - val_accuracy: 0.8146 - val_auc: 0.7994\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.81204\n",
      "Epoch 41/100\n",
      "242/242 - 6s - loss: 0.5651 - accuracy: 0.8195 - auc: 0.8267 - val_loss: 0.5466 - val_accuracy: 0.7909 - val_auc: 0.8115\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.81204\n",
      "Epoch 42/100\n",
      "242/242 - 5s - loss: 0.5674 - accuracy: 0.8318 - auc: 0.8263 - val_loss: 0.5393 - val_accuracy: 0.8323 - val_auc: 0.8167\n",
      "\n",
      "Epoch 00042: val_auc improved from 0.81204 to 0.81665, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "242/242 - 6s - loss: 0.5581 - accuracy: 0.8318 - auc: 0.8340 - val_loss: 0.5431 - val_accuracy: 0.8679 - val_auc: 0.8067\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.81665\n",
      "Epoch 44/100\n",
      "242/242 - 6s - loss: 0.5624 - accuracy: 0.8266 - auc: 0.8287 - val_loss: 0.5479 - val_accuracy: 0.8817 - val_auc: 0.7958\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.81665\n",
      "Epoch 45/100\n",
      "242/242 - 6s - loss: 0.9513 - accuracy: 0.8067 - auc: 0.7728 - val_loss: 1.3208 - val_accuracy: 0.9014 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.81665\n",
      "Epoch 46/100\n",
      "242/242 - 6s - loss: 1.0865 - accuracy: 0.8513 - auc: 0.4903 - val_loss: 1.1180 - val_accuracy: 0.9014 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.81665\n",
      "Epoch 47/100\n",
      "242/242 - 6s - loss: 0.9360 - accuracy: 0.8386 - auc: 0.4986 - val_loss: 0.9667 - val_accuracy: 0.9014 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.81665\n",
      "Epoch 48/100\n",
      "242/242 - 5s - loss: 0.8993 - accuracy: 0.8635 - auc: 0.4919 - val_loss: 0.7811 - val_accuracy: 0.9014 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.81665\n",
      "Epoch 49/100\n",
      "242/242 - 5s - loss: 0.7221 - accuracy: 0.8068 - auc: 0.7790 - val_loss: 0.6467 - val_accuracy: 0.8521 - val_auc: 0.8058\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.81665\n",
      "Epoch 50/100\n",
      "242/242 - 5s - loss: 0.6252 - accuracy: 0.8170 - auc: 0.8259 - val_loss: 0.5828 - val_accuracy: 0.8718 - val_auc: 0.8105\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.81665\n",
      "Epoch 51/100\n",
      "242/242 - 5s - loss: 0.6028 - accuracy: 0.8178 - auc: 0.8177 - val_loss: 0.5785 - val_accuracy: 0.7554 - val_auc: 0.7904\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.81665\n",
      "Epoch 52/100\n",
      "242/242 - 5s - loss: 0.5741 - accuracy: 0.8149 - auc: 0.8320 - val_loss: 0.5563 - val_accuracy: 0.7554 - val_auc: 0.8239\n",
      "\n",
      "Epoch 00052: val_auc improved from 0.81665 to 0.82389, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 53/100\n",
      "242/242 - 6s - loss: 0.5705 - accuracy: 0.8274 - auc: 0.8357 - val_loss: 0.5578 - val_accuracy: 0.8659 - val_auc: 0.8242\n",
      "\n",
      "Epoch 00053: val_auc improved from 0.82389 to 0.82425, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 54/100\n",
      "242/242 - 5s - loss: 0.5944 - accuracy: 0.8303 - auc: 0.8311 - val_loss: 0.5368 - val_accuracy: 0.8560 - val_auc: 0.8245\n",
      "\n",
      "Epoch 00054: val_auc improved from 0.82425 to 0.82453, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 55/100\n",
      "242/242 - 5s - loss: 0.5634 - accuracy: 0.8301 - auc: 0.8363 - val_loss: 0.5443 - val_accuracy: 0.8422 - val_auc: 0.8027\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.82453\n",
      "Epoch 56/100\n",
      "242/242 - 5s - loss: 0.5532 - accuracy: 0.8268 - auc: 0.8405 - val_loss: 0.5491 - val_accuracy: 0.8462 - val_auc: 0.8095\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.82453\n",
      "Epoch 57/100\n",
      "242/242 - 5s - loss: 0.5478 - accuracy: 0.8252 - auc: 0.8459 - val_loss: 0.5592 - val_accuracy: 0.8028 - val_auc: 0.8149\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.82453\n",
      "Epoch 58/100\n",
      "242/242 - 5s - loss: 0.5831 - accuracy: 0.8182 - auc: 0.8348 - val_loss: 0.5457 - val_accuracy: 0.8264 - val_auc: 0.8175\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.82453\n",
      "Epoch 59/100\n",
      "242/242 - 6s - loss: 0.5550 - accuracy: 0.8325 - auc: 0.8390 - val_loss: 0.5430 - val_accuracy: 0.7811 - val_auc: 0.8127\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.82453\n",
      "Epoch 60/100\n",
      "242/242 - 5s - loss: 0.5514 - accuracy: 0.8230 - auc: 0.8421 - val_loss: 0.5401 - val_accuracy: 0.8915 - val_auc: 0.8120\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.82453\n",
      "Epoch 61/100\n",
      "242/242 - 5s - loss: 0.6155 - accuracy: 0.8087 - auc: 0.8378 - val_loss: 0.5846 - val_accuracy: 0.7298 - val_auc: 0.8192\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.82453\n",
      "Epoch 62/100\n",
      "242/242 - 5s - loss: 0.5537 - accuracy: 0.8246 - auc: 0.8424 - val_loss: 0.5285 - val_accuracy: 0.8619 - val_auc: 0.8195\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.82453\n",
      "Epoch 63/100\n",
      "242/242 - 6s - loss: 0.5389 - accuracy: 0.8341 - auc: 0.8488 - val_loss: 0.5557 - val_accuracy: 0.7318 - val_auc: 0.8229\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.82453\n",
      "Epoch 64/100\n",
      "242/242 - 6s - loss: 0.5461 - accuracy: 0.8274 - auc: 0.8462 - val_loss: 0.5458 - val_accuracy: 0.8225 - val_auc: 0.8023\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.82453\n",
      "Epoch 65/100\n",
      "242/242 - 6s - loss: 0.5337 - accuracy: 0.8284 - auc: 0.8524 - val_loss: 0.5502 - val_accuracy: 0.8107 - val_auc: 0.7993\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.82453\n",
      "Epoch 66/100\n",
      "242/242 - 6s - loss: 0.5412 - accuracy: 0.8293 - auc: 0.8529 - val_loss: 0.5656 - val_accuracy: 0.7396 - val_auc: 0.8205\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.82453\n",
      "Epoch 67/100\n",
      "242/242 - 6s - loss: 0.5403 - accuracy: 0.8241 - auc: 0.8547 - val_loss: 0.5934 - val_accuracy: 0.9112 - val_auc: 0.7963\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.82453\n",
      "Epoch 68/100\n",
      "242/242 - 5s - loss: 0.5402 - accuracy: 0.8305 - auc: 0.8520 - val_loss: 0.5470 - val_accuracy: 0.8836 - val_auc: 0.8077\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.82453\n",
      "Epoch 69/100\n",
      "242/242 - 6s - loss: 0.5396 - accuracy: 0.8457 - auc: 0.8517 - val_loss: 0.5656 - val_accuracy: 0.7396 - val_auc: 0.8206\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.82453\n",
      "Epoch 70/100\n",
      "242/242 - 6s - loss: 0.6630 - accuracy: 0.8183 - auc: 0.8402 - val_loss: 0.6893 - val_accuracy: 0.7673 - val_auc: 0.7902\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.82453\n",
      "Epoch 71/100\n",
      "242/242 - 5s - loss: 0.5656 - accuracy: 0.8362 - auc: 0.8517 - val_loss: 0.5797 - val_accuracy: 0.7890 - val_auc: 0.7964\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.82453\n",
      "Epoch 72/100\n",
      "242/242 - 6s - loss: 0.5431 - accuracy: 0.8346 - auc: 0.8546 - val_loss: 0.5516 - val_accuracy: 0.7988 - val_auc: 0.8211\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.82453\n",
      "Epoch 73/100\n",
      "242/242 - 6s - loss: 0.5394 - accuracy: 0.8415 - auc: 0.8574 - val_loss: 0.5977 - val_accuracy: 0.8994 - val_auc: 0.7867\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.82453\n",
      "Epoch 74/100\n",
      "242/242 - 6s - loss: 0.5526 - accuracy: 0.8337 - auc: 0.8529 - val_loss: 0.5294 - val_accuracy: 0.8600 - val_auc: 0.8318\n",
      "\n",
      "Epoch 00074: val_auc improved from 0.82453 to 0.83179, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 75/100\n",
      "242/242 - 6s - loss: 0.5451 - accuracy: 0.8323 - auc: 0.8473 - val_loss: 0.5410 - val_accuracy: 0.8008 - val_auc: 0.8146\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.83179\n",
      "Epoch 76/100\n",
      "242/242 - 6s - loss: 0.5329 - accuracy: 0.8243 - auc: 0.8580 - val_loss: 0.5382 - val_accuracy: 0.8856 - val_auc: 0.8138\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.83179\n",
      "Epoch 77/100\n",
      "242/242 - 5s - loss: 0.5230 - accuracy: 0.8329 - auc: 0.8665 - val_loss: 0.5330 - val_accuracy: 0.8501 - val_auc: 0.8224\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.83179\n",
      "Epoch 78/100\n",
      "242/242 - 6s - loss: 0.5185 - accuracy: 0.8377 - auc: 0.8672 - val_loss: 0.5342 - val_accuracy: 0.7712 - val_auc: 0.8360\n",
      "\n",
      "Epoch 00078: val_auc improved from 0.83179 to 0.83602, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 79/100\n",
      "242/242 - 6s - loss: 0.5273 - accuracy: 0.8297 - auc: 0.8621 - val_loss: 0.5233 - val_accuracy: 0.8363 - val_auc: 0.8272\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.83602\n",
      "Epoch 80/100\n",
      "242/242 - 5s - loss: 0.5332 - accuracy: 0.8377 - auc: 0.8691 - val_loss: 0.5664 - val_accuracy: 0.8521 - val_auc: 0.8384\n",
      "\n",
      "Epoch 00080: val_auc improved from 0.83602 to 0.83836, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER\n",
      "Epoch 81/100\n",
      "242/242 - 5s - loss: 0.5474 - accuracy: 0.8257 - auc: 0.8658 - val_loss: 0.6043 - val_accuracy: 0.8600 - val_auc: 0.7996\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.83836\n",
      "Epoch 82/100\n",
      "242/242 - 5s - loss: 0.5301 - accuracy: 0.8262 - auc: 0.8656 - val_loss: 0.5366 - val_accuracy: 0.7771 - val_auc: 0.8176\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.83836\n",
      "Epoch 83/100\n",
      "242/242 - 5s - loss: 0.5152 - accuracy: 0.8222 - auc: 0.8727 - val_loss: 0.6138 - val_accuracy: 0.7258 - val_auc: 0.7667\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.83836\n",
      "Epoch 84/100\n",
      "242/242 - 5s - loss: 0.5264 - accuracy: 0.8294 - auc: 0.8603 - val_loss: 0.5462 - val_accuracy: 0.8166 - val_auc: 0.8090\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.83836\n",
      "Epoch 85/100\n",
      "242/242 - 5s - loss: 0.5220 - accuracy: 0.8404 - auc: 0.8627 - val_loss: 0.5444 - val_accuracy: 0.7949 - val_auc: 0.8106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: val_auc did not improve from 0.83836\n",
      "Epoch 86/100\n",
      "242/242 - 5s - loss: 0.5205 - accuracy: 0.8362 - auc: 0.8636 - val_loss: 0.5265 - val_accuracy: 0.8560 - val_auc: 0.8225\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.83836\n",
      "Epoch 87/100\n",
      "242/242 - 5s - loss: 0.5309 - accuracy: 0.8343 - auc: 0.8595 - val_loss: 0.5566 - val_accuracy: 0.8560 - val_auc: 0.8143\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.83836\n",
      "Epoch 88/100\n",
      "242/242 - 5s - loss: 0.5387 - accuracy: 0.8334 - auc: 0.8632 - val_loss: 0.5559 - val_accuracy: 0.8383 - val_auc: 0.7956\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.83836\n",
      "Epoch 89/100\n",
      "242/242 - 5s - loss: 0.5200 - accuracy: 0.8296 - auc: 0.8690 - val_loss: 0.5494 - val_accuracy: 0.7653 - val_auc: 0.8204\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.83836\n",
      "Epoch 90/100\n",
      "242/242 - 5s - loss: 0.5156 - accuracy: 0.8321 - auc: 0.8722 - val_loss: 0.5628 - val_accuracy: 0.7574 - val_auc: 0.8264\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.83836\n",
      "Epoch 91/100\n",
      "242/242 - 5s - loss: 0.5153 - accuracy: 0.8261 - auc: 0.8733 - val_loss: 0.5727 - val_accuracy: 0.8659 - val_auc: 0.8011\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.83836\n",
      "Epoch 92/100\n",
      "242/242 - 5s - loss: 0.5157 - accuracy: 0.8266 - auc: 0.8737 - val_loss: 0.5790 - val_accuracy: 0.7495 - val_auc: 0.8160\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.83836\n",
      "Epoch 93/100\n",
      "242/242 - 6s - loss: 0.5171 - accuracy: 0.8311 - auc: 0.8761 - val_loss: 0.5497 - val_accuracy: 0.7673 - val_auc: 0.8332\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.83836\n",
      "Epoch 94/100\n",
      "242/242 - 5s - loss: 0.5152 - accuracy: 0.8338 - auc: 0.8785 - val_loss: 0.5700 - val_accuracy: 0.8659 - val_auc: 0.8061\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.83836\n",
      "Epoch 95/100\n",
      "242/242 - 6s - loss: 0.5114 - accuracy: 0.8336 - auc: 0.8795 - val_loss: 0.6002 - val_accuracy: 0.8679 - val_auc: 0.7788\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.83836\n",
      "Epoch 96/100\n",
      "242/242 - 5s - loss: 0.5244 - accuracy: 0.8310 - auc: 0.8723 - val_loss: 0.5526 - val_accuracy: 0.8383 - val_auc: 0.8081\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.83836\n",
      "Epoch 97/100\n",
      "242/242 - 5s - loss: 0.5088 - accuracy: 0.8483 - auc: 0.8829 - val_loss: 0.6075 - val_accuracy: 0.6746 - val_auc: 0.8056\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.83836\n",
      "Epoch 98/100\n",
      "242/242 - 5s - loss: 0.5363 - accuracy: 0.8254 - auc: 0.8760 - val_loss: 0.5940 - val_accuracy: 0.7120 - val_auc: 0.8280\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.83836\n",
      "Epoch 99/100\n",
      "242/242 - 6s - loss: 0.5144 - accuracy: 0.8337 - auc: 0.8833 - val_loss: 0.5839 - val_accuracy: 0.7515 - val_auc: 0.8161\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.83836\n",
      "Epoch 100/100\n",
      "242/242 - 6s - loss: 0.5135 - accuracy: 0.8345 - auc: 0.8778 - val_loss: 0.5696 - val_accuracy: 0.8205 - val_auc: 0.7832\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.83836\n",
      "Epoch 1/100\n",
      "274/274 - 10s - loss: 3.6841 - accuracy: 0.6500 - auc: 0.6410 - val_loss: 1.7643 - val_accuracy: 0.9676 - val_auc: 0.7274\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.72743, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER-LBD\n",
      "Epoch 2/100\n",
      "274/274 - 6s - loss: 1.1537 - accuracy: 0.8740 - auc: 0.8009 - val_loss: 0.8461 - val_accuracy: 0.9370 - val_auc: 0.7526\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.72743 to 0.75260, saving model to 210120_TrainingDeep\\210120_Dense_NR-ER-LBD\n",
      "Epoch 3/100\n",
      "274/274 - 6s - loss: 0.7566 - accuracy: 0.8745 - auc: 0.8183 - val_loss: 0.7353 - val_accuracy: 0.7836 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.75260\n",
      "Epoch 4/100\n",
      "274/274 - 6s - loss: 0.6838 - accuracy: 0.8807 - auc: 0.8216 - val_loss: 0.6864 - val_accuracy: 0.8092 - val_auc: 0.7443\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.75260\n",
      "Epoch 5/100\n",
      "274/274 - 6s - loss: 0.6250 - accuracy: 0.8776 - auc: 0.8388 - val_loss: 0.6274 - val_accuracy: 0.8995 - val_auc: 0.7310\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.75260\n",
      "Epoch 6/100\n",
      "274/274 - 6s - loss: 0.5948 - accuracy: 0.8807 - auc: 0.8446 - val_loss: 0.6430 - val_accuracy: 0.7734 - val_auc: 0.7084\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.75260\n",
      "Epoch 7/100\n",
      "274/274 - 6s - loss: 0.5683 - accuracy: 0.8775 - auc: 0.8561 - val_loss: 0.6346 - val_accuracy: 0.7853 - val_auc: 0.7223\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.75260\n",
      "Epoch 8/100\n",
      "274/274 - 6s - loss: 0.5559 - accuracy: 0.8758 - auc: 0.8636 - val_loss: 0.6892 - val_accuracy: 0.8399 - val_auc: 0.7287\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.75260\n",
      "Epoch 9/100\n",
      "274/274 - 6s - loss: 0.5436 - accuracy: 0.8721 - auc: 0.8633 - val_loss: 0.6588 - val_accuracy: 0.7717 - val_auc: 0.7197\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.75260\n",
      "Epoch 10/100\n",
      "274/274 - 6s - loss: 0.5411 - accuracy: 0.8658 - auc: 0.8677 - val_loss: 0.6391 - val_accuracy: 0.8739 - val_auc: 0.7016\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.75260\n",
      "Epoch 11/100\n",
      "274/274 - 6s - loss: 0.5312 - accuracy: 0.8629 - auc: 0.8694 - val_loss: 0.6045 - val_accuracy: 0.8739 - val_auc: 0.7147\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.75260\n",
      "Epoch 12/100\n",
      "274/274 - 6s - loss: 0.5186 - accuracy: 0.8675 - auc: 0.8739 - val_loss: 0.6128 - val_accuracy: 0.9267 - val_auc: 0.7000\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.75260\n",
      "Epoch 13/100\n",
      "274/274 - 6s - loss: 0.5019 - accuracy: 0.8748 - auc: 0.8832 - val_loss: 0.7322 - val_accuracy: 0.8433 - val_auc: 0.7000\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75260\n",
      "Epoch 14/100\n",
      "274/274 - 6s - loss: 0.5143 - accuracy: 0.8683 - auc: 0.8777 - val_loss: 0.6445 - val_accuracy: 0.6746 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.75260\n",
      "Epoch 15/100\n",
      "274/274 - 6s - loss: 0.5088 - accuracy: 0.8676 - auc: 0.8829 - val_loss: 0.7087 - val_accuracy: 0.7802 - val_auc: 0.7182\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75260\n",
      "Epoch 16/100\n",
      "274/274 - 6s - loss: 0.5290 - accuracy: 0.8526 - auc: 0.8780 - val_loss: 0.6115 - val_accuracy: 0.8790 - val_auc: 0.7054\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.75260\n",
      "Epoch 17/100\n",
      "274/274 - 6s - loss: 0.4895 - accuracy: 0.8687 - auc: 0.8932 - val_loss: 0.6230 - val_accuracy: 0.8348 - val_auc: 0.6964\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.75260\n",
      "Epoch 18/100\n",
      "274/274 - 6s - loss: 0.4913 - accuracy: 0.8651 - auc: 0.8914 - val_loss: 0.6013 - val_accuracy: 0.8688 - val_auc: 0.6870\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.75260\n",
      "Epoch 19/100\n",
      "274/274 - 6s - loss: 0.4675 - accuracy: 0.8728 - auc: 0.9053 - val_loss: 0.6951 - val_accuracy: 0.8995 - val_auc: 0.6819\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.75260\n",
      "Epoch 20/100\n",
      "274/274 - 6s - loss: 0.4704 - accuracy: 0.8675 - auc: 0.9011 - val_loss: 0.6701 - val_accuracy: 0.8842 - val_auc: 0.6695\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.75260\n",
      "Epoch 21/100\n",
      "274/274 - 6s - loss: 0.4799 - accuracy: 0.8666 - auc: 0.8980 - val_loss: 0.6435 - val_accuracy: 0.8024 - val_auc: 0.6847\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.75260\n",
      "Epoch 22/100\n",
      "274/274 - 6s - loss: 0.4681 - accuracy: 0.8743 - auc: 0.9072 - val_loss: 0.6014 - val_accuracy: 0.8790 - val_auc: 0.6798\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.75260\n",
      "Epoch 23/100\n",
      "274/274 - 6s - loss: 0.4870 - accuracy: 0.8605 - auc: 0.9008 - val_loss: 0.7032 - val_accuracy: 0.9148 - val_auc: 0.6569\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.75260\n",
      "Epoch 24/100\n",
      "274/274 - 6s - loss: 0.6664 - accuracy: 0.8554 - auc: 0.8798 - val_loss: 1.2456 - val_accuracy: 0.9046 - val_auc: 0.5946\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.75260\n",
      "Epoch 25/100\n",
      "274/274 - 6s - loss: 0.6984 - accuracy: 0.8467 - auc: 0.8967 - val_loss: 0.7854 - val_accuracy: 0.7632 - val_auc: 0.6871\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.75260\n",
      "Epoch 26/100\n",
      "274/274 - 6s - loss: 0.5133 - accuracy: 0.8623 - auc: 0.9149 - val_loss: 0.7294 - val_accuracy: 0.8399 - val_auc: 0.6771\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.75260\n",
      "Epoch 27/100\n",
      "274/274 - 6s - loss: 0.4976 - accuracy: 0.8532 - auc: 0.9087 - val_loss: 0.6473 - val_accuracy: 0.8978 - val_auc: 0.6832\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.75260\n",
      "Epoch 28/100\n",
      "274/274 - 6s - loss: 0.5408 - accuracy: 0.8720 - auc: 0.8986 - val_loss: 0.7511 - val_accuracy: 0.8603 - val_auc: 0.6876\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.75260\n",
      "Epoch 29/100\n",
      "274/274 - 6s - loss: 0.4803 - accuracy: 0.8637 - auc: 0.9163 - val_loss: 0.8938 - val_accuracy: 0.5571 - val_auc: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_auc did not improve from 0.75260\n",
      "Epoch 30/100\n",
      "274/274 - 6s - loss: 0.4697 - accuracy: 0.8629 - auc: 0.9128 - val_loss: 0.8142 - val_accuracy: 0.8705 - val_auc: 0.6724\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.75260\n",
      "Epoch 31/100\n",
      "274/274 - 6s - loss: 0.5410 - accuracy: 0.8610 - auc: 0.9095 - val_loss: 0.7722 - val_accuracy: 0.9216 - val_auc: 0.6649\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.75260\n",
      "Epoch 32/100\n",
      "274/274 - 6s - loss: 0.4405 - accuracy: 0.8627 - auc: 0.9239 - val_loss: 0.8358 - val_accuracy: 0.9131 - val_auc: 0.6464\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.75260\n",
      "Epoch 33/100\n",
      "274/274 - 6s - loss: 0.4614 - accuracy: 0.8613 - auc: 0.9136 - val_loss: 0.6651 - val_accuracy: 0.7956 - val_auc: 0.6670\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.75260\n",
      "Epoch 34/100\n",
      "274/274 - 6s - loss: 0.4305 - accuracy: 0.8524 - auc: 0.9273 - val_loss: 0.6759 - val_accuracy: 0.8262 - val_auc: 0.6809\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.75260\n",
      "Epoch 35/100\n",
      "274/274 - 6s - loss: 0.4294 - accuracy: 0.8622 - auc: 0.9264 - val_loss: 0.7418 - val_accuracy: 0.8773 - val_auc: 0.6838\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.75260\n",
      "Epoch 36/100\n",
      "274/274 - 6s - loss: 0.4345 - accuracy: 0.8535 - auc: 0.9229 - val_loss: 0.7655 - val_accuracy: 0.9114 - val_auc: 0.6391\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.75260\n",
      "Epoch 37/100\n",
      "274/274 - 6s - loss: 0.4230 - accuracy: 0.8563 - auc: 0.9276 - val_loss: 0.7669 - val_accuracy: 0.8228 - val_auc: 0.6642\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.75260\n",
      "Epoch 38/100\n",
      "274/274 - 6s - loss: 0.4255 - accuracy: 0.8759 - auc: 0.9280 - val_loss: 0.7111 - val_accuracy: 0.7564 - val_auc: 0.6953\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.75260\n",
      "Epoch 39/100\n",
      "274/274 - 6s - loss: 0.4275 - accuracy: 0.8608 - auc: 0.9270 - val_loss: 0.6623 - val_accuracy: 0.8450 - val_auc: 0.6696\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.75260\n",
      "Epoch 40/100\n",
      "274/274 - 6s - loss: 0.4291 - accuracy: 0.8686 - auc: 0.9255 - val_loss: 0.9027 - val_accuracy: 0.8978 - val_auc: 0.6671\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.75260\n",
      "Epoch 41/100\n",
      "274/274 - 6s - loss: 0.5783 - accuracy: 0.8194 - auc: 0.9050 - val_loss: 1.1004 - val_accuracy: 0.8024 - val_auc: 0.7212\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.75260\n",
      "Epoch 42/100\n",
      "274/274 - 6s - loss: 0.6714 - accuracy: 0.8263 - auc: 0.9102 - val_loss: 0.7864 - val_accuracy: 0.8910 - val_auc: 0.6548\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.75260\n",
      "Epoch 43/100\n",
      "274/274 - 6s - loss: 0.4983 - accuracy: 0.8379 - auc: 0.9217 - val_loss: 0.9272 - val_accuracy: 0.8348 - val_auc: 0.6534\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.75260\n",
      "Epoch 44/100\n",
      "274/274 - 6s - loss: 0.4292 - accuracy: 0.8441 - auc: 0.9333 - val_loss: 0.6426 - val_accuracy: 0.8893 - val_auc: 0.6702\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.75260\n",
      "Epoch 45/100\n",
      "274/274 - 6s - loss: 0.4134 - accuracy: 0.8615 - auc: 0.9356 - val_loss: 0.8080 - val_accuracy: 0.8552 - val_auc: 0.6665\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.75260\n",
      "Epoch 46/100\n",
      "274/274 - 6s - loss: 0.4037 - accuracy: 0.8537 - auc: 0.9369 - val_loss: 0.9755 - val_accuracy: 0.7819 - val_auc: 0.6886\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.75260\n",
      "Epoch 47/100\n",
      "274/274 - 6s - loss: 0.5022 - accuracy: 0.8352 - auc: 0.9255 - val_loss: 0.8786 - val_accuracy: 0.7462 - val_auc: 0.6899\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.75260\n",
      "Epoch 48/100\n",
      "274/274 - 6s - loss: 0.4607 - accuracy: 0.8444 - auc: 0.9298 - val_loss: 0.8240 - val_accuracy: 0.8825 - val_auc: 0.6836\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.75260\n",
      "Epoch 49/100\n",
      "274/274 - 6s - loss: 0.5565 - accuracy: 0.8245 - auc: 0.9137 - val_loss: 0.8286 - val_accuracy: 0.8910 - val_auc: 0.6777\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.75260\n",
      "Epoch 50/100\n",
      "274/274 - 6s - loss: 0.4932 - accuracy: 0.8610 - auc: 0.9306 - val_loss: 0.8848 - val_accuracy: 0.8228 - val_auc: 0.6603\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.75260\n",
      "Epoch 51/100\n",
      "274/274 - 6s - loss: 0.4023 - accuracy: 0.8643 - auc: 0.9427 - val_loss: 1.0505 - val_accuracy: 0.8484 - val_auc: 0.6750\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.75260\n",
      "Epoch 52/100\n",
      "274/274 - 6s - loss: 0.4244 - accuracy: 0.8459 - auc: 0.9303 - val_loss: 1.0019 - val_accuracy: 0.8807 - val_auc: 0.6339\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.75260\n",
      "Epoch 53/100\n",
      "274/274 - 6s - loss: 0.3996 - accuracy: 0.8660 - auc: 0.9395 - val_loss: 0.7306 - val_accuracy: 0.7581 - val_auc: 0.6688\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.75260\n",
      "Epoch 54/100\n",
      "274/274 - 6s - loss: 0.4093 - accuracy: 0.8524 - auc: 0.9376 - val_loss: 0.8970 - val_accuracy: 0.9029 - val_auc: 0.6393\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.75260\n",
      "Epoch 55/100\n",
      "274/274 - 6s - loss: 0.4021 - accuracy: 0.8683 - auc: 0.9378 - val_loss: 0.7757 - val_accuracy: 0.8893 - val_auc: 0.6358\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.75260\n",
      "Epoch 56/100\n",
      "274/274 - 6s - loss: 0.3935 - accuracy: 0.8500 - auc: 0.9397 - val_loss: 0.7635 - val_accuracy: 0.8433 - val_auc: 0.6271\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.75260\n",
      "Epoch 57/100\n",
      "274/274 - 6s - loss: 0.3912 - accuracy: 0.8576 - auc: 0.9414 - val_loss: 0.8045 - val_accuracy: 0.8688 - val_auc: 0.6670\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.75260\n",
      "Epoch 58/100\n",
      "274/274 - 6s - loss: 0.3906 - accuracy: 0.8540 - auc: 0.9407 - val_loss: 0.7793 - val_accuracy: 0.8467 - val_auc: 0.6564\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.75260\n",
      "Epoch 59/100\n",
      "274/274 - 6s - loss: 0.3982 - accuracy: 0.8595 - auc: 0.9387 - val_loss: 0.8878 - val_accuracy: 0.8859 - val_auc: 0.6592\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.75260\n",
      "Epoch 60/100\n",
      "274/274 - 6s - loss: 0.3894 - accuracy: 0.8511 - auc: 0.9406 - val_loss: 1.2089 - val_accuracy: 0.8279 - val_auc: 0.6658\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.75260\n",
      "Epoch 61/100\n",
      "274/274 - 6s - loss: 0.4175 - accuracy: 0.8518 - auc: 0.9424 - val_loss: 0.9889 - val_accuracy: 0.8927 - val_auc: 0.6269\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.75260\n",
      "Epoch 62/100\n",
      "274/274 - 6s - loss: 0.3872 - accuracy: 0.8535 - auc: 0.9452 - val_loss: 1.2478 - val_accuracy: 0.7939 - val_auc: 0.6148\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.75260\n",
      "Epoch 63/100\n",
      "274/274 - 6s - loss: 1.0792 - accuracy: 0.7035 - auc: 0.8576 - val_loss: 1.0517 - val_accuracy: 0.7564 - val_auc: 0.6521\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.75260\n",
      "Epoch 64/100\n",
      "274/274 - 6s - loss: 0.4645 - accuracy: 0.8763 - auc: 0.9406 - val_loss: 0.7626 - val_accuracy: 0.9046 - val_auc: 0.6491\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.75260\n",
      "Epoch 65/100\n",
      "274/274 - 6s - loss: 0.4349 - accuracy: 0.8654 - auc: 0.9444 - val_loss: 0.8909 - val_accuracy: 0.0852 - val_auc: 0.7054\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.75260\n",
      "Epoch 66/100\n",
      "274/274 - 6s - loss: 0.5378 - accuracy: 0.8170 - auc: 0.9250 - val_loss: 0.8253 - val_accuracy: 0.8109 - val_auc: 0.7264\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.75260\n",
      "Epoch 67/100\n",
      "274/274 - 6s - loss: 0.4088 - accuracy: 0.8462 - auc: 0.9444 - val_loss: 0.8378 - val_accuracy: 0.6985 - val_auc: 0.6662\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.75260\n",
      "Epoch 68/100\n",
      "274/274 - 6s - loss: 0.4950 - accuracy: 0.8164 - auc: 0.9275 - val_loss: 0.8475 - val_accuracy: 0.9319 - val_auc: 0.6591\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.75260\n",
      "Epoch 69/100\n",
      "274/274 - 6s - loss: 0.4160 - accuracy: 0.8583 - auc: 0.9398 - val_loss: 0.9169 - val_accuracy: 0.8825 - val_auc: 0.6644\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.75260\n",
      "Epoch 70/100\n",
      "274/274 - 6s - loss: 0.3814 - accuracy: 0.8515 - auc: 0.9456 - val_loss: 1.0079 - val_accuracy: 0.8177 - val_auc: 0.6691\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.75260\n",
      "Epoch 71/100\n",
      "274/274 - 6s - loss: 0.3741 - accuracy: 0.8408 - auc: 0.9482 - val_loss: 0.8840 - val_accuracy: 0.8092 - val_auc: 0.6995\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.75260\n",
      "Epoch 72/100\n",
      "274/274 - 6s - loss: 0.3638 - accuracy: 0.8562 - auc: 0.9506 - val_loss: 1.0306 - val_accuracy: 0.8279 - val_auc: 0.6904\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.75260\n",
      "Epoch 73/100\n",
      "274/274 - 6s - loss: 0.5286 - accuracy: 0.8303 - auc: 0.9305 - val_loss: 1.2647 - val_accuracy: 0.8807 - val_auc: 0.6743\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.75260\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 - 6s - loss: 5.4286 - accuracy: 0.9112 - auc: 0.5975 - val_loss: 5.5898 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.75260\n",
      "Epoch 75/100\n",
      "274/274 - 6s - loss: 9.1451 - accuracy: 0.9509 - auc: 0.4995 - val_loss: 6.1883 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.75260\n",
      "Epoch 76/100\n",
      "274/274 - 6s - loss: 8.0980 - accuracy: 0.9515 - auc: 0.5048 - val_loss: 6.3943 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.75260\n",
      "Epoch 77/100\n",
      "274/274 - 6s - loss: 3.2077 - accuracy: 0.9506 - auc: 0.4932 - val_loss: 0.9344 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.75260\n",
      "Epoch 78/100\n",
      "274/274 - 6s - loss: 0.9718 - accuracy: 0.9500 - auc: 0.4645 - val_loss: 0.8178 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.75260\n",
      "Epoch 79/100\n",
      "274/274 - 6s - loss: 0.8873 - accuracy: 0.9515 - auc: 0.4967 - val_loss: 0.7588 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.75260\n",
      "Epoch 80/100\n",
      "274/274 - 6s - loss: 0.8393 - accuracy: 0.9514 - auc: 0.4907 - val_loss: 0.7232 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.75260\n",
      "Epoch 81/100\n",
      "274/274 - 6s - loss: 0.8100 - accuracy: 0.9505 - auc: 0.5005 - val_loss: 0.7004 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.75260\n",
      "Epoch 82/100\n",
      "274/274 - 6s - loss: 0.7915 - accuracy: 0.9502 - auc: 0.4903 - val_loss: 0.6855 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.75260\n",
      "Epoch 83/100\n",
      "274/274 - 6s - loss: 0.7799 - accuracy: 0.7397 - auc: 0.4995 - val_loss: 0.6773 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.75260\n",
      "Epoch 84/100\n",
      "274/274 - 6s - loss: 0.7725 - accuracy: 0.5790 - auc: 0.4974 - val_loss: 0.6717 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.75260\n",
      "Epoch 85/100\n",
      "274/274 - 6s - loss: 0.7676 - accuracy: 0.8745 - auc: 0.5001 - val_loss: 0.6675 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.75260\n",
      "Epoch 86/100\n",
      "274/274 - 6s - loss: 0.7656 - accuracy: 0.7332 - auc: 0.4990 - val_loss: 0.6651 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.75260\n",
      "Epoch 87/100\n",
      "274/274 - 6s - loss: 0.7621 - accuracy: 0.7024 - auc: 0.5002 - val_loss: 0.6625 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.75260\n",
      "Epoch 88/100\n",
      "274/274 - 6s - loss: 0.7610 - accuracy: 0.8547 - auc: 0.4816 - val_loss: 0.6606 - val_accuracy: 0.9659 - val_auc: 0.5018\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.75260\n",
      "Epoch 89/100\n",
      "274/274 - 6s - loss: 0.9819 - accuracy: 0.7765 - auc: 0.6270 - val_loss: 0.8187 - val_accuracy: 0.9659 - val_auc: 0.7014\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.75260\n",
      "Epoch 90/100\n",
      "274/274 - 6s - loss: 2.0852 - accuracy: 0.6234 - auc: 0.7060 - val_loss: 8.0856 - val_accuracy: 0.0341 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.75260\n",
      "Epoch 91/100\n",
      "274/274 - 6s - loss: 6.7042 - accuracy: 0.2276 - auc: 0.5237 - val_loss: 2.2487 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.75260\n",
      "Epoch 92/100\n",
      "274/274 - 6s - loss: 1.4187 - accuracy: 0.9506 - auc: 0.4966 - val_loss: 0.9628 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.75260\n",
      "Epoch 93/100\n",
      "274/274 - 6s - loss: 0.9719 - accuracy: 0.9361 - auc: 0.4822 - val_loss: 0.8200 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.75260\n",
      "Epoch 94/100\n",
      "274/274 - 6s - loss: 0.8596 - accuracy: 0.9016 - auc: 0.5503 - val_loss: 0.6980 - val_accuracy: 0.9404 - val_auc: 0.6810\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.75260\n",
      "Epoch 95/100\n",
      "274/274 - 6s - loss: 0.6836 - accuracy: 0.8519 - auc: 0.8240 - val_loss: 1.1086 - val_accuracy: 0.0341 - val_auc: 0.7223\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.75260\n",
      "Epoch 96/100\n",
      "274/274 - 6s - loss: 0.8400 - accuracy: 0.8489 - auc: 0.8146 - val_loss: 0.8798 - val_accuracy: 0.1414 - val_auc: 0.7360\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.75260\n",
      "Epoch 97/100\n",
      "274/274 - 6s - loss: 0.9144 - accuracy: 0.8500 - auc: 0.8297 - val_loss: 0.9701 - val_accuracy: 0.5213 - val_auc: 0.7206\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.75260\n",
      "Epoch 98/100\n",
      "274/274 - 6s - loss: 0.7902 - accuracy: 0.8862 - auc: 0.7037 - val_loss: 0.7180 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.75260\n",
      "Epoch 99/100\n",
      "274/274 - 6s - loss: 0.8251 - accuracy: 0.9515 - auc: 0.5128 - val_loss: 0.6796 - val_accuracy: 0.9659 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.75260\n",
      "Epoch 100/100\n",
      "274/274 - 6s - loss: 0.9326 - accuracy: 0.8993 - auc: 0.7219 - val_loss: 1.1804 - val_accuracy: 0.9421 - val_auc: 0.6335\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.75260\n",
      "Epoch 1/100\n",
      "226/226 - 7s - loss: 4.0035 - accuracy: 0.6257 - auc: 0.6938 - val_loss: 3.0177 - val_accuracy: 0.2843 - val_auc: 0.8098\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.80980, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 2/100\n",
      "226/226 - 5s - loss: 1.9819 - accuracy: 0.5981 - auc: 0.7346 - val_loss: 1.5209 - val_accuracy: 0.5010 - val_auc: 0.8058\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.80980\n",
      "Epoch 3/100\n",
      "226/226 - 5s - loss: 1.1075 - accuracy: 0.6841 - auc: 0.7903 - val_loss: 1.1349 - val_accuracy: 0.6654 - val_auc: 0.8125\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.80980 to 0.81250, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 4/100\n",
      "226/226 - 5s - loss: 0.9654 - accuracy: 0.7079 - auc: 0.7932 - val_loss: 1.4591 - val_accuracy: 0.8569 - val_auc: 0.7876\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.81250\n",
      "Epoch 5/100\n",
      "226/226 - 5s - loss: 0.7911 - accuracy: 0.7029 - auc: 0.8192 - val_loss: 0.8305 - val_accuracy: 0.5435 - val_auc: 0.8118\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.81250\n",
      "Epoch 6/100\n",
      "226/226 - 5s - loss: 0.6894 - accuracy: 0.7211 - auc: 0.8482 - val_loss: 1.1675 - val_accuracy: 0.8162 - val_auc: 0.7971\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.81250\n",
      "Epoch 7/100\n",
      "226/226 - 5s - loss: 0.6777 - accuracy: 0.7258 - auc: 0.8350 - val_loss: 0.7762 - val_accuracy: 0.5280 - val_auc: 0.8188\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.81250 to 0.81881, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 8/100\n",
      "226/226 - 5s - loss: 0.6363 - accuracy: 0.7465 - auc: 0.8514 - val_loss: 0.7696 - val_accuracy: 0.6170 - val_auc: 0.8200\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.81881 to 0.82002, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 9/100\n",
      "226/226 - 5s - loss: 0.6215 - accuracy: 0.7648 - auc: 0.8523 - val_loss: 0.7615 - val_accuracy: 0.6228 - val_auc: 0.8183\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.82002\n",
      "Epoch 10/100\n",
      "226/226 - 5s - loss: 0.6034 - accuracy: 0.7537 - auc: 0.8579 - val_loss: 0.7512 - val_accuracy: 0.5493 - val_auc: 0.8157\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.82002\n",
      "Epoch 11/100\n",
      "226/226 - 5s - loss: 0.5762 - accuracy: 0.7616 - auc: 0.8667 - val_loss: 0.7645 - val_accuracy: 0.6750 - val_auc: 0.8156\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.82002\n",
      "Epoch 12/100\n",
      "226/226 - 5s - loss: 0.5670 - accuracy: 0.7671 - auc: 0.8743 - val_loss: 0.8209 - val_accuracy: 0.6325 - val_auc: 0.7967\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.82002\n",
      "Epoch 13/100\n",
      "226/226 - 5s - loss: 0.5721 - accuracy: 0.7505 - auc: 0.8675 - val_loss: 0.9491 - val_accuracy: 0.7718 - val_auc: 0.8124\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.82002\n",
      "Epoch 14/100\n",
      "226/226 - 5s - loss: 0.5710 - accuracy: 0.7681 - auc: 0.8723 - val_loss: 0.9194 - val_accuracy: 0.7350 - val_auc: 0.8168\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.82002\n",
      "Epoch 15/100\n",
      "226/226 - 5s - loss: 0.6293 - accuracy: 0.7307 - auc: 0.8451 - val_loss: 1.4701 - val_accuracy: 0.8182 - val_auc: 0.7869\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.82002\n",
      "Epoch 16/100\n",
      "226/226 - 5s - loss: 0.6774 - accuracy: 0.7016 - auc: 0.8412 - val_loss: 0.7955 - val_accuracy: 0.5957 - val_auc: 0.8217\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.82002 to 0.82173, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "226/226 - 5s - loss: 0.5995 - accuracy: 0.7625 - auc: 0.8687 - val_loss: 0.8102 - val_accuracy: 0.6286 - val_auc: 0.8168\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.82173\n",
      "Epoch 18/100\n",
      "226/226 - 5s - loss: 0.5744 - accuracy: 0.7553 - auc: 0.8778 - val_loss: 0.9551 - val_accuracy: 0.7911 - val_auc: 0.7865\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.82173\n",
      "Epoch 19/100\n",
      "226/226 - 5s - loss: 0.5708 - accuracy: 0.7563 - auc: 0.8783 - val_loss: 1.0623 - val_accuracy: 0.8414 - val_auc: 0.7958\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.82173\n",
      "Epoch 20/100\n",
      "226/226 - 5s - loss: 0.5837 - accuracy: 0.7477 - auc: 0.8744 - val_loss: 1.0962 - val_accuracy: 0.8279 - val_auc: 0.7915\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.82173\n",
      "Epoch 21/100\n",
      "226/226 - 5s - loss: 0.7172 - accuracy: 0.7236 - auc: 0.8423 - val_loss: 0.8495 - val_accuracy: 0.6209 - val_auc: 0.8269\n",
      "\n",
      "Epoch 00021: val_auc improved from 0.82173 to 0.82686, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 22/100\n",
      "226/226 - 5s - loss: 0.6264 - accuracy: 0.7612 - auc: 0.8840 - val_loss: 0.7931 - val_accuracy: 0.5532 - val_auc: 0.8299\n",
      "\n",
      "Epoch 00022: val_auc improved from 0.82686 to 0.82990, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 23/100\n",
      "226/226 - 5s - loss: 0.6214 - accuracy: 0.7546 - auc: 0.8790 - val_loss: 0.9255 - val_accuracy: 0.5222 - val_auc: 0.7954\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.82990\n",
      "Epoch 24/100\n",
      "226/226 - 5s - loss: 0.7568 - accuracy: 0.7185 - auc: 0.8612 - val_loss: 0.8482 - val_accuracy: 0.7234 - val_auc: 0.8154\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.82990\n",
      "Epoch 25/100\n",
      "226/226 - 5s - loss: 0.6342 - accuracy: 0.7530 - auc: 0.8809 - val_loss: 0.9953 - val_accuracy: 0.8279 - val_auc: 0.8066\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.82990\n",
      "Epoch 26/100\n",
      "226/226 - 5s - loss: 0.6515 - accuracy: 0.7537 - auc: 0.8848 - val_loss: 0.9369 - val_accuracy: 0.7176 - val_auc: 0.8195\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.82990\n",
      "Epoch 27/100\n",
      "226/226 - 5s - loss: 0.5968 - accuracy: 0.7700 - auc: 0.8902 - val_loss: 1.1244 - val_accuracy: 0.7176 - val_auc: 0.7704\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.82990\n",
      "Epoch 28/100\n",
      "226/226 - 5s - loss: 0.6199 - accuracy: 0.7777 - auc: 0.8829 - val_loss: 1.1326 - val_accuracy: 0.8085 - val_auc: 0.7670\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.82990\n",
      "Epoch 29/100\n",
      "226/226 - 5s - loss: 0.6181 - accuracy: 0.7670 - auc: 0.8829 - val_loss: 1.3011 - val_accuracy: 0.8607 - val_auc: 0.7948\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.82990\n",
      "Epoch 30/100\n",
      "226/226 - 5s - loss: 0.5830 - accuracy: 0.8105 - auc: 0.8950 - val_loss: 1.0005 - val_accuracy: 0.7292 - val_auc: 0.8251\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.82990\n",
      "Epoch 31/100\n",
      "226/226 - 5s - loss: 0.5500 - accuracy: 0.7930 - auc: 0.8978 - val_loss: 0.9162 - val_accuracy: 0.8395 - val_auc: 0.8318\n",
      "\n",
      "Epoch 00031: val_auc improved from 0.82990 to 0.83176, saving model to 210120_TrainingDeep\\210120_Dense_NR-Aromatase\n",
      "Epoch 32/100\n",
      "226/226 - 5s - loss: 0.5739 - accuracy: 0.7825 - auc: 0.8909 - val_loss: 0.8297 - val_accuracy: 0.7679 - val_auc: 0.8283\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.83176\n",
      "Epoch 33/100\n",
      "226/226 - 5s - loss: 0.5278 - accuracy: 0.8156 - auc: 0.9122 - val_loss: 0.9693 - val_accuracy: 0.7814 - val_auc: 0.8239\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.83176\n",
      "Epoch 34/100\n",
      "226/226 - 5s - loss: 0.5212 - accuracy: 0.7939 - auc: 0.9046 - val_loss: 0.9173 - val_accuracy: 0.7718 - val_auc: 0.8253\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.83176\n",
      "Epoch 35/100\n",
      "226/226 - 5s - loss: 0.5066 - accuracy: 0.7933 - auc: 0.9089 - val_loss: 0.8698 - val_accuracy: 0.7640 - val_auc: 0.8036\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.83176\n",
      "Epoch 36/100\n",
      "226/226 - 5s - loss: 0.5623 - accuracy: 0.7423 - auc: 0.8841 - val_loss: 1.0379 - val_accuracy: 0.9284 - val_auc: 0.8125\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.83176\n",
      "Epoch 37/100\n",
      "226/226 - 5s - loss: 0.6272 - accuracy: 0.8052 - auc: 0.8896 - val_loss: 0.8475 - val_accuracy: 0.7041 - val_auc: 0.8264\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.83176\n",
      "Epoch 38/100\n",
      "226/226 - 5s - loss: 0.5333 - accuracy: 0.7901 - auc: 0.9093 - val_loss: 0.8774 - val_accuracy: 0.7505 - val_auc: 0.8253\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.83176\n",
      "Epoch 39/100\n",
      "226/226 - 5s - loss: 0.5939 - accuracy: 0.7619 - auc: 0.8995 - val_loss: 1.3228 - val_accuracy: 0.8607 - val_auc: 0.8214\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.83176\n",
      "Epoch 40/100\n",
      "226/226 - 5s - loss: 0.5754 - accuracy: 0.7756 - auc: 0.9044 - val_loss: 0.9013 - val_accuracy: 0.7602 - val_auc: 0.8238\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.83176\n",
      "Epoch 41/100\n",
      "226/226 - 5s - loss: 0.5586 - accuracy: 0.7467 - auc: 0.8936 - val_loss: 1.0426 - val_accuracy: 0.8162 - val_auc: 0.7865\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.83176\n",
      "Epoch 42/100\n",
      "226/226 - 5s - loss: 0.5040 - accuracy: 0.8148 - auc: 0.9139 - val_loss: 0.8531 - val_accuracy: 0.7253 - val_auc: 0.8258\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.83176\n",
      "Epoch 43/100\n",
      "226/226 - 5s - loss: 0.4898 - accuracy: 0.8026 - auc: 0.9159 - val_loss: 0.9671 - val_accuracy: 0.7447 - val_auc: 0.8236\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.83176\n",
      "Epoch 44/100\n",
      "226/226 - 5s - loss: 0.4996 - accuracy: 0.7950 - auc: 0.9141 - val_loss: 0.9938 - val_accuracy: 0.8395 - val_auc: 0.8152\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.83176\n",
      "Epoch 45/100\n",
      "226/226 - 5s - loss: 0.4723 - accuracy: 0.8082 - auc: 0.9281 - val_loss: 1.3334 - val_accuracy: 0.8085 - val_auc: 0.7966\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.83176\n",
      "Epoch 46/100\n",
      "226/226 - 5s - loss: 0.4861 - accuracy: 0.7976 - auc: 0.9193 - val_loss: 1.0533 - val_accuracy: 0.7795 - val_auc: 0.8139\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.83176\n",
      "Epoch 47/100\n",
      "226/226 - 5s - loss: 0.4650 - accuracy: 0.8126 - auc: 0.9245 - val_loss: 1.6637 - val_accuracy: 0.7814 - val_auc: 0.7711\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.83176\n",
      "Epoch 48/100\n",
      "226/226 - 5s - loss: 0.4885 - accuracy: 0.7991 - auc: 0.9166 - val_loss: 0.7623 - val_accuracy: 0.6615 - val_auc: 0.8292\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.83176\n",
      "Epoch 49/100\n",
      "226/226 - 5s - loss: 0.4547 - accuracy: 0.8126 - auc: 0.9306 - val_loss: 0.7259 - val_accuracy: 0.5300 - val_auc: 0.8309\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.83176\n",
      "Epoch 50/100\n",
      "226/226 - 5s - loss: 0.4859 - accuracy: 0.7648 - auc: 0.9189 - val_loss: 0.7083 - val_accuracy: 0.5919 - val_auc: 0.8260\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.83176\n",
      "Epoch 51/100\n",
      "226/226 - 5s - loss: 0.4842 - accuracy: 0.7964 - auc: 0.9223 - val_loss: 0.7446 - val_accuracy: 0.6828 - val_auc: 0.8102\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.83176\n",
      "Epoch 52/100\n",
      "226/226 - 5s - loss: 0.4774 - accuracy: 0.8069 - auc: 0.9226 - val_loss: 0.9639 - val_accuracy: 0.7118 - val_auc: 0.8153\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.83176\n",
      "Epoch 53/100\n",
      "226/226 - 5s - loss: 0.5121 - accuracy: 0.7944 - auc: 0.9208 - val_loss: 1.8395 - val_accuracy: 0.7427 - val_auc: 0.7552\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.83176\n",
      "Epoch 54/100\n",
      "226/226 - 5s - loss: 0.5033 - accuracy: 0.8086 - auc: 0.9206 - val_loss: 1.0720 - val_accuracy: 0.6615 - val_auc: 0.8056\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.83176\n",
      "Epoch 55/100\n",
      "226/226 - 5s - loss: 0.5158 - accuracy: 0.8156 - auc: 0.9286 - val_loss: 1.1980 - val_accuracy: 0.7814 - val_auc: 0.8108\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.83176\n",
      "Epoch 56/100\n",
      "226/226 - 5s - loss: 0.5340 - accuracy: 0.8130 - auc: 0.9244 - val_loss: 1.5450 - val_accuracy: 0.8259 - val_auc: 0.7818\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.83176\n",
      "Epoch 57/100\n",
      "226/226 - 5s - loss: 0.5566 - accuracy: 0.7661 - auc: 0.9110 - val_loss: 0.9343 - val_accuracy: 0.7737 - val_auc: 0.7894\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.83176\n",
      "Epoch 58/100\n",
      "226/226 - 5s - loss: 0.7692 - accuracy: 0.7659 - auc: 0.8847 - val_loss: 1.6962 - val_accuracy: 0.9207 - val_auc: 0.3698\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.83176\n",
      "Epoch 59/100\n",
      "226/226 - 5s - loss: 1.0933 - accuracy: 0.9469 - auc: 0.5053 - val_loss: 1.0704 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.83176\n",
      "Epoch 60/100\n",
      "226/226 - 5s - loss: 0.8788 - accuracy: 0.9490 - auc: 0.4893 - val_loss: 0.9893 - val_accuracy: 0.9284 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_auc did not improve from 0.83176\n",
      "Epoch 61/100\n",
      "226/226 - 5s - loss: 0.8353 - accuracy: 0.9491 - auc: 0.5001 - val_loss: 0.9614 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.83176\n",
      "Epoch 62/100\n",
      "226/226 - 5s - loss: 0.8162 - accuracy: 0.9362 - auc: 0.4746 - val_loss: 0.9466 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.83176\n",
      "Epoch 63/100\n",
      "226/226 - 5s - loss: 0.8061 - accuracy: 0.9488 - auc: 0.4918 - val_loss: 0.9376 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.83176\n",
      "Epoch 64/100\n",
      "226/226 - 5s - loss: 0.7994 - accuracy: 0.9483 - auc: 0.5004 - val_loss: 0.9323 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.83176\n",
      "Epoch 65/100\n",
      "226/226 - 5s - loss: 0.7933 - accuracy: 0.9414 - auc: 0.4782 - val_loss: 0.9261 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.83176\n",
      "Epoch 66/100\n",
      "226/226 - 5s - loss: 0.7880 - accuracy: 0.9486 - auc: 0.4814 - val_loss: 0.9213 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.83176\n",
      "Epoch 67/100\n",
      "226/226 - 5s - loss: 0.7842 - accuracy: 0.9480 - auc: 0.4778 - val_loss: 0.9176 - val_accuracy: 0.9284 - val_auc: 0.5010\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.83176\n",
      "Epoch 68/100\n",
      "226/226 - 5s - loss: 0.7815 - accuracy: 0.5351 - auc: 0.5026 - val_loss: 0.9139 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.83176\n",
      "Epoch 69/100\n",
      "226/226 - 5s - loss: 0.7670 - accuracy: 0.6859 - auc: 0.5472 - val_loss: 0.7126 - val_accuracy: 0.5571 - val_auc: 0.8236\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.83176\n",
      "Epoch 70/100\n",
      "226/226 - 5s - loss: 2.5346 - accuracy: 0.7121 - auc: 0.7213 - val_loss: 1.2092 - val_accuracy: 0.8124 - val_auc: 0.8201\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.83176\n",
      "Epoch 71/100\n",
      "226/226 - 5s - loss: 1.0053 - accuracy: 0.6817 - auc: 0.8368 - val_loss: 4.6374 - val_accuracy: 0.8994 - val_auc: 0.7028\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.83176\n",
      "Epoch 72/100\n",
      "226/226 - 5s - loss: 0.9951 - accuracy: 0.7368 - auc: 0.6740 - val_loss: 1.1955 - val_accuracy: 0.9226 - val_auc: 0.5094\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.83176\n",
      "Epoch 73/100\n",
      "226/226 - 5s - loss: 0.8085 - accuracy: 0.8510 - auc: 0.7938 - val_loss: 1.1838 - val_accuracy: 0.7795 - val_auc: 0.8271\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.83176\n",
      "Epoch 74/100\n",
      "226/226 - 5s - loss: 1.0342 - accuracy: 0.7253 - auc: 0.7871 - val_loss: 1.3563 - val_accuracy: 0.7002 - val_auc: 0.8117\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.83176\n",
      "Epoch 75/100\n",
      "226/226 - 5s - loss: 0.9047 - accuracy: 0.6736 - auc: 0.8408 - val_loss: 0.8644 - val_accuracy: 0.5899 - val_auc: 0.8281\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.83176\n",
      "Epoch 76/100\n",
      "226/226 - 5s - loss: 0.7585 - accuracy: 0.7380 - auc: 0.8539 - val_loss: 1.0217 - val_accuracy: 0.7679 - val_auc: 0.8072\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.83176\n",
      "Epoch 77/100\n",
      "226/226 - 5s - loss: 0.8761 - accuracy: 0.7801 - auc: 0.8413 - val_loss: 1.0202 - val_accuracy: 0.6557 - val_auc: 0.8167\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.83176\n",
      "Epoch 78/100\n",
      "226/226 - 5s - loss: 0.9956 - accuracy: 0.8205 - auc: 0.8669 - val_loss: 0.9171 - val_accuracy: 0.8530 - val_auc: 0.8181\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.83176\n",
      "Epoch 79/100\n",
      "226/226 - 5s - loss: 0.9023 - accuracy: 0.9253 - auc: 0.6303 - val_loss: 1.0393 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.83176\n",
      "Epoch 80/100\n",
      "226/226 - 5s - loss: 0.8425 - accuracy: 0.9493 - auc: 0.4685 - val_loss: 0.9913 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.83176\n",
      "Epoch 81/100\n",
      "226/226 - 5s - loss: 0.8170 - accuracy: 0.9493 - auc: 0.4703 - val_loss: 0.9666 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.83176\n",
      "Epoch 82/100\n",
      "226/226 - 5s - loss: 0.8064 - accuracy: 0.9422 - auc: 0.4872 - val_loss: 0.9511 - val_accuracy: 0.9284 - val_auc: 0.5177\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.83176\n",
      "Epoch 83/100\n",
      "226/226 - 5s - loss: 0.9203 - accuracy: 0.9403 - auc: 0.5015 - val_loss: 0.9723 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.83176\n",
      "Epoch 84/100\n",
      "226/226 - 5s - loss: 0.8090 - accuracy: 0.9493 - auc: 0.4757 - val_loss: 0.9433 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.83176\n",
      "Epoch 85/100\n",
      "226/226 - 5s - loss: 0.7941 - accuracy: 0.9493 - auc: 0.5043 - val_loss: 0.9319 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.83176\n",
      "Epoch 86/100\n",
      "226/226 - 5s - loss: 0.7762 - accuracy: 0.9129 - auc: 0.5224 - val_loss: 0.7986 - val_accuracy: 0.7002 - val_auc: 0.7610\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.83176\n",
      "Epoch 87/100\n",
      "226/226 - 5s - loss: 0.6658 - accuracy: 0.8122 - auc: 0.8102 - val_loss: 0.8729 - val_accuracy: 0.8627 - val_auc: 0.6579\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.83176\n",
      "Epoch 88/100\n",
      "226/226 - 5s - loss: 0.9239 - accuracy: 0.7785 - auc: 0.7742 - val_loss: 1.6572 - val_accuracy: 0.8395 - val_auc: 0.7024\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.83176\n",
      "Epoch 89/100\n",
      "226/226 - 5s - loss: 1.0080 - accuracy: 0.7460 - auc: 0.8119 - val_loss: 0.9305 - val_accuracy: 0.7698 - val_auc: 0.7494\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.83176\n",
      "Epoch 90/100\n",
      "226/226 - 5s - loss: 0.7195 - accuracy: 0.8364 - auc: 0.8107 - val_loss: 0.8900 - val_accuracy: 0.8143 - val_auc: 0.7927\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.83176\n",
      "Epoch 91/100\n",
      "226/226 - 5s - loss: 0.7951 - accuracy: 0.8546 - auc: 0.8133 - val_loss: 0.9064 - val_accuracy: 0.7834 - val_auc: 0.7207\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.83176\n",
      "Epoch 92/100\n",
      "226/226 - 5s - loss: 1.0214 - accuracy: 0.8879 - auc: 0.6354 - val_loss: 1.0546 - val_accuracy: 0.9188 - val_auc: 0.7390\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.83176\n",
      "Epoch 93/100\n",
      "226/226 - 5s - loss: 0.8023 - accuracy: 0.8536 - auc: 0.5953 - val_loss: 0.8548 - val_accuracy: 0.8240 - val_auc: 0.7429\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.83176\n",
      "Epoch 94/100\n",
      "226/226 - 5s - loss: 0.7756 - accuracy: 0.8075 - auc: 0.8403 - val_loss: 1.2939 - val_accuracy: 0.8685 - val_auc: 0.7397\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.83176\n",
      "Epoch 95/100\n",
      "226/226 - 5s - loss: 0.8568 - accuracy: 0.7174 - auc: 0.7929 - val_loss: 0.9164 - val_accuracy: 0.7679 - val_auc: 0.8104\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.83176\n",
      "Epoch 96/100\n",
      "226/226 - 5s - loss: 0.6983 - accuracy: 0.8165 - auc: 0.8540 - val_loss: 1.1558 - val_accuracy: 0.8375 - val_auc: 0.7610\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.83176\n",
      "Epoch 97/100\n",
      "226/226 - 7s - loss: 0.9254 - accuracy: 0.8922 - auc: 0.5992 - val_loss: 1.0546 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.83176\n",
      "Epoch 98/100\n",
      "226/226 - 5s - loss: 0.8404 - accuracy: 0.9493 - auc: 0.4817 - val_loss: 0.9885 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.83176\n",
      "Epoch 99/100\n",
      "226/226 - 5s - loss: 0.8086 - accuracy: 0.9493 - auc: 0.5112 - val_loss: 0.9619 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.83176\n",
      "Epoch 100/100\n",
      "226/226 - 5s - loss: 0.7942 - accuracy: 0.9493 - auc: 0.4684 - val_loss: 0.9439 - val_accuracy: 0.9284 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.83176\n",
      "Epoch 1/100\n",
      "257/257 - 7s - loss: 6.0588 - accuracy: 0.7312 - auc: 0.5020 - val_loss: 2.0945 - val_accuracy: 0.0556 - val_auc: 0.5059\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.50592, saving model to 210120_TrainingDeep\\210120_Dense_NR-PPAR-gamma\n",
      "Epoch 2/100\n",
      "257/257 - 6s - loss: 1.3327 - accuracy: 0.4801 - auc: 0.5841 - val_loss: 1.8035 - val_accuracy: 0.0691 - val_auc: 0.7353\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.50592 to 0.73529, saving model to 210120_TrainingDeep\\210120_Dense_NR-PPAR-gamma\n",
      "Epoch 3/100\n",
      "257/257 - 5s - loss: 1.1378 - accuracy: 0.1654 - auc: 0.5171 - val_loss: 1.2243 - val_accuracy: 0.1788 - val_auc: 0.5311\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.73529\n",
      "Epoch 4/100\n",
      "257/257 - 5s - loss: 0.8596 - accuracy: 0.5484 - auc: 0.6353 - val_loss: 1.1068 - val_accuracy: 0.5160 - val_auc: 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_auc improved from 0.73529 to 0.75340, saving model to 210120_TrainingDeep\\210120_Dense_NR-PPAR-gamma\n",
      "Epoch 5/100\n",
      "257/257 - 5s - loss: 0.9080 - accuracy: 0.6086 - auc: 0.6565 - val_loss: 1.1765 - val_accuracy: 0.0506 - val_auc: 0.7127\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.75340\n",
      "Epoch 6/100\n",
      "257/257 - 5s - loss: 0.7835 - accuracy: 0.7066 - auc: 0.7069 - val_loss: 1.0842 - val_accuracy: 0.7572 - val_auc: 0.7445\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.75340\n",
      "Epoch 7/100\n",
      "257/257 - 5s - loss: 0.7151 - accuracy: 0.7509 - auc: 0.7528 - val_loss: 1.4804 - val_accuracy: 0.9275 - val_auc: 0.7493\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.75340\n",
      "Epoch 8/100\n",
      "257/257 - 5s - loss: 0.6822 - accuracy: 0.7558 - auc: 0.7700 - val_loss: 1.1235 - val_accuracy: 0.7808 - val_auc: 0.7485\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.75340\n",
      "Epoch 9/100\n",
      "257/257 - 5s - loss: 0.6551 - accuracy: 0.7380 - auc: 0.7835 - val_loss: 0.9823 - val_accuracy: 0.5717 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.75340\n",
      "Epoch 10/100\n",
      "257/257 - 5s - loss: 0.6148 - accuracy: 0.7392 - auc: 0.8132 - val_loss: 1.2818 - val_accuracy: 0.8769 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.75340\n",
      "Epoch 11/100\n",
      "257/257 - 5s - loss: 0.5973 - accuracy: 0.7860 - auc: 0.8249 - val_loss: 1.2856 - val_accuracy: 0.8533 - val_auc: 0.7319\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.75340\n",
      "Epoch 12/100\n",
      "257/257 - 5s - loss: 0.6077 - accuracy: 0.7729 - auc: 0.8216 - val_loss: 1.6908 - val_accuracy: 0.9342 - val_auc: 0.6674\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.75340\n",
      "Epoch 13/100\n",
      "257/257 - 5s - loss: 0.6469 - accuracy: 0.7475 - auc: 0.8194 - val_loss: 1.0755 - val_accuracy: 0.7943 - val_auc: 0.7501\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75340\n",
      "Epoch 14/100\n",
      "257/257 - 5s - loss: 0.5778 - accuracy: 0.7913 - auc: 0.8462 - val_loss: 1.2088 - val_accuracy: 0.7993 - val_auc: 0.7331\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.75340\n",
      "Epoch 15/100\n",
      "257/257 - 5s - loss: 0.5699 - accuracy: 0.8031 - auc: 0.8493 - val_loss: 0.9330 - val_accuracy: 0.5110 - val_auc: 0.7396\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75340\n",
      "Epoch 16/100\n",
      "257/257 - 5s - loss: 0.5517 - accuracy: 0.7721 - auc: 0.8546 - val_loss: 0.9281 - val_accuracy: 0.5868 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.75340\n",
      "Epoch 17/100\n",
      "257/257 - 5s - loss: 0.8592 - accuracy: 0.8186 - auc: 0.6956 - val_loss: 1.2105 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.75340\n",
      "Epoch 18/100\n",
      "257/257 - 5s - loss: 0.8275 - accuracy: 0.9745 - auc: 0.4775 - val_loss: 1.1366 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.75340\n",
      "Epoch 19/100\n",
      "257/257 - 5s - loss: 0.8050 - accuracy: 0.9745 - auc: 0.5147 - val_loss: 1.1175 - val_accuracy: 0.9494 - val_auc: 0.5018\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.75340\n",
      "Epoch 20/100\n",
      "257/257 - 5s - loss: 0.7797 - accuracy: 0.4762 - auc: 0.5012 - val_loss: 1.1053 - val_accuracy: 0.0590 - val_auc: 0.5036\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.75340\n",
      "Epoch 21/100\n",
      "257/257 - 5s - loss: 0.9279 - accuracy: 0.2566 - auc: 0.5542 - val_loss: 1.6629 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.75340\n",
      "Epoch 22/100\n",
      "257/257 - 5s - loss: 0.9597 - accuracy: 0.1753 - auc: 0.4999 - val_loss: 1.1735 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.75340\n",
      "Epoch 23/100\n",
      "257/257 - 5s - loss: 0.8141 - accuracy: 0.4225 - auc: 0.4999 - val_loss: 1.1285 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.75340\n",
      "Epoch 24/100\n",
      "257/257 - 5s - loss: 0.7885 - accuracy: 0.1870 - auc: 0.4877 - val_loss: 1.1142 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.75340\n",
      "Epoch 25/100\n",
      "257/257 - 5s - loss: 0.7774 - accuracy: 0.8552 - auc: 0.5000 - val_loss: 1.1063 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.75340\n",
      "Epoch 26/100\n",
      "257/257 - 5s - loss: 0.7708 - accuracy: 0.7871 - auc: 0.4999 - val_loss: 1.1013 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.75340\n",
      "Epoch 27/100\n",
      "257/257 - 5s - loss: 0.7665 - accuracy: 0.2459 - auc: 0.4968 - val_loss: 1.0962 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.75340\n",
      "Epoch 28/100\n",
      "257/257 - 5s - loss: 0.7653 - accuracy: 0.6536 - auc: 0.5006 - val_loss: 0.9669 - val_accuracy: 0.0506 - val_auc: 0.7466\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.75340\n",
      "Epoch 29/100\n",
      "257/257 - 5s - loss: 0.7683 - accuracy: 0.6443 - auc: 0.5151 - val_loss: 1.1131 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.75340\n",
      "Epoch 30/100\n",
      "257/257 - 5s - loss: 0.7642 - accuracy: 0.4428 - auc: 0.4993 - val_loss: 1.0930 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.75340\n",
      "Epoch 31/100\n",
      "257/257 - 5s - loss: 0.7592 - accuracy: 0.7049 - auc: 0.5151 - val_loss: 1.0452 - val_accuracy: 0.0523 - val_auc: 0.7507\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.75340\n",
      "Epoch 32/100\n",
      "257/257 - 5s - loss: 4.4817 - accuracy: 0.8262 - auc: 0.5359 - val_loss: 15.9071 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.75340\n",
      "Epoch 33/100\n",
      "257/257 - 5s - loss: 7.6916 - accuracy: 0.9669 - auc: 0.4979 - val_loss: 2.5020 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.75340\n",
      "Epoch 34/100\n",
      "257/257 - 5s - loss: 1.4094 - accuracy: 0.9610 - auc: 0.4891 - val_loss: 1.4729 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.75340\n",
      "Epoch 35/100\n",
      "257/257 - 5s - loss: 1.0487 - accuracy: 0.7648 - auc: 0.4869 - val_loss: 1.3067 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.75340\n",
      "Epoch 36/100\n",
      "257/257 - 5s - loss: 1.0370 - accuracy: 0.8522 - auc: 0.5004 - val_loss: 1.2640 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.75340\n",
      "Epoch 37/100\n",
      "257/257 - 5s - loss: 0.8761 - accuracy: 0.9745 - auc: 0.4873 - val_loss: 1.1732 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.75340\n",
      "Epoch 38/100\n",
      "257/257 - 5s - loss: 0.8174 - accuracy: 0.7158 - auc: 0.4995 - val_loss: 1.1323 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.75340\n",
      "Epoch 39/100\n",
      "257/257 - 5s - loss: 0.7902 - accuracy: 0.6935 - auc: 0.4970 - val_loss: 1.1084 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.75340\n",
      "Epoch 40/100\n",
      "257/257 - 5s - loss: 0.7692 - accuracy: 0.9743 - auc: 0.4924 - val_loss: 1.0974 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.75340\n",
      "Epoch 41/100\n",
      "257/257 - 5s - loss: 0.7600 - accuracy: 0.3262 - auc: 0.5186 - val_loss: 0.9878 - val_accuracy: 0.0506 - val_auc: 0.7524\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.75340\n",
      "Epoch 42/100\n",
      "257/257 - 5s - loss: 0.7715 - accuracy: 0.8161 - auc: 0.5655 - val_loss: 1.1114 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.75340\n",
      "Epoch 43/100\n",
      "257/257 - 5s - loss: 0.7706 - accuracy: 0.7277 - auc: 0.4805 - val_loss: 1.1057 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.75340\n",
      "Epoch 44/100\n",
      "257/257 - 5s - loss: 1.0334 - accuracy: 0.6774 - auc: 0.5073 - val_loss: 3.3969 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.75340\n",
      "Epoch 45/100\n",
      "257/257 - 5s - loss: 1.5185 - accuracy: 0.4429 - auc: 0.4964 - val_loss: 1.3578 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.75340\n",
      "Epoch 46/100\n",
      "257/257 - 5s - loss: 0.9107 - accuracy: 0.5151 - auc: 0.4830 - val_loss: 1.1772 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.75340\n",
      "Epoch 47/100\n",
      "257/257 - 5s - loss: 0.8183 - accuracy: 0.9744 - auc: 0.4808 - val_loss: 1.1341 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.75340\n",
      "Epoch 48/100\n",
      "257/257 - 5s - loss: 0.8367 - accuracy: 0.7457 - auc: 0.5013 - val_loss: 1.2179 - val_accuracy: 0.9494 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_auc did not improve from 0.75340\n",
      "Epoch 49/100\n",
      "257/257 - 5s - loss: 0.8052 - accuracy: 0.8829 - auc: 0.4919 - val_loss: 1.1884 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.75340\n",
      "Epoch 50/100\n",
      "257/257 - 5s - loss: 0.7930 - accuracy: 0.8465 - auc: 0.4843 - val_loss: 1.1008 - val_accuracy: 0.9494 - val_auc: 0.5009\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.75340\n",
      "Epoch 51/100\n",
      "257/257 - 5s - loss: 0.7749 - accuracy: 0.5464 - auc: 0.5145 - val_loss: 1.1316 - val_accuracy: 0.0523 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.75340\n",
      "Epoch 52/100\n",
      "257/257 - 5s - loss: 0.8103 - accuracy: 0.6976 - auc: 0.5055 - val_loss: 1.1043 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.75340\n",
      "Epoch 53/100\n",
      "257/257 - 5s - loss: 0.7677 - accuracy: 0.1287 - auc: 0.5042 - val_loss: 1.0897 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.75340\n",
      "Epoch 54/100\n",
      "257/257 - 5s - loss: 0.7650 - accuracy: 0.6037 - auc: 0.5031 - val_loss: 1.0952 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.75340\n",
      "Epoch 55/100\n",
      "257/257 - 5s - loss: 0.7621 - accuracy: 0.4919 - auc: 0.5075 - val_loss: 1.0887 - val_accuracy: 0.2496 - val_auc: 0.7070\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.75340\n",
      "Epoch 56/100\n",
      "257/257 - 5s - loss: 0.8069 - accuracy: 0.5361 - auc: 0.5987 - val_loss: 1.1978 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.75340\n",
      "Epoch 57/100\n",
      "257/257 - 5s - loss: 0.7835 - accuracy: 0.7929 - auc: 0.5450 - val_loss: 1.0958 - val_accuracy: 0.0506 - val_auc: 0.5451\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.75340\n",
      "Epoch 58/100\n",
      "257/257 - 5s - loss: 0.8498 - accuracy: 0.6748 - auc: 0.6373 - val_loss: 1.3266 - val_accuracy: 0.3794 - val_auc: 0.3996\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.75340\n",
      "Epoch 59/100\n",
      "257/257 - 5s - loss: 0.8077 - accuracy: 0.6822 - auc: 0.6334 - val_loss: 1.1295 - val_accuracy: 0.4890 - val_auc: 0.7181\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.75340\n",
      "Epoch 60/100\n",
      "257/257 - 5s - loss: 0.8043 - accuracy: 0.8723 - auc: 0.4897 - val_loss: 1.1029 - val_accuracy: 0.9494 - val_auc: 0.6887\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.75340\n",
      "Epoch 61/100\n",
      "257/257 - 5s - loss: 0.8013 - accuracy: 0.8999 - auc: 0.5339 - val_loss: 1.1099 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.75340\n",
      "Epoch 62/100\n",
      "257/257 - 5s - loss: 0.7624 - accuracy: 0.6175 - auc: 0.6002 - val_loss: 1.1628 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.75340\n",
      "Epoch 63/100\n",
      "257/257 - 5s - loss: 0.7758 - accuracy: 0.1160 - auc: 0.5153 - val_loss: 1.2995 - val_accuracy: 0.9056 - val_auc: 0.5869\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.75340\n",
      "Epoch 64/100\n",
      "257/257 - 5s - loss: 0.8025 - accuracy: 0.1902 - auc: 0.4709 - val_loss: 1.1001 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.75340\n",
      "Epoch 65/100\n",
      "257/257 - 5s - loss: 0.7618 - accuracy: 0.0895 - auc: 0.4746 - val_loss: 1.0885 - val_accuracy: 0.4772 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.75340\n",
      "Epoch 66/100\n",
      "257/257 - 5s - loss: 0.9150 - accuracy: 0.5270 - auc: 0.5423 - val_loss: 1.1744 - val_accuracy: 0.0506 - val_auc: 0.6713\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.75340\n",
      "Epoch 67/100\n",
      "257/257 - 5s - loss: 0.8005 - accuracy: 0.0460 - auc: 0.4973 - val_loss: 1.0817 - val_accuracy: 0.0506 - val_auc: 0.6747\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.75340\n",
      "Epoch 68/100\n",
      "257/257 - 5s - loss: 0.7996 - accuracy: 0.5323 - auc: 0.5186 - val_loss: 1.2845 - val_accuracy: 0.9494 - val_auc: 0.5419\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.75340\n",
      "Epoch 69/100\n",
      "257/257 - 5s - loss: 0.8185 - accuracy: 0.1870 - auc: 0.5142 - val_loss: 1.1125 - val_accuracy: 0.0506 - val_auc: 0.5283\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.75340\n",
      "Epoch 70/100\n",
      "257/257 - 5s - loss: 0.7909 - accuracy: 0.3746 - auc: 0.4940 - val_loss: 1.1205 - val_accuracy: 0.4688 - val_auc: 0.3949\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.75340\n",
      "Epoch 71/100\n",
      "257/257 - 5s - loss: 0.9220 - accuracy: 0.1833 - auc: 0.5255 - val_loss: 1.1595 - val_accuracy: 0.0506 - val_auc: 0.7043\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.75340\n",
      "Epoch 72/100\n",
      "257/257 - 5s - loss: 0.8016 - accuracy: 0.1532 - auc: 0.5289 - val_loss: 1.1740 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.75340\n",
      "Epoch 73/100\n",
      "257/257 - 5s - loss: 0.8298 - accuracy: 0.0799 - auc: 0.4854 - val_loss: 1.1220 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.75340\n",
      "Epoch 74/100\n",
      "257/257 - 5s - loss: 0.7869 - accuracy: 0.4379 - auc: 0.5354 - val_loss: 1.1009 - val_accuracy: 0.9494 - val_auc: 0.7128\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.75340\n",
      "Epoch 75/100\n",
      "257/257 - 5s - loss: 0.7718 - accuracy: 0.5295 - auc: 0.5241 - val_loss: 1.0863 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.75340\n",
      "Epoch 76/100\n",
      "257/257 - 5s - loss: 0.7615 - accuracy: 0.1848 - auc: 0.4877 - val_loss: 1.1638 - val_accuracy: 0.9494 - val_auc: 0.5009\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.75340\n",
      "Epoch 77/100\n",
      "257/257 - 5s - loss: 0.7751 - accuracy: 0.4655 - auc: 0.5000 - val_loss: 1.0926 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.75340\n",
      "Epoch 78/100\n",
      "257/257 - 5s - loss: 0.7755 - accuracy: 0.3925 - auc: 0.5439 - val_loss: 1.1151 - val_accuracy: 0.0506 - val_auc: 0.5284\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.75340\n",
      "Epoch 79/100\n",
      "257/257 - 5s - loss: 0.8147 - accuracy: 0.3780 - auc: 0.5609 - val_loss: 1.1583 - val_accuracy: 0.0877 - val_auc: 0.6968\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.75340\n",
      "Epoch 80/100\n",
      "257/257 - 5s - loss: 0.8102 - accuracy: 0.3470 - auc: 0.6012 - val_loss: 1.1048 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.75340\n",
      "Epoch 81/100\n",
      "257/257 - 5s - loss: 0.8446 - accuracy: 0.3118 - auc: 0.5331 - val_loss: 1.2436 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.75340\n",
      "Epoch 82/100\n",
      "257/257 - 5s - loss: 0.8125 - accuracy: 0.2552 - auc: 0.5425 - val_loss: 1.0886 - val_accuracy: 0.0523 - val_auc: 0.5036\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.75340\n",
      "Epoch 83/100\n",
      "257/257 - 5s - loss: 0.8039 - accuracy: 0.3348 - auc: 0.5606 - val_loss: 1.2436 - val_accuracy: 0.9477 - val_auc: 0.6023\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.75340\n",
      "Epoch 84/100\n",
      "257/257 - 5s - loss: 0.7772 - accuracy: 0.3568 - auc: 0.5776 - val_loss: 1.0984 - val_accuracy: 0.6256 - val_auc: 0.6811\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.75340\n",
      "Epoch 85/100\n",
      "257/257 - 5s - loss: 0.7958 - accuracy: 0.0993 - auc: 0.5121 - val_loss: 1.0839 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.75340\n",
      "Epoch 86/100\n",
      "257/257 - 5s - loss: 0.7900 - accuracy: 0.1353 - auc: 0.4889 - val_loss: 1.1315 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.75340\n",
      "Epoch 87/100\n",
      "257/257 - 5s - loss: 0.7727 - accuracy: 0.1198 - auc: 0.4790 - val_loss: 1.1035 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.75340\n",
      "Epoch 88/100\n",
      "257/257 - 5s - loss: 0.9404 - accuracy: 0.4351 - auc: 0.5436 - val_loss: 1.1365 - val_accuracy: 0.0506 - val_auc: 0.3914\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.75340\n",
      "Epoch 89/100\n",
      "257/257 - 5s - loss: 0.7867 - accuracy: 0.3003 - auc: 0.4898 - val_loss: 1.0850 - val_accuracy: 0.0843 - val_auc: 0.5595\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.75340\n",
      "Epoch 90/100\n",
      "257/257 - 5s - loss: 0.7736 - accuracy: 0.5127 - auc: 0.6061 - val_loss: 1.1106 - val_accuracy: 0.3103 - val_auc: 0.6985\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.75340\n",
      "Epoch 91/100\n",
      "257/257 - 5s - loss: 0.9960 - accuracy: 0.1101 - auc: 0.5383 - val_loss: 1.1266 - val_accuracy: 0.0506 - val_auc: 0.7246\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.75340\n",
      "Epoch 92/100\n",
      "257/257 - 5s - loss: 0.8494 - accuracy: 0.1920 - auc: 0.6079 - val_loss: 1.1633 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.75340\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 5s - loss: 0.7842 - accuracy: 0.0322 - auc: 0.4815 - val_loss: 1.1067 - val_accuracy: 0.0506 - val_auc: 0.6516\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.75340\n",
      "Epoch 94/100\n",
      "257/257 - 5s - loss: 0.7735 - accuracy: 0.2099 - auc: 0.5853 - val_loss: 1.1031 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.75340\n",
      "Epoch 95/100\n",
      "257/257 - 5s - loss: 0.7718 - accuracy: 0.0432 - auc: 0.4704 - val_loss: 1.0872 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.75340\n",
      "Epoch 96/100\n",
      "257/257 - 5s - loss: 0.7544 - accuracy: 0.0255 - auc: 0.4703 - val_loss: 1.0813 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.75340\n",
      "Epoch 97/100\n",
      "257/257 - 5s - loss: 0.7507 - accuracy: 0.0274 - auc: 0.4719 - val_loss: 1.0800 - val_accuracy: 0.0506 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.75340\n",
      "Epoch 98/100\n",
      "257/257 - 5s - loss: 0.7935 - accuracy: 0.3386 - auc: 0.5485 - val_loss: 1.1363 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.75340\n",
      "Epoch 99/100\n",
      "257/257 - 5s - loss: 3.6527 - accuracy: 0.7736 - auc: 0.5474 - val_loss: 16.5056 - val_accuracy: 0.9494 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.75340\n",
      "Epoch 100/100\n",
      "257/257 - 5s - loss: 5.9984 - accuracy: 0.9460 - auc: 0.5055 - val_loss: 1.4362 - val_accuracy: 0.0506 - val_auc: 0.6964\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.75340\n",
      "Epoch 1/100\n",
      "227/227 - 8s - loss: 3.5219 - accuracy: 0.5404 - auc: 0.6197 - val_loss: 1.9698 - val_accuracy: 0.4954 - val_auc: 0.7482\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.74823, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 2/100\n",
      "227/227 - 7s - loss: 1.4979 - accuracy: 0.6169 - auc: 0.6961 - val_loss: 1.2137 - val_accuracy: 0.7819 - val_auc: 0.7287\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.74823\n",
      "Epoch 3/100\n",
      "227/227 - 5s - loss: 0.9549 - accuracy: 0.6252 - auc: 0.7324 - val_loss: 0.8679 - val_accuracy: 0.6506 - val_auc: 0.7516\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.74823 to 0.75160, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 4/100\n",
      "227/227 - 5s - loss: 0.7961 - accuracy: 0.6696 - auc: 0.7595 - val_loss: 0.8022 - val_accuracy: 0.6784 - val_auc: 0.7595\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.75160 to 0.75955, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 5/100\n",
      "227/227 - 5s - loss: 0.7378 - accuracy: 0.6873 - auc: 0.7699 - val_loss: 0.8048 - val_accuracy: 0.7116 - val_auc: 0.7551\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.75955\n",
      "Epoch 6/100\n",
      "227/227 - 5s - loss: 0.7039 - accuracy: 0.7036 - auc: 0.7812 - val_loss: 0.7410 - val_accuracy: 0.7283 - val_auc: 0.7649\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.75955 to 0.76488, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 7/100\n",
      "227/227 - 5s - loss: 0.6904 - accuracy: 0.7155 - auc: 0.7809 - val_loss: 0.7225 - val_accuracy: 0.5860 - val_auc: 0.7705\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.76488 to 0.77046, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 8/100\n",
      "227/227 - 5s - loss: 0.6604 - accuracy: 0.7249 - auc: 0.7954 - val_loss: 0.7388 - val_accuracy: 0.5675 - val_auc: 0.7657\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77046\n",
      "Epoch 9/100\n",
      "227/227 - 5s - loss: 0.6436 - accuracy: 0.7083 - auc: 0.8016 - val_loss: 0.7192 - val_accuracy: 0.6895 - val_auc: 0.7737\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.77046 to 0.77373, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 10/100\n",
      "227/227 - 5s - loss: 0.6862 - accuracy: 0.6729 - auc: 0.7770 - val_loss: 0.7774 - val_accuracy: 0.7301 - val_auc: 0.7637\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.77373\n",
      "Epoch 11/100\n",
      "227/227 - 5s - loss: 0.6497 - accuracy: 0.7184 - auc: 0.8023 - val_loss: 0.6952 - val_accuracy: 0.6433 - val_auc: 0.7695\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77373\n",
      "Epoch 12/100\n",
      "227/227 - 5s - loss: 0.6170 - accuracy: 0.7419 - auc: 0.8176 - val_loss: 0.7426 - val_accuracy: 0.7190 - val_auc: 0.7708\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.77373\n",
      "Epoch 13/100\n",
      "227/227 - 5s - loss: 0.6079 - accuracy: 0.7425 - auc: 0.8212 - val_loss: 0.7847 - val_accuracy: 0.7209 - val_auc: 0.7628\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77373\n",
      "Epoch 14/100\n",
      "227/227 - 5s - loss: 0.6057 - accuracy: 0.7398 - auc: 0.8257 - val_loss: 0.7704 - val_accuracy: 0.7930 - val_auc: 0.7537\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.77373\n",
      "Epoch 15/100\n",
      "227/227 - 5s - loss: 0.6033 - accuracy: 0.7564 - auc: 0.8247 - val_loss: 0.6925 - val_accuracy: 0.6969 - val_auc: 0.7694\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77373\n",
      "Epoch 16/100\n",
      "227/227 - 5s - loss: 0.5877 - accuracy: 0.7532 - auc: 0.8365 - val_loss: 0.6946 - val_accuracy: 0.6710 - val_auc: 0.7689\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77373\n",
      "Epoch 17/100\n",
      "227/227 - 5s - loss: 0.5800 - accuracy: 0.7755 - auc: 0.8421 - val_loss: 0.7164 - val_accuracy: 0.7006 - val_auc: 0.7683\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77373\n",
      "Epoch 18/100\n",
      "227/227 - 5s - loss: 0.5742 - accuracy: 0.7643 - auc: 0.8485 - val_loss: 0.7110 - val_accuracy: 0.7172 - val_auc: 0.7783\n",
      "\n",
      "Epoch 00018: val_auc improved from 0.77373 to 0.77834, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 19/100\n",
      "227/227 - 5s - loss: 0.5765 - accuracy: 0.7662 - auc: 0.8494 - val_loss: 0.7121 - val_accuracy: 0.7634 - val_auc: 0.7770\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.77834\n",
      "Epoch 20/100\n",
      "227/227 - 5s - loss: 0.5533 - accuracy: 0.7733 - auc: 0.8620 - val_loss: 0.7888 - val_accuracy: 0.7856 - val_auc: 0.7747\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.77834\n",
      "Epoch 21/100\n",
      "227/227 - 5s - loss: 0.5703 - accuracy: 0.7832 - auc: 0.8576 - val_loss: 0.7351 - val_accuracy: 0.7616 - val_auc: 0.7756\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.77834\n",
      "Epoch 22/100\n",
      "227/227 - 5s - loss: 0.5477 - accuracy: 0.7848 - auc: 0.8648 - val_loss: 0.7001 - val_accuracy: 0.6747 - val_auc: 0.7801\n",
      "\n",
      "Epoch 00022: val_auc improved from 0.77834 to 0.78014, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 23/100\n",
      "227/227 - 5s - loss: 0.5470 - accuracy: 0.7881 - auc: 0.8654 - val_loss: 0.7231 - val_accuracy: 0.5933 - val_auc: 0.7748\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.78014\n",
      "Epoch 24/100\n",
      "227/227 - 5s - loss: 0.5464 - accuracy: 0.8047 - auc: 0.8726 - val_loss: 0.7711 - val_accuracy: 0.6710 - val_auc: 0.7816\n",
      "\n",
      "Epoch 00024: val_auc improved from 0.78014 to 0.78156, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 25/100\n",
      "227/227 - 5s - loss: 0.5402 - accuracy: 0.7882 - auc: 0.8717 - val_loss: 0.7972 - val_accuracy: 0.5083 - val_auc: 0.7843\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.78156 to 0.78426, saving model to 210120_TrainingDeep\\210120_Dense_SR-ARE\n",
      "Epoch 26/100\n",
      "227/227 - 5s - loss: 0.5956 - accuracy: 0.7962 - auc: 0.8542 - val_loss: 0.7658 - val_accuracy: 0.7357 - val_auc: 0.7792\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.78426\n",
      "Epoch 27/100\n",
      "227/227 - 5s - loss: 0.5290 - accuracy: 0.8120 - auc: 0.8801 - val_loss: 0.7138 - val_accuracy: 0.7486 - val_auc: 0.7814\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.78426\n",
      "Epoch 28/100\n",
      "227/227 - 5s - loss: 0.5220 - accuracy: 0.8047 - auc: 0.8802 - val_loss: 0.8412 - val_accuracy: 0.8004 - val_auc: 0.7634\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.78426\n",
      "Epoch 29/100\n",
      "227/227 - 5s - loss: 0.5519 - accuracy: 0.8002 - auc: 0.8759 - val_loss: 0.8328 - val_accuracy: 0.5989 - val_auc: 0.7688\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.78426\n",
      "Epoch 30/100\n",
      "227/227 - 5s - loss: 0.5394 - accuracy: 0.7964 - auc: 0.8758 - val_loss: 0.7501 - val_accuracy: 0.6322 - val_auc: 0.7737\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.78426\n",
      "Epoch 31/100\n",
      "227/227 - 5s - loss: 0.5261 - accuracy: 0.7997 - auc: 0.8844 - val_loss: 0.7985 - val_accuracy: 0.7209 - val_auc: 0.7735\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.78426\n",
      "Epoch 32/100\n",
      "227/227 - 5s - loss: 0.5044 - accuracy: 0.8062 - auc: 0.8894 - val_loss: 0.7289 - val_accuracy: 0.7597 - val_auc: 0.7687\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.78426\n",
      "Epoch 33/100\n",
      "227/227 - 5s - loss: 0.4961 - accuracy: 0.8164 - auc: 0.8938 - val_loss: 0.8701 - val_accuracy: 0.7708 - val_auc: 0.7595\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.78426\n",
      "Epoch 34/100\n",
      "227/227 - 5s - loss: 0.4996 - accuracy: 0.8095 - auc: 0.8927 - val_loss: 0.7194 - val_accuracy: 0.6858 - val_auc: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_auc did not improve from 0.78426\n",
      "Epoch 35/100\n",
      "227/227 - 5s - loss: 0.4959 - accuracy: 0.8224 - auc: 0.8960 - val_loss: 0.7487 - val_accuracy: 0.7468 - val_auc: 0.7737\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.78426\n",
      "Epoch 36/100\n",
      "227/227 - 5s - loss: 0.4859 - accuracy: 0.8320 - auc: 0.8999 - val_loss: 0.7416 - val_accuracy: 0.7652 - val_auc: 0.7727\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.78426\n",
      "Epoch 37/100\n",
      "227/227 - 5s - loss: 0.4968 - accuracy: 0.8170 - auc: 0.8966 - val_loss: 0.7633 - val_accuracy: 0.7006 - val_auc: 0.7619\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.78426\n",
      "Epoch 38/100\n",
      "227/227 - 5s - loss: 0.4743 - accuracy: 0.8311 - auc: 0.9043 - val_loss: 0.7618 - val_accuracy: 0.6747 - val_auc: 0.7718\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.78426\n",
      "Epoch 39/100\n",
      "227/227 - 5s - loss: 0.4708 - accuracy: 0.8253 - auc: 0.9064 - val_loss: 0.8451 - val_accuracy: 0.7579 - val_auc: 0.7728\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.78426\n",
      "Epoch 40/100\n",
      "227/227 - 5s - loss: 0.4836 - accuracy: 0.8264 - auc: 0.9003 - val_loss: 0.7208 - val_accuracy: 0.7098 - val_auc: 0.7780\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.78426\n",
      "Epoch 41/100\n",
      "227/227 - 5s - loss: 0.4750 - accuracy: 0.8218 - auc: 0.9071 - val_loss: 0.7596 - val_accuracy: 0.6007 - val_auc: 0.7682\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.78426\n",
      "Epoch 42/100\n",
      "227/227 - 5s - loss: 0.4941 - accuracy: 0.8199 - auc: 0.9053 - val_loss: 0.7929 - val_accuracy: 0.7394 - val_auc: 0.7748\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.78426\n",
      "Epoch 43/100\n",
      "227/227 - 5s - loss: 0.4751 - accuracy: 0.8206 - auc: 0.9046 - val_loss: 0.7775 - val_accuracy: 0.7338 - val_auc: 0.7688\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.78426\n",
      "Epoch 44/100\n",
      "227/227 - 5s - loss: 0.4553 - accuracy: 0.8282 - auc: 0.9126 - val_loss: 0.7513 - val_accuracy: 0.6470 - val_auc: 0.7674\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.78426\n",
      "Epoch 45/100\n",
      "227/227 - 5s - loss: 0.4662 - accuracy: 0.8304 - auc: 0.9084 - val_loss: 0.8182 - val_accuracy: 0.6802 - val_auc: 0.7604\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.78426\n",
      "Epoch 46/100\n",
      "227/227 - 5s - loss: 0.4537 - accuracy: 0.8258 - auc: 0.9137 - val_loss: 0.8366 - val_accuracy: 0.6340 - val_auc: 0.7813\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.78426\n",
      "Epoch 47/100\n",
      "227/227 - 5s - loss: 0.4486 - accuracy: 0.8327 - auc: 0.9184 - val_loss: 0.8168 - val_accuracy: 0.5564 - val_auc: 0.7827\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.78426\n",
      "Epoch 48/100\n",
      "227/227 - 5s - loss: 0.4793 - accuracy: 0.8161 - auc: 0.9086 - val_loss: 0.8267 - val_accuracy: 0.7412 - val_auc: 0.7739\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.78426\n",
      "Epoch 49/100\n",
      "227/227 - 5s - loss: 0.4565 - accuracy: 0.8304 - auc: 0.9134 - val_loss: 0.8371 - val_accuracy: 0.7375 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.78426\n",
      "Epoch 50/100\n",
      "227/227 - 5s - loss: 0.4374 - accuracy: 0.8425 - auc: 0.9180 - val_loss: 0.8740 - val_accuracy: 0.7431 - val_auc: 0.7525\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.78426\n",
      "Epoch 51/100\n",
      "227/227 - 5s - loss: 0.4524 - accuracy: 0.8319 - auc: 0.9162 - val_loss: 0.8391 - val_accuracy: 0.7043 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.78426\n",
      "Epoch 52/100\n",
      "227/227 - 5s - loss: 0.4384 - accuracy: 0.8428 - auc: 0.9195 - val_loss: 0.7918 - val_accuracy: 0.6802 - val_auc: 0.7443\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.78426\n",
      "Epoch 53/100\n",
      "227/227 - 5s - loss: 0.4415 - accuracy: 0.8367 - auc: 0.9183 - val_loss: 0.8051 - val_accuracy: 0.7246 - val_auc: 0.7642\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.78426\n",
      "Epoch 54/100\n",
      "227/227 - 5s - loss: 0.4748 - accuracy: 0.8202 - auc: 0.9105 - val_loss: 0.8820 - val_accuracy: 0.7209 - val_auc: 0.7586\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.78426\n",
      "Epoch 55/100\n",
      "227/227 - 5s - loss: 0.4578 - accuracy: 0.8341 - auc: 0.9163 - val_loss: 0.9323 - val_accuracy: 0.7320 - val_auc: 0.7770\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.78426\n",
      "Epoch 56/100\n",
      "227/227 - 5s - loss: 0.4371 - accuracy: 0.8367 - auc: 0.9222 - val_loss: 0.8594 - val_accuracy: 0.6488 - val_auc: 0.7575\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.78426\n",
      "Epoch 57/100\n",
      "227/227 - 5s - loss: 0.4372 - accuracy: 0.8344 - auc: 0.9222 - val_loss: 0.8105 - val_accuracy: 0.7301 - val_auc: 0.7661\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.78426\n",
      "Epoch 58/100\n",
      "227/227 - 5s - loss: 0.4226 - accuracy: 0.8423 - auc: 0.9263 - val_loss: 0.8168 - val_accuracy: 0.7819 - val_auc: 0.7788\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.78426\n",
      "Epoch 59/100\n",
      "227/227 - 5s - loss: 0.4302 - accuracy: 0.8348 - auc: 0.9217 - val_loss: 0.9302 - val_accuracy: 0.7634 - val_auc: 0.7629\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.78426\n",
      "Epoch 60/100\n",
      "227/227 - 5s - loss: 0.4254 - accuracy: 0.8425 - auc: 0.9230 - val_loss: 0.7417 - val_accuracy: 0.6950 - val_auc: 0.7813\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.78426\n",
      "Epoch 61/100\n",
      "227/227 - 5s - loss: 0.4322 - accuracy: 0.8354 - auc: 0.9222 - val_loss: 0.9649 - val_accuracy: 0.7579 - val_auc: 0.7687\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.78426\n",
      "Epoch 62/100\n",
      "227/227 - 5s - loss: 0.4397 - accuracy: 0.8315 - auc: 0.9221 - val_loss: 0.9069 - val_accuracy: 0.7708 - val_auc: 0.7772\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.78426\n",
      "Epoch 63/100\n",
      "227/227 - 5s - loss: 0.4239 - accuracy: 0.8496 - auc: 0.9254 - val_loss: 0.8131 - val_accuracy: 0.7153 - val_auc: 0.7797\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.78426\n",
      "Epoch 64/100\n",
      "227/227 - 5s - loss: 0.4309 - accuracy: 0.8372 - auc: 0.9213 - val_loss: 0.9215 - val_accuracy: 0.7283 - val_auc: 0.7746\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.78426\n",
      "Epoch 65/100\n",
      "227/227 - 5s - loss: 0.4202 - accuracy: 0.8435 - auc: 0.9279 - val_loss: 0.8343 - val_accuracy: 0.6784 - val_auc: 0.7688\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.78426\n",
      "Epoch 66/100\n",
      "227/227 - 5s - loss: 0.4176 - accuracy: 0.8511 - auc: 0.9280 - val_loss: 0.8341 - val_accuracy: 0.7172 - val_auc: 0.7603\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.78426\n",
      "Epoch 67/100\n",
      "227/227 - 5s - loss: 0.4336 - accuracy: 0.8341 - auc: 0.9214 - val_loss: 0.9087 - val_accuracy: 0.7412 - val_auc: 0.7588\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.78426\n",
      "Epoch 68/100\n",
      "227/227 - 5s - loss: 0.4128 - accuracy: 0.8443 - auc: 0.9295 - val_loss: 0.8097 - val_accuracy: 0.6876 - val_auc: 0.7763\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.78426\n",
      "Epoch 69/100\n",
      "227/227 - 5s - loss: 0.4126 - accuracy: 0.8489 - auc: 0.9295 - val_loss: 0.7929 - val_accuracy: 0.7043 - val_auc: 0.7638\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.78426\n",
      "Epoch 70/100\n",
      "227/227 - 5s - loss: 0.4167 - accuracy: 0.8536 - auc: 0.9314 - val_loss: 0.8963 - val_accuracy: 0.6876 - val_auc: 0.7696\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.78426\n",
      "Epoch 71/100\n",
      "227/227 - 5s - loss: 0.4176 - accuracy: 0.8410 - auc: 0.9319 - val_loss: 0.9310 - val_accuracy: 0.7431 - val_auc: 0.7725\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.78426\n",
      "Epoch 72/100\n",
      "227/227 - 5s - loss: 0.4447 - accuracy: 0.8376 - auc: 0.9206 - val_loss: 0.8905 - val_accuracy: 0.7856 - val_auc: 0.7804\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.78426\n",
      "Epoch 73/100\n",
      "227/227 - 5s - loss: 0.4191 - accuracy: 0.8445 - auc: 0.9282 - val_loss: 0.7963 - val_accuracy: 0.7024 - val_auc: 0.7740\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.78426\n",
      "Epoch 74/100\n",
      "227/227 - 5s - loss: 0.4821 - accuracy: 0.8547 - auc: 0.9298 - val_loss: 0.9424 - val_accuracy: 0.7061 - val_auc: 0.7671\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.78426\n",
      "Epoch 75/100\n",
      "227/227 - 5s - loss: 0.4336 - accuracy: 0.8625 - auc: 0.9344 - val_loss: 1.0182 - val_accuracy: 0.7227 - val_auc: 0.7497\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.78426\n",
      "Epoch 76/100\n",
      "227/227 - 5s - loss: 0.4090 - accuracy: 0.8560 - auc: 0.9331 - val_loss: 0.9211 - val_accuracy: 0.7800 - val_auc: 0.7805\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.78426\n",
      "Epoch 77/100\n",
      "227/227 - 5s - loss: 0.4107 - accuracy: 0.8607 - auc: 0.9338 - val_loss: 0.9288 - val_accuracy: 0.7116 - val_auc: 0.7496\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.78426\n",
      "Epoch 78/100\n",
      "227/227 - 5s - loss: 0.4205 - accuracy: 0.8488 - auc: 0.9274 - val_loss: 0.8566 - val_accuracy: 0.7024 - val_auc: 0.7435\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.78426\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 - 5s - loss: 0.4020 - accuracy: 0.8569 - auc: 0.9340 - val_loss: 0.8776 - val_accuracy: 0.7967 - val_auc: 0.7796\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.78426\n",
      "Epoch 80/100\n",
      "227/227 - 5s - loss: 0.3975 - accuracy: 0.8542 - auc: 0.9358 - val_loss: 0.9037 - val_accuracy: 0.7689 - val_auc: 0.7686\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.78426\n",
      "Epoch 81/100\n",
      "227/227 - 5s - loss: 0.3978 - accuracy: 0.8584 - auc: 0.9348 - val_loss: 1.0470 - val_accuracy: 0.7985 - val_auc: 0.7704\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.78426\n",
      "Epoch 82/100\n",
      "227/227 - 5s - loss: 0.3944 - accuracy: 0.8644 - auc: 0.9382 - val_loss: 0.8981 - val_accuracy: 0.6192 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.78426\n",
      "Epoch 83/100\n",
      "227/227 - 5s - loss: 0.3981 - accuracy: 0.8555 - auc: 0.9353 - val_loss: 0.9402 - val_accuracy: 0.7523 - val_auc: 0.7652\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.78426\n",
      "Epoch 84/100\n",
      "227/227 - 5s - loss: 0.3847 - accuracy: 0.8669 - auc: 0.9397 - val_loss: 0.9460 - val_accuracy: 0.7616 - val_auc: 0.7773\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.78426\n",
      "Epoch 85/100\n",
      "227/227 - 5s - loss: 0.3828 - accuracy: 0.8659 - auc: 0.9411 - val_loss: 0.9098 - val_accuracy: 0.7468 - val_auc: 0.7685\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.78426\n",
      "Epoch 86/100\n",
      "227/227 - 5s - loss: 0.3809 - accuracy: 0.8672 - auc: 0.9416 - val_loss: 0.9464 - val_accuracy: 0.7043 - val_auc: 0.7574\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.78426\n",
      "Epoch 87/100\n",
      "227/227 - 5s - loss: 0.4162 - accuracy: 0.8579 - auc: 0.9323 - val_loss: 0.9215 - val_accuracy: 0.6322 - val_auc: 0.7587\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.78426\n",
      "Epoch 88/100\n",
      "227/227 - 5s - loss: 0.4407 - accuracy: 0.8637 - auc: 0.9370 - val_loss: 0.9522 - val_accuracy: 0.7726 - val_auc: 0.7733\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.78426\n",
      "Epoch 89/100\n",
      "227/227 - 5s - loss: 0.3878 - accuracy: 0.8706 - auc: 0.9410 - val_loss: 0.9247 - val_accuracy: 0.7468 - val_auc: 0.7605\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.78426\n",
      "Epoch 90/100\n",
      "227/227 - 5s - loss: 0.3738 - accuracy: 0.8738 - auc: 0.9443 - val_loss: 1.0000 - val_accuracy: 0.7560 - val_auc: 0.7700\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.78426\n",
      "Epoch 91/100\n",
      "227/227 - 5s - loss: 0.3643 - accuracy: 0.8828 - auc: 0.9475 - val_loss: 1.0271 - val_accuracy: 0.6969 - val_auc: 0.7396\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.78426\n",
      "Epoch 92/100\n",
      "227/227 - 5s - loss: 0.3753 - accuracy: 0.8735 - auc: 0.9438 - val_loss: 0.9914 - val_accuracy: 0.7689 - val_auc: 0.7575\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.78426\n",
      "Epoch 93/100\n",
      "227/227 - 5s - loss: 0.3806 - accuracy: 0.8741 - auc: 0.9399 - val_loss: 0.9789 - val_accuracy: 0.7634 - val_auc: 0.7617\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.78426\n",
      "Epoch 94/100\n",
      "227/227 - 5s - loss: 0.3863 - accuracy: 0.8688 - auc: 0.9411 - val_loss: 0.9796 - val_accuracy: 0.7135 - val_auc: 0.7661\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.78426\n",
      "Epoch 95/100\n",
      "227/227 - 5s - loss: 0.3735 - accuracy: 0.8732 - auc: 0.9451 - val_loss: 1.0190 - val_accuracy: 0.7985 - val_auc: 0.7512\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.78426\n",
      "Epoch 96/100\n",
      "227/227 - 5s - loss: 0.3697 - accuracy: 0.8807 - auc: 0.9454 - val_loss: 0.8843 - val_accuracy: 0.7246 - val_auc: 0.7610\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.78426\n",
      "Epoch 97/100\n",
      "227/227 - 5s - loss: 0.3560 - accuracy: 0.8843 - auc: 0.9495 - val_loss: 1.1054 - val_accuracy: 0.7449 - val_auc: 0.7387\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.78426\n",
      "Epoch 98/100\n",
      "227/227 - 5s - loss: 0.3724 - accuracy: 0.8792 - auc: 0.9456 - val_loss: 0.9450 - val_accuracy: 0.7394 - val_auc: 0.7424\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.78426\n",
      "Epoch 99/100\n",
      "227/227 - 5s - loss: 0.3931 - accuracy: 0.8620 - auc: 0.9376 - val_loss: 0.9128 - val_accuracy: 0.7394 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.78426\n",
      "Epoch 100/100\n",
      "227/227 - 5s - loss: 0.3832 - accuracy: 0.8784 - auc: 0.9449 - val_loss: 0.9105 - val_accuracy: 0.6636 - val_auc: 0.7385\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.78426\n",
      "Epoch 1/100\n",
      "284/284 - 8s - loss: 4.1164 - accuracy: 0.5307 - auc: 0.5457 - val_loss: 2.5534 - val_accuracy: 0.8177 - val_auc: 0.7263\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.72627, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 2/100\n",
      "284/284 - 6s - loss: 1.7250 - accuracy: 0.4435 - auc: 0.5937 - val_loss: 1.3653 - val_accuracy: 0.6552 - val_auc: 0.7102\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.72627\n",
      "Epoch 3/100\n",
      "284/284 - 6s - loss: 1.0199 - accuracy: 0.5269 - auc: 0.6561 - val_loss: 1.0020 - val_accuracy: 0.5107 - val_auc: 0.7317\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.72627 to 0.73165, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 4/100\n",
      "284/284 - 6s - loss: 0.8416 - accuracy: 0.7674 - auc: 0.7127 - val_loss: 0.9535 - val_accuracy: 0.6831 - val_auc: 0.7449\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.73165 to 0.74493, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 5/100\n",
      "284/284 - 7s - loss: 0.7550 - accuracy: 0.7459 - auc: 0.7714 - val_loss: 0.9020 - val_accuracy: 0.5320 - val_auc: 0.7485\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.74493 to 0.74852, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 6/100\n",
      "284/284 - 6s - loss: 0.6690 - accuracy: 0.7443 - auc: 0.8127 - val_loss: 0.8814 - val_accuracy: 0.3957 - val_auc: 0.7559\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.74852 to 0.75594, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 7/100\n",
      "284/284 - 6s - loss: 0.6082 - accuracy: 0.7415 - auc: 0.8438 - val_loss: 0.9882 - val_accuracy: 0.6864 - val_auc: 0.7767\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.75594 to 0.77671, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 8/100\n",
      "284/284 - 6s - loss: 0.7634 - accuracy: 0.6356 - auc: 0.8030 - val_loss: 0.9311 - val_accuracy: 0.8062 - val_auc: 0.7746\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77671\n",
      "Epoch 9/100\n",
      "284/284 - 6s - loss: 0.6108 - accuracy: 0.7671 - auc: 0.8562 - val_loss: 0.8584 - val_accuracy: 0.7603 - val_auc: 0.8007\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.77671 to 0.80066, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 10/100\n",
      "284/284 - 6s - loss: 0.5794 - accuracy: 0.7801 - auc: 0.8708 - val_loss: 0.7624 - val_accuracy: 0.6650 - val_auc: 0.8032\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.80066 to 0.80316, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 11/100\n",
      "284/284 - 6s - loss: 0.5748 - accuracy: 0.7769 - auc: 0.8607 - val_loss: 1.1103 - val_accuracy: 0.8588 - val_auc: 0.7909\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.80316\n",
      "Epoch 12/100\n",
      "284/284 - 6s - loss: 0.5233 - accuracy: 0.7673 - auc: 0.8810 - val_loss: 0.7852 - val_accuracy: 0.4417 - val_auc: 0.8024\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.80316\n",
      "Epoch 13/100\n",
      "284/284 - 7s - loss: 0.5319 - accuracy: 0.7685 - auc: 0.8842 - val_loss: 1.0041 - val_accuracy: 0.7586 - val_auc: 0.8000\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.80316\n",
      "Epoch 14/100\n",
      "284/284 - 6s - loss: 0.4993 - accuracy: 0.8055 - auc: 0.9003 - val_loss: 0.8471 - val_accuracy: 0.7750 - val_auc: 0.7972\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.80316\n",
      "Epoch 15/100\n",
      "284/284 - 6s - loss: 0.6683 - accuracy: 0.7199 - auc: 0.8740 - val_loss: 1.0291 - val_accuracy: 0.7406 - val_auc: 0.7906\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.80316\n",
      "Epoch 16/100\n",
      "284/284 - 6s - loss: 0.5689 - accuracy: 0.7794 - auc: 0.8913 - val_loss: 0.9616 - val_accuracy: 0.6617 - val_auc: 0.8115\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.80316 to 0.81154, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 17/100\n",
      "284/284 - 6s - loss: 0.5662 - accuracy: 0.7466 - auc: 0.8758 - val_loss: 0.9780 - val_accuracy: 0.8292 - val_auc: 0.8141\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.81154 to 0.81414, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 18/100\n",
      "284/284 - 6s - loss: 0.6419 - accuracy: 0.7497 - auc: 0.8825 - val_loss: 1.1350 - val_accuracy: 0.7980 - val_auc: 0.8083\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.81414\n",
      "Epoch 19/100\n",
      "284/284 - 6s - loss: 0.5036 - accuracy: 0.8013 - auc: 0.9107 - val_loss: 0.8539 - val_accuracy: 0.5829 - val_auc: 0.7864\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.81414\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 - 6s - loss: 0.4408 - accuracy: 0.8225 - auc: 0.9285 - val_loss: 1.1223 - val_accuracy: 0.7800 - val_auc: 0.7926\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.81414\n",
      "Epoch 21/100\n",
      "284/284 - 6s - loss: 0.4529 - accuracy: 0.8121 - auc: 0.9202 - val_loss: 1.0635 - val_accuracy: 0.7258 - val_auc: 0.8033\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.81414\n",
      "Epoch 22/100\n",
      "284/284 - 6s - loss: 0.4345 - accuracy: 0.8303 - auc: 0.9259 - val_loss: 0.9017 - val_accuracy: 0.7209 - val_auc: 0.8033\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.81414\n",
      "Epoch 23/100\n",
      "284/284 - 6s - loss: 0.4491 - accuracy: 0.8039 - auc: 0.9133 - val_loss: 1.0510 - val_accuracy: 0.6929 - val_auc: 0.7991\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.81414\n",
      "Epoch 24/100\n",
      "284/284 - 6s - loss: 0.4394 - accuracy: 0.8283 - auc: 0.9208 - val_loss: 1.6510 - val_accuracy: 0.7833 - val_auc: 0.7931\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.81414\n",
      "Epoch 25/100\n",
      "284/284 - 6s - loss: 0.4531 - accuracy: 0.8315 - auc: 0.9262 - val_loss: 1.3337 - val_accuracy: 0.8144 - val_auc: 0.8018\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.81414\n",
      "Epoch 26/100\n",
      "284/284 - 6s - loss: 0.4485 - accuracy: 0.8165 - auc: 0.9250 - val_loss: 1.0413 - val_accuracy: 0.7882 - val_auc: 0.8144\n",
      "\n",
      "Epoch 00026: val_auc improved from 0.81414 to 0.81440, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 27/100\n",
      "284/284 - 6s - loss: 0.4304 - accuracy: 0.8286 - auc: 0.9316 - val_loss: 1.2941 - val_accuracy: 0.8062 - val_auc: 0.8013\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.81440\n",
      "Epoch 28/100\n",
      "284/284 - 6s - loss: 0.4096 - accuracy: 0.8226 - auc: 0.9330 - val_loss: 1.4669 - val_accuracy: 0.7389 - val_auc: 0.7847\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.81440\n",
      "Epoch 29/100\n",
      "284/284 - 6s - loss: 0.4005 - accuracy: 0.8301 - auc: 0.9381 - val_loss: 1.0522 - val_accuracy: 0.6749 - val_auc: 0.8029\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.81440\n",
      "Epoch 30/100\n",
      "284/284 - 6s - loss: 0.3832 - accuracy: 0.8479 - auc: 0.9416 - val_loss: 1.1010 - val_accuracy: 0.6913 - val_auc: 0.8020\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.81440\n",
      "Epoch 31/100\n",
      "284/284 - 6s - loss: 0.3718 - accuracy: 0.8555 - auc: 0.9470 - val_loss: 1.1932 - val_accuracy: 0.7438 - val_auc: 0.7959\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.81440\n",
      "Epoch 32/100\n",
      "284/284 - 6s - loss: 0.4328 - accuracy: 0.7802 - auc: 0.9223 - val_loss: 1.0203 - val_accuracy: 0.6256 - val_auc: 0.7873\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.81440\n",
      "Epoch 33/100\n",
      "284/284 - 6s - loss: 0.4418 - accuracy: 0.8008 - auc: 0.9352 - val_loss: 1.3420 - val_accuracy: 0.6683 - val_auc: 0.7901\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.81440\n",
      "Epoch 34/100\n",
      "284/284 - 6s - loss: 0.4043 - accuracy: 0.8194 - auc: 0.9394 - val_loss: 2.0596 - val_accuracy: 0.8210 - val_auc: 0.7709\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.81440\n",
      "Epoch 35/100\n",
      "284/284 - 6s - loss: 0.4632 - accuracy: 0.8011 - auc: 0.9276 - val_loss: 1.0778 - val_accuracy: 0.6585 - val_auc: 0.8092\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.81440\n",
      "Epoch 36/100\n",
      "284/284 - 6s - loss: 0.4102 - accuracy: 0.8405 - auc: 0.9449 - val_loss: 2.4076 - val_accuracy: 0.8785 - val_auc: 0.8157\n",
      "\n",
      "Epoch 00036: val_auc improved from 0.81440 to 0.81571, saving model to 210120_TrainingDeep\\210120_Dense_SR-ATAD5\n",
      "Epoch 37/100\n",
      "284/284 - 6s - loss: 0.3815 - accuracy: 0.8508 - auc: 0.9510 - val_loss: 1.3857 - val_accuracy: 0.7537 - val_auc: 0.7898\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.81571\n",
      "Epoch 38/100\n",
      "284/284 - 6s - loss: 0.3925 - accuracy: 0.8289 - auc: 0.9432 - val_loss: 2.2071 - val_accuracy: 0.8194 - val_auc: 0.7938\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.81571\n",
      "Epoch 39/100\n",
      "284/284 - 6s - loss: 0.6915 - accuracy: 0.7782 - auc: 0.9104 - val_loss: 1.7338 - val_accuracy: 0.7471 - val_auc: 0.7609\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.81571\n",
      "Epoch 40/100\n",
      "284/284 - 6s - loss: 0.5906 - accuracy: 0.8536 - auc: 0.9475 - val_loss: 1.7087 - val_accuracy: 0.8374 - val_auc: 0.8050\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.81571\n",
      "Epoch 41/100\n",
      "284/284 - 6s - loss: 0.4619 - accuracy: 0.8433 - auc: 0.9512 - val_loss: 1.5163 - val_accuracy: 0.7964 - val_auc: 0.8065\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.81571\n",
      "Epoch 42/100\n",
      "284/284 - 6s - loss: 0.4848 - accuracy: 0.7870 - auc: 0.9298 - val_loss: 2.5055 - val_accuracy: 0.8621 - val_auc: 0.7739\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.81571\n",
      "Epoch 43/100\n",
      "284/284 - 6s - loss: 0.8136 - accuracy: 0.7846 - auc: 0.9137 - val_loss: 1.5908 - val_accuracy: 0.7915 - val_auc: 0.8030\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.81571\n",
      "Epoch 44/100\n",
      "284/284 - 6s - loss: 0.4862 - accuracy: 0.8315 - auc: 0.9450 - val_loss: 1.5237 - val_accuracy: 0.7176 - val_auc: 0.7869\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.81571\n",
      "Epoch 45/100\n",
      "284/284 - 6s - loss: 0.4086 - accuracy: 0.8656 - auc: 0.9562 - val_loss: 1.6422 - val_accuracy: 0.7389 - val_auc: 0.7812\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.81571\n",
      "Epoch 46/100\n",
      "284/284 - 6s - loss: 0.3632 - accuracy: 0.8831 - auc: 0.9633 - val_loss: 1.9297 - val_accuracy: 0.7701 - val_auc: 0.7896\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.81571\n",
      "Epoch 47/100\n",
      "284/284 - 6s - loss: 0.3614 - accuracy: 0.8746 - auc: 0.9603 - val_loss: 2.4205 - val_accuracy: 0.8719 - val_auc: 0.7573\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.81571\n",
      "Epoch 48/100\n",
      "284/284 - 6s - loss: 0.3881 - accuracy: 0.8506 - auc: 0.9482 - val_loss: 1.6651 - val_accuracy: 0.7570 - val_auc: 0.7853\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.81571\n",
      "Epoch 49/100\n",
      "284/284 - 6s - loss: 0.3319 - accuracy: 0.8834 - auc: 0.9630 - val_loss: 2.5475 - val_accuracy: 0.8703 - val_auc: 0.7734\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.81571\n",
      "Epoch 50/100\n",
      "284/284 - 6s - loss: 0.3239 - accuracy: 0.8685 - auc: 0.9628 - val_loss: 2.5494 - val_accuracy: 0.7915 - val_auc: 0.7590\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.81571\n",
      "Epoch 51/100\n",
      "284/284 - 6s - loss: 0.5057 - accuracy: 0.7616 - auc: 0.9110 - val_loss: 1.3411 - val_accuracy: 0.5222 - val_auc: 0.7740\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.81571\n",
      "Epoch 52/100\n",
      "284/284 - 6s - loss: 0.6241 - accuracy: 0.7890 - auc: 0.9270 - val_loss: 1.1779 - val_accuracy: 0.7258 - val_auc: 0.7863\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.81571\n",
      "Epoch 53/100\n",
      "284/284 - 6s - loss: 0.3980 - accuracy: 0.8722 - auc: 0.9592 - val_loss: 2.2821 - val_accuracy: 0.8144 - val_auc: 0.7862\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.81571\n",
      "Epoch 54/100\n",
      "284/284 - 6s - loss: 0.4608 - accuracy: 0.8262 - auc: 0.9477 - val_loss: 1.4314 - val_accuracy: 0.5698 - val_auc: 0.7782\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.81571\n",
      "Epoch 55/100\n",
      "284/284 - 6s - loss: 0.6504 - accuracy: 0.5743 - auc: 0.8501 - val_loss: 1.0392 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.81571\n",
      "Epoch 56/100\n",
      "284/284 - 6s - loss: 0.8283 - accuracy: 0.0544 - auc: 0.4977 - val_loss: 0.9996 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.81571\n",
      "Epoch 57/100\n",
      "284/284 - 6s - loss: 0.8424 - accuracy: 0.1850 - auc: 0.5636 - val_loss: 1.2159 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.81571\n",
      "Epoch 58/100\n",
      "284/284 - 6s - loss: 0.8968 - accuracy: 0.3480 - auc: 0.4904 - val_loss: 1.0425 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.81571\n",
      "Epoch 59/100\n",
      "284/284 - 6s - loss: 0.8440 - accuracy: 0.0382 - auc: 0.4853 - val_loss: 1.0198 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.81571\n",
      "Epoch 60/100\n",
      "284/284 - 6s - loss: 0.8265 - accuracy: 0.7909 - auc: 0.4938 - val_loss: 1.0066 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.81571\n",
      "Epoch 61/100\n",
      "284/284 - 6s - loss: 0.8154 - accuracy: 0.6011 - auc: 0.4929 - val_loss: 0.9961 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.81571\n",
      "Epoch 62/100\n",
      "284/284 - 6s - loss: 0.8062 - accuracy: 0.5315 - auc: 0.4962 - val_loss: 0.9892 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.81571\n",
      "Epoch 63/100\n",
      "284/284 - 6s - loss: 0.7989 - accuracy: 0.5472 - auc: 0.4991 - val_loss: 0.9822 - val_accuracy: 0.0591 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00063: val_auc did not improve from 0.81571\n",
      "Epoch 64/100\n",
      "284/284 - 6s - loss: 0.7926 - accuracy: 0.2989 - auc: 0.5000 - val_loss: 0.9765 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.81571\n",
      "Epoch 65/100\n",
      "284/284 - 6s - loss: 0.7873 - accuracy: 0.8959 - auc: 0.4859 - val_loss: 0.9713 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.81571\n",
      "Epoch 66/100\n",
      "284/284 - 6s - loss: 0.7826 - accuracy: 0.1578 - auc: 0.4937 - val_loss: 0.9662 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.81571\n",
      "Epoch 67/100\n",
      "284/284 - 6s - loss: 0.7785 - accuracy: 0.0403 - auc: 0.4793 - val_loss: 0.9628 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.81571\n",
      "Epoch 68/100\n",
      "284/284 - 6s - loss: 0.7750 - accuracy: 0.6000 - auc: 0.4891 - val_loss: 0.9595 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.81571\n",
      "Epoch 69/100\n",
      "284/284 - 6s - loss: 3.1145 - accuracy: 0.2458 - auc: 0.5116 - val_loss: 2.0442 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.81571\n",
      "Epoch 70/100\n",
      "284/284 - 6s - loss: 1.3128 - accuracy: 0.8013 - auc: 0.4939 - val_loss: 1.2188 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.81571\n",
      "Epoch 71/100\n",
      "284/284 - 6s - loss: 0.9473 - accuracy: 0.8209 - auc: 0.4878 - val_loss: 1.0751 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.81571\n",
      "Epoch 72/100\n",
      "284/284 - 6s - loss: 0.8567 - accuracy: 0.6124 - auc: 0.5000 - val_loss: 1.0179 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.81571\n",
      "Epoch 73/100\n",
      "284/284 - 6s - loss: 0.8360 - accuracy: 0.3866 - auc: 0.6597 - val_loss: 1.1529 - val_accuracy: 0.2726 - val_auc: 0.6968\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.81571\n",
      "Epoch 74/100\n",
      "284/284 - 6s - loss: 1.0104 - accuracy: 0.7293 - auc: 0.6124 - val_loss: 1.0343 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.81571\n",
      "Epoch 75/100\n",
      "284/284 - 6s - loss: 0.9332 - accuracy: 0.7805 - auc: 0.5958 - val_loss: 1.0159 - val_accuracy: 0.6043 - val_auc: 0.7224\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.81571\n",
      "Epoch 76/100\n",
      "284/284 - 6s - loss: 0.8876 - accuracy: 0.8808 - auc: 0.6184 - val_loss: 1.0625 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.81571\n",
      "Epoch 77/100\n",
      "284/284 - 6s - loss: 0.8250 - accuracy: 0.9036 - auc: 0.4901 - val_loss: 0.9989 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.81571\n",
      "Epoch 78/100\n",
      "284/284 - 6s - loss: 0.7957 - accuracy: 0.9440 - auc: 0.4917 - val_loss: 0.9841 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.81571\n",
      "Epoch 79/100\n",
      "284/284 - 6s - loss: 0.7828 - accuracy: 0.9597 - auc: 0.4989 - val_loss: 0.9701 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.81571\n",
      "Epoch 80/100\n",
      "284/284 - 6s - loss: 0.8302 - accuracy: 0.8499 - auc: 0.5087 - val_loss: 0.9856 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.81571\n",
      "Epoch 81/100\n",
      "284/284 - 6s - loss: 0.8006 - accuracy: 0.9608 - auc: 0.4858 - val_loss: 1.0014 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.81571\n",
      "Epoch 82/100\n",
      "284/284 - 6s - loss: 0.7833 - accuracy: 0.9621 - auc: 0.4793 - val_loss: 0.9635 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.81571\n",
      "Epoch 83/100\n",
      "284/284 - 6s - loss: 0.7718 - accuracy: 0.9621 - auc: 0.4858 - val_loss: 0.9573 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.81571\n",
      "Epoch 84/100\n",
      "284/284 - 6s - loss: 0.7677 - accuracy: 0.8223 - auc: 0.4867 - val_loss: 0.9533 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.81571\n",
      "Epoch 85/100\n",
      "284/284 - 6s - loss: 0.7651 - accuracy: 0.9474 - auc: 0.4798 - val_loss: 0.9511 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.81571\n",
      "Epoch 86/100\n",
      "284/284 - 6s - loss: 0.7693 - accuracy: 0.7432 - auc: 0.5042 - val_loss: 0.9592 - val_accuracy: 0.9409 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.81571\n",
      "Epoch 87/100\n",
      "284/284 - 6s - loss: 0.7661 - accuracy: 0.8573 - auc: 0.4935 - val_loss: 0.9491 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.81571\n",
      "Epoch 88/100\n",
      "284/284 - 6s - loss: 0.7611 - accuracy: 0.6170 - auc: 0.4949 - val_loss: 0.9467 - val_accuracy: 0.0608 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.81571\n",
      "Epoch 89/100\n",
      "284/284 - 6s - loss: 0.8008 - accuracy: 0.4289 - auc: 0.5297 - val_loss: 1.0243 - val_accuracy: 0.1018 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.81571\n",
      "Epoch 90/100\n",
      "284/284 - 6s - loss: 0.8553 - accuracy: 0.3970 - auc: 0.4915 - val_loss: 1.0058 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.81571\n",
      "Epoch 91/100\n",
      "284/284 - 6s - loss: 0.8247 - accuracy: 0.1765 - auc: 0.5001 - val_loss: 0.9615 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.81571\n",
      "Epoch 92/100\n",
      "284/284 - 6s - loss: 0.7814 - accuracy: 0.3907 - auc: 0.5483 - val_loss: 1.0460 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.81571\n",
      "Epoch 93/100\n",
      "284/284 - 6s - loss: 0.8000 - accuracy: 0.3294 - auc: 0.5594 - val_loss: 0.9708 - val_accuracy: 0.0591 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.81571\n",
      "Epoch 94/100\n",
      "284/284 - 6s - loss: 0.7483 - accuracy: 0.8195 - auc: 0.6447 - val_loss: 0.9514 - val_accuracy: 0.6535 - val_auc: 0.7229\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.81571\n",
      "Epoch 95/100\n",
      "284/284 - 6s - loss: 0.7435 - accuracy: 0.8315 - auc: 0.7353 - val_loss: 1.0621 - val_accuracy: 0.4286 - val_auc: 0.7197\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.81571\n",
      "Epoch 96/100\n",
      "284/284 - 6s - loss: 0.8610 - accuracy: 0.7239 - auc: 0.7982 - val_loss: 0.9879 - val_accuracy: 0.4680 - val_auc: 0.7323\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.81571\n",
      "Epoch 97/100\n",
      "284/284 - 6s - loss: 0.8458 - accuracy: 0.6677 - auc: 0.7989 - val_loss: 1.0539 - val_accuracy: 0.7947 - val_auc: 0.7824\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.81571\n",
      "Epoch 98/100\n",
      "284/284 - 6s - loss: 0.7972 - accuracy: 0.7658 - auc: 0.8401 - val_loss: 1.0899 - val_accuracy: 0.7028 - val_auc: 0.7725\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.81571\n",
      "Epoch 99/100\n",
      "284/284 - 6s - loss: 0.9875 - accuracy: 0.7491 - auc: 0.8057 - val_loss: 1.0563 - val_accuracy: 0.2791 - val_auc: 0.7456\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.81571\n",
      "Epoch 100/100\n",
      "284/284 - 6s - loss: 0.7796 - accuracy: 0.6894 - auc: 0.8462 - val_loss: 1.1304 - val_accuracy: 0.4877 - val_auc: 0.7588\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.81571\n",
      "Epoch 1/100\n",
      "257/257 - 10s - loss: 3.4407 - accuracy: 0.5786 - auc: 0.5363 - val_loss: 1.8589 - val_accuracy: 0.0319 - val_auc: 0.7111\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.71112, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 2/100\n",
      "257/257 - 6s - loss: 1.2389 - accuracy: 0.6493 - auc: 0.6841 - val_loss: 0.9149 - val_accuracy: 0.3473 - val_auc: 0.7342\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.71112 to 0.73415, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 3/100\n",
      "257/257 - 6s - loss: 0.9274 - accuracy: 0.6289 - auc: 0.6906 - val_loss: 0.6824 - val_accuracy: 0.9128 - val_auc: 0.7490\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.73415 to 0.74902, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 4/100\n",
      "257/257 - 6s - loss: 0.7554 - accuracy: 0.6971 - auc: 0.7560 - val_loss: 0.6360 - val_accuracy: 0.7064 - val_auc: 0.7458\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.74902\n",
      "Epoch 5/100\n",
      "257/257 - 6s - loss: 0.6912 - accuracy: 0.7401 - auc: 0.7830 - val_loss: 0.6230 - val_accuracy: 0.7919 - val_auc: 0.7348\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.74902\n",
      "Epoch 6/100\n",
      "257/257 - 6s - loss: 0.6440 - accuracy: 0.7658 - auc: 0.8072 - val_loss: 0.6072 - val_accuracy: 0.6795 - val_auc: 0.7700\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.74902 to 0.77004, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "257/257 - 6s - loss: 0.6285 - accuracy: 0.7801 - auc: 0.8125 - val_loss: 0.7482 - val_accuracy: 0.5034 - val_auc: 0.7587\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.77004\n",
      "Epoch 8/100\n",
      "257/257 - 6s - loss: 0.6345 - accuracy: 0.7611 - auc: 0.8082 - val_loss: 0.5917 - val_accuracy: 0.8255 - val_auc: 0.7505\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77004\n",
      "Epoch 9/100\n",
      "257/257 - 6s - loss: 0.6006 - accuracy: 0.7877 - auc: 0.8261 - val_loss: 0.5826 - val_accuracy: 0.8003 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.77004\n",
      "Epoch 10/100\n",
      "257/257 - 6s - loss: 0.5977 - accuracy: 0.7875 - auc: 0.8250 - val_loss: 0.5822 - val_accuracy: 0.7936 - val_auc: 0.7409\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.77004\n",
      "Epoch 11/100\n",
      "257/257 - 6s - loss: 0.7067 - accuracy: 0.7476 - auc: 0.8069 - val_loss: 0.7244 - val_accuracy: 0.6174 - val_auc: 0.7213\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77004\n",
      "Epoch 12/100\n",
      "257/257 - 6s - loss: 0.6390 - accuracy: 0.7523 - auc: 0.8231 - val_loss: 0.6894 - val_accuracy: 0.5956 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.77004\n",
      "Epoch 13/100\n",
      "257/257 - 6s - loss: 0.5891 - accuracy: 0.7167 - auc: 0.8404 - val_loss: 0.6823 - val_accuracy: 0.4564 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77004\n",
      "Epoch 14/100\n",
      "257/257 - 6s - loss: 0.5955 - accuracy: 0.7721 - auc: 0.8432 - val_loss: 0.6726 - val_accuracy: 0.6644 - val_auc: 0.7554\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.77004\n",
      "Epoch 15/100\n",
      "257/257 - 6s - loss: 0.5663 - accuracy: 0.7911 - auc: 0.8518 - val_loss: 0.7010 - val_accuracy: 0.6745 - val_auc: 0.7463\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77004\n",
      "Epoch 16/100\n",
      "257/257 - 6s - loss: 0.5571 - accuracy: 0.8026 - auc: 0.8574 - val_loss: 0.6057 - val_accuracy: 0.6661 - val_auc: 0.7644\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77004\n",
      "Epoch 17/100\n",
      "257/257 - 6s - loss: 0.5371 - accuracy: 0.8232 - auc: 0.8681 - val_loss: 0.6411 - val_accuracy: 0.6946 - val_auc: 0.7503\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77004\n",
      "Epoch 18/100\n",
      "257/257 - 6s - loss: 0.5740 - accuracy: 0.7714 - auc: 0.8488 - val_loss: 0.6340 - val_accuracy: 0.5889 - val_auc: 0.7446\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.77004\n",
      "Epoch 19/100\n",
      "257/257 - 6s - loss: 0.5396 - accuracy: 0.8189 - auc: 0.8700 - val_loss: 0.6921 - val_accuracy: 0.6242 - val_auc: 0.7324\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.77004\n",
      "Epoch 20/100\n",
      "257/257 - 6s - loss: 0.5498 - accuracy: 0.8214 - auc: 0.8653 - val_loss: 0.6226 - val_accuracy: 0.7332 - val_auc: 0.7600\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.77004\n",
      "Epoch 21/100\n",
      "257/257 - 6s - loss: 0.5299 - accuracy: 0.8172 - auc: 0.8759 - val_loss: 0.6180 - val_accuracy: 0.7164 - val_auc: 0.7447\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.77004\n",
      "Epoch 22/100\n",
      "257/257 - 6s - loss: 0.5265 - accuracy: 0.7985 - auc: 0.8771 - val_loss: 0.6163 - val_accuracy: 0.8003 - val_auc: 0.7134\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.77004\n",
      "Epoch 23/100\n",
      "257/257 - 6s - loss: 0.5646 - accuracy: 0.7912 - auc: 0.8605 - val_loss: 0.6359 - val_accuracy: 0.7517 - val_auc: 0.7095\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.77004\n",
      "Epoch 24/100\n",
      "257/257 - 6s - loss: 0.5333 - accuracy: 0.7899 - auc: 0.8764 - val_loss: 0.6619 - val_accuracy: 0.7131 - val_auc: 0.7466\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.77004\n",
      "Epoch 25/100\n",
      "257/257 - 6s - loss: 0.5125 - accuracy: 0.8133 - auc: 0.8842 - val_loss: 0.6879 - val_accuracy: 0.7248 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.77004\n",
      "Epoch 26/100\n",
      "257/257 - 6s - loss: 0.5151 - accuracy: 0.8047 - auc: 0.8847 - val_loss: 0.6190 - val_accuracy: 0.7567 - val_auc: 0.7235\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.77004\n",
      "Epoch 27/100\n",
      "257/257 - 6s - loss: 0.5027 - accuracy: 0.8121 - auc: 0.8897 - val_loss: 0.6283 - val_accuracy: 0.8372 - val_auc: 0.7533\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.77004\n",
      "Epoch 28/100\n",
      "257/257 - 6s - loss: 0.5187 - accuracy: 0.7985 - auc: 0.8865 - val_loss: 0.7418 - val_accuracy: 0.5940 - val_auc: 0.7100\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.77004\n",
      "Epoch 29/100\n",
      "257/257 - 6s - loss: 0.4986 - accuracy: 0.8097 - auc: 0.8956 - val_loss: 0.5800 - val_accuracy: 0.8574 - val_auc: 0.7617\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.77004\n",
      "Epoch 30/100\n",
      "257/257 - 6s - loss: 0.5018 - accuracy: 0.8007 - auc: 0.8920 - val_loss: 0.6148 - val_accuracy: 0.8742 - val_auc: 0.7112\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.77004\n",
      "Epoch 31/100\n",
      "257/257 - 6s - loss: 0.5165 - accuracy: 0.7881 - auc: 0.8883 - val_loss: 0.6802 - val_accuracy: 0.6829 - val_auc: 0.7358\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.77004\n",
      "Epoch 32/100\n",
      "257/257 - 6s - loss: 0.5569 - accuracy: 0.7762 - auc: 0.8881 - val_loss: 1.1140 - val_accuracy: 0.2936 - val_auc: 0.7409\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.77004\n",
      "Epoch 33/100\n",
      "257/257 - 6s - loss: 0.6780 - accuracy: 0.8183 - auc: 0.8894 - val_loss: 0.9541 - val_accuracy: 0.5285 - val_auc: 0.7290\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.77004\n",
      "Epoch 34/100\n",
      "257/257 - 6s - loss: 0.5344 - accuracy: 0.7862 - auc: 0.8975 - val_loss: 0.6332 - val_accuracy: 0.8691 - val_auc: 0.7507\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.77004\n",
      "Epoch 35/100\n",
      "257/257 - 6s - loss: 0.4860 - accuracy: 0.8292 - auc: 0.9059 - val_loss: 0.7396 - val_accuracy: 0.8775 - val_auc: 0.7117\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.77004\n",
      "Epoch 36/100\n",
      "257/257 - 6s - loss: 0.4756 - accuracy: 0.8349 - auc: 0.9089 - val_loss: 0.7259 - val_accuracy: 0.7802 - val_auc: 0.6948\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.77004\n",
      "Epoch 37/100\n",
      "257/257 - 6s - loss: 0.4951 - accuracy: 0.8114 - auc: 0.8974 - val_loss: 0.6468 - val_accuracy: 0.7047 - val_auc: 0.7244\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.77004\n",
      "Epoch 38/100\n",
      "257/257 - 6s - loss: 0.4570 - accuracy: 0.8166 - auc: 0.9154 - val_loss: 0.6575 - val_accuracy: 0.8607 - val_auc: 0.7477\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.77004\n",
      "Epoch 39/100\n",
      "257/257 - 6s - loss: 0.5064 - accuracy: 0.8102 - auc: 0.8984 - val_loss: 0.6332 - val_accuracy: 0.8154 - val_auc: 0.7084\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.77004\n",
      "Epoch 40/100\n",
      "257/257 - 6s - loss: 0.4767 - accuracy: 0.8253 - auc: 0.9103 - val_loss: 0.7163 - val_accuracy: 0.8020 - val_auc: 0.6835\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.77004\n",
      "Epoch 41/100\n",
      "257/257 - 6s - loss: 0.4737 - accuracy: 0.8023 - auc: 0.9059 - val_loss: 0.6652 - val_accuracy: 0.8255 - val_auc: 0.7246\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.77004\n",
      "Epoch 42/100\n",
      "257/257 - 6s - loss: 0.4771 - accuracy: 0.8232 - auc: 0.9048 - val_loss: 0.7075 - val_accuracy: 0.7366 - val_auc: 0.7360\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.77004\n",
      "Epoch 43/100\n",
      "257/257 - 6s - loss: 0.4493 - accuracy: 0.8209 - auc: 0.9180 - val_loss: 0.7015 - val_accuracy: 0.7315 - val_auc: 0.6968\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.77004\n",
      "Epoch 44/100\n",
      "257/257 - 6s - loss: 0.4532 - accuracy: 0.8323 - auc: 0.9177 - val_loss: 0.7375 - val_accuracy: 0.7047 - val_auc: 0.7218\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.77004\n",
      "Epoch 45/100\n",
      "257/257 - 6s - loss: 0.5364 - accuracy: 0.7986 - auc: 0.9015 - val_loss: 1.0599 - val_accuracy: 0.5789 - val_auc: 0.7357\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.77004\n",
      "Epoch 46/100\n",
      "257/257 - 6s - loss: 0.9073 - accuracy: 0.7746 - auc: 0.8913 - val_loss: 0.8302 - val_accuracy: 0.6678 - val_auc: 0.6862\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.77004\n",
      "Epoch 47/100\n",
      "257/257 - 6s - loss: 0.5320 - accuracy: 0.8271 - auc: 0.9114 - val_loss: 0.8809 - val_accuracy: 0.5789 - val_auc: 0.7210\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.77004\n",
      "Epoch 48/100\n",
      "257/257 - 6s - loss: 0.4866 - accuracy: 0.8236 - auc: 0.9108 - val_loss: 0.6704 - val_accuracy: 0.7114 - val_auc: 0.7560\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.77004\n",
      "Epoch 49/100\n",
      "257/257 - 6s - loss: 0.4377 - accuracy: 0.8288 - auc: 0.9281 - val_loss: 0.7237 - val_accuracy: 0.7836 - val_auc: 0.7123\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.77004\n",
      "Epoch 50/100\n",
      "257/257 - 6s - loss: 0.4516 - accuracy: 0.8200 - auc: 0.9187 - val_loss: 0.6717 - val_accuracy: 0.7919 - val_auc: 0.7263\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.77004\n",
      "Epoch 51/100\n",
      "257/257 - 6s - loss: 0.4344 - accuracy: 0.8348 - auc: 0.9258 - val_loss: 0.7433 - val_accuracy: 0.7584 - val_auc: 0.7591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_auc did not improve from 0.77004\n",
      "Epoch 52/100\n",
      "257/257 - 6s - loss: 0.4159 - accuracy: 0.8320 - auc: 0.9317 - val_loss: 0.7643 - val_accuracy: 0.7819 - val_auc: 0.7527\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.77004\n",
      "Epoch 53/100\n",
      "257/257 - 6s - loss: 0.4343 - accuracy: 0.8418 - auc: 0.9253 - val_loss: 0.8128 - val_accuracy: 0.8725 - val_auc: 0.7518\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.77004\n",
      "Epoch 54/100\n",
      "257/257 - 6s - loss: 0.4374 - accuracy: 0.8379 - auc: 0.9271 - val_loss: 0.7729 - val_accuracy: 0.8020 - val_auc: 0.7002\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.77004\n",
      "Epoch 55/100\n",
      "257/257 - 6s - loss: 0.4174 - accuracy: 0.8346 - auc: 0.9304 - val_loss: 0.8809 - val_accuracy: 0.7534 - val_auc: 0.7331\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.77004\n",
      "Epoch 56/100\n",
      "257/257 - 6s - loss: 0.4154 - accuracy: 0.8371 - auc: 0.9313 - val_loss: 0.7760 - val_accuracy: 0.7668 - val_auc: 0.7747\n",
      "\n",
      "Epoch 00056: val_auc improved from 0.77004 to 0.77465, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 57/100\n",
      "257/257 - 6s - loss: 0.4136 - accuracy: 0.8311 - auc: 0.9308 - val_loss: 0.8571 - val_accuracy: 0.7450 - val_auc: 0.6600\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.77465\n",
      "Epoch 58/100\n",
      "257/257 - 6s - loss: 0.4041 - accuracy: 0.8407 - auc: 0.9353 - val_loss: 0.9581 - val_accuracy: 0.7919 - val_auc: 0.6691\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.77465\n",
      "Epoch 59/100\n",
      "257/257 - 6s - loss: 0.4305 - accuracy: 0.8229 - auc: 0.9241 - val_loss: 0.7882 - val_accuracy: 0.8641 - val_auc: 0.7373\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.77465\n",
      "Epoch 60/100\n",
      "257/257 - 6s - loss: 0.8171 - accuracy: 0.7905 - auc: 0.9006 - val_loss: 0.9441 - val_accuracy: 0.7198 - val_auc: 0.6924\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.77465\n",
      "Epoch 61/100\n",
      "257/257 - 6s - loss: 0.4772 - accuracy: 0.8281 - auc: 0.9378 - val_loss: 1.0815 - val_accuracy: 0.5436 - val_auc: 0.7242\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.77465\n",
      "Epoch 62/100\n",
      "257/257 - 6s - loss: 0.4383 - accuracy: 0.8524 - auc: 0.9384 - val_loss: 0.9574 - val_accuracy: 0.7282 - val_auc: 0.7399\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.77465\n",
      "Epoch 63/100\n",
      "257/257 - 6s - loss: 0.4637 - accuracy: 0.7861 - auc: 0.9139 - val_loss: 0.8278 - val_accuracy: 0.8607 - val_auc: 0.7504\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.77465\n",
      "Epoch 64/100\n",
      "257/257 - 6s - loss: 0.4032 - accuracy: 0.8350 - auc: 0.9384 - val_loss: 0.8867 - val_accuracy: 0.8289 - val_auc: 0.7517\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.77465\n",
      "Epoch 65/100\n",
      "257/257 - 6s - loss: 0.3924 - accuracy: 0.8384 - auc: 0.9423 - val_loss: 0.9378 - val_accuracy: 0.8121 - val_auc: 0.7831\n",
      "\n",
      "Epoch 00065: val_auc improved from 0.77465 to 0.78313, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 66/100\n",
      "257/257 - 6s - loss: 0.4280 - accuracy: 0.8332 - auc: 0.9286 - val_loss: 0.7808 - val_accuracy: 0.8641 - val_auc: 0.7566\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.78313\n",
      "Epoch 67/100\n",
      "257/257 - 6s - loss: 0.3725 - accuracy: 0.8545 - auc: 0.9493 - val_loss: 0.8908 - val_accuracy: 0.8322 - val_auc: 0.7747\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.78313\n",
      "Epoch 68/100\n",
      "257/257 - 6s - loss: 0.3947 - accuracy: 0.8498 - auc: 0.9390 - val_loss: 0.9420 - val_accuracy: 0.9010 - val_auc: 0.7765\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.78313\n",
      "Epoch 69/100\n",
      "257/257 - 6s - loss: 0.3919 - accuracy: 0.8517 - auc: 0.9426 - val_loss: 0.8603 - val_accuracy: 0.7617 - val_auc: 0.7112\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.78313\n",
      "Epoch 70/100\n",
      "257/257 - 6s - loss: 0.3655 - accuracy: 0.8769 - auc: 0.9516 - val_loss: 1.2379 - val_accuracy: 0.8674 - val_auc: 0.7664\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.78313\n",
      "Epoch 71/100\n",
      "257/257 - 6s - loss: 0.4070 - accuracy: 0.8449 - auc: 0.9376 - val_loss: 0.8692 - val_accuracy: 0.7164 - val_auc: 0.7542\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.78313\n",
      "Epoch 72/100\n",
      "257/257 - 6s - loss: 0.4808 - accuracy: 0.8208 - auc: 0.9259 - val_loss: 0.6205 - val_accuracy: 0.8356 - val_auc: 0.8119\n",
      "\n",
      "Epoch 00072: val_auc improved from 0.78313 to 0.81191, saving model to 210120_TrainingDeep\\210120_Dense_SR-HSE\n",
      "Epoch 73/100\n",
      "257/257 - 6s - loss: 0.3947 - accuracy: 0.8676 - auc: 0.9487 - val_loss: 0.9106 - val_accuracy: 0.7500 - val_auc: 0.7341\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.81191\n",
      "Epoch 74/100\n",
      "257/257 - 6s - loss: 0.3876 - accuracy: 0.8570 - auc: 0.9459 - val_loss: 0.7364 - val_accuracy: 0.5419 - val_auc: 0.7157\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.81191\n",
      "Epoch 75/100\n",
      "257/257 - 6s - loss: 0.3865 - accuracy: 0.8605 - auc: 0.9455 - val_loss: 0.9207 - val_accuracy: 0.7450 - val_auc: 0.7382\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.81191\n",
      "Epoch 76/100\n",
      "257/257 - 6s - loss: 0.3599 - accuracy: 0.8608 - auc: 0.9519 - val_loss: 0.8554 - val_accuracy: 0.8104 - val_auc: 0.7638\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.81191\n",
      "Epoch 77/100\n",
      "257/257 - 6s - loss: 0.4885 - accuracy: 0.8284 - auc: 0.9231 - val_loss: 0.6942 - val_accuracy: 0.7869 - val_auc: 0.7416\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.81191\n",
      "Epoch 78/100\n",
      "257/257 - 6s - loss: 0.4264 - accuracy: 0.8537 - auc: 0.9405 - val_loss: 1.0163 - val_accuracy: 0.6711 - val_auc: 0.7208\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.81191\n",
      "Epoch 79/100\n",
      "257/257 - 6s - loss: 0.3852 - accuracy: 0.8619 - auc: 0.9460 - val_loss: 1.0436 - val_accuracy: 0.8070 - val_auc: 0.7637\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.81191\n",
      "Epoch 80/100\n",
      "257/257 - 6s - loss: 0.3638 - accuracy: 0.8578 - auc: 0.9504 - val_loss: 1.0266 - val_accuracy: 0.7802 - val_auc: 0.7312\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.81191\n",
      "Epoch 81/100\n",
      "257/257 - 6s - loss: 0.3750 - accuracy: 0.8519 - auc: 0.9451 - val_loss: 1.0507 - val_accuracy: 0.7886 - val_auc: 0.7351\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.81191\n",
      "Epoch 82/100\n",
      "257/257 - 6s - loss: 0.3702 - accuracy: 0.8666 - auc: 0.9473 - val_loss: 0.9656 - val_accuracy: 0.7366 - val_auc: 0.7188\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.81191\n",
      "Epoch 83/100\n",
      "257/257 - 6s - loss: 0.3758 - accuracy: 0.8685 - auc: 0.9487 - val_loss: 1.0137 - val_accuracy: 0.7685 - val_auc: 0.7081\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.81191\n",
      "Epoch 84/100\n",
      "257/257 - 6s - loss: 0.5042 - accuracy: 0.8217 - auc: 0.9206 - val_loss: 0.8789 - val_accuracy: 0.7601 - val_auc: 0.7371\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.81191\n",
      "Epoch 85/100\n",
      "257/257 - 6s - loss: 0.4707 - accuracy: 0.8430 - auc: 0.9431 - val_loss: 1.0711 - val_accuracy: 0.7198 - val_auc: 0.7180\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.81191\n",
      "Epoch 86/100\n",
      "257/257 - 6s - loss: 0.4168 - accuracy: 0.8580 - auc: 0.9432 - val_loss: 1.1298 - val_accuracy: 0.7601 - val_auc: 0.6939\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.81191\n",
      "Epoch 87/100\n",
      "257/257 - 6s - loss: 0.3892 - accuracy: 0.8597 - auc: 0.9462 - val_loss: 0.9404 - val_accuracy: 0.8507 - val_auc: 0.7308\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.81191\n",
      "Epoch 88/100\n",
      "257/257 - 6s - loss: 0.3911 - accuracy: 0.8564 - auc: 0.9404 - val_loss: 1.1944 - val_accuracy: 0.8138 - val_auc: 0.7087\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.81191\n",
      "Epoch 89/100\n",
      "257/257 - 6s - loss: 0.4914 - accuracy: 0.7979 - auc: 0.9245 - val_loss: 0.8576 - val_accuracy: 0.8926 - val_auc: 0.7182\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.81191\n",
      "Epoch 90/100\n",
      "257/257 - 6s - loss: 0.4027 - accuracy: 0.8632 - auc: 0.9519 - val_loss: 1.0178 - val_accuracy: 0.8473 - val_auc: 0.7469\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.81191\n",
      "Epoch 91/100\n",
      "257/257 - 6s - loss: 0.4135 - accuracy: 0.8494 - auc: 0.9433 - val_loss: 0.8911 - val_accuracy: 0.8255 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.81191\n",
      "Epoch 92/100\n",
      "257/257 - 6s - loss: 0.3640 - accuracy: 0.8743 - auc: 0.9557 - val_loss: 1.3041 - val_accuracy: 0.8171 - val_auc: 0.6743\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.81191\n",
      "Epoch 93/100\n",
      "257/257 - 6s - loss: 0.3590 - accuracy: 0.8658 - auc: 0.9549 - val_loss: 1.0112 - val_accuracy: 0.8339 - val_auc: 0.7260\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.81191\n",
      "Epoch 94/100\n",
      "257/257 - 6s - loss: 0.3800 - accuracy: 0.8369 - auc: 0.9499 - val_loss: 0.7480 - val_accuracy: 0.6997 - val_auc: 0.7283\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.81191\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 6s - loss: 0.3566 - accuracy: 0.8672 - auc: 0.9567 - val_loss: 1.0749 - val_accuracy: 0.8389 - val_auc: 0.7191\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.81191\n",
      "Epoch 96/100\n",
      "257/257 - 6s - loss: 0.3601 - accuracy: 0.8691 - auc: 0.9536 - val_loss: 0.8648 - val_accuracy: 0.7114 - val_auc: 0.7402\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.81191\n",
      "Epoch 97/100\n",
      "257/257 - 6s - loss: 0.3445 - accuracy: 0.8792 - auc: 0.9595 - val_loss: 0.9937 - val_accuracy: 0.7685 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.81191\n",
      "Epoch 98/100\n",
      "257/257 - 6s - loss: 0.3597 - accuracy: 0.8595 - auc: 0.9534 - val_loss: 0.8146 - val_accuracy: 0.7919 - val_auc: 0.7362\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.81191\n",
      "Epoch 99/100\n",
      "257/257 - 6s - loss: 0.3713 - accuracy: 0.8654 - auc: 0.9511 - val_loss: 0.9996 - val_accuracy: 0.6846 - val_auc: 0.6708\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.81191\n",
      "Epoch 100/100\n",
      "257/257 - 6s - loss: 0.3693 - accuracy: 0.8677 - auc: 0.9538 - val_loss: 1.0771 - val_accuracy: 0.8171 - val_auc: 0.7061\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.81191\n",
      "Epoch 1/100\n",
      "230/230 - 7s - loss: 3.1800 - accuracy: 0.6627 - auc: 0.7874 - val_loss: 1.5220 - val_accuracy: 0.8908 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.90556, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 2/100\n",
      "230/230 - 6s - loss: 1.0909 - accuracy: 0.7413 - auc: 0.8541 - val_loss: 0.6918 - val_accuracy: 0.8041 - val_auc: 0.8994\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.90556\n",
      "Epoch 3/100\n",
      "230/230 - 5s - loss: 0.6990 - accuracy: 0.7655 - auc: 0.8747 - val_loss: 0.5049 - val_accuracy: 0.8606 - val_auc: 0.9185\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.90556 to 0.91848, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 4/100\n",
      "230/230 - 5s - loss: 0.5837 - accuracy: 0.7790 - auc: 0.8908 - val_loss: 0.5551 - val_accuracy: 0.7213 - val_auc: 0.9160\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.91848\n",
      "Epoch 5/100\n",
      "230/230 - 5s - loss: 0.5474 - accuracy: 0.7941 - auc: 0.8942 - val_loss: 0.4779 - val_accuracy: 0.7702 - val_auc: 0.9160\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.91848\n",
      "Epoch 6/100\n",
      "230/230 - 5s - loss: 0.5190 - accuracy: 0.8174 - auc: 0.9013 - val_loss: 0.4425 - val_accuracy: 0.8004 - val_auc: 0.9257\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.91848 to 0.92575, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 7/100\n",
      "230/230 - 5s - loss: 0.4997 - accuracy: 0.8181 - auc: 0.9061 - val_loss: 0.5587 - val_accuracy: 0.6328 - val_auc: 0.9227\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.92575\n",
      "Epoch 8/100\n",
      "230/230 - 5s - loss: 0.4855 - accuracy: 0.8276 - auc: 0.9109 - val_loss: 0.5461 - val_accuracy: 0.7232 - val_auc: 0.9216\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.92575\n",
      "Epoch 9/100\n",
      "230/230 - 5s - loss: 0.4712 - accuracy: 0.8365 - auc: 0.9156 - val_loss: 0.4157 - val_accuracy: 0.8437 - val_auc: 0.9230\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.92575\n",
      "Epoch 10/100\n",
      "230/230 - 5s - loss: 0.4657 - accuracy: 0.8471 - auc: 0.9199 - val_loss: 0.5674 - val_accuracy: 0.6478 - val_auc: 0.9263\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.92575 to 0.92633, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 11/100\n",
      "230/230 - 5s - loss: 0.4717 - accuracy: 0.8337 - auc: 0.9164 - val_loss: 0.3951 - val_accuracy: 0.8795 - val_auc: 0.9292\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.92633 to 0.92923, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 12/100\n",
      "230/230 - 5s - loss: 0.4795 - accuracy: 0.8269 - auc: 0.9126 - val_loss: 0.5872 - val_accuracy: 0.6685 - val_auc: 0.9195\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.92923\n",
      "Epoch 13/100\n",
      "230/230 - 5s - loss: 0.4484 - accuracy: 0.8538 - auc: 0.9263 - val_loss: 0.4235 - val_accuracy: 0.7947 - val_auc: 0.9235\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.92923\n",
      "Epoch 14/100\n",
      "230/230 - 5s - loss: 0.4404 - accuracy: 0.8563 - auc: 0.9271 - val_loss: 0.4729 - val_accuracy: 0.7533 - val_auc: 0.9262\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.92923\n",
      "Epoch 15/100\n",
      "230/230 - 5s - loss: 0.4287 - accuracy: 0.8574 - auc: 0.9308 - val_loss: 0.5031 - val_accuracy: 0.7307 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.92923\n",
      "Epoch 16/100\n",
      "230/230 - 5s - loss: 0.4467 - accuracy: 0.8520 - auc: 0.9270 - val_loss: 0.4426 - val_accuracy: 0.8437 - val_auc: 0.9168\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.92923\n",
      "Epoch 17/100\n",
      "230/230 - 5s - loss: 0.4259 - accuracy: 0.8638 - auc: 0.9338 - val_loss: 0.4164 - val_accuracy: 0.8588 - val_auc: 0.9296\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.92923 to 0.92965, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 18/100\n",
      "230/230 - 5s - loss: 0.4274 - accuracy: 0.8576 - auc: 0.9337 - val_loss: 0.4415 - val_accuracy: 0.9021 - val_auc: 0.9282\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.92965\n",
      "Epoch 19/100\n",
      "230/230 - 5s - loss: 0.4304 - accuracy: 0.8664 - auc: 0.9355 - val_loss: 0.4238 - val_accuracy: 0.8136 - val_auc: 0.9142\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.92965\n",
      "Epoch 20/100\n",
      "230/230 - 5s - loss: 0.4042 - accuracy: 0.8791 - auc: 0.9398 - val_loss: 0.4353 - val_accuracy: 0.8079 - val_auc: 0.9282\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.92965\n",
      "Epoch 21/100\n",
      "230/230 - 5s - loss: 0.3945 - accuracy: 0.8804 - auc: 0.9429 - val_loss: 0.4428 - val_accuracy: 0.8023 - val_auc: 0.9232\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.92965\n",
      "Epoch 22/100\n",
      "230/230 - 5s - loss: 0.3973 - accuracy: 0.8768 - auc: 0.9422 - val_loss: 0.4016 - val_accuracy: 0.8136 - val_auc: 0.9281\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.92965\n",
      "Epoch 23/100\n",
      "230/230 - 5s - loss: 0.3845 - accuracy: 0.8811 - auc: 0.9454 - val_loss: 0.4106 - val_accuracy: 0.8701 - val_auc: 0.9201\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.92965\n",
      "Epoch 24/100\n",
      "230/230 - 5s - loss: 0.3828 - accuracy: 0.8843 - auc: 0.9488 - val_loss: 0.4657 - val_accuracy: 0.8060 - val_auc: 0.9225\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.92965\n",
      "Epoch 25/100\n",
      "230/230 - 5s - loss: 0.3904 - accuracy: 0.8765 - auc: 0.9466 - val_loss: 0.4360 - val_accuracy: 0.8211 - val_auc: 0.9302\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.92965 to 0.93021, saving model to 210120_TrainingDeep\\210120_Dense_SR-MMP\n",
      "Epoch 26/100\n",
      "230/230 - 5s - loss: 0.3983 - accuracy: 0.8794 - auc: 0.9454 - val_loss: 0.4673 - val_accuracy: 0.8211 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.93021\n",
      "Epoch 27/100\n",
      "230/230 - 5s - loss: 0.3734 - accuracy: 0.8905 - auc: 0.9514 - val_loss: 0.4603 - val_accuracy: 0.7872 - val_auc: 0.9201\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.93021\n",
      "Epoch 28/100\n",
      "230/230 - 5s - loss: 0.3829 - accuracy: 0.8818 - auc: 0.9512 - val_loss: 0.4517 - val_accuracy: 0.7947 - val_auc: 0.9141\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.93021\n",
      "Epoch 29/100\n",
      "230/230 - 5s - loss: 0.3611 - accuracy: 0.8915 - auc: 0.9537 - val_loss: 0.4128 - val_accuracy: 0.8606 - val_auc: 0.9191\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.93021\n",
      "Epoch 30/100\n",
      "230/230 - 5s - loss: 0.3565 - accuracy: 0.8930 - auc: 0.9554 - val_loss: 0.4111 - val_accuracy: 0.8663 - val_auc: 0.9208\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.93021\n",
      "Epoch 31/100\n",
      "230/230 - 5s - loss: 0.3490 - accuracy: 0.8971 - auc: 0.9561 - val_loss: 0.4284 - val_accuracy: 0.8418 - val_auc: 0.9115\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.93021\n",
      "Epoch 32/100\n",
      "230/230 - 5s - loss: 0.3535 - accuracy: 0.8904 - auc: 0.9545 - val_loss: 0.4448 - val_accuracy: 0.8719 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.93021\n",
      "Epoch 33/100\n",
      "230/230 - 5s - loss: 0.3402 - accuracy: 0.9021 - auc: 0.9585 - val_loss: 0.4884 - val_accuracy: 0.7721 - val_auc: 0.9240\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.93021\n",
      "Epoch 34/100\n",
      "230/230 - 5s - loss: 0.3416 - accuracy: 0.8988 - auc: 0.9576 - val_loss: 0.4239 - val_accuracy: 0.8380 - val_auc: 0.9199\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.93021\n",
      "Epoch 35/100\n",
      "230/230 - 5s - loss: 0.3327 - accuracy: 0.8967 - auc: 0.9617 - val_loss: 0.4845 - val_accuracy: 0.8606 - val_auc: 0.9183\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.93021\n",
      "Epoch 36/100\n",
      "230/230 - 5s - loss: 0.3443 - accuracy: 0.8952 - auc: 0.9573 - val_loss: 0.4278 - val_accuracy: 0.8343 - val_auc: 0.9248\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.93021\n",
      "Epoch 37/100\n",
      "230/230 - 5s - loss: 0.3293 - accuracy: 0.8990 - auc: 0.9618 - val_loss: 0.4676 - val_accuracy: 0.8606 - val_auc: 0.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_auc did not improve from 0.93021\n",
      "Epoch 38/100\n",
      "230/230 - 5s - loss: 0.3528 - accuracy: 0.8946 - auc: 0.9590 - val_loss: 0.4293 - val_accuracy: 0.8701 - val_auc: 0.9224\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.93021\n",
      "Epoch 39/100\n",
      "230/230 - 5s - loss: 0.3494 - accuracy: 0.8986 - auc: 0.9604 - val_loss: 0.4223 - val_accuracy: 0.8814 - val_auc: 0.9292\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.93021\n",
      "Epoch 40/100\n",
      "230/230 - 5s - loss: 0.3389 - accuracy: 0.8975 - auc: 0.9610 - val_loss: 0.4342 - val_accuracy: 0.8719 - val_auc: 0.9232\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.93021\n",
      "Epoch 41/100\n",
      "230/230 - 5s - loss: 0.3468 - accuracy: 0.8946 - auc: 0.9594 - val_loss: 0.5784 - val_accuracy: 0.6911 - val_auc: 0.9207\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.93021\n",
      "Epoch 42/100\n",
      "230/230 - 5s - loss: 0.3521 - accuracy: 0.8975 - auc: 0.9598 - val_loss: 0.5073 - val_accuracy: 0.8004 - val_auc: 0.9251\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.93021\n",
      "Epoch 43/100\n",
      "230/230 - 5s - loss: 0.3378 - accuracy: 0.9028 - auc: 0.9634 - val_loss: 0.4621 - val_accuracy: 0.8719 - val_auc: 0.9187\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.93021\n",
      "Epoch 44/100\n",
      "230/230 - 5s - loss: 0.3264 - accuracy: 0.9018 - auc: 0.9618 - val_loss: 0.4450 - val_accuracy: 0.8324 - val_auc: 0.9178\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.93021\n",
      "Epoch 45/100\n",
      "230/230 - 5s - loss: 0.3143 - accuracy: 0.9051 - auc: 0.9643 - val_loss: 0.5165 - val_accuracy: 0.7571 - val_auc: 0.9222\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.93021\n",
      "Epoch 46/100\n",
      "230/230 - 5s - loss: 0.3226 - accuracy: 0.8983 - auc: 0.9620 - val_loss: 0.4282 - val_accuracy: 0.8399 - val_auc: 0.9195\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.93021\n",
      "Epoch 47/100\n",
      "230/230 - 5s - loss: 0.3109 - accuracy: 0.9089 - auc: 0.9657 - val_loss: 0.4648 - val_accuracy: 0.8588 - val_auc: 0.9132\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.93021\n",
      "Epoch 48/100\n",
      "230/230 - 5s - loss: 0.3049 - accuracy: 0.9094 - auc: 0.9663 - val_loss: 0.5364 - val_accuracy: 0.8362 - val_auc: 0.8896\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.93021\n",
      "Epoch 49/100\n",
      "230/230 - 5s - loss: 0.3073 - accuracy: 0.9047 - auc: 0.9677 - val_loss: 0.4588 - val_accuracy: 0.8192 - val_auc: 0.9097\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.93021\n",
      "Epoch 50/100\n",
      "230/230 - 5s - loss: 0.2992 - accuracy: 0.9105 - auc: 0.9680 - val_loss: 0.6757 - val_accuracy: 0.6817 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.93021\n",
      "Epoch 51/100\n",
      "230/230 - 5s - loss: 0.3436 - accuracy: 0.8962 - auc: 0.9627 - val_loss: 0.4004 - val_accuracy: 0.8606 - val_auc: 0.9235\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.93021\n",
      "Epoch 52/100\n",
      "230/230 - 5s - loss: 0.4070 - accuracy: 0.8920 - auc: 0.9587 - val_loss: 0.4718 - val_accuracy: 0.8625 - val_auc: 0.9122\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.93021\n",
      "Epoch 53/100\n",
      "230/230 - 5s - loss: 0.3345 - accuracy: 0.9013 - auc: 0.9632 - val_loss: 0.4256 - val_accuracy: 0.8230 - val_auc: 0.9169\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.93021\n",
      "Epoch 54/100\n",
      "230/230 - 5s - loss: 0.3211 - accuracy: 0.8942 - auc: 0.9644 - val_loss: 0.4346 - val_accuracy: 0.8644 - val_auc: 0.9144\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.93021\n",
      "Epoch 55/100\n",
      "230/230 - 5s - loss: 0.2968 - accuracy: 0.9146 - auc: 0.9689 - val_loss: 0.4715 - val_accuracy: 0.8343 - val_auc: 0.9083\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.93021\n",
      "Epoch 56/100\n",
      "230/230 - 5s - loss: 0.3159 - accuracy: 0.8968 - auc: 0.9640 - val_loss: 0.4588 - val_accuracy: 0.8776 - val_auc: 0.9098\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.93021\n",
      "Epoch 57/100\n",
      "230/230 - 5s - loss: 0.2957 - accuracy: 0.9176 - auc: 0.9684 - val_loss: 0.4318 - val_accuracy: 0.8230 - val_auc: 0.9175\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.93021\n",
      "Epoch 58/100\n",
      "230/230 - 5s - loss: 0.3027 - accuracy: 0.9089 - auc: 0.9675 - val_loss: 0.4427 - val_accuracy: 0.8588 - val_auc: 0.9190\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.93021\n",
      "Epoch 59/100\n",
      "230/230 - 5s - loss: 0.2905 - accuracy: 0.9104 - auc: 0.9707 - val_loss: 0.4540 - val_accuracy: 0.8456 - val_auc: 0.9191\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.93021\n",
      "Epoch 60/100\n",
      "230/230 - 5s - loss: 0.3005 - accuracy: 0.9036 - auc: 0.9672 - val_loss: 0.4955 - val_accuracy: 0.8606 - val_auc: 0.9154\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.93021\n",
      "Epoch 61/100\n",
      "230/230 - 5s - loss: 0.2902 - accuracy: 0.9060 - auc: 0.9702 - val_loss: 0.5355 - val_accuracy: 0.8399 - val_auc: 0.8936\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.93021\n",
      "Epoch 62/100\n",
      "230/230 - 5s - loss: 0.3342 - accuracy: 0.8911 - auc: 0.9621 - val_loss: 0.4943 - val_accuracy: 0.8060 - val_auc: 0.9152\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.93021\n",
      "Epoch 63/100\n",
      "230/230 - 5s - loss: 0.3350 - accuracy: 0.8965 - auc: 0.9613 - val_loss: 0.4354 - val_accuracy: 0.8192 - val_auc: 0.9162\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.93021\n",
      "Epoch 64/100\n",
      "230/230 - 5s - loss: 0.3072 - accuracy: 0.9014 - auc: 0.9669 - val_loss: 0.4263 - val_accuracy: 0.8493 - val_auc: 0.9117\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.93021\n",
      "Epoch 65/100\n",
      "230/230 - 5s - loss: 0.2931 - accuracy: 0.9105 - auc: 0.9689 - val_loss: 0.4883 - val_accuracy: 0.8795 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.93021\n",
      "Epoch 66/100\n",
      "230/230 - 5s - loss: 0.3043 - accuracy: 0.9115 - auc: 0.9678 - val_loss: 0.6406 - val_accuracy: 0.8719 - val_auc: 0.8697\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.93021\n",
      "Epoch 67/100\n",
      "230/230 - 5s - loss: 0.3180 - accuracy: 0.9052 - auc: 0.9655 - val_loss: 0.4678 - val_accuracy: 0.7175 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.93021\n",
      "Epoch 68/100\n",
      "230/230 - 5s - loss: 0.4759 - accuracy: 0.8817 - auc: 0.9559 - val_loss: 0.5210 - val_accuracy: 0.8324 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.93021\n",
      "Epoch 69/100\n",
      "230/230 - 5s - loss: 0.3232 - accuracy: 0.9116 - auc: 0.9705 - val_loss: 0.5346 - val_accuracy: 0.8493 - val_auc: 0.8981\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.93021\n",
      "Epoch 70/100\n",
      "230/230 - 5s - loss: 0.2981 - accuracy: 0.9176 - auc: 0.9722 - val_loss: 0.4635 - val_accuracy: 0.8211 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.93021\n",
      "Epoch 71/100\n",
      "230/230 - 5s - loss: 0.2994 - accuracy: 0.9142 - auc: 0.9688 - val_loss: 0.5116 - val_accuracy: 0.8343 - val_auc: 0.8935\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.93021\n",
      "Epoch 72/100\n",
      "230/230 - 5s - loss: 0.2853 - accuracy: 0.9179 - auc: 0.9720 - val_loss: 0.5055 - val_accuracy: 0.8475 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.93021\n",
      "Epoch 73/100\n",
      "230/230 - 5s - loss: 0.2878 - accuracy: 0.9142 - auc: 0.9710 - val_loss: 0.5639 - val_accuracy: 0.8776 - val_auc: 0.8887\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.93021\n",
      "Epoch 74/100\n",
      "230/230 - 5s - loss: 0.2925 - accuracy: 0.9063 - auc: 0.9713 - val_loss: 0.4986 - val_accuracy: 0.8493 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.93021\n",
      "Epoch 75/100\n",
      "230/230 - 5s - loss: 0.2765 - accuracy: 0.9176 - auc: 0.9739 - val_loss: 0.4755 - val_accuracy: 0.7928 - val_auc: 0.9139\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.93021\n",
      "Epoch 76/100\n",
      "230/230 - 5s - loss: 0.2807 - accuracy: 0.9152 - auc: 0.9727 - val_loss: 0.4601 - val_accuracy: 0.8267 - val_auc: 0.9142\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.93021\n",
      "Epoch 77/100\n",
      "230/230 - 5s - loss: 0.2732 - accuracy: 0.9186 - auc: 0.9735 - val_loss: 0.5223 - val_accuracy: 0.8625 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.93021\n",
      "Epoch 78/100\n",
      "230/230 - 5s - loss: 0.2774 - accuracy: 0.9138 - auc: 0.9727 - val_loss: 0.5597 - val_accuracy: 0.8324 - val_auc: 0.8864\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.93021\n",
      "Epoch 79/100\n",
      "230/230 - 5s - loss: 0.3189 - accuracy: 0.9032 - auc: 0.9690 - val_loss: 0.6102 - val_accuracy: 0.8286 - val_auc: 0.8794\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.93021\n",
      "Epoch 80/100\n",
      "230/230 - 5s - loss: 0.2834 - accuracy: 0.9150 - auc: 0.9743 - val_loss: 0.5060 - val_accuracy: 0.8569 - val_auc: 0.9041\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.93021\n",
      "Epoch 81/100\n",
      "230/230 - 5s - loss: 0.2613 - accuracy: 0.9218 - auc: 0.9763 - val_loss: 0.5060 - val_accuracy: 0.8475 - val_auc: 0.8990\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.93021\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 - 5s - loss: 0.2662 - accuracy: 0.9233 - auc: 0.9757 - val_loss: 0.5510 - val_accuracy: 0.7721 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.93021\n",
      "Epoch 83/100\n",
      "230/230 - 5s - loss: 0.2765 - accuracy: 0.9141 - auc: 0.9730 - val_loss: 0.7198 - val_accuracy: 0.8625 - val_auc: 0.8796\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.93021\n",
      "Epoch 84/100\n",
      "230/230 - 5s - loss: 0.2827 - accuracy: 0.9138 - auc: 0.9734 - val_loss: 0.4703 - val_accuracy: 0.8399 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.93021\n",
      "Epoch 85/100\n",
      "230/230 - 5s - loss: 0.2599 - accuracy: 0.9250 - auc: 0.9762 - val_loss: 0.5350 - val_accuracy: 0.8192 - val_auc: 0.8962\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.93021\n",
      "Epoch 86/100\n",
      "230/230 - 5s - loss: 0.2638 - accuracy: 0.9216 - auc: 0.9756 - val_loss: 0.4603 - val_accuracy: 0.7966 - val_auc: 0.9120\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.93021\n",
      "Epoch 87/100\n",
      "230/230 - 5s - loss: 0.2652 - accuracy: 0.9190 - auc: 0.9761 - val_loss: 0.4443 - val_accuracy: 0.8588 - val_auc: 0.9107\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.93021\n",
      "Epoch 88/100\n",
      "230/230 - 5s - loss: 0.2902 - accuracy: 0.9081 - auc: 0.9720 - val_loss: 0.5420 - val_accuracy: 0.8173 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.93021\n",
      "Epoch 89/100\n",
      "230/230 - 5s - loss: 0.2646 - accuracy: 0.9242 - auc: 0.9771 - val_loss: 0.5709 - val_accuracy: 0.8267 - val_auc: 0.8791\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.93021\n",
      "Epoch 90/100\n",
      "230/230 - 5s - loss: 0.2742 - accuracy: 0.9138 - auc: 0.9740 - val_loss: 0.5396 - val_accuracy: 0.8475 - val_auc: 0.8973\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.93021\n",
      "Epoch 91/100\n",
      "230/230 - 5s - loss: 0.2712 - accuracy: 0.9199 - auc: 0.9754 - val_loss: 0.4820 - val_accuracy: 0.8362 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.93021\n",
      "Epoch 92/100\n",
      "230/230 - 5s - loss: 0.2629 - accuracy: 0.9191 - auc: 0.9753 - val_loss: 0.7456 - val_accuracy: 0.8663 - val_auc: 0.8675\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.93021\n",
      "Epoch 93/100\n",
      "230/230 - 5s - loss: 0.2547 - accuracy: 0.9262 - auc: 0.9767 - val_loss: 0.5926 - val_accuracy: 0.8512 - val_auc: 0.8974\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.93021\n",
      "Epoch 94/100\n",
      "230/230 - 5s - loss: 0.2584 - accuracy: 0.9202 - auc: 0.9765 - val_loss: 0.5379 - val_accuracy: 0.7891 - val_auc: 0.9084\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.93021\n",
      "Epoch 95/100\n",
      "230/230 - 5s - loss: 0.2588 - accuracy: 0.9188 - auc: 0.9750 - val_loss: 0.4853 - val_accuracy: 0.8343 - val_auc: 0.9094\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.93021\n",
      "Epoch 96/100\n",
      "230/230 - 5s - loss: 0.2660 - accuracy: 0.9295 - auc: 0.9769 - val_loss: 0.5631 - val_accuracy: 0.8380 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.93021\n",
      "Epoch 97/100\n",
      "230/230 - 5s - loss: 0.2681 - accuracy: 0.9206 - auc: 0.9762 - val_loss: 0.5388 - val_accuracy: 0.8324 - val_auc: 0.9082\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.93021\n",
      "Epoch 98/100\n",
      "230/230 - 5s - loss: 0.2650 - accuracy: 0.9158 - auc: 0.9757 - val_loss: 0.5670 - val_accuracy: 0.8606 - val_auc: 0.8981\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.93021\n",
      "Epoch 99/100\n",
      "230/230 - 5s - loss: 0.2557 - accuracy: 0.9239 - auc: 0.9780 - val_loss: 0.4232 - val_accuracy: 0.8286 - val_auc: 0.9181\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.93021\n",
      "Epoch 100/100\n",
      "230/230 - 5s - loss: 0.2776 - accuracy: 0.9187 - auc: 0.9754 - val_loss: 0.6042 - val_accuracy: 0.8211 - val_auc: 0.8947\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.93021\n",
      "Epoch 1/100\n",
      "271/271 - 10s - loss: 7.1964 - accuracy: 0.7022 - auc: 0.4961 - val_loss: 2.0315 - val_accuracy: 0.0680 - val_auc: 0.5385\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.53854, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 2/100\n",
      "271/271 - 6s - loss: 1.3843 - accuracy: 0.6034 - auc: 0.4821 - val_loss: 1.1047 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.53854\n",
      "Epoch 3/100\n",
      "271/271 - 6s - loss: 1.2198 - accuracy: 0.3466 - auc: 0.5192 - val_loss: 1.0170 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.53854\n",
      "Epoch 4/100\n",
      "271/271 - 6s - loss: 0.9431 - accuracy: 0.4949 - auc: 0.5269 - val_loss: 0.8892 - val_accuracy: 0.9337 - val_auc: 0.5595\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.53854 to 0.55950, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 5/100\n",
      "271/271 - 6s - loss: 0.8275 - accuracy: 0.7353 - auc: 0.6002 - val_loss: 0.7929 - val_accuracy: 0.7264 - val_auc: 0.7926\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.55950 to 0.79261, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 6/100\n",
      "271/271 - 6s - loss: 0.7364 - accuracy: 0.6697 - auc: 0.7554 - val_loss: 0.7002 - val_accuracy: 0.5871 - val_auc: 0.8243\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.79261 to 0.82431, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 7/100\n",
      "271/271 - 6s - loss: 0.6636 - accuracy: 0.7124 - auc: 0.7976 - val_loss: 0.6434 - val_accuracy: 0.7595 - val_auc: 0.8253\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.82431 to 0.82533, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 8/100\n",
      "271/271 - 6s - loss: 0.6093 - accuracy: 0.7289 - auc: 0.8251 - val_loss: 0.7267 - val_accuracy: 0.8259 - val_auc: 0.7717\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.82533\n",
      "Epoch 9/100\n",
      "271/271 - 6s - loss: 0.5934 - accuracy: 0.7251 - auc: 0.8327 - val_loss: 0.6086 - val_accuracy: 0.7413 - val_auc: 0.8313\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.82533 to 0.83131, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 10/100\n",
      "271/271 - 6s - loss: 0.5692 - accuracy: 0.7405 - auc: 0.8465 - val_loss: 0.6223 - val_accuracy: 0.7114 - val_auc: 0.8137\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.83131\n",
      "Epoch 11/100\n",
      "271/271 - 6s - loss: 1.7308 - accuracy: 0.7557 - auc: 0.5237 - val_loss: 1.0918 - val_accuracy: 0.0663 - val_auc: 0.6856\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.83131\n",
      "Epoch 12/100\n",
      "271/271 - 6s - loss: 0.9114 - accuracy: 0.8047 - auc: 0.4855 - val_loss: 0.8695 - val_accuracy: 0.9337 - val_auc: 0.5090\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.83131\n",
      "Epoch 13/100\n",
      "271/271 - 6s - loss: 0.8490 - accuracy: 0.4617 - auc: 0.5318 - val_loss: 1.0003 - val_accuracy: 0.5506 - val_auc: 0.7700\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.83131\n",
      "Epoch 14/100\n",
      "271/271 - 6s - loss: 0.8765 - accuracy: 0.8922 - auc: 0.5083 - val_loss: 0.8218 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.83131\n",
      "Epoch 15/100\n",
      "271/271 - 6s - loss: 0.7846 - accuracy: 0.9383 - auc: 0.5163 - val_loss: 0.8263 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.83131\n",
      "Epoch 16/100\n",
      "271/271 - 6s - loss: 0.7756 - accuracy: 0.9383 - auc: 0.5028 - val_loss: 0.7909 - val_accuracy: 0.9337 - val_auc: 0.6172\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.83131\n",
      "Epoch 17/100\n",
      "271/271 - 6s - loss: 0.8505 - accuracy: 0.8118 - auc: 0.5274 - val_loss: 0.9126 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.83131\n",
      "Epoch 18/100\n",
      "271/271 - 6s - loss: 0.8377 - accuracy: 0.6570 - auc: 0.5476 - val_loss: 0.8821 - val_accuracy: 0.0663 - val_auc: 0.7801\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.83131\n",
      "Epoch 19/100\n",
      "271/271 - 6s - loss: 1.0215 - accuracy: 0.6264 - auc: 0.6734 - val_loss: 1.3049 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.83131\n",
      "Epoch 20/100\n",
      "271/271 - 6s - loss: 0.9203 - accuracy: 0.9383 - auc: 0.4852 - val_loss: 0.8450 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.83131\n",
      "Epoch 21/100\n",
      "271/271 - 6s - loss: 0.8016 - accuracy: 0.8858 - auc: 0.4965 - val_loss: 0.8135 - val_accuracy: 0.9337 - val_auc: 0.7047\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.83131\n",
      "Epoch 22/100\n",
      "271/271 - 6s - loss: 0.8904 - accuracy: 0.7789 - auc: 0.5146 - val_loss: 0.8292 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.83131\n",
      "Epoch 23/100\n",
      "271/271 - 6s - loss: 0.7821 - accuracy: 0.9385 - auc: 0.4856 - val_loss: 0.7968 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.83131\n",
      "Epoch 24/100\n",
      "271/271 - 6s - loss: 0.7933 - accuracy: 0.9324 - auc: 0.4914 - val_loss: 0.8359 - val_accuracy: 0.9337 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_auc did not improve from 0.83131\n",
      "Epoch 25/100\n",
      "271/271 - 6s - loss: 0.7780 - accuracy: 0.9385 - auc: 0.4917 - val_loss: 0.7909 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.83131\n",
      "Epoch 26/100\n",
      "271/271 - 6s - loss: 0.7609 - accuracy: 0.8272 - auc: 0.4897 - val_loss: 0.7831 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.83131\n",
      "Epoch 27/100\n",
      "271/271 - 6s - loss: 0.7559 - accuracy: 0.9385 - auc: 0.4873 - val_loss: 0.7798 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.83131\n",
      "Epoch 28/100\n",
      "271/271 - 6s - loss: 0.7534 - accuracy: 0.6798 - auc: 0.4946 - val_loss: 0.7779 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.83131\n",
      "Epoch 29/100\n",
      "271/271 - 6s - loss: 0.7521 - accuracy: 0.8570 - auc: 0.4826 - val_loss: 0.7761 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.83131\n",
      "Epoch 30/100\n",
      "271/271 - 6s - loss: 0.7508 - accuracy: 0.3812 - auc: 0.4908 - val_loss: 0.7750 - val_accuracy: 0.9337 - val_auc: 0.5009\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.83131\n",
      "Epoch 31/100\n",
      "271/271 - 6s - loss: 0.9350 - accuracy: 0.4705 - auc: 0.5072 - val_loss: 0.9948 - val_accuracy: 0.0680 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.83131\n",
      "Epoch 32/100\n",
      "271/271 - 6s - loss: 1.4354 - accuracy: 0.1410 - auc: 0.4952 - val_loss: 0.9906 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.83131\n",
      "Epoch 33/100\n",
      "271/271 - 6s - loss: 0.8600 - accuracy: 0.0960 - auc: 0.4845 - val_loss: 0.8349 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.83131\n",
      "Epoch 34/100\n",
      "271/271 - 6s - loss: 0.8168 - accuracy: 0.1159 - auc: 0.4957 - val_loss: 0.8173 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.83131\n",
      "Epoch 35/100\n",
      "271/271 - 6s - loss: 0.8672 - accuracy: 0.2700 - auc: 0.4975 - val_loss: 1.0521 - val_accuracy: 0.0663 - val_auc: 0.5027\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.83131\n",
      "Epoch 36/100\n",
      "271/271 - 6s - loss: 0.8938 - accuracy: 0.1889 - auc: 0.4974 - val_loss: 0.8723 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.83131\n",
      "Epoch 37/100\n",
      "271/271 - 6s - loss: 1.0247 - accuracy: 0.3962 - auc: 0.5534 - val_loss: 1.6452 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.83131\n",
      "Epoch 38/100\n",
      "271/271 - 6s - loss: 0.9559 - accuracy: 0.0617 - auc: 0.4964 - val_loss: 0.8241 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.83131\n",
      "Epoch 39/100\n",
      "271/271 - 6s - loss: 0.7808 - accuracy: 0.1614 - auc: 0.4880 - val_loss: 0.7926 - val_accuracy: 0.0663 - val_auc: 0.7303\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.83131\n",
      "Epoch 40/100\n",
      "271/271 - 6s - loss: 0.8197 - accuracy: 0.2096 - auc: 0.5276 - val_loss: 0.9671 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.83131\n",
      "Epoch 41/100\n",
      "271/271 - 6s - loss: 0.8097 - accuracy: 0.4298 - auc: 0.5406 - val_loss: 0.8138 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.83131\n",
      "Epoch 42/100\n",
      "271/271 - 6s - loss: 0.7769 - accuracy: 0.1018 - auc: 0.4785 - val_loss: 0.7854 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.83131\n",
      "Epoch 43/100\n",
      "271/271 - 6s - loss: 0.7655 - accuracy: 0.2350 - auc: 0.5372 - val_loss: 0.7843 - val_accuracy: 0.5821 - val_auc: 0.7109\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.83131\n",
      "Epoch 44/100\n",
      "271/271 - 6s - loss: 0.7988 - accuracy: 0.2487 - auc: 0.5142 - val_loss: 0.8088 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.83131\n",
      "Epoch 45/100\n",
      "271/271 - 6s - loss: 0.7675 - accuracy: 0.1408 - auc: 0.4878 - val_loss: 0.8079 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.83131\n",
      "Epoch 46/100\n",
      "271/271 - 6s - loss: 0.7602 - accuracy: 0.1189 - auc: 0.5105 - val_loss: 0.7728 - val_accuracy: 0.3814 - val_auc: 0.7262\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.83131\n",
      "Epoch 47/100\n",
      "271/271 - 6s - loss: 0.8299 - accuracy: 0.3301 - auc: 0.5128 - val_loss: 0.8095 - val_accuracy: 0.0663 - val_auc: 0.5009\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.83131\n",
      "Epoch 48/100\n",
      "271/271 - 6s - loss: 0.7656 - accuracy: 0.2492 - auc: 0.5069 - val_loss: 0.7994 - val_accuracy: 0.0663 - val_auc: 0.5036\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.83131\n",
      "Epoch 49/100\n",
      "271/271 - 6s - loss: 0.7616 - accuracy: 0.1806 - auc: 0.4884 - val_loss: 0.8153 - val_accuracy: 0.9337 - val_auc: 0.7066\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.83131\n",
      "Epoch 50/100\n",
      "271/271 - 6s - loss: 0.9332 - accuracy: 0.3314 - auc: 0.5551 - val_loss: 0.9459 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.83131\n",
      "Epoch 51/100\n",
      "271/271 - 6s - loss: 0.8431 - accuracy: 0.2067 - auc: 0.5299 - val_loss: 0.8062 - val_accuracy: 0.0663 - val_auc: 0.5009\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.83131\n",
      "Epoch 52/100\n",
      "271/271 - 6s - loss: 0.7867 - accuracy: 0.3685 - auc: 0.5293 - val_loss: 0.7816 - val_accuracy: 0.8159 - val_auc: 0.7886\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.83131\n",
      "Epoch 53/100\n",
      "271/271 - 6s - loss: 0.7866 - accuracy: 0.4714 - auc: 0.5629 - val_loss: 0.8181 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.83131\n",
      "Epoch 54/100\n",
      "271/271 - 6s - loss: 0.7755 - accuracy: 0.3098 - auc: 0.5067 - val_loss: 0.7853 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.83131\n",
      "Epoch 55/100\n",
      "271/271 - 6s - loss: 0.7537 - accuracy: 0.6494 - auc: 0.6232 - val_loss: 0.8017 - val_accuracy: 0.8109 - val_auc: 0.7760\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.83131\n",
      "Epoch 56/100\n",
      "271/271 - 6s - loss: 0.9342 - accuracy: 0.5079 - auc: 0.6891 - val_loss: 1.0944 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.83131\n",
      "Epoch 57/100\n",
      "271/271 - 6s - loss: 0.8631 - accuracy: 0.6000 - auc: 0.4997 - val_loss: 0.8266 - val_accuracy: 0.0663 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.83131\n",
      "Epoch 58/100\n",
      "271/271 - 6s - loss: 0.7851 - accuracy: 0.2842 - auc: 0.4908 - val_loss: 0.7987 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.83131\n",
      "Epoch 59/100\n",
      "271/271 - 6s - loss: 0.7678 - accuracy: 0.5833 - auc: 0.4950 - val_loss: 0.7822 - val_accuracy: 0.0663 - val_auc: 0.7735\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.83131\n",
      "Epoch 60/100\n",
      "271/271 - 6s - loss: 0.7880 - accuracy: 0.6544 - auc: 0.5250 - val_loss: 0.7933 - val_accuracy: 0.9337 - val_auc: 0.5417\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.83131\n",
      "Epoch 61/100\n",
      "271/271 - 6s - loss: 1.0653 - accuracy: 0.7433 - auc: 0.6278 - val_loss: 0.9332 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.83131\n",
      "Epoch 62/100\n",
      "271/271 - 6s - loss: 0.8198 - accuracy: 0.9385 - auc: 0.4929 - val_loss: 0.8105 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.83131\n",
      "Epoch 63/100\n",
      "271/271 - 6s - loss: 0.8570 - accuracy: 0.7294 - auc: 0.6081 - val_loss: 0.9206 - val_accuracy: 0.5937 - val_auc: 0.8076\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.83131\n",
      "Epoch 64/100\n",
      "271/271 - 6s - loss: 0.8119 - accuracy: 0.5780 - auc: 0.7479 - val_loss: 0.9092 - val_accuracy: 0.8823 - val_auc: 0.8222\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.83131\n",
      "Epoch 65/100\n",
      "271/271 - 6s - loss: 0.7311 - accuracy: 0.6519 - auc: 0.7844 - val_loss: 0.6411 - val_accuracy: 0.6318 - val_auc: 0.8262\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.83131\n",
      "Epoch 66/100\n",
      "271/271 - 6s - loss: 0.6601 - accuracy: 0.6432 - auc: 0.8066 - val_loss: 0.7948 - val_accuracy: 0.8325 - val_auc: 0.8084\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.83131\n",
      "Epoch 67/100\n",
      "271/271 - 6s - loss: 0.8168 - accuracy: 0.6314 - auc: 0.7554 - val_loss: 0.7280 - val_accuracy: 0.6401 - val_auc: 0.8325\n",
      "\n",
      "Epoch 00067: val_auc improved from 0.83131 to 0.83253, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 68/100\n",
      "271/271 - 6s - loss: 0.9424 - accuracy: 0.6437 - auc: 0.7693 - val_loss: 0.9306 - val_accuracy: 0.6915 - val_auc: 0.8382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: val_auc improved from 0.83253 to 0.83821, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 69/100\n",
      "271/271 - 6s - loss: 0.7532 - accuracy: 0.7036 - auc: 0.8159 - val_loss: 0.7281 - val_accuracy: 0.4080 - val_auc: 0.8397\n",
      "\n",
      "Epoch 00069: val_auc improved from 0.83821 to 0.83965, saving model to 210120_TrainingDeep\\210120_Dense_SR-p53\n",
      "Epoch 70/100\n",
      "271/271 - 6s - loss: 0.9168 - accuracy: 0.6822 - auc: 0.7088 - val_loss: 0.8664 - val_accuracy: 0.7944 - val_auc: 0.7349\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.83965\n",
      "Epoch 71/100\n",
      "271/271 - 6s - loss: 0.8909 - accuracy: 0.6318 - auc: 0.7809 - val_loss: 0.8495 - val_accuracy: 0.5406 - val_auc: 0.8369\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.83965\n",
      "Epoch 72/100\n",
      "271/271 - 6s - loss: 0.7544 - accuracy: 0.6583 - auc: 0.8050 - val_loss: 0.7465 - val_accuracy: 0.8093 - val_auc: 0.8306\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.83965\n",
      "Epoch 73/100\n",
      "271/271 - 6s - loss: 0.7741 - accuracy: 0.6718 - auc: 0.7851 - val_loss: 0.7366 - val_accuracy: 0.7927 - val_auc: 0.8354\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.83965\n",
      "Epoch 74/100\n",
      "271/271 - 6s - loss: 0.7083 - accuracy: 0.6584 - auc: 0.8051 - val_loss: 0.7633 - val_accuracy: 0.4743 - val_auc: 0.8331\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.83965\n",
      "Epoch 75/100\n",
      "271/271 - 6s - loss: 0.6851 - accuracy: 0.6791 - auc: 0.8226 - val_loss: 0.7232 - val_accuracy: 0.7512 - val_auc: 0.8315\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.83965\n",
      "Epoch 76/100\n",
      "271/271 - 6s - loss: 0.7208 - accuracy: 0.6882 - auc: 0.8209 - val_loss: 0.7301 - val_accuracy: 0.6202 - val_auc: 0.8288\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.83965\n",
      "Epoch 77/100\n",
      "271/271 - 6s - loss: 0.7495 - accuracy: 0.6770 - auc: 0.8088 - val_loss: 0.8475 - val_accuracy: 0.4411 - val_auc: 0.8356\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.83965\n",
      "Epoch 78/100\n",
      "271/271 - 6s - loss: 0.7450 - accuracy: 0.6975 - auc: 0.8075 - val_loss: 0.7462 - val_accuracy: 0.6783 - val_auc: 0.8345\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.83965\n",
      "Epoch 79/100\n",
      "271/271 - 6s - loss: 0.7114 - accuracy: 0.6978 - auc: 0.8232 - val_loss: 0.6946 - val_accuracy: 0.6683 - val_auc: 0.8352\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.83965\n",
      "Epoch 80/100\n",
      "271/271 - 6s - loss: 0.6585 - accuracy: 0.7273 - auc: 0.8452 - val_loss: 0.7497 - val_accuracy: 0.7380 - val_auc: 0.8235\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.83965\n",
      "Epoch 81/100\n",
      "271/271 - 6s - loss: 0.9086 - accuracy: 0.8157 - auc: 0.7110 - val_loss: 0.9907 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.83965\n",
      "Epoch 82/100\n",
      "271/271 - 6s - loss: 0.7562 - accuracy: 0.7721 - auc: 0.8288 - val_loss: 0.7046 - val_accuracy: 0.6998 - val_auc: 0.8268\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.83965\n",
      "Epoch 83/100\n",
      "271/271 - 6s - loss: 0.6826 - accuracy: 0.7303 - auc: 0.8460 - val_loss: 0.9108 - val_accuracy: 0.7711 - val_auc: 0.8102\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.83965\n",
      "Epoch 84/100\n",
      "271/271 - 6s - loss: 0.8457 - accuracy: 0.7912 - auc: 0.7150 - val_loss: 0.9124 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.83965\n",
      "Epoch 85/100\n",
      "271/271 - 6s - loss: 0.7467 - accuracy: 0.7365 - auc: 0.8012 - val_loss: 1.0857 - val_accuracy: 0.9337 - val_auc: 0.4610\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.83965\n",
      "Epoch 86/100\n",
      "271/271 - 6s - loss: 0.8771 - accuracy: 0.9385 - auc: 0.5152 - val_loss: 0.8535 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.83965\n",
      "Epoch 87/100\n",
      "271/271 - 6s - loss: 0.8605 - accuracy: 0.8316 - auc: 0.5904 - val_loss: 0.8877 - val_accuracy: 0.9320 - val_auc: 0.4991\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.83965\n",
      "Epoch 88/100\n",
      "271/271 - 6s - loss: 0.9220 - accuracy: 0.9167 - auc: 0.5046 - val_loss: 0.8556 - val_accuracy: 0.9337 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.83965\n",
      "Epoch 89/100\n",
      "271/271 - 6s - loss: 0.8226 - accuracy: 0.9320 - auc: 0.4968 - val_loss: 0.8303 - val_accuracy: 0.9320 - val_auc: 0.4991\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.83965\n",
      "Epoch 90/100\n",
      "271/271 - 6s - loss: 0.7963 - accuracy: 0.9385 - auc: 0.4872 - val_loss: 0.8167 - val_accuracy: 0.9320 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.83965\n",
      "Epoch 91/100\n",
      "271/271 - 6s - loss: 0.7961 - accuracy: 0.9368 - auc: 0.4890 - val_loss: 0.8110 - val_accuracy: 0.9320 - val_auc: 0.4991\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.83965\n",
      "Epoch 92/100\n",
      "271/271 - 6s - loss: 0.7806 - accuracy: 0.9385 - auc: 0.5013 - val_loss: 0.8031 - val_accuracy: 0.9320 - val_auc: 0.4991\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.83965\n",
      "Epoch 93/100\n",
      "271/271 - 6s - loss: 0.7748 - accuracy: 0.9383 - auc: 0.4900 - val_loss: 0.7992 - val_accuracy: 0.9303 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.83965\n",
      "Epoch 94/100\n",
      "271/271 - 6s - loss: 0.8104 - accuracy: 0.8102 - auc: 0.6679 - val_loss: 1.4986 - val_accuracy: 0.4262 - val_auc: 0.8239\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.83965\n",
      "Epoch 95/100\n",
      "271/271 - 6s - loss: 1.0575 - accuracy: 0.7009 - auc: 0.8211 - val_loss: 0.9740 - val_accuracy: 0.8358 - val_auc: 0.8224\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.83965\n",
      "Epoch 96/100\n",
      "271/271 - 6s - loss: 0.8207 - accuracy: 0.7169 - auc: 0.8313 - val_loss: 0.6854 - val_accuracy: 0.6352 - val_auc: 0.8303\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.83965\n",
      "Epoch 97/100\n",
      "271/271 - 6s - loss: 0.6208 - accuracy: 0.7173 - auc: 0.8525 - val_loss: 0.7261 - val_accuracy: 0.3798 - val_auc: 0.8261\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.83965\n",
      "Epoch 98/100\n",
      "271/271 - 6s - loss: 0.7054 - accuracy: 0.7005 - auc: 0.8442 - val_loss: 0.7070 - val_accuracy: 0.6302 - val_auc: 0.8253\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.83965\n",
      "Epoch 99/100\n",
      "271/271 - 6s - loss: 0.6652 - accuracy: 0.7023 - auc: 0.8426 - val_loss: 0.7127 - val_accuracy: 0.6783 - val_auc: 0.8281\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.83965\n",
      "Epoch 100/100\n",
      "271/271 - 6s - loss: 0.9099 - accuracy: 0.5901 - auc: 0.8126 - val_loss: 0.8207 - val_accuracy: 0.7546 - val_auc: 0.8244\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.83965\n"
     ]
    }
   ],
   "source": [
    "# Repeat above for all labels\n",
    "n_epoch = 100\n",
    "tmp_file = os.path.join(save_folder,\n",
    "\"{}_Dense_tmpfile.csv\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     ))\n",
    "\n",
    "with open(tmp_file, 'w') as tmpfile:\n",
    "    tmpfile.write(\",\".join([\"Label\", \"Best_AUC\", \"/n\"]))\n",
    "\n",
    "for label in y_train.columns:\n",
    "    # Load data\n",
    "    train_inds = ~np.isnan(y_train[label])\n",
    "    test_inds = ~np.isnan(y_test[label])\n",
    "\n",
    "    train_data = X_train[train_inds, :]\n",
    "    train_targets = y_train[label][train_inds].astype(np.float32)\n",
    "    test_data = X_test[test_inds, :]\n",
    "    test_targets = y_test[label][test_inds].astype(np.float32)\n",
    "    # train_Fweights\n",
    "    # test_Fweights\n",
    "\n",
    "    weights_dicts = get_weights_dicts(np.expand_dims(train_targets, 1))\n",
    "\n",
    "    # Set save folders\n",
    "    checkpoint_path = os.path.join(save_folder, \"{}_Dense_{}\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     label)\n",
    "                                  )\n",
    "    try:\n",
    "        os.mkdir(checkpoint_path)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    dense_model_=initialize_model(weights_dicts = weights_dicts)\n",
    "\n",
    "\n",
    "    cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 monitor = 'val_auc',\n",
    "                                                 mode = 'max',\n",
    "                                                 save_best_only = True,\n",
    "                                                 save_weights_only = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "    csv_filename=os.path.join(checkpoint_path, \"training_log.csv\")\n",
    "    csvlogger_callback=tf.keras.callbacks.CSVLogger(\n",
    "        filename = csv_filename, append = True)\n",
    "\n",
    "    dense_model_.fit(train_data,\n",
    "                    train_targets,\n",
    "                    epochs=n_epoch, \n",
    "                    batch_size=n_batch, \n",
    "                    validation_data=(test_data, test_targets),\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[csvlogger_callback,\n",
    "                               cp_callback\n",
    "                              ])\n",
    "    \n",
    "    with open(tmp_file, 'a') as tmpfile:\n",
    "        tmpfile.write(\",\".join([label, str(cp_callback.best)+\"/n\"]))\n",
    "    \n",
    "    del dense_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Best_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.797439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.903049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.856840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.838359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.752601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.831757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.753404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.784257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.815712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.811913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.930214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.839654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label  Best_AUC\n",
       "0           NR-AR  0.797439\n",
       "1          NR-AhR  0.903049\n",
       "2       NR-AR-LBD  0.856840\n",
       "3           NR-ER  0.838359\n",
       "4       NR-ER-LBD  0.752601\n",
       "5    NR-Aromatase  0.831757\n",
       "6   NR-PPAR-gamma  0.753404\n",
       "7          SR-ARE  0.784257\n",
       "8        SR-ATAD5  0.815712\n",
       "9          SR-HSE  0.811913\n",
       "10         SR-MMP  0.930214\n",
       "11         SR-p53  0.839654"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(tmp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Locality-Sensitive Deep Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 6th Jan 2021 (Edited Line 71 to Line 72. Reduce_mean instead of mean, to preserve the required rank)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "epsilon=K.epsilon\n",
    "\n",
    "def get_weights_dicts(Y):\n",
    "    weights_dicts=[]\n",
    "    for j in range(Y.shape[1]):\n",
    "        weight_zero, weight_one = _get_label_weights(Y[:,j])\n",
    "        d={'weight_zero':weight_zero,\n",
    "           'weight_one':weight_one\n",
    "          }\n",
    "        weights_dicts.append(d)\n",
    "    return weights_dicts\n",
    "def _get_label_weights(y):\n",
    "    #Get label weights for majority and minority class using the following:\n",
    "        #major_weight=n/(n_major*2)\n",
    "        #minor_weight=n*(n_major/n_minor)/(n_major*2)\n",
    "        #NaN weights are set to zero\n",
    "    y1=y[~np.isnan(y)]\n",
    "    n=len(y1)\n",
    "    n_zero=np.count_nonzero(np.isclose(y1,0))\n",
    "    n_one=np.count_nonzero(np.isclose(y1,1))\n",
    "    if n_zero>n_one:\n",
    "        weight_zero=n/(n_zero*2)\n",
    "        weight_one=n*(n_zero/n_one)/(n_zero*2)\n",
    "    else:\n",
    "        weight_zero=n*(n_one/n_zero)/(n_one*2)\n",
    "        weight_one=n/(n_one*2)\n",
    "    return weight_zero, weight_one    \n",
    "\n",
    "class BinaryCrossEntropyIgnoreNaN(tf.keras.losses.Loss):\n",
    "    def __init__(self, weights_dicts=None, axis=0, **kwargs):\n",
    "        super(BinaryCrossEntropyIgnoreNaN, self).__init__(**kwargs)\n",
    "        self.weights_dicts=weights_dicts\n",
    "        self.axis=axis        \n",
    "\n",
    "    def __call__(self, target, output, sample_weight=None):\n",
    "        #Binary cross entropy that ignores Nan and replaces with mini-batch Nan with 0\n",
    "        #modified from tf.python.keras.backend.binary_crossentropy\n",
    "        \n",
    "        ##NEED TO TEST THIS CODE MORE THOROUGHLY\n",
    "        target=tf.convert_to_tensor(target)\n",
    "        output=tf.convert_to_tensor(output)\n",
    "        if len(target.shape)==1:\n",
    "            target=tf.expand_dims(target, 1)\n",
    "            output=tf.expand_dims(output, 1)\n",
    "        epsilon_ = tf.constant(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output=tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "\n",
    "        #Compute cross entropy from probabilities\n",
    "        bce=target * tf.math.log(output+epsilon_)\n",
    "        bce+=(1-target)* tf.math.log(1-output+epsilon_)\n",
    "\n",
    "        bce=tf.where(tf.math.is_nan(-bce), epsilon(), -bce)\n",
    "        if self.weights_dicts is not None:\n",
    "            sample_weight=tf.cast(tf.where(target==0.,1.,0.)*[self.weights_dicts[i]['weight_zero'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            sample_weight+=tf.cast(tf.where(target==1., 1., 0.)*[self.weights_dicts[i]['weight_one'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            bce=tf.multiply(sample_weight, bce)\n",
    "#         return tf.keras.backend.mean(bce, axis=self.axis)  \n",
    "        return tf.math.reduce_mean(bce)\n",
    "\n",
    "    def call(self, target, output, sample_weight=None):\n",
    "        return self(target, output, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Single label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label='NR-AR'\n",
    "\n",
    "train_inds = ~np.isnan(y_train[label])\n",
    "test_inds = ~np.isnan(y_test[label])\n",
    "\n",
    "train_data = X_train[train_inds, :]\n",
    "train_targets = y_train[label][train_inds].astype(np.float32)\n",
    "test_data = X_test[test_inds, :]\n",
    "test_targets = y_test[label][test_inds].astype(np.float32)\n",
    "train_Fweights = Fweights_train[train_inds,:]\n",
    "test_Fweights = Fweights_test[test_inds,:]\n",
    "\n",
    "train_tensor=np.hstack([train_data, train_Fweights])\n",
    "test_tensor=np.hstack([test_data, test_Fweights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingLocalitySensitivewFW'\n",
      "[WinError 183] Cannot create a file when that file already exists: '210120_TrainingLocalitySensitivewFW\\\\LocalitySensitivewFW_NR-AR'\n"
     ]
    }
   ],
   "source": [
    "n_feat = train_data.shape[1]\n",
    "n_attention = 20 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=20\n",
    "n_attention_out=1\n",
    "n_concat_hidden=2048\n",
    "n_hidden1 =1024\n",
    "n_hidden2 = 128 #Added 2nd hidden layer\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=32\n",
    "\n",
    "\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewFW\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"LocalitySensitivewFW_{}\".format(label),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"gelu\"\n",
    "attention_hidden_activation=\"gelu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"gelu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "input_layer=Input(shape=(n_feat*2, ))\n",
    "attentions_layer=[attention_model.DenseAttentionwFeatWeights(\n",
    "    n_feat,\n",
    "    n_attention_hidden, \n",
    "    out=n_hidden_out,\n",
    "    hidden_activation=attention_hidden_activation,\n",
    "    output_activation=attention_output_activation,\n",
    "    \n",
    ")]\n",
    "\n",
    "# attentions_layer=attention_model.ConcatAttentionswFeatWeights(\n",
    "#     n_attention=n_attention,\n",
    "#     n_attention_hidden=n_attention_hidden,\n",
    "#     n_attention_out=n_attention_out,\n",
    "#     n_feat=n_feat,\n",
    "#     n_hidden=n_concat_hidden,\n",
    "#     activation=concat_activation, \n",
    "#     kernel_initializer=kernel_initializer,\n",
    "#     kernel_regularizer=l1(1E-5),\n",
    "#     bias_regularizer=l1(1E-5),\n",
    "#     attention_initializer=kernel_initializer,\n",
    "#     attention_hidden_activation=attention_hidden_activation,\n",
    "#     attention_output_activation=attention_output_activation\n",
    "# )(input_layer)\n",
    "dropout0=Dropout(0.1)(attentions_layer)\n",
    "dense_layer1=Dense(n_hidden1, \n",
    "                   activation=hidden_activation, \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l1(1E-5),\n",
    "                   bias_regularizer=l1(1E-5),\n",
    "                  )(dropout0)\n",
    "dropout1=Dropout(0.1)(dense_layer1)\n",
    "dense_layer2=Dense(n_hidden2,\n",
    "                   activation=hidden_activation,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l1(1E-5),\n",
    "                   bias_regularizer=l1(1E-5)\n",
    "                  )(dropout1)\n",
    "dropout2=Dropout(0.1)(dense_layer2)\n",
    "output_layer=Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "LSwFW_model=Model(inputs=input_layer, \n",
    "                  outputs=output_layer\n",
    "                 )\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "LSwFW_model.compile(loss=loss_fn, \n",
    "              optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy', 'AUC']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "195/195 - 33s - loss: 8.6768 - accuracy: 0.9644 - auc: 0.4965 - val_loss: 7.9526 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.50000, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_NR-AR\n",
      "Epoch 2/100\n",
      "195/195 - 14s - loss: 2.0181 - accuracy: 0.6468 - auc: 0.6117 - val_loss: 1.2486 - val_accuracy: 0.4261 - val_auc: 0.6636\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.50000 to 0.66363, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_NR-AR\n",
      "Epoch 3/100\n",
      "195/195 - 14s - loss: 1.0373 - accuracy: 0.6927 - auc: 0.7375 - val_loss: 0.9501 - val_accuracy: 0.8713 - val_auc: 0.6890\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.66363 to 0.68902, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_NR-AR\n",
      "Epoch 4/100\n",
      "195/195 - 14s - loss: 0.8154 - accuracy: 0.7310 - auc: 0.7706 - val_loss: 0.9018 - val_accuracy: 0.9513 - val_auc: 0.6860\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.68902\n",
      "Epoch 5/100\n",
      "195/195 - 14s - loss: 0.7235 - accuracy: 0.8070 - auc: 0.7926 - val_loss: 0.8114 - val_accuracy: 0.9443 - val_auc: 0.6855\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.68902\n",
      "Epoch 6/100\n",
      "195/195 - 14s - loss: 0.6779 - accuracy: 0.8094 - auc: 0.7910 - val_loss: 0.7473 - val_accuracy: 0.7774 - val_auc: 0.6966\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.68902 to 0.69664, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_NR-AR\n",
      "Epoch 7/100\n",
      "195/195 - 14s - loss: 0.6270 - accuracy: 0.7940 - auc: 0.8235 - val_loss: 0.7454 - val_accuracy: 0.6852 - val_auc: 0.6938\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.69664\n",
      "Epoch 8/100\n",
      "195/195 - 14s - loss: 0.5952 - accuracy: 0.8191 - auc: 0.8201 - val_loss: 0.9670 - val_accuracy: 0.9061 - val_auc: 0.6835\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.69664\n",
      "Epoch 9/100\n",
      "195/195 - 13s - loss: 0.6120 - accuracy: 0.7129 - auc: 0.8105 - val_loss: 0.7680 - val_accuracy: 0.5809 - val_auc: 0.6907\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.69664\n",
      "Epoch 10/100\n",
      "195/195 - 13s - loss: 0.5766 - accuracy: 0.7870 - auc: 0.8325 - val_loss: 0.8837 - val_accuracy: 0.8487 - val_auc: 0.6785\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.69664\n",
      "Epoch 11/100\n",
      "195/195 - 14s - loss: 0.5557 - accuracy: 0.8407 - auc: 0.8486 - val_loss: 0.7865 - val_accuracy: 0.7165 - val_auc: 0.6716\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.69664\n",
      "Epoch 12/100\n",
      "195/195 - 14s - loss: 0.5427 - accuracy: 0.8008 - auc: 0.8524 - val_loss: 0.9378 - val_accuracy: 0.8939 - val_auc: 0.6606\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.69664\n",
      "Epoch 13/100\n",
      "195/195 - 14s - loss: 0.5476 - accuracy: 0.7892 - auc: 0.8482 - val_loss: 0.9884 - val_accuracy: 0.8087 - val_auc: 0.6644\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.69664\n",
      "Epoch 14/100\n",
      "195/195 - 14s - loss: 0.5286 - accuracy: 0.7868 - auc: 0.8589 - val_loss: 0.8805 - val_accuracy: 0.6609 - val_auc: 0.6676\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.69664\n",
      "Epoch 15/100\n",
      "195/195 - 14s - loss: 0.5378 - accuracy: 0.7903 - auc: 0.8583 - val_loss: 0.9534 - val_accuracy: 0.8470 - val_auc: 0.6637\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.69664\n",
      "Epoch 16/100\n",
      "195/195 - 14s - loss: 0.5119 - accuracy: 0.7830 - auc: 0.8614 - val_loss: 1.0535 - val_accuracy: 0.8157 - val_auc: 0.6610\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.69664\n",
      "Epoch 17/100\n",
      "195/195 - 14s - loss: 0.5148 - accuracy: 0.7929 - auc: 0.8613 - val_loss: 1.0953 - val_accuracy: 0.8661 - val_auc: 0.6543\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.69664\n",
      "Epoch 18/100\n",
      "195/195 - 14s - loss: 0.5011 - accuracy: 0.8022 - auc: 0.8790 - val_loss: 0.9867 - val_accuracy: 0.6487 - val_auc: 0.6718\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.69664\n",
      "Epoch 19/100\n",
      "195/195 - 14s - loss: 0.5277 - accuracy: 0.7798 - auc: 0.8662 - val_loss: 1.1488 - val_accuracy: 0.7930 - val_auc: 0.6683\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.69664\n",
      "Epoch 20/100\n",
      "195/195 - 14s - loss: 0.5276 - accuracy: 0.7817 - auc: 0.8665 - val_loss: 0.8721 - val_accuracy: 0.5583 - val_auc: 0.6636\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.69664\n",
      "Epoch 21/100\n",
      "195/195 - 14s - loss: 0.5605 - accuracy: 0.7939 - auc: 0.8757 - val_loss: 0.9737 - val_accuracy: 0.7443 - val_auc: 0.6631\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.69664\n",
      "Epoch 22/100\n",
      "195/195 - 14s - loss: 0.5274 - accuracy: 0.8189 - auc: 0.8734 - val_loss: 1.1348 - val_accuracy: 0.5896 - val_auc: 0.6735\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.69664\n",
      "Epoch 23/100\n",
      "195/195 - 13s - loss: 0.5043 - accuracy: 0.7777 - auc: 0.8825 - val_loss: 1.2393 - val_accuracy: 0.7583 - val_auc: 0.6699\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.69664\n",
      "Epoch 24/100\n",
      "195/195 - 14s - loss: 0.5077 - accuracy: 0.7927 - auc: 0.8773 - val_loss: 1.6182 - val_accuracy: 0.8765 - val_auc: 0.6618\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.69664\n",
      "Epoch 25/100\n",
      "195/195 - 14s - loss: 0.4719 - accuracy: 0.8271 - auc: 0.8986 - val_loss: 1.9544 - val_accuracy: 0.8870 - val_auc: 0.6869\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.69664\n",
      "Epoch 26/100\n",
      "195/195 - 14s - loss: 0.4664 - accuracy: 0.8086 - auc: 0.9002 - val_loss: 1.6969 - val_accuracy: 0.7965 - val_auc: 0.6686\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.69664\n",
      "Epoch 27/100\n",
      "195/195 - 14s - loss: 0.4751 - accuracy: 0.7889 - auc: 0.8991 - val_loss: 1.5229 - val_accuracy: 0.7600 - val_auc: 0.6838\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.69664\n",
      "Epoch 28/100\n",
      "195/195 - 14s - loss: 0.4626 - accuracy: 0.7918 - auc: 0.9038 - val_loss: 1.3394 - val_accuracy: 0.7130 - val_auc: 0.6764\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.69664\n",
      "Epoch 29/100\n",
      "195/195 - 14s - loss: 0.4769 - accuracy: 0.7931 - auc: 0.8946 - val_loss: 1.5325 - val_accuracy: 0.7391 - val_auc: 0.6768\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.69664\n",
      "Epoch 30/100\n",
      "195/195 - 14s - loss: 0.4652 - accuracy: 0.7817 - auc: 0.9036 - val_loss: 1.5517 - val_accuracy: 0.8000 - val_auc: 0.6796\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.69664\n",
      "Epoch 31/100\n",
      "195/195 - 14s - loss: 0.4482 - accuracy: 0.8165 - auc: 0.9153 - val_loss: 1.7373 - val_accuracy: 0.7896 - val_auc: 0.6374\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.69664\n",
      "Epoch 32/100\n",
      "195/195 - 14s - loss: 0.4492 - accuracy: 0.7860 - auc: 0.9113 - val_loss: 1.8657 - val_accuracy: 0.8052 - val_auc: 0.6571\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.69664\n",
      "Epoch 33/100\n",
      "195/195 - 14s - loss: 0.4584 - accuracy: 0.7817 - auc: 0.9113 - val_loss: 2.0145 - val_accuracy: 0.8574 - val_auc: 0.6768\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.69664\n",
      "Epoch 34/100\n",
      "195/195 - 14s - loss: 0.5476 - accuracy: 0.7772 - auc: 0.8901 - val_loss: 1.9163 - val_accuracy: 0.8052 - val_auc: 0.6928\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.69664\n",
      "Epoch 35/100\n",
      "195/195 - 14s - loss: 0.4983 - accuracy: 0.7757 - auc: 0.9021 - val_loss: 1.8061 - val_accuracy: 0.8087 - val_auc: 0.6827\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.69664\n",
      "Epoch 36/100\n",
      "195/195 - 14s - loss: 0.5075 - accuracy: 0.7817 - auc: 0.8962 - val_loss: 2.3396 - val_accuracy: 0.8574 - val_auc: 0.6717\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.69664\n",
      "Epoch 37/100\n",
      "195/195 - 14s - loss: 0.5138 - accuracy: 0.7867 - auc: 0.9146 - val_loss: 1.7479 - val_accuracy: 0.7791 - val_auc: 0.6690\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.69664\n",
      "Epoch 38/100\n",
      "195/195 - 14s - loss: 0.4494 - accuracy: 0.7936 - auc: 0.9177 - val_loss: 1.8418 - val_accuracy: 0.7670 - val_auc: 0.6727\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.69664\n",
      "Epoch 39/100\n",
      "195/195 - 14s - loss: 0.4379 - accuracy: 0.7998 - auc: 0.9259 - val_loss: 2.0405 - val_accuracy: 0.8643 - val_auc: 0.6434\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.69664\n",
      "Epoch 40/100\n",
      "195/195 - 14s - loss: 0.4355 - accuracy: 0.7918 - auc: 0.9247 - val_loss: 2.3886 - val_accuracy: 0.8991 - val_auc: 0.6587\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.69664\n",
      "Epoch 41/100\n",
      "195/195 - 14s - loss: 0.4177 - accuracy: 0.8065 - auc: 0.9274 - val_loss: 2.2119 - val_accuracy: 0.7530 - val_auc: 0.6730\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.69664\n",
      "Epoch 42/100\n",
      "195/195 - 14s - loss: 0.4064 - accuracy: 0.7913 - auc: 0.9341 - val_loss: 2.2501 - val_accuracy: 0.8122 - val_auc: 0.6883\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.69664\n",
      "Epoch 43/100\n",
      "195/195 - 14s - loss: 0.4414 - accuracy: 0.8025 - auc: 0.9277 - val_loss: 2.3109 - val_accuracy: 0.8609 - val_auc: 0.6814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_auc did not improve from 0.69664\n",
      "Epoch 44/100\n",
      "195/195 - 14s - loss: 0.3972 - accuracy: 0.8232 - auc: 0.9435 - val_loss: 2.2092 - val_accuracy: 0.8052 - val_auc: 0.6711\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.69664\n",
      "Epoch 45/100\n",
      "195/195 - 14s - loss: 0.4180 - accuracy: 0.8000 - auc: 0.9289 - val_loss: 1.9424 - val_accuracy: 0.7270 - val_auc: 0.6331\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.69664\n",
      "Epoch 46/100\n",
      "195/195 - 14s - loss: 0.5983 - accuracy: 0.7846 - auc: 0.9007 - val_loss: 2.9123 - val_accuracy: 0.9583 - val_auc: 0.6793\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.69664\n",
      "Epoch 47/100\n",
      "195/195 - 14s - loss: 0.5015 - accuracy: 0.8223 - auc: 0.9269 - val_loss: 1.9013 - val_accuracy: 0.7426 - val_auc: 0.6750\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.69664\n",
      "Epoch 48/100\n",
      "195/195 - 14s - loss: 0.4289 - accuracy: 0.8207 - auc: 0.9401 - val_loss: 2.7197 - val_accuracy: 0.8574 - val_auc: 0.6844\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.69664\n",
      "Epoch 49/100\n",
      "195/195 - 14s - loss: 0.4043 - accuracy: 0.8215 - auc: 0.9428 - val_loss: 2.4612 - val_accuracy: 0.8487 - val_auc: 0.6676\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.69664\n",
      "Epoch 50/100\n",
      "195/195 - 14s - loss: 0.3866 - accuracy: 0.8197 - auc: 0.9458 - val_loss: 1.9561 - val_accuracy: 0.6922 - val_auc: 0.6727\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.69664\n",
      "Epoch 51/100\n",
      "195/195 - 14s - loss: 0.3729 - accuracy: 0.8269 - auc: 0.9472 - val_loss: 2.4198 - val_accuracy: 0.7687 - val_auc: 0.6539\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.69664\n",
      "Epoch 52/100\n",
      "195/195 - 14s - loss: 0.3668 - accuracy: 0.8179 - auc: 0.9492 - val_loss: 2.8632 - val_accuracy: 0.8452 - val_auc: 0.6143\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.69664\n",
      "Epoch 53/100\n",
      "195/195 - 14s - loss: 0.4110 - accuracy: 0.7960 - auc: 0.9346 - val_loss: 2.6860 - val_accuracy: 0.7826 - val_auc: 0.6533\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.69664\n",
      "Epoch 54/100\n",
      "195/195 - 14s - loss: 0.3890 - accuracy: 0.8067 - auc: 0.9418 - val_loss: 2.4973 - val_accuracy: 0.8000 - val_auc: 0.6476\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.69664\n",
      "Epoch 55/100\n",
      "195/195 - 14s - loss: 0.3667 - accuracy: 0.8157 - auc: 0.9504 - val_loss: 3.0033 - val_accuracy: 0.9026 - val_auc: 0.6465\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.69664\n",
      "Epoch 56/100\n",
      "195/195 - 14s - loss: 0.3674 - accuracy: 0.8176 - auc: 0.9472 - val_loss: 2.2945 - val_accuracy: 0.7565 - val_auc: 0.6595\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.69664\n",
      "Epoch 57/100\n",
      "195/195 - 14s - loss: 0.3788 - accuracy: 0.8240 - auc: 0.9459 - val_loss: 2.9054 - val_accuracy: 0.9548 - val_auc: 0.6499\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.69664\n",
      "Epoch 58/100\n",
      "195/195 - 14s - loss: 0.4514 - accuracy: 0.8157 - auc: 0.9291 - val_loss: 2.4522 - val_accuracy: 0.7826 - val_auc: 0.6650\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.69664\n",
      "Epoch 59/100\n",
      "195/195 - 14s - loss: 0.4085 - accuracy: 0.8274 - auc: 0.9470 - val_loss: 2.0779 - val_accuracy: 0.7183 - val_auc: 0.6562\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.69664\n",
      "Epoch 60/100\n",
      "195/195 - 13s - loss: 0.3889 - accuracy: 0.8171 - auc: 0.9471 - val_loss: 3.0434 - val_accuracy: 0.8626 - val_auc: 0.6781\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.69664\n",
      "Epoch 61/100\n",
      "195/195 - 13s - loss: 0.3713 - accuracy: 0.8272 - auc: 0.9516 - val_loss: 2.7677 - val_accuracy: 0.8452 - val_auc: 0.6545\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.69664\n",
      "Epoch 62/100\n",
      "195/195 - 14s - loss: 0.3666 - accuracy: 0.8373 - auc: 0.9511 - val_loss: 2.7252 - val_accuracy: 0.8313 - val_auc: 0.6515\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.69664\n",
      "Epoch 63/100\n",
      "195/195 - 14s - loss: 0.3391 - accuracy: 0.8457 - auc: 0.9617 - val_loss: 2.8120 - val_accuracy: 0.8470 - val_auc: 0.6273\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.69664\n",
      "Epoch 64/100\n",
      "195/195 - 14s - loss: 0.3859 - accuracy: 0.8227 - auc: 0.9477 - val_loss: 2.9567 - val_accuracy: 0.8504 - val_auc: 0.6650\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.69664\n",
      "Epoch 65/100\n",
      "195/195 - 13s - loss: 0.3392 - accuracy: 0.8547 - auc: 0.9605 - val_loss: 2.9434 - val_accuracy: 0.8574 - val_auc: 0.6632\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.69664\n",
      "Epoch 66/100\n",
      "195/195 - 13s - loss: 0.3646 - accuracy: 0.8592 - auc: 0.9576 - val_loss: 3.2547 - val_accuracy: 0.9409 - val_auc: 0.6716\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.69664\n",
      "Epoch 67/100\n",
      "195/195 - 14s - loss: 0.4545 - accuracy: 0.8367 - auc: 0.9432 - val_loss: 2.7150 - val_accuracy: 0.8070 - val_auc: 0.6394\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.69664\n",
      "Epoch 68/100\n",
      "195/195 - 14s - loss: 0.3952 - accuracy: 0.8391 - auc: 0.9560 - val_loss: 3.3634 - val_accuracy: 0.8678 - val_auc: 0.6234\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.69664\n",
      "Epoch 69/100\n",
      "195/195 - 14s - loss: 0.3237 - accuracy: 0.8733 - auc: 0.9686 - val_loss: 2.9583 - val_accuracy: 0.7339 - val_auc: 0.6789\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.69664\n",
      "Epoch 70/100\n",
      "195/195 - 14s - loss: 0.3822 - accuracy: 0.8264 - auc: 0.9526 - val_loss: 1.8486 - val_accuracy: 0.6696 - val_auc: 0.6683\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.69664\n",
      "Epoch 71/100\n",
      "195/195 - 14s - loss: 0.3290 - accuracy: 0.8585 - auc: 0.9646 - val_loss: 3.0424 - val_accuracy: 0.8835 - val_auc: 0.6744\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.69664\n",
      "Epoch 72/100\n",
      "195/195 - 14s - loss: 0.3286 - accuracy: 0.8635 - auc: 0.9639 - val_loss: 3.0203 - val_accuracy: 0.8052 - val_auc: 0.6493\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.69664\n",
      "Epoch 73/100\n",
      "195/195 - 14s - loss: 0.3484 - accuracy: 0.8422 - auc: 0.9563 - val_loss: 3.1148 - val_accuracy: 0.8504 - val_auc: 0.6699\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.69664\n",
      "Epoch 74/100\n",
      "195/195 - 14s - loss: 0.3712 - accuracy: 0.8402 - auc: 0.9584 - val_loss: 3.1213 - val_accuracy: 0.8470 - val_auc: 0.6741\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.69664\n",
      "Epoch 75/100\n",
      "195/195 - 14s - loss: 0.3810 - accuracy: 0.8423 - auc: 0.9580 - val_loss: 3.1153 - val_accuracy: 0.8591 - val_auc: 0.6831\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.69664\n",
      "Epoch 76/100\n",
      "195/195 - 14s - loss: 0.3531 - accuracy: 0.8523 - auc: 0.9612 - val_loss: 3.1363 - val_accuracy: 0.8243 - val_auc: 0.6488\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.69664\n",
      "Epoch 77/100\n",
      "195/195 - 14s - loss: 0.3437 - accuracy: 0.8516 - auc: 0.9626 - val_loss: 3.2916 - val_accuracy: 0.7339 - val_auc: 0.5918\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.69664\n",
      "Epoch 78/100\n",
      "195/195 - 14s - loss: 0.3825 - accuracy: 0.8439 - auc: 0.9556 - val_loss: 3.2906 - val_accuracy: 0.8435 - val_auc: 0.6867\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.69664\n",
      "Epoch 79/100\n",
      "195/195 - 14s - loss: 0.4905 - accuracy: 0.8083 - auc: 0.9315 - val_loss: 2.8742 - val_accuracy: 0.6922 - val_auc: 0.6607\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.69664\n",
      "Epoch 80/100\n",
      "195/195 - 14s - loss: 0.4584 - accuracy: 0.8505 - auc: 0.9585 - val_loss: 2.9632 - val_accuracy: 0.8017 - val_auc: 0.6733\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.69664\n",
      "Epoch 81/100\n",
      "195/195 - 14s - loss: 0.3795 - accuracy: 0.8627 - auc: 0.9638 - val_loss: 3.3446 - val_accuracy: 0.8696 - val_auc: 0.6763\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.69664\n",
      "Epoch 82/100\n",
      "195/195 - 14s - loss: 0.3256 - accuracy: 0.8816 - auc: 0.9707 - val_loss: 3.6142 - val_accuracy: 0.8974 - val_auc: 0.6538\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.69664\n",
      "Epoch 83/100\n",
      "195/195 - 14s - loss: 0.2840 - accuracy: 0.8965 - auc: 0.9762 - val_loss: 3.4152 - val_accuracy: 0.8748 - val_auc: 0.6832\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.69664\n",
      "Epoch 84/100\n",
      "195/195 - 14s - loss: 0.3435 - accuracy: 0.8619 - auc: 0.9613 - val_loss: 2.3399 - val_accuracy: 0.5183 - val_auc: 0.6055\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.69664\n",
      "Epoch 85/100\n",
      "195/195 - 14s - loss: 0.6705 - accuracy: 0.6120 - auc: 0.8291 - val_loss: 1.2028 - val_accuracy: 0.6017 - val_auc: 0.6619\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.69664\n",
      "Epoch 86/100\n",
      "195/195 - 14s - loss: 0.5993 - accuracy: 0.8061 - auc: 0.9188 - val_loss: 2.7673 - val_accuracy: 0.7826 - val_auc: 0.6652\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.69664\n",
      "Epoch 87/100\n",
      "195/195 - 14s - loss: 0.4221 - accuracy: 0.8664 - auc: 0.9587 - val_loss: 3.0958 - val_accuracy: 0.8974 - val_auc: 0.6730\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.69664\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 - 14s - loss: 0.3394 - accuracy: 0.8969 - auc: 0.9735 - val_loss: 2.7593 - val_accuracy: 0.8191 - val_auc: 0.6427\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.69664\n",
      "Epoch 89/100\n",
      "195/195 - 14s - loss: 0.3416 - accuracy: 0.8858 - auc: 0.9684 - val_loss: 3.3463 - val_accuracy: 0.9130 - val_auc: 0.6448\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.69664\n",
      "Epoch 90/100\n",
      "195/195 - 14s - loss: 0.2788 - accuracy: 0.9108 - auc: 0.9792 - val_loss: 3.4435 - val_accuracy: 0.8939 - val_auc: 0.6406\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.69664\n",
      "Epoch 91/100\n",
      "195/195 - 14s - loss: 0.2786 - accuracy: 0.9071 - auc: 0.9781 - val_loss: 3.5347 - val_accuracy: 0.9183 - val_auc: 0.6632\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.69664\n",
      "Epoch 92/100\n",
      "195/195 - 14s - loss: 0.3032 - accuracy: 0.8842 - auc: 0.9702 - val_loss: 4.5120 - val_accuracy: 0.9548 - val_auc: 0.5771\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.69664\n",
      "Epoch 93/100\n",
      "195/195 - 14s - loss: 0.3077 - accuracy: 0.8863 - auc: 0.9719 - val_loss: 3.7866 - val_accuracy: 0.9357 - val_auc: 0.6739\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.69664\n",
      "Epoch 94/100\n",
      "195/195 - 14s - loss: 0.2535 - accuracy: 0.9116 - auc: 0.9797 - val_loss: 4.0001 - val_accuracy: 0.9252 - val_auc: 0.6704\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.69664\n",
      "Epoch 95/100\n",
      "195/195 - 14s - loss: 0.2885 - accuracy: 0.8795 - auc: 0.9730 - val_loss: 3.2936 - val_accuracy: 0.8974 - val_auc: 0.7046\n",
      "\n",
      "Epoch 00095: val_auc improved from 0.69664 to 0.70456, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_NR-AR\n",
      "Epoch 96/100\n",
      "195/195 - 14s - loss: 0.3767 - accuracy: 0.8399 - auc: 0.9569 - val_loss: 3.1413 - val_accuracy: 0.8017 - val_auc: 0.6334\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.70456\n",
      "Epoch 97/100\n",
      "195/195 - 14s - loss: 0.3428 - accuracy: 0.8845 - auc: 0.9740 - val_loss: 3.5377 - val_accuracy: 0.9252 - val_auc: 0.6519\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.70456\n",
      "Epoch 98/100\n",
      "195/195 - 14s - loss: 0.3221 - accuracy: 0.8991 - auc: 0.9739 - val_loss: 3.6933 - val_accuracy: 0.8870 - val_auc: 0.6133\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.70456\n",
      "Epoch 99/100\n",
      "195/195 - 14s - loss: 0.2849 - accuracy: 0.9081 - auc: 0.9774 - val_loss: 3.6381 - val_accuracy: 0.9113 - val_auc: 0.6627\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.70456\n",
      "Epoch 100/100\n",
      "195/195 - 14s - loss: 0.3120 - accuracy: 0.8906 - auc: 0.9711 - val_loss: 2.7785 - val_accuracy: 0.8209 - val_auc: 0.6508\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.70456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c09f42ba00>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_auc',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "\n",
    "n_epoch=100\n",
    "\n",
    "\n",
    "LSwFW_model.fit(train_tensor, \n",
    "                train_targets, \n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_tensor, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 632)]             0         \n",
      "_________________________________________________________________\n",
      "concat_attentionsw_feat_weig (None, 8192)              51915172  \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 60,436,133\n",
      "Trainable params: 60,436,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSwFW_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 400)               126800    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 6320)              2534320   \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 2048)              12945408  \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,688,513\n",
      "Trainable params: 16,688,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = train_data.shape[1]\n",
    "n_attention = 20 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=20\n",
    "n_attention_out=16\n",
    "n_concat_hidden=2048\n",
    "n_hidden1 =1024\n",
    "n_hidden2 = 128 #Added 2nd hidden layer\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=8\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"gelu\"\n",
    "attention_hidden_activation=\"gelu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"gelu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "def initialize_LSwFWmodel(weights_dicts,\n",
    "                     n_attention=n_attention, \n",
    "                     n_attention_hidden=n_attention_hidden, \n",
    "                     n_feat=n_feat,\n",
    "                     n_concat_hidden=n_concat_hidden,\n",
    "                     n_hidden1=n_hidden1, \n",
    "                     n_hidden2=n_hidden2,\n",
    "                          n_hidden_out=n_attention_out, \n",
    "                          attention_hidden_activation=attention_hidden_activation,\n",
    "                          attention_output_activation=attention_output_activation,\n",
    "                          kernel_initializer=kernel_initializer,\n",
    "                          hidden_activation=hidden_activation\n",
    "                         ):\n",
    "\n",
    "    input_layer=Input(shape=(n_feat*2, ))\n",
    "    attention_heads_=[attention_model.DenseAttentionwFeatWeights(\n",
    "        n_feat,\n",
    "        n_attention_hidden, \n",
    "        out=n_hidden_out,\n",
    "        hidden_activation=attention_hidden_activation,\n",
    "        output_activation=attention_output_activation,\n",
    "    )(input_layer) for i in range(n_attention)]\n",
    "    concat_layer=Concatenate()(attention_heads_)\n",
    "    # attentions_layer=attention_model.ConcatAttentionswFeatWeights(\n",
    "    #     n_attention=n_attention,\n",
    "    #     n_attention_hidden=n_attention_hidden,\n",
    "    #     n_attention_out=n_attention_out,\n",
    "    #     n_feat=n_feat,\n",
    "    #     n_hidden=n_concat_hidden,\n",
    "    #     activation=concat_activation, \n",
    "    #     kernel_initializer=kernel_initializer,\n",
    "    #     kernel_regularizer=l1(1E-5),\n",
    "    #     bias_regularizer=l1(1E-5),\n",
    "    #     attention_initializer=kernel_initializer,\n",
    "    #     attention_hidden_activation=attention_hidden_activation,\n",
    "    #     attention_output_activation=attention_output_activation\n",
    "    # )(input_layer)\n",
    "    dropout0=Dropout(0.1)(concat_layer)\n",
    "    dense_layer1=Dense(n_hidden1, \n",
    "                       activation=hidden_activation, \n",
    "                       kernel_initializer=kernel_initializer,\n",
    "                       kernel_regularizer=l1(1E-5),\n",
    "                       bias_regularizer=l1(1E-5),\n",
    "                      )(dropout0)\n",
    "    dropout1=Dropout(0.1)(dense_layer1)\n",
    "    dense_layer2=Dense(n_hidden2,\n",
    "                       activation=hidden_activation,\n",
    "                       kernel_initializer=kernel_initializer,\n",
    "                       kernel_regularizer=l1(1E-5),\n",
    "                       bias_regularizer=l1(1E-5)\n",
    "                      )(dropout1)\n",
    "    dropout2=Dropout(0.1)(dense_layer2)\n",
    "    output_layer=Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "    LSwFW_model=Model(inputs=input_layer, \n",
    "                      outputs=output_layer\n",
    "                     )\n",
    "\n",
    "#     weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "    loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "    LSwFW_model.compile(loss=loss_fn, \n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  metrics=['accuracy', 'AUC']\n",
    "                 )\n",
    "    return LSwFW_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1168/1168 - 130s - loss: 0.7179 - accuracy: 0.8371 - auc: 0.7473 - val_loss: 0.5867 - val_accuracy: 0.9513 - val_auc: 0.6661\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.66615, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 2/100\n",
      "1168/1168 - 115s - loss: 0.5822 - accuracy: 0.9170 - auc: 0.8039 - val_loss: 0.5359 - val_accuracy: 0.9565 - val_auc: 0.6673\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.66615 to 0.66726, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 3/100\n",
      "1168/1168 - 115s - loss: 0.5397 - accuracy: 0.9125 - auc: 0.8023 - val_loss: 0.5053 - val_accuracy: 0.9583 - val_auc: 0.6912\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.66726 to 0.69116, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 4/100\n",
      "1168/1168 - 109s - loss: 0.5068 - accuracy: 0.9309 - auc: 0.8177 - val_loss: 0.4743 - val_accuracy: 0.9530 - val_auc: 0.6812\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.69116\n",
      "Epoch 5/100\n",
      "1168/1168 - 112s - loss: 0.4750 - accuracy: 0.9235 - auc: 0.8377 - val_loss: 0.4794 - val_accuracy: 0.9652 - val_auc: 0.6730\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.69116\n",
      "Epoch 6/100\n",
      "1168/1168 - 114s - loss: 0.4768 - accuracy: 0.9148 - auc: 0.8368 - val_loss: 0.4574 - val_accuracy: 0.9774 - val_auc: 0.6912\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.69116 to 0.69116, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 7/100\n",
      "1168/1168 - 114s - loss: 0.4876 - accuracy: 0.9241 - auc: 0.8369 - val_loss: 0.5095 - val_accuracy: 0.9478 - val_auc: 0.6893\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.69116\n",
      "Epoch 8/100\n",
      "1168/1168 - 114s - loss: 0.4589 - accuracy: 0.9201 - auc: 0.8528 - val_loss: 0.4818 - val_accuracy: 0.9617 - val_auc: 0.6787\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.69116\n",
      "Epoch 9/100\n",
      "1168/1168 - 109s - loss: 0.4644 - accuracy: 0.9131 - auc: 0.8423 - val_loss: 0.4877 - val_accuracy: 0.9461 - val_auc: 0.6918\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.69116 to 0.69176, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 10/100\n",
      "1168/1168 - 112s - loss: 0.4625 - accuracy: 0.9083 - auc: 0.8520 - val_loss: 0.5529 - val_accuracy: 0.9130 - val_auc: 0.6940\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.69176 to 0.69405, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 11/100\n",
      "1168/1168 - 115s - loss: 0.4646 - accuracy: 0.8987 - auc: 0.8539 - val_loss: 0.4786 - val_accuracy: 0.9739 - val_auc: 0.6934\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.69405\n",
      "Epoch 12/100\n",
      "1168/1168 - 114s - loss: 0.4717 - accuracy: 0.9226 - auc: 0.8416 - val_loss: 0.5255 - val_accuracy: 0.9235 - val_auc: 0.6757\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.69405\n",
      "Epoch 13/100\n",
      "1168/1168 - 114s - loss: 0.4492 - accuracy: 0.9178 - auc: 0.8608 - val_loss: 0.5153 - val_accuracy: 0.9652 - val_auc: 0.6830\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.69405\n",
      "Epoch 14/100\n",
      "1168/1168 - 109s - loss: 0.4446 - accuracy: 0.9246 - auc: 0.8634 - val_loss: 0.4956 - val_accuracy: 0.9687 - val_auc: 0.6506\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.69405\n",
      "Epoch 15/100\n",
      "1168/1168 - 111s - loss: 0.4383 - accuracy: 0.9098 - auc: 0.8717 - val_loss: 0.4837 - val_accuracy: 0.9043 - val_auc: 0.6829\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.69405\n",
      "Epoch 16/100\n",
      "1168/1168 - 115s - loss: 0.4590 - accuracy: 0.9111 - auc: 0.8684 - val_loss: 0.5330 - val_accuracy: 0.9496 - val_auc: 0.6833\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.69405\n",
      "Epoch 17/100\n",
      "1168/1168 - 114s - loss: 0.4137 - accuracy: 0.9037 - auc: 0.8895 - val_loss: 0.4976 - val_accuracy: 0.9357 - val_auc: 0.6710\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.69405\n",
      "Epoch 18/100\n",
      "1168/1168 - 115s - loss: 0.4096 - accuracy: 0.8921 - auc: 0.8885 - val_loss: 0.6190 - val_accuracy: 0.9687 - val_auc: 0.6935\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.69405\n",
      "Epoch 19/100\n",
      "1168/1168 - 110s - loss: 0.4206 - accuracy: 0.8840 - auc: 0.8878 - val_loss: 0.4965 - val_accuracy: 0.9722 - val_auc: 0.6835\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.69405\n",
      "Epoch 20/100\n",
      "1168/1168 - 106s - loss: 0.4854 - accuracy: 0.9002 - auc: 0.8637 - val_loss: 0.5766 - val_accuracy: 0.9774 - val_auc: 0.6901\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.69405\n",
      "Epoch 21/100\n",
      "1168/1168 - 108s - loss: 0.4475 - accuracy: 0.8811 - auc: 0.8781 - val_loss: 0.5197 - val_accuracy: 0.9617 - val_auc: 0.6898\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.69405\n",
      "Epoch 22/100\n",
      "1168/1168 - 108s - loss: 0.4137 - accuracy: 0.8935 - auc: 0.8983 - val_loss: 0.6419 - val_accuracy: 0.5861 - val_auc: 0.7026\n",
      "\n",
      "Epoch 00022: val_auc improved from 0.69405 to 0.70263, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 23/100\n",
      "1168/1168 - 108s - loss: 0.4157 - accuracy: 0.8905 - auc: 0.8908 - val_loss: 0.6823 - val_accuracy: 0.5148 - val_auc: 0.6409\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.70263\n",
      "Epoch 24/100\n",
      "1168/1168 - 104s - loss: 0.4074 - accuracy: 0.8934 - auc: 0.8985 - val_loss: 0.5603 - val_accuracy: 0.7670 - val_auc: 0.6967\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.70263\n",
      "Epoch 25/100\n",
      "1168/1168 - 105s - loss: 0.3916 - accuracy: 0.8775 - auc: 0.9085 - val_loss: 0.5679 - val_accuracy: 0.9357 - val_auc: 0.7037\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.70263 to 0.70367, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 26/100\n",
      "1168/1168 - 108s - loss: 0.3971 - accuracy: 0.8909 - auc: 0.9079 - val_loss: 0.6097 - val_accuracy: 0.8574 - val_auc: 0.7004\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.70367\n",
      "Epoch 27/100\n",
      "1168/1168 - 108s - loss: 0.4088 - accuracy: 0.8746 - auc: 0.8996 - val_loss: 0.5631 - val_accuracy: 0.9722 - val_auc: 0.7167\n",
      "\n",
      "Epoch 00027: val_auc improved from 0.70367 to 0.71670, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 28/100\n",
      "1168/1168 - 107s - loss: 0.4125 - accuracy: 0.8863 - auc: 0.8967 - val_loss: 0.5603 - val_accuracy: 0.9513 - val_auc: 0.6908\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.71670\n",
      "Epoch 29/100\n",
      "1168/1168 - 104s - loss: 0.3901 - accuracy: 0.8905 - auc: 0.9094 - val_loss: 0.7124 - val_accuracy: 0.7791 - val_auc: 0.6758\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.71670\n",
      "Epoch 30/100\n",
      "1168/1168 - 105s - loss: 0.3842 - accuracy: 0.8793 - auc: 0.9156 - val_loss: 0.9463 - val_accuracy: 0.8400 - val_auc: 0.6987\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.71670\n",
      "Epoch 31/100\n",
      "1168/1168 - 108s - loss: 0.3967 - accuracy: 0.8683 - auc: 0.9170 - val_loss: 0.9612 - val_accuracy: 0.9530 - val_auc: 0.6967\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.71670\n",
      "Epoch 32/100\n",
      "1168/1168 - 108s - loss: 0.3973 - accuracy: 0.8719 - auc: 0.9104 - val_loss: 0.9612 - val_accuracy: 0.6922 - val_auc: 0.6698\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.71670\n",
      "Epoch 33/100\n",
      "1168/1168 - 108s - loss: 0.4053 - accuracy: 0.8565 - auc: 0.9109 - val_loss: 0.6429 - val_accuracy: 0.8765 - val_auc: 0.6861\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.71670\n",
      "Epoch 34/100\n",
      "1168/1168 - 103s - loss: 0.3693 - accuracy: 0.8592 - auc: 0.9279 - val_loss: 0.6575 - val_accuracy: 0.8643 - val_auc: 0.6519\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.71670\n",
      "Epoch 35/100\n",
      "1168/1168 - 106s - loss: 0.3740 - accuracy: 0.8747 - auc: 0.9219 - val_loss: 0.6119 - val_accuracy: 0.9617 - val_auc: 0.6847\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.71670\n",
      "Epoch 36/100\n",
      "1168/1168 - 108s - loss: 0.3834 - accuracy: 0.9033 - auc: 0.9149 - val_loss: 1.0095 - val_accuracy: 0.7965 - val_auc: 0.6857\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.71670\n",
      "Epoch 37/100\n",
      "1168/1168 - 108s - loss: 0.3618 - accuracy: 0.8971 - auc: 0.9290 - val_loss: 1.0938 - val_accuracy: 0.9704 - val_auc: 0.7208\n",
      "\n",
      "Epoch 00037: val_auc improved from 0.71670 to 0.72077, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 38/100\n",
      "1168/1168 - 108s - loss: 0.3714 - accuracy: 0.8736 - auc: 0.9277 - val_loss: 0.7865 - val_accuracy: 0.9548 - val_auc: 0.6817\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.72077\n",
      "Epoch 39/100\n",
      "1168/1168 - 103s - loss: 0.3661 - accuracy: 0.9148 - auc: 0.9230 - val_loss: 1.1430 - val_accuracy: 0.7687 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.72077\n",
      "Epoch 40/100\n",
      "1168/1168 - 106s - loss: 0.3615 - accuracy: 0.8887 - auc: 0.9223 - val_loss: 0.9434 - val_accuracy: 0.9583 - val_auc: 0.6972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_auc did not improve from 0.72077\n",
      "Epoch 41/100\n",
      "1168/1168 - 112s - loss: 0.3498 - accuracy: 0.8915 - auc: 0.9350 - val_loss: 0.7808 - val_accuracy: 0.9148 - val_auc: 0.7076\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.72077\n",
      "Epoch 42/100\n",
      "1168/1168 - 107s - loss: 0.3171 - accuracy: 0.8801 - auc: 0.9465 - val_loss: 1.0527 - val_accuracy: 0.8765 - val_auc: 0.7094\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.72077\n",
      "Epoch 43/100\n",
      "1168/1168 - 107s - loss: 0.3381 - accuracy: 0.8905 - auc: 0.9427 - val_loss: 0.9674 - val_accuracy: 0.7774 - val_auc: 0.6946\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.72077\n",
      "Epoch 44/100\n",
      "1168/1168 - 102s - loss: 0.3019 - accuracy: 0.8841 - auc: 0.9535 - val_loss: 0.7856 - val_accuracy: 0.8817 - val_auc: 0.6990\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.72077\n",
      "Epoch 45/100\n",
      "1168/1168 - 106s - loss: 0.3089 - accuracy: 0.8826 - auc: 0.9507 - val_loss: 0.8982 - val_accuracy: 0.8730 - val_auc: 0.6940\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.72077\n",
      "Epoch 46/100\n",
      "1168/1168 - 107s - loss: 0.3343 - accuracy: 0.8912 - auc: 0.9434 - val_loss: 1.2523 - val_accuracy: 0.8226 - val_auc: 0.7214\n",
      "\n",
      "Epoch 00046: val_auc improved from 0.72077 to 0.72143, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 47/100\n",
      "1168/1168 - 108s - loss: 0.3154 - accuracy: 0.8927 - auc: 0.9473 - val_loss: 1.3771 - val_accuracy: 0.8035 - val_auc: 0.7382\n",
      "\n",
      "Epoch 00047: val_auc improved from 0.72143 to 0.73816, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR\n",
      "Epoch 48/100\n",
      "1168/1168 - 109s - loss: 0.2973 - accuracy: 0.8773 - auc: 0.9542 - val_loss: 1.1898 - val_accuracy: 0.5113 - val_auc: 0.6557\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.73816\n",
      "Epoch 49/100\n",
      "1168/1168 - 102s - loss: 0.3320 - accuracy: 0.8923 - auc: 0.9514 - val_loss: 0.4872 - val_accuracy: 0.7357 - val_auc: 0.7352\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.73816\n",
      "Epoch 50/100\n",
      "1168/1168 - 108s - loss: 0.3123 - accuracy: 0.8709 - auc: 0.9535 - val_loss: 1.0169 - val_accuracy: 0.8104 - val_auc: 0.6630\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.73816\n",
      "Epoch 51/100\n",
      "1168/1168 - 109s - loss: 0.2866 - accuracy: 0.8821 - auc: 0.9621 - val_loss: 1.2946 - val_accuracy: 0.8730 - val_auc: 0.6839\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.73816\n",
      "Epoch 52/100\n",
      "1168/1168 - 110s - loss: 0.3211 - accuracy: 0.8959 - auc: 0.9521 - val_loss: 1.1309 - val_accuracy: 0.8609 - val_auc: 0.7123\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.73816\n",
      "Epoch 53/100\n",
      "1168/1168 - 110s - loss: 0.2868 - accuracy: 0.9013 - auc: 0.9613 - val_loss: 1.2320 - val_accuracy: 0.6783 - val_auc: 0.6596\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.73816\n",
      "Epoch 54/100\n",
      "1168/1168 - 103s - loss: 0.2952 - accuracy: 0.8876 - auc: 0.9566 - val_loss: 1.1096 - val_accuracy: 0.9339 - val_auc: 0.7314\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.73816\n",
      "Epoch 55/100\n",
      "1168/1168 - 109s - loss: 0.2775 - accuracy: 0.9011 - auc: 0.9637 - val_loss: 0.9711 - val_accuracy: 0.9391 - val_auc: 0.7029\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.73816\n",
      "Epoch 56/100\n",
      "1168/1168 - 108s - loss: 0.2667 - accuracy: 0.9021 - auc: 0.9645 - val_loss: 1.1909 - val_accuracy: 0.9757 - val_auc: 0.6587\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.73816\n",
      "Epoch 57/100\n",
      "1168/1168 - 110s - loss: 0.2755 - accuracy: 0.9015 - auc: 0.9640 - val_loss: 0.8320 - val_accuracy: 0.8557 - val_auc: 0.6889\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.73816\n",
      "Epoch 58/100\n",
      "1168/1168 - 111s - loss: 0.2688 - accuracy: 0.8991 - auc: 0.9664 - val_loss: 1.5429 - val_accuracy: 0.8696 - val_auc: 0.6924\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.73816\n",
      "Epoch 59/100\n",
      "1168/1168 - 103s - loss: 0.2548 - accuracy: 0.9025 - auc: 0.9707 - val_loss: 1.0780 - val_accuracy: 0.8191 - val_auc: 0.6454\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.73816\n",
      "Epoch 60/100\n",
      "1168/1168 - 107s - loss: 0.2803 - accuracy: 0.8988 - auc: 0.9639 - val_loss: 0.9864 - val_accuracy: 0.8643 - val_auc: 0.6854\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.73816\n",
      "Epoch 61/100\n",
      "1168/1168 - 107s - loss: 0.2548 - accuracy: 0.8988 - auc: 0.9710 - val_loss: 1.2270 - val_accuracy: 0.8887 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.73816\n",
      "Epoch 62/100\n",
      "1168/1168 - 107s - loss: 0.2581 - accuracy: 0.9137 - auc: 0.9704 - val_loss: 0.7791 - val_accuracy: 0.9026 - val_auc: 0.6667\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.73816\n",
      "Epoch 63/100\n",
      "1168/1168 - 107s - loss: 0.2438 - accuracy: 0.9099 - auc: 0.9735 - val_loss: 1.3447 - val_accuracy: 0.9443 - val_auc: 0.6975\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.73816\n",
      "Epoch 64/100\n",
      "1168/1168 - 102s - loss: 0.2766 - accuracy: 0.9104 - auc: 0.9649 - val_loss: 0.9592 - val_accuracy: 0.9078 - val_auc: 0.7221\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.73816\n",
      "Epoch 65/100\n",
      "1168/1168 - 108s - loss: 0.2605 - accuracy: 0.9133 - auc: 0.9702 - val_loss: 1.1016 - val_accuracy: 0.9200 - val_auc: 0.7046\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.73816\n",
      "Epoch 66/100\n",
      "1168/1168 - 114s - loss: 0.2371 - accuracy: 0.9284 - auc: 0.9742 - val_loss: 0.9754 - val_accuracy: 0.7513 - val_auc: 0.6990\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.73816\n",
      "Epoch 67/100\n",
      "1168/1168 - 113s - loss: 0.2283 - accuracy: 0.9161 - auc: 0.9765 - val_loss: 1.1816 - val_accuracy: 0.7774 - val_auc: 0.7345\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.73816\n",
      "Epoch 68/100\n",
      "1168/1168 - 112s - loss: 0.2237 - accuracy: 0.9105 - auc: 0.9771 - val_loss: 1.3690 - val_accuracy: 0.8661 - val_auc: 0.6881\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.73816\n",
      "Epoch 69/100\n",
      "1168/1168 - 105s - loss: 0.2328 - accuracy: 0.9139 - auc: 0.9757 - val_loss: 1.3978 - val_accuracy: 0.8991 - val_auc: 0.6672\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.73816\n",
      "Epoch 70/100\n",
      "1168/1168 - 113s - loss: 0.2530 - accuracy: 0.9158 - auc: 0.9756 - val_loss: 1.1488 - val_accuracy: 0.9270 - val_auc: 0.7113\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.73816\n",
      "Epoch 71/100\n",
      "1168/1168 - 112s - loss: 0.2422 - accuracy: 0.9187 - auc: 0.9755 - val_loss: 1.2751 - val_accuracy: 0.9443 - val_auc: 0.6880\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.73816\n",
      "Epoch 72/100\n",
      "1168/1168 - 112s - loss: 0.2189 - accuracy: 0.9212 - auc: 0.9803 - val_loss: 1.6086 - val_accuracy: 0.8817 - val_auc: 0.7103\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.73816\n",
      "Epoch 73/100\n",
      "1168/1168 - 112s - loss: 0.2207 - accuracy: 0.9134 - auc: 0.9789 - val_loss: 1.7295 - val_accuracy: 0.9583 - val_auc: 0.6249\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.73816\n",
      "Epoch 74/100\n",
      "1168/1168 - 105s - loss: 0.2031 - accuracy: 0.9165 - auc: 0.9817 - val_loss: 1.5040 - val_accuracy: 0.8765 - val_auc: 0.7022\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.73816\n",
      "Epoch 75/100\n",
      "1168/1168 - 112s - loss: 0.2200 - accuracy: 0.9123 - auc: 0.9784 - val_loss: 1.4010 - val_accuracy: 0.7235 - val_auc: 0.6952\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.73816\n",
      "Epoch 76/100\n",
      "1168/1168 - 112s - loss: 0.2017 - accuracy: 0.9125 - auc: 0.9810 - val_loss: 1.5653 - val_accuracy: 0.7774 - val_auc: 0.6978\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.73816\n",
      "Epoch 77/100\n",
      "1168/1168 - 113s - loss: 0.2292 - accuracy: 0.9152 - auc: 0.9773 - val_loss: 1.2798 - val_accuracy: 0.9200 - val_auc: 0.7131\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.73816\n",
      "Epoch 78/100\n",
      "1168/1168 - 112s - loss: 0.1977 - accuracy: 0.9244 - auc: 0.9839 - val_loss: 1.6571 - val_accuracy: 0.9304 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.73816\n",
      "Epoch 79/100\n",
      "1168/1168 - 106s - loss: 0.2092 - accuracy: 0.9075 - auc: 0.9807 - val_loss: 1.3758 - val_accuracy: 0.8852 - val_auc: 0.6792\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.73816\n",
      "Epoch 80/100\n",
      "1168/1168 - 112s - loss: 0.1868 - accuracy: 0.9272 - auc: 0.9842 - val_loss: 1.2293 - val_accuracy: 0.8609 - val_auc: 0.6643\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.73816\n",
      "Epoch 81/100\n",
      "1168/1168 - 112s - loss: 0.1999 - accuracy: 0.9166 - auc: 0.9815 - val_loss: 1.2174 - val_accuracy: 0.9426 - val_auc: 0.6847\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.73816\n",
      "Epoch 82/100\n",
      "1168/1168 - 113s - loss: 0.2349 - accuracy: 0.9224 - auc: 0.9768 - val_loss: 1.5587 - val_accuracy: 0.9113 - val_auc: 0.6539\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.73816\n",
      "Epoch 83/100\n",
      "1168/1168 - 112s - loss: 0.1813 - accuracy: 0.9279 - auc: 0.9845 - val_loss: 1.6627 - val_accuracy: 0.9357 - val_auc: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_auc did not improve from 0.73816\n",
      "Epoch 84/100\n",
      "1168/1168 - 105s - loss: 0.1912 - accuracy: 0.9163 - auc: 0.9832 - val_loss: 1.4365 - val_accuracy: 0.9513 - val_auc: 0.6897\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.73816\n",
      "Epoch 85/100\n",
      "1168/1168 - 112s - loss: 0.2510 - accuracy: 0.9158 - auc: 0.9722 - val_loss: 1.5982 - val_accuracy: 0.9287 - val_auc: 0.7062\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.73816\n",
      "Epoch 86/100\n",
      "1168/1168 - 112s - loss: 0.1870 - accuracy: 0.9343 - auc: 0.9839 - val_loss: 1.5015 - val_accuracy: 0.9478 - val_auc: 0.7316\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.73816\n",
      "Epoch 87/100\n",
      "1168/1168 - 109s - loss: 0.2170 - accuracy: 0.9300 - auc: 0.9801 - val_loss: 1.9116 - val_accuracy: 0.9583 - val_auc: 0.6837\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.73816\n",
      "Epoch 88/100\n",
      "1168/1168 - 107s - loss: 0.2789 - accuracy: 0.9229 - auc: 0.9749 - val_loss: 1.6466 - val_accuracy: 0.9583 - val_auc: 0.7040\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.73816\n",
      "Epoch 89/100\n",
      "1168/1168 - 101s - loss: 0.2258 - accuracy: 0.9293 - auc: 0.9797 - val_loss: 1.3381 - val_accuracy: 0.9652 - val_auc: 0.7165\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.73816\n",
      "Epoch 90/100\n",
      "1168/1168 - 107s - loss: 0.1872 - accuracy: 0.9363 - auc: 0.9863 - val_loss: 1.4128 - val_accuracy: 0.9270 - val_auc: 0.6695\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.73816\n",
      "Epoch 91/100\n",
      "1168/1168 - 107s - loss: 0.1727 - accuracy: 0.9365 - auc: 0.9861 - val_loss: 1.1920 - val_accuracy: 0.8730 - val_auc: 0.6954\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.73816\n",
      "Epoch 92/100\n",
      "1168/1168 - 107s - loss: 0.1973 - accuracy: 0.9133 - auc: 0.9817 - val_loss: 1.5512 - val_accuracy: 0.9548 - val_auc: 0.6745\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.73816\n",
      "Epoch 93/100\n",
      "1168/1168 - 107s - loss: 0.1570 - accuracy: 0.9307 - auc: 0.9876 - val_loss: 1.5397 - val_accuracy: 0.8504 - val_auc: 0.6757\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.73816\n",
      "Epoch 94/100\n",
      "1168/1168 - 100s - loss: 0.1935 - accuracy: 0.9262 - auc: 0.9837 - val_loss: 1.4094 - val_accuracy: 0.8817 - val_auc: 0.7153\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.73816\n",
      "Epoch 95/100\n",
      "1168/1168 - 107s - loss: 0.1895 - accuracy: 0.9326 - auc: 0.9842 - val_loss: 1.5953 - val_accuracy: 0.9374 - val_auc: 0.6915\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.73816\n",
      "Epoch 96/100\n",
      "1168/1168 - 107s - loss: 0.2331 - accuracy: 0.9300 - auc: 0.9786 - val_loss: 1.7136 - val_accuracy: 0.9652 - val_auc: 0.7067\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.73816\n",
      "Epoch 97/100\n",
      "1168/1168 - 107s - loss: 0.1795 - accuracy: 0.9392 - auc: 0.9873 - val_loss: 1.5531 - val_accuracy: 0.9130 - val_auc: 0.7109\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.73816\n",
      "Epoch 98/100\n",
      "1168/1168 - 106s - loss: 0.1877 - accuracy: 0.9295 - auc: 0.9852 - val_loss: 1.4867 - val_accuracy: 0.9304 - val_auc: 0.6605\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.73816\n",
      "Epoch 99/100\n",
      "1168/1168 - 101s - loss: 0.1773 - accuracy: 0.9328 - auc: 0.9862 - val_loss: 1.3973 - val_accuracy: 0.9113 - val_auc: 0.7291\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.73816\n",
      "Epoch 100/100\n",
      "1168/1168 - 107s - loss: 0.2031 - accuracy: 0.9250 - auc: 0.9824 - val_loss: 1.6295 - val_accuracy: 0.9496 - val_auc: 0.7264\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.73816\n",
      "Epoch 1/100\n",
      "1025/1025 - 109s - loss: 0.7239 - accuracy: 0.6373 - auc: 0.7614 - val_loss: 0.5950 - val_accuracy: 0.7164 - val_auc: 0.8726\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.87259, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 2/100\n",
      "1025/1025 - 95s - loss: 0.5717 - accuracy: 0.7325 - auc: 0.8408 - val_loss: 0.5077 - val_accuracy: 0.7349 - val_auc: 0.8749\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.87259 to 0.87492, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 3/100\n",
      "1025/1025 - 95s - loss: 0.5087 - accuracy: 0.7639 - auc: 0.8579 - val_loss: 0.5066 - val_accuracy: 0.6695 - val_auc: 0.8732\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.87492\n",
      "Epoch 4/100\n",
      "1025/1025 - 90s - loss: 0.4733 - accuracy: 0.7714 - auc: 0.8683 - val_loss: 0.4921 - val_accuracy: 0.8238 - val_auc: 0.8717\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.87492\n",
      "Epoch 5/100\n",
      "1025/1025 - 92s - loss: 0.4590 - accuracy: 0.7783 - auc: 0.8728 - val_loss: 0.5718 - val_accuracy: 0.5453 - val_auc: 0.8796\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.87492 to 0.87965, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 6/100\n",
      "1025/1025 - 95s - loss: 0.4309 - accuracy: 0.7892 - auc: 0.8884 - val_loss: 0.4699 - val_accuracy: 0.7886 - val_auc: 0.8803\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.87965 to 0.88033, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 7/100\n",
      "1025/1025 - 94s - loss: 0.4315 - accuracy: 0.8013 - auc: 0.8886 - val_loss: 0.5008 - val_accuracy: 0.6594 - val_auc: 0.8822\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.88033 to 0.88219, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 8/100\n",
      "1025/1025 - 97s - loss: 0.4250 - accuracy: 0.8025 - auc: 0.8919 - val_loss: 0.4656 - val_accuracy: 0.8456 - val_auc: 0.8842\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.88219 to 0.88424, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 9/100\n",
      "1025/1025 - 99s - loss: 0.4369 - accuracy: 0.7919 - auc: 0.8920 - val_loss: 0.4673 - val_accuracy: 0.7315 - val_auc: 0.8878\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.88424 to 0.88779, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AhR\n",
      "Epoch 10/100\n",
      "1025/1025 - 92s - loss: 0.4166 - accuracy: 0.7996 - auc: 0.8988 - val_loss: 0.4642 - val_accuracy: 0.7416 - val_auc: 0.8774\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.88779\n",
      "Epoch 11/100\n",
      "1025/1025 - 99s - loss: 0.4099 - accuracy: 0.8081 - auc: 0.9024 - val_loss: 0.4578 - val_accuracy: 0.7987 - val_auc: 0.8785\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.88779\n",
      "Epoch 12/100\n",
      "1025/1025 - 99s - loss: 0.4062 - accuracy: 0.8021 - auc: 0.9032 - val_loss: 0.5781 - val_accuracy: 0.4849 - val_auc: 0.8789\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.88779\n",
      "Epoch 13/100\n",
      "1025/1025 - 99s - loss: 0.3932 - accuracy: 0.8218 - auc: 0.9097 - val_loss: 0.5305 - val_accuracy: 0.8440 - val_auc: 0.8856\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.88779\n",
      "Epoch 14/100\n",
      "1025/1025 - 99s - loss: 0.4017 - accuracy: 0.8084 - auc: 0.9058 - val_loss: 0.4575 - val_accuracy: 0.7987 - val_auc: 0.8806\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.88779\n",
      "Epoch 15/100\n",
      "1025/1025 - 97s - loss: 0.4080 - accuracy: 0.8096 - auc: 0.9066 - val_loss: 0.4659 - val_accuracy: 0.7534 - val_auc: 0.8829\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.88779\n",
      "Epoch 16/100\n",
      "1025/1025 - 94s - loss: 0.3827 - accuracy: 0.8211 - auc: 0.9156 - val_loss: 0.4461 - val_accuracy: 0.7802 - val_auc: 0.8843\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.88779\n",
      "Epoch 17/100\n",
      "1025/1025 - 99s - loss: 0.3772 - accuracy: 0.8258 - auc: 0.9191 - val_loss: 0.4782 - val_accuracy: 0.6846 - val_auc: 0.8781\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.88779\n",
      "Epoch 18/100\n",
      "1025/1025 - 100s - loss: 0.3782 - accuracy: 0.8180 - auc: 0.9186 - val_loss: 0.5069 - val_accuracy: 0.6493 - val_auc: 0.8761\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.88779\n",
      "Epoch 19/100\n",
      "1025/1025 - 99s - loss: 0.3743 - accuracy: 0.8086 - auc: 0.9193 - val_loss: 0.4906 - val_accuracy: 0.8255 - val_auc: 0.8744\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.88779\n",
      "Epoch 20/100\n",
      "1025/1025 - 99s - loss: 0.3630 - accuracy: 0.8167 - auc: 0.9242 - val_loss: 0.4753 - val_accuracy: 0.7601 - val_auc: 0.8801\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.88779\n",
      "Epoch 21/100\n",
      "1025/1025 - 94s - loss: 0.3731 - accuracy: 0.8219 - auc: 0.9227 - val_loss: 0.4686 - val_accuracy: 0.7886 - val_auc: 0.8786\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.88779\n",
      "Epoch 22/100\n",
      "1025/1025 - 97s - loss: 0.3505 - accuracy: 0.8311 - auc: 0.9305 - val_loss: 0.5260 - val_accuracy: 0.7785 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.88779\n",
      "Epoch 23/100\n",
      "1025/1025 - 99s - loss: 0.3491 - accuracy: 0.8342 - auc: 0.9326 - val_loss: 0.5048 - val_accuracy: 0.7131 - val_auc: 0.8758\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.88779\n",
      "Epoch 24/100\n",
      "1025/1025 - 99s - loss: 0.3471 - accuracy: 0.8388 - auc: 0.9322 - val_loss: 0.4659 - val_accuracy: 0.7819 - val_auc: 0.8784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_auc did not improve from 0.88779\n",
      "Epoch 25/100\n",
      "1025/1025 - 99s - loss: 0.3294 - accuracy: 0.8465 - auc: 0.9376 - val_loss: 0.5098 - val_accuracy: 0.6779 - val_auc: 0.8657\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.88779\n",
      "Epoch 26/100\n",
      "1025/1025 - 99s - loss: 0.3254 - accuracy: 0.8435 - auc: 0.9385 - val_loss: 0.5313 - val_accuracy: 0.6426 - val_auc: 0.8713\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.88779\n",
      "Epoch 27/100\n",
      "1025/1025 - 92s - loss: 0.3329 - accuracy: 0.8444 - auc: 0.9371 - val_loss: 0.5008 - val_accuracy: 0.7164 - val_auc: 0.8724\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.88779\n",
      "Epoch 28/100\n",
      "1025/1025 - 99s - loss: 0.3300 - accuracy: 0.8427 - auc: 0.9381 - val_loss: 0.5181 - val_accuracy: 0.6930 - val_auc: 0.8735\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.88779\n",
      "Epoch 29/100\n",
      "1025/1025 - 99s - loss: 0.3231 - accuracy: 0.8495 - auc: 0.9405 - val_loss: 0.5890 - val_accuracy: 0.8591 - val_auc: 0.8757\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.88779\n",
      "Epoch 30/100\n",
      "1025/1025 - 99s - loss: 0.3133 - accuracy: 0.8527 - auc: 0.9432 - val_loss: 0.5763 - val_accuracy: 0.8188 - val_auc: 0.8759\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.88779\n",
      "Epoch 31/100\n",
      "1025/1025 - 99s - loss: 0.3000 - accuracy: 0.8557 - auc: 0.9481 - val_loss: 0.5345 - val_accuracy: 0.8708 - val_auc: 0.8877\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.88779\n",
      "Epoch 32/100\n",
      "1025/1025 - 98s - loss: 0.2985 - accuracy: 0.8616 - auc: 0.9492 - val_loss: 0.5581 - val_accuracy: 0.8154 - val_auc: 0.8648\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.88779\n",
      "Epoch 33/100\n",
      "1025/1025 - 93s - loss: 0.2924 - accuracy: 0.8649 - auc: 0.9506 - val_loss: 0.4990 - val_accuracy: 0.8255 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.88779\n",
      "Epoch 34/100\n",
      "1025/1025 - 99s - loss: 0.2955 - accuracy: 0.8611 - auc: 0.9503 - val_loss: 0.5089 - val_accuracy: 0.7802 - val_auc: 0.8791\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.88779\n",
      "Epoch 35/100\n",
      "1025/1025 - 96s - loss: 0.2889 - accuracy: 0.8705 - auc: 0.9528 - val_loss: 0.5468 - val_accuracy: 0.8356 - val_auc: 0.8818\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.88779\n",
      "Epoch 36/100\n",
      "1025/1025 - 95s - loss: 0.2794 - accuracy: 0.8690 - auc: 0.9557 - val_loss: 0.5307 - val_accuracy: 0.7450 - val_auc: 0.8721\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.88779\n",
      "Epoch 37/100\n",
      "1025/1025 - 94s - loss: 0.2671 - accuracy: 0.8759 - auc: 0.9593 - val_loss: 0.5535 - val_accuracy: 0.7819 - val_auc: 0.8746\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.88779\n",
      "Epoch 38/100\n",
      "1025/1025 - 90s - loss: 0.2805 - accuracy: 0.8671 - auc: 0.9551 - val_loss: 0.6571 - val_accuracy: 0.8238 - val_auc: 0.8700\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.88779\n",
      "Epoch 39/100\n",
      "1025/1025 - 92s - loss: 0.2870 - accuracy: 0.8696 - auc: 0.9538 - val_loss: 0.5208 - val_accuracy: 0.8221 - val_auc: 0.8793\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.88779\n",
      "Epoch 40/100\n",
      "1025/1025 - 94s - loss: 0.2775 - accuracy: 0.8779 - auc: 0.9572 - val_loss: 0.5615 - val_accuracy: 0.8742 - val_auc: 0.8868\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.88779\n",
      "Epoch 41/100\n",
      "1025/1025 - 95s - loss: 0.2701 - accuracy: 0.8775 - auc: 0.9582 - val_loss: 0.5689 - val_accuracy: 0.7970 - val_auc: 0.8727\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.88779\n",
      "Epoch 42/100\n",
      "1025/1025 - 95s - loss: 0.2624 - accuracy: 0.8819 - auc: 0.9601 - val_loss: 0.6232 - val_accuracy: 0.7735 - val_auc: 0.8715\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.88779\n",
      "Epoch 43/100\n",
      "1025/1025 - 95s - loss: 0.2666 - accuracy: 0.8839 - auc: 0.9602 - val_loss: 0.6217 - val_accuracy: 0.7987 - val_auc: 0.8728\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.88779\n",
      "Epoch 44/100\n",
      "1025/1025 - 88s - loss: 0.2623 - accuracy: 0.8816 - auc: 0.9610 - val_loss: 0.6730 - val_accuracy: 0.8557 - val_auc: 0.8768\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.88779\n",
      "Epoch 45/100\n",
      "1025/1025 - 94s - loss: 0.2663 - accuracy: 0.8804 - auc: 0.9588 - val_loss: 0.5419 - val_accuracy: 0.7617 - val_auc: 0.8738\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.88779\n",
      "Epoch 46/100\n",
      "1025/1025 - 94s - loss: 0.2429 - accuracy: 0.8889 - auc: 0.9660 - val_loss: 0.4885 - val_accuracy: 0.7651 - val_auc: 0.8773\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.88779\n",
      "Epoch 47/100\n",
      "1025/1025 - 95s - loss: 0.2579 - accuracy: 0.8911 - auc: 0.9637 - val_loss: 0.6960 - val_accuracy: 0.8624 - val_auc: 0.8746\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.88779\n",
      "Epoch 48/100\n",
      "1025/1025 - 95s - loss: 0.2396 - accuracy: 0.8902 - auc: 0.9669 - val_loss: 0.6131 - val_accuracy: 0.8272 - val_auc: 0.8739\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.88779\n",
      "Epoch 49/100\n",
      "1025/1025 - 93s - loss: 0.2295 - accuracy: 0.9014 - auc: 0.9697 - val_loss: 0.5808 - val_accuracy: 0.8272 - val_auc: 0.8723\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.88779\n",
      "Epoch 50/100\n",
      "1025/1025 - 90s - loss: 0.2471 - accuracy: 0.8943 - auc: 0.9656 - val_loss: 0.6431 - val_accuracy: 0.7987 - val_auc: 0.8643\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.88779\n",
      "Epoch 51/100\n",
      "1025/1025 - 95s - loss: 0.2417 - accuracy: 0.8909 - auc: 0.9674 - val_loss: 0.5513 - val_accuracy: 0.8070 - val_auc: 0.8721\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.88779\n",
      "Epoch 52/100\n",
      "1025/1025 - 94s - loss: 0.2249 - accuracy: 0.8988 - auc: 0.9704 - val_loss: 0.6039 - val_accuracy: 0.7919 - val_auc: 0.8668\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.88779\n",
      "Epoch 53/100\n",
      "1025/1025 - 95s - loss: 0.2269 - accuracy: 0.8949 - auc: 0.9702 - val_loss: 0.6475 - val_accuracy: 0.8205 - val_auc: 0.8702\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.88779\n",
      "Epoch 54/100\n",
      "1025/1025 - 95s - loss: 0.2198 - accuracy: 0.9050 - auc: 0.9722 - val_loss: 0.6856 - val_accuracy: 0.7869 - val_auc: 0.8565\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.88779\n",
      "Epoch 55/100\n",
      "1025/1025 - 89s - loss: 0.2290 - accuracy: 0.9054 - auc: 0.9711 - val_loss: 0.7956 - val_accuracy: 0.8171 - val_auc: 0.8620\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.88779\n",
      "Epoch 56/100\n",
      "1025/1025 - 93s - loss: 0.2326 - accuracy: 0.8955 - auc: 0.9695 - val_loss: 0.5986 - val_accuracy: 0.8372 - val_auc: 0.8625\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.88779\n",
      "Epoch 57/100\n",
      "1025/1025 - 94s - loss: 0.2182 - accuracy: 0.9063 - auc: 0.9733 - val_loss: 0.6545 - val_accuracy: 0.7752 - val_auc: 0.8683\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.88779\n",
      "Epoch 58/100\n",
      "1025/1025 - 95s - loss: 0.2206 - accuracy: 0.9091 - auc: 0.9726 - val_loss: 0.6591 - val_accuracy: 0.8490 - val_auc: 0.8736\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.88779\n",
      "Epoch 59/100\n",
      "1025/1025 - 94s - loss: 0.2053 - accuracy: 0.9091 - auc: 0.9754 - val_loss: 0.6126 - val_accuracy: 0.8003 - val_auc: 0.8470\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.88779\n",
      "Epoch 60/100\n",
      "1025/1025 - 95s - loss: 0.2047 - accuracy: 0.9089 - auc: 0.9757 - val_loss: 0.7616 - val_accuracy: 0.8456 - val_auc: 0.8603\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.88779\n",
      "Epoch 61/100\n",
      "1025/1025 - 88s - loss: 0.2219 - accuracy: 0.8995 - auc: 0.9716 - val_loss: 0.8447 - val_accuracy: 0.8322 - val_auc: 0.8520\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.88779\n",
      "Epoch 62/100\n",
      "1025/1025 - 94s - loss: 0.2148 - accuracy: 0.9121 - auc: 0.9741 - val_loss: 0.5759 - val_accuracy: 0.7836 - val_auc: 0.8741\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.88779\n",
      "Epoch 63/100\n",
      "1025/1025 - 94s - loss: 0.2119 - accuracy: 0.9017 - auc: 0.9755 - val_loss: 0.7642 - val_accuracy: 0.8003 - val_auc: 0.8529\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.88779\n",
      "Epoch 64/100\n",
      "1025/1025 - 94s - loss: 0.2141 - accuracy: 0.9083 - auc: 0.9748 - val_loss: 0.8523 - val_accuracy: 0.8305 - val_auc: 0.8417\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.88779\n",
      "Epoch 65/100\n",
      "1025/1025 - 95s - loss: 0.2010 - accuracy: 0.9154 - auc: 0.9766 - val_loss: 0.7703 - val_accuracy: 0.8473 - val_auc: 0.8599\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.88779\n",
      "Epoch 66/100\n",
      "1025/1025 - 91s - loss: 0.1999 - accuracy: 0.9155 - auc: 0.9773 - val_loss: 0.7932 - val_accuracy: 0.7768 - val_auc: 0.8594\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.88779\n",
      "Epoch 67/100\n",
      "1025/1025 - 91s - loss: 0.2024 - accuracy: 0.9121 - auc: 0.9771 - val_loss: 0.7991 - val_accuracy: 0.8473 - val_auc: 0.8653\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.88779\n",
      "Epoch 68/100\n",
      "1025/1025 - 95s - loss: 0.1940 - accuracy: 0.9180 - auc: 0.9791 - val_loss: 0.6727 - val_accuracy: 0.7617 - val_auc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: val_auc did not improve from 0.88779\n",
      "Epoch 69/100\n",
      "1025/1025 - 95s - loss: 0.1989 - accuracy: 0.9113 - auc: 0.9778 - val_loss: 0.7192 - val_accuracy: 0.8289 - val_auc: 0.8687\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.88779\n",
      "Epoch 70/100\n",
      "1025/1025 - 94s - loss: 0.2037 - accuracy: 0.9087 - auc: 0.9769 - val_loss: 0.7210 - val_accuracy: 0.7685 - val_auc: 0.8709\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.88779\n",
      "Epoch 71/100\n",
      "1025/1025 - 94s - loss: 0.1925 - accuracy: 0.9161 - auc: 0.9786 - val_loss: 1.0055 - val_accuracy: 0.8507 - val_auc: 0.8470\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.88779\n",
      "Epoch 72/100\n",
      "1025/1025 - 88s - loss: 0.1976 - accuracy: 0.9207 - auc: 0.9783 - val_loss: 0.8144 - val_accuracy: 0.8490 - val_auc: 0.8563\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.88779\n",
      "Epoch 73/100\n",
      "1025/1025 - 94s - loss: 0.1851 - accuracy: 0.9273 - auc: 0.9804 - val_loss: 0.6959 - val_accuracy: 0.8171 - val_auc: 0.8668\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.88779\n",
      "Epoch 74/100\n",
      "1025/1025 - 95s - loss: 0.1666 - accuracy: 0.9312 - auc: 0.9830 - val_loss: 0.9131 - val_accuracy: 0.7903 - val_auc: 0.8577\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.88779\n",
      "Epoch 75/100\n",
      "1025/1025 - 94s - loss: 0.1972 - accuracy: 0.9169 - auc: 0.9773 - val_loss: 0.8297 - val_accuracy: 0.8423 - val_auc: 0.8592\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.88779\n",
      "Epoch 76/100\n",
      "1025/1025 - 95s - loss: 0.1793 - accuracy: 0.9321 - auc: 0.9813 - val_loss: 0.8686 - val_accuracy: 0.8070 - val_auc: 0.8537\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.88779\n",
      "Epoch 77/100\n",
      "1025/1025 - 94s - loss: 0.1900 - accuracy: 0.9166 - auc: 0.9785 - val_loss: 0.6058 - val_accuracy: 0.8389 - val_auc: 0.8578\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.88779\n",
      "Epoch 78/100\n",
      "1025/1025 - 87s - loss: 0.1763 - accuracy: 0.9252 - auc: 0.9823 - val_loss: 0.9939 - val_accuracy: 0.8574 - val_auc: 0.8513\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.88779\n",
      "Epoch 79/100\n",
      "1025/1025 - 95s - loss: 0.1793 - accuracy: 0.9257 - auc: 0.9820 - val_loss: 1.1711 - val_accuracy: 0.8842 - val_auc: 0.8490\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.88779\n",
      "Epoch 80/100\n",
      "1025/1025 - 95s - loss: 0.1910 - accuracy: 0.9163 - auc: 0.9797 - val_loss: 0.9346 - val_accuracy: 0.8624 - val_auc: 0.8553\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.88779\n",
      "Epoch 81/100\n",
      "1025/1025 - 94s - loss: 0.1625 - accuracy: 0.9332 - auc: 0.9846 - val_loss: 0.7513 - val_accuracy: 0.8255 - val_auc: 0.8675\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.88779\n",
      "Epoch 82/100\n",
      "1025/1025 - 94s - loss: 0.1739 - accuracy: 0.9196 - auc: 0.9819 - val_loss: 0.7244 - val_accuracy: 0.7852 - val_auc: 0.8616\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.88779\n",
      "Epoch 83/100\n",
      "1025/1025 - 91s - loss: 0.1660 - accuracy: 0.9295 - auc: 0.9831 - val_loss: 1.0074 - val_accuracy: 0.8540 - val_auc: 0.8431\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.88779\n",
      "Epoch 84/100\n",
      "1025/1025 - 92s - loss: 0.1642 - accuracy: 0.9260 - auc: 0.9840 - val_loss: 0.9139 - val_accuracy: 0.8205 - val_auc: 0.8629\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.88779\n",
      "Epoch 85/100\n",
      "1025/1025 - 95s - loss: 0.1665 - accuracy: 0.9299 - auc: 0.9829 - val_loss: 1.1628 - val_accuracy: 0.8708 - val_auc: 0.8338\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.88779\n",
      "Epoch 86/100\n",
      "1025/1025 - 94s - loss: 0.1794 - accuracy: 0.9287 - auc: 0.9828 - val_loss: 0.9191 - val_accuracy: 0.8406 - val_auc: 0.8472\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.88779\n",
      "Epoch 87/100\n",
      "1025/1025 - 99s - loss: 0.1668 - accuracy: 0.9315 - auc: 0.9840 - val_loss: 1.0196 - val_accuracy: 0.8322 - val_auc: 0.8333\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.88779\n",
      "Epoch 88/100\n",
      "1025/1025 - 100s - loss: 0.1549 - accuracy: 0.9356 - auc: 0.9853 - val_loss: 1.2378 - val_accuracy: 0.8406 - val_auc: 0.8356\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.88779\n",
      "Epoch 89/100\n",
      "1025/1025 - 92s - loss: 0.1560 - accuracy: 0.9323 - auc: 0.9847 - val_loss: 1.0960 - val_accuracy: 0.8624 - val_auc: 0.8497\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.88779\n",
      "Epoch 90/100\n",
      "1025/1025 - 100s - loss: 0.1625 - accuracy: 0.9314 - auc: 0.9845 - val_loss: 0.7758 - val_accuracy: 0.8154 - val_auc: 0.8381\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.88779\n",
      "Epoch 91/100\n",
      "1025/1025 - 99s - loss: 0.1721 - accuracy: 0.9298 - auc: 0.9826 - val_loss: 0.9651 - val_accuracy: 0.8490 - val_auc: 0.8447\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.88779\n",
      "Epoch 92/100\n",
      "1025/1025 - 99s - loss: 0.1508 - accuracy: 0.9365 - auc: 0.9857 - val_loss: 0.7823 - val_accuracy: 0.7416 - val_auc: 0.8252\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.88779\n",
      "Epoch 93/100\n",
      "1025/1025 - 99s - loss: 0.1546 - accuracy: 0.9375 - auc: 0.9851 - val_loss: 0.9047 - val_accuracy: 0.8238 - val_auc: 0.8489\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.88779\n",
      "Epoch 94/100\n",
      "1025/1025 - 98s - loss: 0.1515 - accuracy: 0.9357 - auc: 0.9862 - val_loss: 1.4628 - val_accuracy: 0.8456 - val_auc: 0.7998\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.88779\n",
      "Epoch 95/100\n",
      "1025/1025 - 93s - loss: 0.1436 - accuracy: 0.9434 - auc: 0.9868 - val_loss: 1.2689 - val_accuracy: 0.8305 - val_auc: 0.7980\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.88779\n",
      "Epoch 96/100\n",
      "1025/1025 - 99s - loss: 0.1418 - accuracy: 0.9450 - auc: 0.9873 - val_loss: 1.3269 - val_accuracy: 0.8540 - val_auc: 0.8065\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.88779\n",
      "Epoch 97/100\n",
      "1025/1025 - 99s - loss: 0.1481 - accuracy: 0.9397 - auc: 0.9867 - val_loss: 1.1803 - val_accuracy: 0.8624 - val_auc: 0.8380\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.88779\n",
      "Epoch 98/100\n",
      "1025/1025 - 99s - loss: 0.1442 - accuracy: 0.9456 - auc: 0.9875 - val_loss: 1.0328 - val_accuracy: 0.8574 - val_auc: 0.8389\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.88779\n",
      "Epoch 99/100\n",
      "1025/1025 - 99s - loss: 0.1336 - accuracy: 0.9425 - auc: 0.9887 - val_loss: 0.9569 - val_accuracy: 0.8440 - val_auc: 0.8503\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.88779\n",
      "Epoch 100/100\n",
      "1025/1025 - 95s - loss: 0.1404 - accuracy: 0.9412 - auc: 0.9878 - val_loss: 1.5562 - val_accuracy: 0.8624 - val_auc: 0.7803\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.88779\n",
      "Epoch 1/100\n",
      "1075/1075 - 115s - loss: 0.7495 - accuracy: 0.7985 - auc: 0.7849 - val_loss: 0.5703 - val_accuracy: 0.9684 - val_auc: 0.5501\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.55013, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 2/100\n",
      "1075/1075 - 104s - loss: 0.5855 - accuracy: 0.9259 - auc: 0.8262 - val_loss: 0.5173 - val_accuracy: 0.9719 - val_auc: 0.6228\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.55013 to 0.62277, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 3/100\n",
      "1075/1075 - 104s - loss: 0.5247 - accuracy: 0.9398 - auc: 0.8333 - val_loss: 0.4958 - val_accuracy: 0.9789 - val_auc: 0.6903\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.62277 to 0.69029, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 4/100\n",
      "1075/1075 - 105s - loss: 0.4904 - accuracy: 0.9368 - auc: 0.8410 - val_loss: 0.4586 - val_accuracy: 0.9736 - val_auc: 0.7077\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.69029 to 0.70766, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 5/100\n",
      "1075/1075 - 102s - loss: 0.4481 - accuracy: 0.9410 - auc: 0.8538 - val_loss: 0.4606 - val_accuracy: 0.9807 - val_auc: 0.7129\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.70766 to 0.71290, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 6/100\n",
      "1075/1075 - 97s - loss: 0.4304 - accuracy: 0.9583 - auc: 0.8678 - val_loss: 0.4146 - val_accuracy: 0.9455 - val_auc: 0.7204\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.71290 to 0.72037, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 7/100\n",
      "1075/1075 - 101s - loss: 0.4638 - accuracy: 0.9131 - auc: 0.8604 - val_loss: 0.7388 - val_accuracy: 0.4218 - val_auc: 0.6547\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.72037\n",
      "Epoch 8/100\n",
      "1075/1075 - 100s - loss: 0.4098 - accuracy: 0.9347 - auc: 0.8845 - val_loss: 0.4119 - val_accuracy: 0.9666 - val_auc: 0.7327\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.72037 to 0.73273, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 9/100\n",
      "1075/1075 - 98s - loss: 0.3920 - accuracy: 0.9225 - auc: 0.8985 - val_loss: 0.4137 - val_accuracy: 0.9051 - val_auc: 0.7463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_auc improved from 0.73273 to 0.74632, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 10/100\n",
      "1075/1075 - 98s - loss: 0.3859 - accuracy: 0.9304 - auc: 0.8997 - val_loss: 0.4052 - val_accuracy: 0.9315 - val_auc: 0.7511\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.74632 to 0.75111, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 11/100\n",
      "1075/1075 - 92s - loss: 0.3735 - accuracy: 0.9183 - auc: 0.9088 - val_loss: 0.4261 - val_accuracy: 0.9613 - val_auc: 0.7512\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.75111 to 0.75123, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 12/100\n",
      "1075/1075 - 98s - loss: 0.3599 - accuracy: 0.9265 - auc: 0.9182 - val_loss: 0.4645 - val_accuracy: 0.9227 - val_auc: 0.7576\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.75123 to 0.75758, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 13/100\n",
      "1075/1075 - 101s - loss: 0.3726 - accuracy: 0.9197 - auc: 0.9141 - val_loss: 0.4070 - val_accuracy: 0.9420 - val_auc: 0.7432\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75758\n",
      "Epoch 14/100\n",
      "1075/1075 - 102s - loss: 0.3525 - accuracy: 0.9403 - auc: 0.9224 - val_loss: 0.4121 - val_accuracy: 0.9156 - val_auc: 0.7413\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.75758\n",
      "Epoch 15/100\n",
      "1075/1075 - 101s - loss: 0.3832 - accuracy: 0.9236 - auc: 0.9111 - val_loss: 0.4382 - val_accuracy: 0.9227 - val_auc: 0.7467\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75758\n",
      "Epoch 16/100\n",
      "1075/1075 - 97s - loss: 0.3647 - accuracy: 0.9146 - auc: 0.9238 - val_loss: 0.4098 - val_accuracy: 0.8699 - val_auc: 0.7369\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.75758\n",
      "Epoch 17/100\n",
      "1075/1075 - 100s - loss: 0.3294 - accuracy: 0.9208 - auc: 0.9372 - val_loss: 0.5167 - val_accuracy: 0.9209 - val_auc: 0.7306\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.75758\n",
      "Epoch 18/100\n",
      "1075/1075 - 102s - loss: 0.3005 - accuracy: 0.9419 - auc: 0.9472 - val_loss: 0.4963 - val_accuracy: 0.6643 - val_auc: 0.7443\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.75758\n",
      "Epoch 19/100\n",
      "1075/1075 - 102s - loss: 0.3342 - accuracy: 0.9244 - auc: 0.9368 - val_loss: 0.3995 - val_accuracy: 0.9561 - val_auc: 0.7738\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.75758 to 0.77384, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 20/100\n",
      "1075/1075 - 102s - loss: 0.3115 - accuracy: 0.9389 - auc: 0.9444 - val_loss: 0.3736 - val_accuracy: 0.9613 - val_auc: 0.8092\n",
      "\n",
      "Epoch 00020: val_auc improved from 0.77384 to 0.80916, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 21/100\n",
      "1075/1075 - 100s - loss: 0.3075 - accuracy: 0.9348 - auc: 0.9502 - val_loss: 0.4384 - val_accuracy: 0.9666 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.80916\n",
      "Epoch 22/100\n",
      "1075/1075 - 97s - loss: 0.3644 - accuracy: 0.9418 - auc: 0.9387 - val_loss: 0.4111 - val_accuracy: 0.9508 - val_auc: 0.7797\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.80916\n",
      "Epoch 23/100\n",
      "1075/1075 - 102s - loss: 0.2934 - accuracy: 0.9398 - auc: 0.9572 - val_loss: 0.3920 - val_accuracy: 0.9262 - val_auc: 0.7851\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.80916\n",
      "Epoch 24/100\n",
      "1075/1075 - 102s - loss: 0.2989 - accuracy: 0.9394 - auc: 0.9527 - val_loss: 0.4095 - val_accuracy: 0.9649 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.80916\n",
      "Epoch 25/100\n",
      "1075/1075 - 102s - loss: 0.2898 - accuracy: 0.9302 - auc: 0.9559 - val_loss: 0.3813 - val_accuracy: 0.9684 - val_auc: 0.8187\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.80916 to 0.81874, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 26/100\n",
      "1075/1075 - 105s - loss: 0.3027 - accuracy: 0.9462 - auc: 0.9501 - val_loss: 0.7091 - val_accuracy: 0.9701 - val_auc: 0.6596\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.81874\n",
      "Epoch 27/100\n",
      "1075/1075 - 98s - loss: 0.3381 - accuracy: 0.9383 - auc: 0.9415 - val_loss: 0.4533 - val_accuracy: 0.9279 - val_auc: 0.7625\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.81874\n",
      "Epoch 28/100\n",
      "1075/1075 - 108s - loss: 0.3119 - accuracy: 0.9411 - auc: 0.9520 - val_loss: 0.5346 - val_accuracy: 0.6485 - val_auc: 0.7689\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.81874\n",
      "Epoch 29/100\n",
      "1075/1075 - 110s - loss: 0.2687 - accuracy: 0.9439 - auc: 0.9653 - val_loss: 0.8400 - val_accuracy: 0.9684 - val_auc: 0.6225\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.81874\n",
      "Epoch 30/100\n",
      "1075/1075 - 100s - loss: 0.2580 - accuracy: 0.9566 - auc: 0.9657 - val_loss: 1.1243 - val_accuracy: 0.9789 - val_auc: 0.6502\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.81874\n",
      "Epoch 31/100\n",
      "1075/1075 - 102s - loss: 0.2808 - accuracy: 0.9429 - auc: 0.9624 - val_loss: 0.4573 - val_accuracy: 0.9666 - val_auc: 0.8182\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.81874\n",
      "Epoch 32/100\n",
      "1075/1075 - 100s - loss: 0.2696 - accuracy: 0.9379 - auc: 0.9702 - val_loss: 0.9447 - val_accuracy: 0.9613 - val_auc: 0.6748\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.81874\n",
      "Epoch 33/100\n",
      "1075/1075 - 103s - loss: 0.2773 - accuracy: 0.9429 - auc: 0.9646 - val_loss: 1.0072 - val_accuracy: 0.9754 - val_auc: 0.6757\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.81874\n",
      "Epoch 34/100\n",
      "1075/1075 - 104s - loss: 0.2971 - accuracy: 0.9412 - auc: 0.9592 - val_loss: 0.4911 - val_accuracy: 0.9561 - val_auc: 0.7440\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.81874\n",
      "Epoch 35/100\n",
      "1075/1075 - 98s - loss: 0.2320 - accuracy: 0.9588 - auc: 0.9756 - val_loss: 0.7122 - val_accuracy: 0.9613 - val_auc: 0.7570\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.81874\n",
      "Epoch 36/100\n",
      "1075/1075 - 99s - loss: 0.2531 - accuracy: 0.9542 - auc: 0.9726 - val_loss: 0.4288 - val_accuracy: 0.9420 - val_auc: 0.7805\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.81874\n",
      "Epoch 37/100\n",
      "1075/1075 - 98s - loss: 0.2028 - accuracy: 0.9609 - auc: 0.9818 - val_loss: 0.4649 - val_accuracy: 0.7821 - val_auc: 0.8199\n",
      "\n",
      "Epoch 00037: val_auc improved from 0.81874 to 0.81985, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 38/100\n",
      "1075/1075 - 92s - loss: 0.2326 - accuracy: 0.9545 - auc: 0.9729 - val_loss: 0.5210 - val_accuracy: 0.9649 - val_auc: 0.7219\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.81985\n",
      "Epoch 39/100\n",
      "1075/1075 - 99s - loss: 0.2382 - accuracy: 0.9485 - auc: 0.9718 - val_loss: 0.4073 - val_accuracy: 0.9508 - val_auc: 0.7895\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.81985\n",
      "Epoch 40/100\n",
      "1075/1075 - 105s - loss: 0.2494 - accuracy: 0.9547 - auc: 0.9716 - val_loss: 0.5440 - val_accuracy: 0.9525 - val_auc: 0.8008\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.81985\n",
      "Epoch 41/100\n",
      "1075/1075 - 105s - loss: 0.1956 - accuracy: 0.9656 - auc: 0.9819 - val_loss: 1.2047 - val_accuracy: 0.9596 - val_auc: 0.6237\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.81985\n",
      "Epoch 42/100\n",
      "1075/1075 - 104s - loss: 0.2278 - accuracy: 0.9521 - auc: 0.9752 - val_loss: 0.4386 - val_accuracy: 0.9473 - val_auc: 0.7695\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.81985\n",
      "Epoch 43/100\n",
      "1075/1075 - 99s - loss: 0.2278 - accuracy: 0.9580 - auc: 0.9750 - val_loss: 0.4346 - val_accuracy: 0.9613 - val_auc: 0.8202\n",
      "\n",
      "Epoch 00043: val_auc improved from 0.81985 to 0.82019, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 44/100\n",
      "1075/1075 - 104s - loss: 0.2447 - accuracy: 0.9639 - auc: 0.9737 - val_loss: 0.4219 - val_accuracy: 0.9613 - val_auc: 0.7518\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.82019\n",
      "Epoch 45/100\n",
      "1075/1075 - 104s - loss: 0.2483 - accuracy: 0.9558 - auc: 0.9751 - val_loss: 0.9852 - val_accuracy: 0.9490 - val_auc: 0.6430\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.82019\n",
      "Epoch 46/100\n",
      "1075/1075 - 101s - loss: 0.2792 - accuracy: 0.9599 - auc: 0.9675 - val_loss: 0.6373 - val_accuracy: 0.9490 - val_auc: 0.7196\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.82019\n",
      "Epoch 47/100\n",
      "1075/1075 - 98s - loss: 0.2365 - accuracy: 0.9629 - auc: 0.9791 - val_loss: 0.8382 - val_accuracy: 0.8699 - val_auc: 0.6943\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.82019\n",
      "Epoch 48/100\n",
      "1075/1075 - 96s - loss: 0.2503 - accuracy: 0.9625 - auc: 0.9746 - val_loss: 0.6028 - val_accuracy: 0.9244 - val_auc: 0.7445\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.82019\n",
      "Epoch 49/100\n",
      "1075/1075 - 94s - loss: 0.1935 - accuracy: 0.9606 - auc: 0.9847 - val_loss: 0.4246 - val_accuracy: 0.9649 - val_auc: 0.7694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: val_auc did not improve from 0.82019\n",
      "Epoch 50/100\n",
      "1075/1075 - 98s - loss: 0.2146 - accuracy: 0.9629 - auc: 0.9786 - val_loss: 0.4431 - val_accuracy: 0.9385 - val_auc: 0.7979\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.82019\n",
      "Epoch 51/100\n",
      "1075/1075 - 98s - loss: 0.2146 - accuracy: 0.9551 - auc: 0.9813 - val_loss: 0.5661 - val_accuracy: 0.9684 - val_auc: 0.8019\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.82019\n",
      "Epoch 52/100\n",
      "1075/1075 - 99s - loss: 0.1986 - accuracy: 0.9533 - auc: 0.9818 - val_loss: 0.4606 - val_accuracy: 0.7768 - val_auc: 0.7597\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.82019\n",
      "Epoch 53/100\n",
      "1075/1075 - 98s - loss: 0.1835 - accuracy: 0.9554 - auc: 0.9855 - val_loss: 0.5567 - val_accuracy: 0.9297 - val_auc: 0.8116\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.82019\n",
      "Epoch 54/100\n",
      "1075/1075 - 84s - loss: 0.1950 - accuracy: 0.9518 - auc: 0.9828 - val_loss: 0.5408 - val_accuracy: 0.8172 - val_auc: 0.7555\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.82019\n",
      "Epoch 55/100\n",
      "1075/1075 - 50s - loss: 0.1848 - accuracy: 0.9499 - auc: 0.9849 - val_loss: 0.5570 - val_accuracy: 0.5975 - val_auc: 0.7990\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.82019\n",
      "Epoch 56/100\n",
      "1075/1075 - 50s - loss: 0.1804 - accuracy: 0.9579 - auc: 0.9863 - val_loss: 0.5599 - val_accuracy: 0.9543 - val_auc: 0.8244\n",
      "\n",
      "Epoch 00056: val_auc improved from 0.82019 to 0.82442, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 57/100\n",
      "1075/1075 - 51s - loss: 0.1455 - accuracy: 0.9677 - auc: 0.9913 - val_loss: 0.9501 - val_accuracy: 0.8875 - val_auc: 0.6760\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.82442\n",
      "Epoch 58/100\n",
      "1075/1075 - 52s - loss: 0.1729 - accuracy: 0.9631 - auc: 0.9878 - val_loss: 0.4967 - val_accuracy: 0.9192 - val_auc: 0.7958\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.82442\n",
      "Epoch 59/100\n",
      "1075/1075 - 52s - loss: 0.1862 - accuracy: 0.9573 - auc: 0.9859 - val_loss: 0.6651 - val_accuracy: 0.9631 - val_auc: 0.8346\n",
      "\n",
      "Epoch 00059: val_auc improved from 0.82442 to 0.83456, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-AR-LBD\n",
      "Epoch 60/100\n",
      "1075/1075 - 52s - loss: 0.1532 - accuracy: 0.9652 - auc: 0.9909 - val_loss: 1.1985 - val_accuracy: 0.9649 - val_auc: 0.6473\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.83456\n",
      "Epoch 61/100\n",
      "1075/1075 - 52s - loss: 0.1494 - accuracy: 0.9682 - auc: 0.9910 - val_loss: 0.7531 - val_accuracy: 0.9069 - val_auc: 0.7359\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.83456\n",
      "Epoch 62/100\n",
      "1075/1075 - 52s - loss: 0.1264 - accuracy: 0.9625 - auc: 0.9929 - val_loss: 1.1340 - val_accuracy: 0.9455 - val_auc: 0.5814\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.83456\n",
      "Epoch 63/100\n",
      "1075/1075 - 52s - loss: 0.1558 - accuracy: 0.9623 - auc: 0.9901 - val_loss: 2.0309 - val_accuracy: 0.9701 - val_auc: 0.5216\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.83456\n",
      "Epoch 64/100\n",
      "1075/1075 - 52s - loss: 0.1358 - accuracy: 0.9631 - auc: 0.9917 - val_loss: 0.6391 - val_accuracy: 0.9262 - val_auc: 0.7904\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.83456\n",
      "Epoch 65/100\n",
      "1075/1075 - 52s - loss: 0.1451 - accuracy: 0.9695 - auc: 0.9906 - val_loss: 1.1989 - val_accuracy: 0.9613 - val_auc: 0.6795\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.83456\n",
      "Epoch 66/100\n",
      "1075/1075 - 52s - loss: 0.1145 - accuracy: 0.9721 - auc: 0.9938 - val_loss: 1.1090 - val_accuracy: 0.9420 - val_auc: 0.6654\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.83456\n",
      "Epoch 67/100\n",
      "1075/1075 - 52s - loss: 0.1524 - accuracy: 0.9629 - auc: 0.9888 - val_loss: 0.5526 - val_accuracy: 0.8981 - val_auc: 0.8072\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.83456\n",
      "Epoch 68/100\n",
      "1075/1075 - 52s - loss: 0.1439 - accuracy: 0.9681 - auc: 0.9921 - val_loss: 1.8799 - val_accuracy: 0.9578 - val_auc: 0.5130\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.83456\n",
      "Epoch 69/100\n",
      "1075/1075 - 52s - loss: 0.1303 - accuracy: 0.9651 - auc: 0.9925 - val_loss: 1.2003 - val_accuracy: 0.9402 - val_auc: 0.6882\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.83456\n",
      "Epoch 70/100\n",
      "1075/1075 - 52s - loss: 0.1130 - accuracy: 0.9665 - auc: 0.9938 - val_loss: 1.1939 - val_accuracy: 0.9227 - val_auc: 0.7030\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.83456\n",
      "Epoch 71/100\n",
      "1075/1075 - 52s - loss: 0.1552 - accuracy: 0.9550 - auc: 0.9897 - val_loss: 1.2666 - val_accuracy: 0.9543 - val_auc: 0.6130\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.83456\n",
      "Epoch 72/100\n",
      "1075/1075 - 52s - loss: 0.1056 - accuracy: 0.9722 - auc: 0.9952 - val_loss: 0.7986 - val_accuracy: 0.9016 - val_auc: 0.7478\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.83456\n",
      "Epoch 73/100\n",
      "1075/1075 - 52s - loss: 0.1691 - accuracy: 0.9671 - auc: 0.9898 - val_loss: 1.1190 - val_accuracy: 0.9297 - val_auc: 0.7395\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.83456\n",
      "Epoch 74/100\n",
      "1075/1075 - 52s - loss: 0.1450 - accuracy: 0.9687 - auc: 0.9920 - val_loss: 1.3201 - val_accuracy: 0.9402 - val_auc: 0.6827\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.83456\n",
      "Epoch 75/100\n",
      "1075/1075 - 52s - loss: 0.1286 - accuracy: 0.9713 - auc: 0.9934 - val_loss: 0.8294 - val_accuracy: 0.7381 - val_auc: 0.8129\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.83456\n",
      "Epoch 76/100\n",
      "1075/1075 - 52s - loss: 0.1292 - accuracy: 0.9659 - auc: 0.9927 - val_loss: 1.2767 - val_accuracy: 0.9525 - val_auc: 0.6767\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.83456\n",
      "Epoch 77/100\n",
      "1075/1075 - 52s - loss: 0.1136 - accuracy: 0.9703 - auc: 0.9945 - val_loss: 1.0395 - val_accuracy: 0.9543 - val_auc: 0.6749\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.83456\n",
      "Epoch 78/100\n",
      "1075/1075 - 52s - loss: 0.1138 - accuracy: 0.9707 - auc: 0.9917 - val_loss: 1.0491 - val_accuracy: 0.9402 - val_auc: 0.6865\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.83456\n",
      "Epoch 79/100\n",
      "1075/1075 - 52s - loss: 0.1026 - accuracy: 0.9750 - auc: 0.9951 - val_loss: 1.5712 - val_accuracy: 0.9684 - val_auc: 0.5752\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.83456\n",
      "Epoch 80/100\n",
      "1075/1075 - 52s - loss: 0.1740 - accuracy: 0.9638 - auc: 0.9876 - val_loss: 1.0444 - val_accuracy: 0.9315 - val_auc: 0.6975\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.83456\n",
      "Epoch 81/100\n",
      "1075/1075 - 52s - loss: 0.1314 - accuracy: 0.9670 - auc: 0.9909 - val_loss: 0.7056 - val_accuracy: 0.8858 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.83456\n",
      "Epoch 82/100\n",
      "1075/1075 - 52s - loss: 0.1509 - accuracy: 0.9687 - auc: 0.9905 - val_loss: 1.5463 - val_accuracy: 0.9631 - val_auc: 0.5653\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.83456\n",
      "Epoch 83/100\n",
      "1075/1075 - 52s - loss: 0.1442 - accuracy: 0.9689 - auc: 0.9926 - val_loss: 1.4617 - val_accuracy: 0.9666 - val_auc: 0.5579\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.83456\n",
      "Epoch 84/100\n",
      "1075/1075 - 52s - loss: 0.1224 - accuracy: 0.9737 - auc: 0.9933 - val_loss: 2.0740 - val_accuracy: 0.9613 - val_auc: 0.4456\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.83456\n",
      "Epoch 85/100\n",
      "1075/1075 - 52s - loss: 0.1034 - accuracy: 0.9782 - auc: 0.9939 - val_loss: 1.8295 - val_accuracy: 0.9596 - val_auc: 0.4988\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.83456\n",
      "Epoch 86/100\n",
      "1075/1075 - 52s - loss: 0.1625 - accuracy: 0.9677 - auc: 0.9894 - val_loss: 0.7024 - val_accuracy: 0.8190 - val_auc: 0.7618\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.83456\n",
      "Epoch 87/100\n",
      "1075/1075 - 51s - loss: 0.1255 - accuracy: 0.9703 - auc: 0.9930 - val_loss: 0.7063 - val_accuracy: 0.8541 - val_auc: 0.7755\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.83456\n",
      "Epoch 88/100\n",
      "1075/1075 - 51s - loss: 0.1053 - accuracy: 0.9697 - auc: 0.9950 - val_loss: 2.5211 - val_accuracy: 0.9701 - val_auc: 0.4635\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.83456\n",
      "Epoch 89/100\n",
      "1075/1075 - 52s - loss: 0.1203 - accuracy: 0.9759 - auc: 0.9939 - val_loss: 1.9636 - val_accuracy: 0.9754 - val_auc: 0.5360\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.83456\n",
      "Epoch 90/100\n",
      "1075/1075 - 52s - loss: 0.1134 - accuracy: 0.9694 - auc: 0.9949 - val_loss: 1.7832 - val_accuracy: 0.9543 - val_auc: 0.5152\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.83456\n",
      "Epoch 91/100\n",
      "1075/1075 - 52s - loss: 0.1339 - accuracy: 0.9729 - auc: 0.9920 - val_loss: 1.0818 - val_accuracy: 0.9332 - val_auc: 0.6593\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.83456\n",
      "Epoch 92/100\n",
      "1075/1075 - 52s - loss: 0.1128 - accuracy: 0.9739 - auc: 0.9954 - val_loss: 1.2560 - val_accuracy: 0.8910 - val_auc: 0.6420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00092: val_auc did not improve from 0.83456\n",
      "Epoch 93/100\n",
      "1075/1075 - 52s - loss: 0.1219 - accuracy: 0.9714 - auc: 0.9935 - val_loss: 1.6118 - val_accuracy: 0.9613 - val_auc: 0.5091\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.83456\n",
      "Epoch 94/100\n",
      "1075/1075 - 52s - loss: 0.1020 - accuracy: 0.9768 - auc: 0.9951 - val_loss: 2.0193 - val_accuracy: 0.9666 - val_auc: 0.5164\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.83456\n",
      "Epoch 95/100\n",
      "1075/1075 - 52s - loss: 0.1428 - accuracy: 0.9687 - auc: 0.9920 - val_loss: 1.0266 - val_accuracy: 0.9297 - val_auc: 0.6887\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.83456\n",
      "Epoch 96/100\n",
      "1075/1075 - 52s - loss: 0.1092 - accuracy: 0.9711 - auc: 0.9955 - val_loss: 2.0725 - val_accuracy: 0.9684 - val_auc: 0.4590\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.83456\n",
      "Epoch 97/100\n",
      "1075/1075 - 51s - loss: 0.1059 - accuracy: 0.9757 - auc: 0.9952 - val_loss: 1.9412 - val_accuracy: 0.9350 - val_auc: 0.5041\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.83456\n",
      "Epoch 98/100\n",
      "1075/1075 - 50s - loss: 0.1350 - accuracy: 0.9688 - auc: 0.9919 - val_loss: 0.8229 - val_accuracy: 0.9332 - val_auc: 0.7148\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.83456\n",
      "Epoch 99/100\n",
      "1075/1075 - 50s - loss: 0.0814 - accuracy: 0.9813 - auc: 0.9967 - val_loss: 0.8883 - val_accuracy: 0.8963 - val_auc: 0.7604\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.83456\n",
      "Epoch 100/100\n",
      "1075/1075 - 50s - loss: 0.1511 - accuracy: 0.9560 - auc: 0.9889 - val_loss: 1.0363 - val_accuracy: 0.9262 - val_auc: 0.6780\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.83456\n",
      "Epoch 1/100\n",
      "966/966 - 58s - loss: 0.8304 - accuracy: 0.6090 - auc: 0.6319 - val_loss: 0.7037 - val_accuracy: 0.8738 - val_auc: 0.7477\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.74768, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 2/100\n",
      "966/966 - 45s - loss: 0.7088 - accuracy: 0.7304 - auc: 0.7217 - val_loss: 0.6188 - val_accuracy: 0.8797 - val_auc: 0.7630\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.74768 to 0.76295, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 3/100\n",
      "966/966 - 45s - loss: 0.6420 - accuracy: 0.7755 - auc: 0.7425 - val_loss: 0.5581 - val_accuracy: 0.8540 - val_auc: 0.7709\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.76295 to 0.77085, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 4/100\n",
      "966/966 - 45s - loss: 0.5973 - accuracy: 0.8003 - auc: 0.7615 - val_loss: 0.5328 - val_accuracy: 0.8521 - val_auc: 0.7853\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.77085 to 0.78532, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 5/100\n",
      "966/966 - 45s - loss: 0.5804 - accuracy: 0.7976 - auc: 0.7676 - val_loss: 0.5237 - val_accuracy: 0.8679 - val_auc: 0.7827\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.78532\n",
      "Epoch 6/100\n",
      "966/966 - 45s - loss: 0.5626 - accuracy: 0.8100 - auc: 0.7749 - val_loss: 0.5492 - val_accuracy: 0.6391 - val_auc: 0.7909\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.78532 to 0.79088, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 7/100\n",
      "966/966 - 45s - loss: 0.5575 - accuracy: 0.8015 - auc: 0.7801 - val_loss: 0.5020 - val_accuracy: 0.8402 - val_auc: 0.7912\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.79088 to 0.79120, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 8/100\n",
      "966/966 - 45s - loss: 0.5483 - accuracy: 0.8134 - auc: 0.7867 - val_loss: 0.4959 - val_accuracy: 0.8323 - val_auc: 0.7981\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.79120 to 0.79805, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER\n",
      "Epoch 9/100\n",
      "966/966 - 45s - loss: 0.5434 - accuracy: 0.8204 - auc: 0.7885 - val_loss: 0.5154 - val_accuracy: 0.7732 - val_auc: 0.7872\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.79805\n",
      "Epoch 10/100\n",
      "966/966 - 46s - loss: 0.5421 - accuracy: 0.8310 - auc: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7870 - val_auc: 0.7884\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.79805\n",
      "Epoch 11/100\n",
      "966/966 - 45s - loss: 0.5432 - accuracy: 0.8236 - auc: 0.7934 - val_loss: 0.5185 - val_accuracy: 0.8639 - val_auc: 0.7833\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.79805\n",
      "Epoch 12/100\n",
      "966/966 - 45s - loss: 0.5305 - accuracy: 0.8389 - auc: 0.8040 - val_loss: 0.5020 - val_accuracy: 0.8600 - val_auc: 0.7806\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.79805\n",
      "Epoch 13/100\n",
      "966/966 - 46s - loss: 0.5343 - accuracy: 0.8346 - auc: 0.7966 - val_loss: 0.5090 - val_accuracy: 0.8560 - val_auc: 0.7845\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.79805\n",
      "Epoch 14/100\n",
      "966/966 - 45s - loss: 0.5257 - accuracy: 0.8434 - auc: 0.8066 - val_loss: 0.5150 - val_accuracy: 0.7771 - val_auc: 0.7803\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.79805\n",
      "Epoch 15/100\n",
      "966/966 - 45s - loss: 0.5206 - accuracy: 0.8337 - auc: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7870 - val_auc: 0.7782\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.79805\n",
      "Epoch 16/100\n",
      "966/966 - 45s - loss: 0.5148 - accuracy: 0.8360 - auc: 0.8182 - val_loss: 0.5161 - val_accuracy: 0.8166 - val_auc: 0.7725\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.79805\n",
      "Epoch 17/100\n",
      "966/966 - 45s - loss: 0.5121 - accuracy: 0.8425 - auc: 0.8183 - val_loss: 0.5229 - val_accuracy: 0.8757 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.79805\n",
      "Epoch 18/100\n",
      "966/966 - 45s - loss: 0.5043 - accuracy: 0.8452 - auc: 0.8245 - val_loss: 0.5207 - val_accuracy: 0.8540 - val_auc: 0.7589\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.79805\n",
      "Epoch 19/100\n",
      "966/966 - 45s - loss: 0.5046 - accuracy: 0.8367 - auc: 0.8257 - val_loss: 0.5328 - val_accuracy: 0.8718 - val_auc: 0.7656\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.79805\n",
      "Epoch 20/100\n",
      "966/966 - 45s - loss: 0.4982 - accuracy: 0.8501 - auc: 0.8295 - val_loss: 0.5259 - val_accuracy: 0.8126 - val_auc: 0.7724\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.79805\n",
      "Epoch 21/100\n",
      "966/966 - 45s - loss: 0.4953 - accuracy: 0.8447 - auc: 0.8339 - val_loss: 0.5336 - val_accuracy: 0.8876 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.79805\n",
      "Epoch 22/100\n",
      "966/966 - 45s - loss: 0.5017 - accuracy: 0.8419 - auc: 0.8313 - val_loss: 0.5292 - val_accuracy: 0.8166 - val_auc: 0.7665\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.79805\n",
      "Epoch 23/100\n",
      "966/966 - 45s - loss: 0.4916 - accuracy: 0.8415 - auc: 0.8386 - val_loss: 0.5350 - val_accuracy: 0.8540 - val_auc: 0.7655\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.79805\n",
      "Epoch 24/100\n",
      "966/966 - 45s - loss: 0.4869 - accuracy: 0.8387 - auc: 0.8445 - val_loss: 0.5155 - val_accuracy: 0.8284 - val_auc: 0.7670\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.79805\n",
      "Epoch 25/100\n",
      "966/966 - 45s - loss: 0.4874 - accuracy: 0.8438 - auc: 0.8417 - val_loss: 0.5155 - val_accuracy: 0.8067 - val_auc: 0.7744\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.79805\n",
      "Epoch 26/100\n",
      "966/966 - 45s - loss: 0.4754 - accuracy: 0.8356 - auc: 0.8532 - val_loss: 0.5319 - val_accuracy: 0.8146 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.79805\n",
      "Epoch 27/100\n",
      "966/966 - 45s - loss: 0.4715 - accuracy: 0.8544 - auc: 0.8518 - val_loss: 0.5255 - val_accuracy: 0.8462 - val_auc: 0.7685\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.79805\n",
      "Epoch 28/100\n",
      "966/966 - 45s - loss: 0.4754 - accuracy: 0.8492 - auc: 0.8541 - val_loss: 0.7188 - val_accuracy: 0.9132 - val_auc: 0.7422\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.79805\n",
      "Epoch 29/100\n",
      "966/966 - 45s - loss: 0.4723 - accuracy: 0.8481 - auc: 0.8550 - val_loss: 0.5210 - val_accuracy: 0.8619 - val_auc: 0.7462\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.79805\n",
      "Epoch 30/100\n",
      "966/966 - 45s - loss: 0.4546 - accuracy: 0.8417 - auc: 0.8694 - val_loss: 0.6108 - val_accuracy: 0.7929 - val_auc: 0.7265\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.79805\n",
      "Epoch 31/100\n",
      "966/966 - 45s - loss: 0.4532 - accuracy: 0.8494 - auc: 0.8708 - val_loss: 0.5306 - val_accuracy: 0.7278 - val_auc: 0.7819\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.79805\n",
      "Epoch 32/100\n",
      "966/966 - 45s - loss: 0.4454 - accuracy: 0.8499 - auc: 0.8748 - val_loss: 0.6085 - val_accuracy: 0.7850 - val_auc: 0.7658\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.79805\n",
      "Epoch 33/100\n",
      "966/966 - 45s - loss: 0.4509 - accuracy: 0.8397 - auc: 0.8735 - val_loss: 0.5846 - val_accuracy: 0.8185 - val_auc: 0.7326\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.79805\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966/966 - 45s - loss: 0.4458 - accuracy: 0.8380 - auc: 0.8737 - val_loss: 0.6105 - val_accuracy: 0.8994 - val_auc: 0.7708\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.79805\n",
      "Epoch 35/100\n",
      "966/966 - 45s - loss: 0.4418 - accuracy: 0.8591 - auc: 0.8781 - val_loss: 0.6056 - val_accuracy: 0.8738 - val_auc: 0.7639\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.79805\n",
      "Epoch 36/100\n",
      "966/966 - 45s - loss: 0.4396 - accuracy: 0.8447 - auc: 0.8805 - val_loss: 0.5357 - val_accuracy: 0.8757 - val_auc: 0.7519\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.79805\n",
      "Epoch 37/100\n",
      "966/966 - 45s - loss: 0.4319 - accuracy: 0.8588 - auc: 0.8862 - val_loss: 0.5976 - val_accuracy: 0.8521 - val_auc: 0.7511\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.79805\n",
      "Epoch 38/100\n",
      "966/966 - 45s - loss: 0.4309 - accuracy: 0.8431 - auc: 0.8879 - val_loss: 0.5748 - val_accuracy: 0.8422 - val_auc: 0.7647\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.79805\n",
      "Epoch 39/100\n",
      "966/966 - 45s - loss: 0.4265 - accuracy: 0.8464 - auc: 0.8902 - val_loss: 0.6164 - val_accuracy: 0.6667 - val_auc: 0.7592\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.79805\n",
      "Epoch 40/100\n",
      "966/966 - 45s - loss: 0.4251 - accuracy: 0.8463 - auc: 0.8906 - val_loss: 0.5978 - val_accuracy: 0.8442 - val_auc: 0.7575\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.79805\n",
      "Epoch 41/100\n",
      "966/966 - 45s - loss: 0.4173 - accuracy: 0.8438 - auc: 0.8936 - val_loss: 0.5976 - val_accuracy: 0.8738 - val_auc: 0.7671\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.79805\n",
      "Epoch 42/100\n",
      "966/966 - 45s - loss: 0.4044 - accuracy: 0.8521 - auc: 0.9015 - val_loss: 0.7017 - val_accuracy: 0.8679 - val_auc: 0.7279\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.79805\n",
      "Epoch 43/100\n",
      "966/966 - 45s - loss: 0.4106 - accuracy: 0.8466 - auc: 0.8987 - val_loss: 0.5814 - val_accuracy: 0.8442 - val_auc: 0.7607\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.79805\n",
      "Epoch 44/100\n",
      "966/966 - 45s - loss: 0.3983 - accuracy: 0.8433 - auc: 0.9048 - val_loss: 0.6837 - val_accuracy: 0.8185 - val_auc: 0.7519\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.79805\n",
      "Epoch 45/100\n",
      "966/966 - 45s - loss: 0.3988 - accuracy: 0.8495 - auc: 0.9055 - val_loss: 0.6687 - val_accuracy: 0.8856 - val_auc: 0.7431\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.79805\n",
      "Epoch 46/100\n",
      "966/966 - 45s - loss: 0.3941 - accuracy: 0.8466 - auc: 0.9094 - val_loss: 0.6427 - val_accuracy: 0.8067 - val_auc: 0.7739\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.79805\n",
      "Epoch 47/100\n",
      "966/966 - 45s - loss: 0.3995 - accuracy: 0.8553 - auc: 0.9043 - val_loss: 0.6533 - val_accuracy: 0.8225 - val_auc: 0.7753\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.79805\n",
      "Epoch 48/100\n",
      "966/966 - 45s - loss: 0.3815 - accuracy: 0.8562 - auc: 0.9142 - val_loss: 0.6865 - val_accuracy: 0.8245 - val_auc: 0.7649\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.79805\n",
      "Epoch 49/100\n",
      "966/966 - 45s - loss: 0.3900 - accuracy: 0.8487 - auc: 0.9108 - val_loss: 0.5691 - val_accuracy: 0.8679 - val_auc: 0.7600\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.79805\n",
      "Epoch 50/100\n",
      "966/966 - 45s - loss: 0.3825 - accuracy: 0.8475 - auc: 0.9146 - val_loss: 0.6283 - val_accuracy: 0.7199 - val_auc: 0.7475\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.79805\n",
      "Epoch 51/100\n",
      "966/966 - 45s - loss: 0.3723 - accuracy: 0.8521 - auc: 0.9185 - val_loss: 0.5900 - val_accuracy: 0.8284 - val_auc: 0.7498\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.79805\n",
      "Epoch 52/100\n",
      "966/966 - 45s - loss: 0.3674 - accuracy: 0.8574 - auc: 0.9219 - val_loss: 0.7145 - val_accuracy: 0.8560 - val_auc: 0.7477\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.79805\n",
      "Epoch 53/100\n",
      "966/966 - 45s - loss: 0.3610 - accuracy: 0.8605 - auc: 0.9247 - val_loss: 0.7006 - val_accuracy: 0.8659 - val_auc: 0.7425\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.79805\n",
      "Epoch 54/100\n",
      "966/966 - 45s - loss: 0.3572 - accuracy: 0.8416 - auc: 0.9254 - val_loss: 0.7946 - val_accuracy: 0.8797 - val_auc: 0.7594\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.79805\n",
      "Epoch 55/100\n",
      "966/966 - 44s - loss: 0.3595 - accuracy: 0.8519 - auc: 0.9256 - val_loss: 0.8298 - val_accuracy: 0.8442 - val_auc: 0.7737\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.79805\n",
      "Epoch 56/100\n",
      "966/966 - 45s - loss: 0.3716 - accuracy: 0.8399 - auc: 0.9187 - val_loss: 0.8372 - val_accuracy: 0.8107 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.79805\n",
      "Epoch 57/100\n",
      "966/966 - 45s - loss: 0.3572 - accuracy: 0.8530 - auc: 0.9264 - val_loss: 0.9220 - val_accuracy: 0.8304 - val_auc: 0.7274\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.79805\n",
      "Epoch 58/100\n",
      "966/966 - 45s - loss: 0.3527 - accuracy: 0.8510 - auc: 0.9279 - val_loss: 0.8921 - val_accuracy: 0.8600 - val_auc: 0.7426\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.79805\n",
      "Epoch 59/100\n",
      "966/966 - 45s - loss: 0.3578 - accuracy: 0.8459 - auc: 0.9252 - val_loss: 1.1023 - val_accuracy: 0.8560 - val_auc: 0.7334\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.79805\n",
      "Epoch 60/100\n",
      "966/966 - 45s - loss: 0.3427 - accuracy: 0.8433 - auc: 0.9318 - val_loss: 0.7316 - val_accuracy: 0.8205 - val_auc: 0.7885\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.79805\n",
      "Epoch 61/100\n",
      "966/966 - 45s - loss: 0.3491 - accuracy: 0.8566 - auc: 0.9321 - val_loss: 0.7579 - val_accuracy: 0.8067 - val_auc: 0.7631\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.79805\n",
      "Epoch 62/100\n",
      "966/966 - 45s - loss: 0.3360 - accuracy: 0.8429 - auc: 0.9349 - val_loss: 0.8137 - val_accuracy: 0.7219 - val_auc: 0.7496\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.79805\n",
      "Epoch 63/100\n",
      "966/966 - 45s - loss: 0.3327 - accuracy: 0.8466 - auc: 0.9358 - val_loss: 0.9024 - val_accuracy: 0.8067 - val_auc: 0.7507\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.79805\n",
      "Epoch 64/100\n",
      "966/966 - 45s - loss: 0.3220 - accuracy: 0.8517 - auc: 0.9414 - val_loss: 0.7695 - val_accuracy: 0.7929 - val_auc: 0.7657\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.79805\n",
      "Epoch 65/100\n",
      "966/966 - 45s - loss: 0.3229 - accuracy: 0.8386 - auc: 0.9397 - val_loss: 0.8782 - val_accuracy: 0.7535 - val_auc: 0.7492\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.79805\n",
      "Epoch 66/100\n",
      "966/966 - 45s - loss: 0.3230 - accuracy: 0.8534 - auc: 0.9406 - val_loss: 1.2758 - val_accuracy: 0.8501 - val_auc: 0.7192\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.79805\n",
      "Epoch 67/100\n",
      "966/966 - 45s - loss: 0.3152 - accuracy: 0.8503 - auc: 0.9430 - val_loss: 1.0414 - val_accuracy: 0.7396 - val_auc: 0.7014\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.79805\n",
      "Epoch 68/100\n",
      "966/966 - 45s - loss: 0.3013 - accuracy: 0.8397 - auc: 0.9467 - val_loss: 1.0025 - val_accuracy: 0.8679 - val_auc: 0.7543\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.79805\n",
      "Epoch 69/100\n",
      "966/966 - 45s - loss: 0.3233 - accuracy: 0.8579 - auc: 0.9403 - val_loss: 0.8658 - val_accuracy: 0.8067 - val_auc: 0.7612\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.79805\n",
      "Epoch 70/100\n",
      "966/966 - 45s - loss: 0.3173 - accuracy: 0.8497 - auc: 0.9422 - val_loss: 0.7310 - val_accuracy: 0.8245 - val_auc: 0.7770\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.79805\n",
      "Epoch 71/100\n",
      "966/966 - 45s - loss: 0.3107 - accuracy: 0.8532 - auc: 0.9452 - val_loss: 1.0185 - val_accuracy: 0.8284 - val_auc: 0.7334\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.79805\n",
      "Epoch 72/100\n",
      "966/966 - 45s - loss: 0.2985 - accuracy: 0.8529 - auc: 0.9492 - val_loss: 1.0918 - val_accuracy: 0.8343 - val_auc: 0.7249\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.79805\n",
      "Epoch 73/100\n",
      "966/966 - 45s - loss: 0.2980 - accuracy: 0.8554 - auc: 0.9492 - val_loss: 1.0614 - val_accuracy: 0.7732 - val_auc: 0.7299\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.79805\n",
      "Epoch 74/100\n",
      "966/966 - 45s - loss: 0.3019 - accuracy: 0.8545 - auc: 0.9483 - val_loss: 1.1934 - val_accuracy: 0.8343 - val_auc: 0.7369\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.79805\n",
      "Epoch 75/100\n",
      "966/966 - 45s - loss: 0.2986 - accuracy: 0.8606 - auc: 0.9505 - val_loss: 1.1004 - val_accuracy: 0.8600 - val_auc: 0.7288\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.79805\n",
      "Epoch 76/100\n",
      "966/966 - 45s - loss: 0.2802 - accuracy: 0.8657 - auc: 0.9551 - val_loss: 1.3941 - val_accuracy: 0.8580 - val_auc: 0.7383\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.79805\n",
      "Epoch 77/100\n",
      "966/966 - 45s - loss: 0.3062 - accuracy: 0.8390 - auc: 0.9460 - val_loss: 0.9795 - val_accuracy: 0.8462 - val_auc: 0.7284\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.79805\n",
      "Epoch 78/100\n",
      "966/966 - 45s - loss: 0.2832 - accuracy: 0.8661 - auc: 0.9541 - val_loss: 0.8193 - val_accuracy: 0.7850 - val_auc: 0.7376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: val_auc did not improve from 0.79805\n",
      "Epoch 79/100\n",
      "966/966 - 45s - loss: 0.2727 - accuracy: 0.8733 - auc: 0.9569 - val_loss: 1.4487 - val_accuracy: 0.8501 - val_auc: 0.7197\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.79805\n",
      "Epoch 80/100\n",
      "966/966 - 45s - loss: 0.2841 - accuracy: 0.8611 - auc: 0.9531 - val_loss: 1.4286 - val_accuracy: 0.8698 - val_auc: 0.7080\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.79805\n",
      "Epoch 81/100\n",
      "966/966 - 45s - loss: 0.2973 - accuracy: 0.8490 - auc: 0.9485 - val_loss: 1.3889 - val_accuracy: 0.8422 - val_auc: 0.7143\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.79805\n",
      "Epoch 82/100\n",
      "966/966 - 45s - loss: 0.2885 - accuracy: 0.8535 - auc: 0.9521 - val_loss: 1.0272 - val_accuracy: 0.7929 - val_auc: 0.7240\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.79805\n",
      "Epoch 83/100\n",
      "966/966 - 45s - loss: 0.2763 - accuracy: 0.8641 - auc: 0.9560 - val_loss: 1.2975 - val_accuracy: 0.8718 - val_auc: 0.7336\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.79805\n",
      "Epoch 84/100\n",
      "966/966 - 45s - loss: 0.2713 - accuracy: 0.8641 - auc: 0.9576 - val_loss: 1.2004 - val_accuracy: 0.7594 - val_auc: 0.7129\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.79805\n",
      "Epoch 85/100\n",
      "966/966 - 45s - loss: 0.2752 - accuracy: 0.8596 - auc: 0.9559 - val_loss: 1.1432 - val_accuracy: 0.8047 - val_auc: 0.7475\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.79805\n",
      "Epoch 86/100\n",
      "966/966 - 45s - loss: 0.2662 - accuracy: 0.8698 - auc: 0.9593 - val_loss: 1.0000 - val_accuracy: 0.7811 - val_auc: 0.7521\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.79805\n",
      "Epoch 87/100\n",
      "966/966 - 45s - loss: 0.2647 - accuracy: 0.8839 - auc: 0.9608 - val_loss: 1.2312 - val_accuracy: 0.8304 - val_auc: 0.7377\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.79805\n",
      "Epoch 88/100\n",
      "966/966 - 45s - loss: 0.2656 - accuracy: 0.8688 - auc: 0.9599 - val_loss: 0.8983 - val_accuracy: 0.8442 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.79805\n",
      "Epoch 89/100\n",
      "966/966 - 45s - loss: 0.2489 - accuracy: 0.8738 - auc: 0.9627 - val_loss: 1.5167 - val_accuracy: 0.7633 - val_auc: 0.7224\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.79805\n",
      "Epoch 90/100\n",
      "966/966 - 45s - loss: 0.2862 - accuracy: 0.8512 - auc: 0.9525 - val_loss: 1.4536 - val_accuracy: 0.8264 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.79805\n",
      "Epoch 91/100\n",
      "966/966 - 45s - loss: 0.2762 - accuracy: 0.8668 - auc: 0.9574 - val_loss: 1.1231 - val_accuracy: 0.8067 - val_auc: 0.7279\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.79805\n",
      "Epoch 92/100\n",
      "966/966 - 45s - loss: 0.2566 - accuracy: 0.8741 - auc: 0.9624 - val_loss: 0.9430 - val_accuracy: 0.7022 - val_auc: 0.7129\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.79805\n",
      "Epoch 93/100\n",
      "966/966 - 45s - loss: 0.2660 - accuracy: 0.8714 - auc: 0.9598 - val_loss: 1.1200 - val_accuracy: 0.8047 - val_auc: 0.7511\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.79805\n",
      "Epoch 94/100\n",
      "966/966 - 45s - loss: 0.2590 - accuracy: 0.8653 - auc: 0.9610 - val_loss: 1.4602 - val_accuracy: 0.8284 - val_auc: 0.7300\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.79805\n",
      "Epoch 95/100\n",
      "966/966 - 45s - loss: 0.2599 - accuracy: 0.8582 - auc: 0.9598 - val_loss: 1.2359 - val_accuracy: 0.7258 - val_auc: 0.7229\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.79805\n",
      "Epoch 96/100\n",
      "966/966 - 45s - loss: 0.2551 - accuracy: 0.8782 - auc: 0.9625 - val_loss: 0.9183 - val_accuracy: 0.8521 - val_auc: 0.7607\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.79805\n",
      "Epoch 97/100\n",
      "966/966 - 45s - loss: 0.2485 - accuracy: 0.8781 - auc: 0.9651 - val_loss: 1.0110 - val_accuracy: 0.7732 - val_auc: 0.7598\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.79805\n",
      "Epoch 98/100\n",
      "966/966 - 45s - loss: 0.2530 - accuracy: 0.8723 - auc: 0.9632 - val_loss: 1.3626 - val_accuracy: 0.8738 - val_auc: 0.7353\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.79805\n",
      "Epoch 99/100\n",
      "966/966 - 45s - loss: 0.2468 - accuracy: 0.8834 - auc: 0.9653 - val_loss: 1.2429 - val_accuracy: 0.8284 - val_auc: 0.7154\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.79805\n",
      "Epoch 100/100\n",
      "966/966 - 45s - loss: 0.2536 - accuracy: 0.8664 - auc: 0.9625 - val_loss: 1.5363 - val_accuracy: 0.8619 - val_auc: 0.7579\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.79805\n",
      "Epoch 1/100\n",
      "1095/1095 - 46s - loss: 0.8438 - accuracy: 0.5493 - auc: 0.6248 - val_loss: 0.6918 - val_accuracy: 0.6763 - val_auc: 0.7336\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.73355, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 2/100\n",
      "1095/1095 - 39s - loss: 0.6789 - accuracy: 0.7382 - auc: 0.7686 - val_loss: 0.5920 - val_accuracy: 0.7342 - val_auc: 0.7423\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.73355 to 0.74233, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 3/100\n",
      "1095/1095 - 39s - loss: 0.5901 - accuracy: 0.8158 - auc: 0.8029 - val_loss: 0.5291 - val_accuracy: 0.9319 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.74233 to 0.75128, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 4/100\n",
      "1095/1095 - 39s - loss: 0.5816 - accuracy: 0.8252 - auc: 0.7947 - val_loss: 0.5527 - val_accuracy: 0.6797 - val_auc: 0.7721\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.75128 to 0.77209, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 5/100\n",
      "1095/1095 - 39s - loss: 0.5359 - accuracy: 0.8429 - auc: 0.8130 - val_loss: 0.5735 - val_accuracy: 0.6763 - val_auc: 0.7772\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.77209 to 0.77720, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 6/100\n",
      "1095/1095 - 38s - loss: 0.4899 - accuracy: 0.8680 - auc: 0.8443 - val_loss: 0.4957 - val_accuracy: 0.8382 - val_auc: 0.7778\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.77720 to 0.77778, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 7/100\n",
      "1095/1095 - 39s - loss: 0.4695 - accuracy: 0.8604 - auc: 0.8564 - val_loss: 0.4949 - val_accuracy: 0.8859 - val_auc: 0.7603\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.77778\n",
      "Epoch 8/100\n",
      "1095/1095 - 38s - loss: 0.4698 - accuracy: 0.8718 - auc: 0.8595 - val_loss: 0.5107 - val_accuracy: 0.8330 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77778\n",
      "Epoch 9/100\n",
      "1095/1095 - 38s - loss: 0.4455 - accuracy: 0.8658 - auc: 0.8710 - val_loss: 0.5441 - val_accuracy: 0.9131 - val_auc: 0.7338\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.77778\n",
      "Epoch 10/100\n",
      "1095/1095 - 39s - loss: 0.4899 - accuracy: 0.8405 - auc: 0.8530 - val_loss: 0.5112 - val_accuracy: 0.8722 - val_auc: 0.7510\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.77778\n",
      "Epoch 11/100\n",
      "1095/1095 - 38s - loss: 0.4988 - accuracy: 0.8610 - auc: 0.8667 - val_loss: 0.5693 - val_accuracy: 0.8995 - val_auc: 0.7656\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77778\n",
      "Epoch 12/100\n",
      "1095/1095 - 39s - loss: 0.4571 - accuracy: 0.8653 - auc: 0.8800 - val_loss: 0.5597 - val_accuracy: 0.8842 - val_auc: 0.7467\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.77778\n",
      "Epoch 13/100\n",
      "1095/1095 - 39s - loss: 0.4340 - accuracy: 0.8611 - auc: 0.8851 - val_loss: 0.6146 - val_accuracy: 0.8756 - val_auc: 0.7471\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77778\n",
      "Epoch 14/100\n",
      "1095/1095 - 39s - loss: 0.4322 - accuracy: 0.8775 - auc: 0.8922 - val_loss: 0.5545 - val_accuracy: 0.6899 - val_auc: 0.7669\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.77778\n",
      "Epoch 15/100\n",
      "1095/1095 - 38s - loss: 0.4299 - accuracy: 0.8621 - auc: 0.8900 - val_loss: 0.5262 - val_accuracy: 0.9029 - val_auc: 0.7534\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77778\n",
      "Epoch 16/100\n",
      "1095/1095 - 39s - loss: 0.4191 - accuracy: 0.8652 - auc: 0.8961 - val_loss: 0.5726 - val_accuracy: 0.7751 - val_auc: 0.7707\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77778\n",
      "Epoch 17/100\n",
      "1095/1095 - 39s - loss: 0.4086 - accuracy: 0.8678 - auc: 0.9006 - val_loss: 0.6826 - val_accuracy: 0.9267 - val_auc: 0.7221\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77778\n",
      "Epoch 18/100\n",
      "1095/1095 - 39s - loss: 0.3994 - accuracy: 0.8841 - auc: 0.9076 - val_loss: 0.5863 - val_accuracy: 0.6763 - val_auc: 0.7630\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.77778\n",
      "Epoch 19/100\n",
      "1095/1095 - 39s - loss: 0.4218 - accuracy: 0.8666 - auc: 0.9007 - val_loss: 0.5146 - val_accuracy: 0.8671 - val_auc: 0.7351\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.77778\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 - 39s - loss: 0.3864 - accuracy: 0.8799 - auc: 0.9130 - val_loss: 0.6899 - val_accuracy: 0.9131 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.77778\n",
      "Epoch 21/100\n",
      "1095/1095 - 39s - loss: 0.3845 - accuracy: 0.8686 - auc: 0.9155 - val_loss: 0.5760 - val_accuracy: 0.7428 - val_auc: 0.7780\n",
      "\n",
      "Epoch 00021: val_auc improved from 0.77778 to 0.77804, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 22/100\n",
      "1095/1095 - 39s - loss: 0.3665 - accuracy: 0.8803 - auc: 0.9254 - val_loss: 0.5389 - val_accuracy: 0.8978 - val_auc: 0.7319\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.77804\n",
      "Epoch 23/100\n",
      "1095/1095 - 39s - loss: 0.3860 - accuracy: 0.8719 - auc: 0.9166 - val_loss: 0.5108 - val_accuracy: 0.7445 - val_auc: 0.7562\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.77804\n",
      "Epoch 24/100\n",
      "1095/1095 - 39s - loss: 0.3585 - accuracy: 0.8901 - auc: 0.9283 - val_loss: 0.6976 - val_accuracy: 0.9387 - val_auc: 0.7622\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.77804\n",
      "Epoch 25/100\n",
      "1095/1095 - 38s - loss: 0.3875 - accuracy: 0.8618 - auc: 0.9212 - val_loss: 0.6341 - val_accuracy: 0.8262 - val_auc: 0.7905\n",
      "\n",
      "Epoch 00025: val_auc improved from 0.77804 to 0.79052, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 26/100\n",
      "1095/1095 - 38s - loss: 0.3860 - accuracy: 0.8766 - auc: 0.9252 - val_loss: 0.5991 - val_accuracy: 0.8705 - val_auc: 0.7041\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.79052\n",
      "Epoch 27/100\n",
      "1095/1095 - 38s - loss: 0.3461 - accuracy: 0.8763 - auc: 0.9382 - val_loss: 0.7887 - val_accuracy: 0.9250 - val_auc: 0.7718\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.79052\n",
      "Epoch 28/100\n",
      "1095/1095 - 38s - loss: 0.3388 - accuracy: 0.8809 - auc: 0.9387 - val_loss: 0.6360 - val_accuracy: 0.8790 - val_auc: 0.7411\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.79052\n",
      "Epoch 29/100\n",
      "1095/1095 - 39s - loss: 0.3400 - accuracy: 0.8930 - auc: 0.9377 - val_loss: 0.5814 - val_accuracy: 0.5213 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.79052\n",
      "Epoch 30/100\n",
      "1095/1095 - 39s - loss: 0.3170 - accuracy: 0.8753 - auc: 0.9463 - val_loss: 0.6442 - val_accuracy: 0.7666 - val_auc: 0.7536\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.79052\n",
      "Epoch 31/100\n",
      "1095/1095 - 39s - loss: 0.3203 - accuracy: 0.8812 - auc: 0.9461 - val_loss: 0.7641 - val_accuracy: 0.8245 - val_auc: 0.7738\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.79052\n",
      "Epoch 32/100\n",
      "1095/1095 - 39s - loss: 0.3413 - accuracy: 0.8780 - auc: 0.9400 - val_loss: 0.5869 - val_accuracy: 0.6695 - val_auc: 0.7171\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.79052\n",
      "Epoch 33/100\n",
      "1095/1095 - 38s - loss: 0.2916 - accuracy: 0.8816 - auc: 0.9563 - val_loss: 1.0552 - val_accuracy: 0.9046 - val_auc: 0.7049\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.79052\n",
      "Epoch 34/100\n",
      "1095/1095 - 39s - loss: 0.3031 - accuracy: 0.8618 - auc: 0.9514 - val_loss: 1.3561 - val_accuracy: 0.9302 - val_auc: 0.6959\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.79052\n",
      "Epoch 35/100\n",
      "1095/1095 - 39s - loss: 0.2938 - accuracy: 0.8828 - auc: 0.9561 - val_loss: 1.3053 - val_accuracy: 0.9182 - val_auc: 0.7072\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.79052\n",
      "Epoch 36/100\n",
      "1095/1095 - 39s - loss: 0.2883 - accuracy: 0.8852 - auc: 0.9572 - val_loss: 0.6200 - val_accuracy: 0.8586 - val_auc: 0.7968\n",
      "\n",
      "Epoch 00036: val_auc improved from 0.79052 to 0.79683, saving model to 210126_TrainingLocalitySensitivewFW\\210126_LSwFW_NR-ER-LBD\n",
      "Epoch 37/100\n",
      "1095/1095 - 38s - loss: 0.2715 - accuracy: 0.8963 - auc: 0.9618 - val_loss: 0.9578 - val_accuracy: 0.8467 - val_auc: 0.7495\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.79683\n",
      "Epoch 38/100\n",
      "1095/1095 - 39s - loss: 0.2853 - accuracy: 0.8804 - auc: 0.9576 - val_loss: 0.7590 - val_accuracy: 0.9097 - val_auc: 0.7638\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.79683\n",
      "Epoch 39/100\n",
      "1095/1095 - 39s - loss: 0.2724 - accuracy: 0.8975 - auc: 0.9620 - val_loss: 0.6977 - val_accuracy: 0.7394 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.79683\n",
      "Epoch 40/100\n",
      "1095/1095 - 39s - loss: 0.2747 - accuracy: 0.8896 - auc: 0.9618 - val_loss: 0.6276 - val_accuracy: 0.8637 - val_auc: 0.7571\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.79683\n",
      "Epoch 41/100\n",
      "1095/1095 - 39s - loss: 0.2510 - accuracy: 0.8991 - auc: 0.9670 - val_loss: 1.4268 - val_accuracy: 0.9250 - val_auc: 0.7073\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.79683\n",
      "Epoch 42/100\n",
      "1095/1095 - 39s - loss: 0.2604 - accuracy: 0.9071 - auc: 0.9647 - val_loss: 0.9625 - val_accuracy: 0.9148 - val_auc: 0.7284\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.79683\n",
      "Epoch 43/100\n",
      "1095/1095 - 39s - loss: 0.2518 - accuracy: 0.9000 - auc: 0.9678 - val_loss: 0.8057 - val_accuracy: 0.7734 - val_auc: 0.7652\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.79683\n",
      "Epoch 44/100\n",
      "1095/1095 - 38s - loss: 0.2512 - accuracy: 0.8955 - auc: 0.9682 - val_loss: 0.9560 - val_accuracy: 0.8569 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.79683\n",
      "Epoch 45/100\n",
      "1095/1095 - 39s - loss: 0.2411 - accuracy: 0.9025 - auc: 0.9705 - val_loss: 0.9520 - val_accuracy: 0.8024 - val_auc: 0.7293\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.79683\n",
      "Epoch 46/100\n",
      "1095/1095 - 39s - loss: 0.2492 - accuracy: 0.9037 - auc: 0.9700 - val_loss: 1.1767 - val_accuracy: 0.8552 - val_auc: 0.7224\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.79683\n",
      "Epoch 47/100\n",
      "1095/1095 - 39s - loss: 0.2494 - accuracy: 0.8917 - auc: 0.9696 - val_loss: 1.2218 - val_accuracy: 0.8637 - val_auc: 0.7287\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.79683\n",
      "Epoch 48/100\n",
      "1095/1095 - 39s - loss: 0.2616 - accuracy: 0.8929 - auc: 0.9666 - val_loss: 1.1612 - val_accuracy: 0.8944 - val_auc: 0.7391\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.79683\n",
      "Epoch 49/100\n",
      "1095/1095 - 38s - loss: 0.2108 - accuracy: 0.8992 - auc: 0.9762 - val_loss: 1.0761 - val_accuracy: 0.7700 - val_auc: 0.7029\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.79683\n",
      "Epoch 50/100\n",
      "1095/1095 - 39s - loss: 0.2486 - accuracy: 0.8735 - auc: 0.9673 - val_loss: 1.8047 - val_accuracy: 0.9216 - val_auc: 0.6176\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.79683\n",
      "Epoch 51/100\n",
      "1095/1095 - 39s - loss: 0.2119 - accuracy: 0.8975 - auc: 0.9762 - val_loss: 1.2834 - val_accuracy: 0.8518 - val_auc: 0.7259\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.79683\n",
      "Epoch 52/100\n",
      "1095/1095 - 39s - loss: 0.2116 - accuracy: 0.9037 - auc: 0.9769 - val_loss: 1.7294 - val_accuracy: 0.8876 - val_auc: 0.6653\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.79683\n",
      "Epoch 53/100\n",
      "1095/1095 - 39s - loss: 0.2062 - accuracy: 0.9086 - auc: 0.9783 - val_loss: 0.9335 - val_accuracy: 0.8109 - val_auc: 0.7034\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.79683\n",
      "Epoch 54/100\n",
      "1095/1095 - 39s - loss: 0.2286 - accuracy: 0.8977 - auc: 0.9730 - val_loss: 1.5933 - val_accuracy: 0.9114 - val_auc: 0.6799\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.79683\n",
      "Epoch 55/100\n",
      "1095/1095 - 39s - loss: 0.2159 - accuracy: 0.9041 - auc: 0.9760 - val_loss: 1.6626 - val_accuracy: 0.9148 - val_auc: 0.6374\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.79683\n",
      "Epoch 56/100\n",
      "1095/1095 - 39s - loss: 0.2070 - accuracy: 0.9130 - auc: 0.9785 - val_loss: 2.1038 - val_accuracy: 0.9233 - val_auc: 0.6515\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.79683\n",
      "Epoch 57/100\n",
      "1095/1095 - 39s - loss: 0.2089 - accuracy: 0.9003 - auc: 0.9772 - val_loss: 1.3889 - val_accuracy: 0.8790 - val_auc: 0.7588\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.79683\n",
      "Epoch 58/100\n",
      "1095/1095 - 39s - loss: 0.2013 - accuracy: 0.9065 - auc: 0.9789 - val_loss: 1.5127 - val_accuracy: 0.8927 - val_auc: 0.6586\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.79683\n",
      "Epoch 59/100\n",
      "1095/1095 - 39s - loss: 0.2030 - accuracy: 0.9016 - auc: 0.9784 - val_loss: 1.4682 - val_accuracy: 0.8978 - val_auc: 0.7063\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.79683\n",
      "Epoch 60/100\n",
      "1095/1095 - 38s - loss: 0.2203 - accuracy: 0.8984 - auc: 0.9741 - val_loss: 1.5251 - val_accuracy: 0.9046 - val_auc: 0.7114\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.79683\n",
      "Epoch 61/100\n",
      "1095/1095 - 39s - loss: 0.2044 - accuracy: 0.9026 - auc: 0.9783 - val_loss: 1.1278 - val_accuracy: 0.8671 - val_auc: 0.7432\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.79683\n",
      "Epoch 62/100\n",
      "1095/1095 - 39s - loss: 0.2356 - accuracy: 0.9218 - auc: 0.9733 - val_loss: 1.2054 - val_accuracy: 0.9063 - val_auc: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00062: val_auc did not improve from 0.79683\n",
      "Epoch 63/100\n",
      "1095/1095 - 39s - loss: 0.1987 - accuracy: 0.9113 - auc: 0.9800 - val_loss: 1.5503 - val_accuracy: 0.8671 - val_auc: 0.6580\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.79683\n",
      "Epoch 64/100\n",
      "1095/1095 - 38s - loss: 0.2312 - accuracy: 0.8985 - auc: 0.9740 - val_loss: 1.9445 - val_accuracy: 0.9148 - val_auc: 0.6650\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.79683\n",
      "Epoch 65/100\n",
      "1095/1095 - 38s - loss: 0.2271 - accuracy: 0.8969 - auc: 0.9745 - val_loss: 2.0082 - val_accuracy: 0.9029 - val_auc: 0.6608\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.79683\n",
      "Epoch 66/100\n",
      "1095/1095 - 38s - loss: 0.1738 - accuracy: 0.9212 - auc: 0.9840 - val_loss: 1.2462 - val_accuracy: 0.8109 - val_auc: 0.7423\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.79683\n",
      "Epoch 67/100\n",
      "1095/1095 - 38s - loss: 0.1664 - accuracy: 0.9244 - auc: 0.9835 - val_loss: 1.1031 - val_accuracy: 0.8041 - val_auc: 0.7307\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.79683\n",
      "Epoch 68/100\n",
      "1095/1095 - 38s - loss: 0.1965 - accuracy: 0.9232 - auc: 0.9802 - val_loss: 1.0288 - val_accuracy: 0.8262 - val_auc: 0.7501\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.79683\n",
      "Epoch 69/100\n",
      "1095/1095 - 39s - loss: 0.1888 - accuracy: 0.9169 - auc: 0.9807 - val_loss: 1.3191 - val_accuracy: 0.8569 - val_auc: 0.6737\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.79683\n",
      "Epoch 70/100\n",
      "1095/1095 - 38s - loss: 0.1705 - accuracy: 0.9213 - auc: 0.9838 - val_loss: 2.0706 - val_accuracy: 0.8961 - val_auc: 0.6841\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.79683\n",
      "Epoch 71/100\n",
      "1095/1095 - 38s - loss: 0.1786 - accuracy: 0.9162 - auc: 0.9815 - val_loss: 2.1791 - val_accuracy: 0.9267 - val_auc: 0.6817\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.79683\n",
      "Epoch 72/100\n",
      "1095/1095 - 39s - loss: 0.1823 - accuracy: 0.9201 - auc: 0.9811 - val_loss: 1.8889 - val_accuracy: 0.9199 - val_auc: 0.6821\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.79683\n",
      "Epoch 73/100\n",
      "1095/1095 - 39s - loss: 0.2279 - accuracy: 0.9112 - auc: 0.9749 - val_loss: 1.4628 - val_accuracy: 0.9284 - val_auc: 0.6933\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.79683\n",
      "Epoch 74/100\n",
      "1095/1095 - 38s - loss: 0.1750 - accuracy: 0.9305 - auc: 0.9854 - val_loss: 1.8174 - val_accuracy: 0.8944 - val_auc: 0.7415\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.79683\n",
      "Epoch 75/100\n",
      "1095/1095 - 39s - loss: 0.1842 - accuracy: 0.9087 - auc: 0.9810 - val_loss: 1.9869 - val_accuracy: 0.9148 - val_auc: 0.7260\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.79683\n",
      "Epoch 76/100\n",
      "1095/1095 - 38s - loss: 0.2047 - accuracy: 0.9224 - auc: 0.9792 - val_loss: 1.6085 - val_accuracy: 0.9182 - val_auc: 0.7098\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.79683\n",
      "Epoch 77/100\n",
      "1095/1095 - 39s - loss: 0.1926 - accuracy: 0.9232 - auc: 0.9812 - val_loss: 0.7134 - val_accuracy: 0.7973 - val_auc: 0.7575\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.79683\n",
      "Epoch 78/100\n",
      "1095/1095 - 39s - loss: 0.1779 - accuracy: 0.9265 - auc: 0.9847 - val_loss: 2.0503 - val_accuracy: 0.9472 - val_auc: 0.6912\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.79683\n",
      "Epoch 79/100\n",
      "1095/1095 - 39s - loss: 0.1756 - accuracy: 0.9299 - auc: 0.9828 - val_loss: 1.7088 - val_accuracy: 0.9131 - val_auc: 0.6975\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.79683\n",
      "Epoch 80/100\n",
      "1095/1095 - 38s - loss: 0.1858 - accuracy: 0.9233 - auc: 0.9818 - val_loss: 0.8898 - val_accuracy: 0.8859 - val_auc: 0.7762\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.79683\n",
      "Epoch 81/100\n",
      "1095/1095 - 38s - loss: 0.1640 - accuracy: 0.9325 - auc: 0.9863 - val_loss: 2.6404 - val_accuracy: 0.9131 - val_auc: 0.6636\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.79683\n",
      "Epoch 82/100\n",
      "1095/1095 - 38s - loss: 0.1748 - accuracy: 0.9204 - auc: 0.9833 - val_loss: 1.4090 - val_accuracy: 0.9114 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.79683\n",
      "Epoch 83/100\n",
      "1095/1095 - 39s - loss: 0.1695 - accuracy: 0.9311 - auc: 0.9851 - val_loss: 1.5409 - val_accuracy: 0.9012 - val_auc: 0.6844\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.79683\n",
      "Epoch 84/100\n",
      "1095/1095 - 38s - loss: 0.1741 - accuracy: 0.9217 - auc: 0.9838 - val_loss: 2.3395 - val_accuracy: 0.9165 - val_auc: 0.6838\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.79683\n",
      "Epoch 85/100\n",
      "1095/1095 - 39s - loss: 0.2145 - accuracy: 0.9127 - auc: 0.9764 - val_loss: 0.8388 - val_accuracy: 0.7342 - val_auc: 0.7470\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.79683\n",
      "Epoch 86/100\n",
      "1095/1095 - 39s - loss: 0.1896 - accuracy: 0.9235 - auc: 0.9838 - val_loss: 1.8446 - val_accuracy: 0.8620 - val_auc: 0.6982\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.79683\n",
      "Epoch 87/100\n",
      "1095/1095 - 38s - loss: 0.1666 - accuracy: 0.9295 - auc: 0.9856 - val_loss: 2.1627 - val_accuracy: 0.9540 - val_auc: 0.6904\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.79683\n",
      "Epoch 88/100\n",
      "1095/1095 - 38s - loss: 0.1559 - accuracy: 0.9393 - auc: 0.9871 - val_loss: 1.5336 - val_accuracy: 0.9046 - val_auc: 0.5932\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.79683\n",
      "Epoch 89/100\n",
      "1095/1095 - 38s - loss: 0.1842 - accuracy: 0.9295 - auc: 0.9846 - val_loss: 0.9039 - val_accuracy: 0.8382 - val_auc: 0.7139\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.79683\n",
      "Epoch 90/100\n",
      "1095/1095 - 39s - loss: 0.1737 - accuracy: 0.9337 - auc: 0.9852 - val_loss: 2.0319 - val_accuracy: 0.9250 - val_auc: 0.6931\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.79683\n",
      "Epoch 91/100\n",
      "1095/1095 - 38s - loss: 0.1735 - accuracy: 0.9323 - auc: 0.9840 - val_loss: 2.1656 - val_accuracy: 0.9267 - val_auc: 0.6933\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.79683\n",
      "Epoch 92/100\n",
      "1095/1095 - 39s - loss: 0.1540 - accuracy: 0.9458 - auc: 0.9867 - val_loss: 1.9496 - val_accuracy: 0.9489 - val_auc: 0.6725\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.79683\n",
      "Epoch 93/100\n",
      "1095/1095 - 39s - loss: 0.1967 - accuracy: 0.9354 - auc: 0.9818 - val_loss: 2.0886 - val_accuracy: 0.9302 - val_auc: 0.6790\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.79683\n",
      "Epoch 94/100\n",
      "1095/1095 - 38s - loss: 0.1553 - accuracy: 0.9313 - auc: 0.9868 - val_loss: 2.2918 - val_accuracy: 0.9387 - val_auc: 0.6771\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.79683\n",
      "Epoch 95/100\n",
      "1095/1095 - 38s - loss: 0.1755 - accuracy: 0.9243 - auc: 0.9834 - val_loss: 2.2754 - val_accuracy: 0.9438 - val_auc: 0.6742\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.79683\n",
      "Epoch 96/100\n",
      "1095/1095 - 39s - loss: 0.1546 - accuracy: 0.9372 - auc: 0.9867 - val_loss: 1.0345 - val_accuracy: 0.8586 - val_auc: 0.7866\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.79683\n",
      "Epoch 97/100\n",
      "1095/1095 - 39s - loss: 0.1551 - accuracy: 0.9364 - auc: 0.9867 - val_loss: 2.8204 - val_accuracy: 0.9608 - val_auc: 0.6889\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.79683\n",
      "Epoch 98/100\n",
      "1095/1095 - 39s - loss: 0.1991 - accuracy: 0.9189 - auc: 0.9813 - val_loss: 2.2985 - val_accuracy: 0.9131 - val_auc: 0.7142\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.79683\n",
      "Epoch 99/100\n",
      "1095/1095 - 38s - loss: 0.1580 - accuracy: 0.9356 - auc: 0.9859 - val_loss: 2.1141 - val_accuracy: 0.9182 - val_auc: 0.7241\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.79683\n",
      "Epoch 100/100\n",
      "1095/1095 - 38s - loss: 0.1522 - accuracy: 0.9353 - auc: 0.9870 - val_loss: 2.2047 - val_accuracy: 0.9182 - val_auc: 0.6899\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.79683\n",
      "Epoch 1/100\n",
      "902/902 - 52s - loss: 0.8082 - accuracy: 0.6202 - auc: 0.7082 - val_loss: 0.9044 - val_accuracy: 0.7253 - val_auc: 0.7721\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.77213, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 2/100\n",
      "902/902 - 42s - loss: 0.6885 - accuracy: 0.6799 - auc: 0.7833 - val_loss: 0.7804 - val_accuracy: 0.6383 - val_auc: 0.7800\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.77213 to 0.77995, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 3/100\n",
      "902/902 - 42s - loss: 0.6007 - accuracy: 0.7052 - auc: 0.8223 - val_loss: 0.9110 - val_accuracy: 0.8066 - val_auc: 0.7812\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.77995 to 0.78122, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 4/100\n",
      "902/902 - 42s - loss: 0.5529 - accuracy: 0.7479 - auc: 0.8370 - val_loss: 0.7100 - val_accuracy: 0.6170 - val_auc: 0.7862\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.78122 to 0.78623, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 - 42s - loss: 0.5321 - accuracy: 0.7304 - auc: 0.8393 - val_loss: 0.7336 - val_accuracy: 0.6750 - val_auc: 0.7914\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.78623 to 0.79141, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 6/100\n",
      "902/902 - 42s - loss: 0.5223 - accuracy: 0.7691 - auc: 0.8486 - val_loss: 0.7367 - val_accuracy: 0.7137 - val_auc: 0.7862\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.79141\n",
      "Epoch 7/100\n",
      "902/902 - 42s - loss: 0.4989 - accuracy: 0.7506 - auc: 0.8528 - val_loss: 0.7067 - val_accuracy: 0.6615 - val_auc: 0.7981\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.79141 to 0.79811, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 8/100\n",
      "902/902 - 42s - loss: 0.4863 - accuracy: 0.7638 - auc: 0.8634 - val_loss: 0.8606 - val_accuracy: 0.9168 - val_auc: 0.8048\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.79811 to 0.80484, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 9/100\n",
      "902/902 - 42s - loss: 0.4813 - accuracy: 0.7631 - auc: 0.8671 - val_loss: 0.6864 - val_accuracy: 0.7582 - val_auc: 0.7990\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.80484\n",
      "Epoch 10/100\n",
      "902/902 - 42s - loss: 0.4507 - accuracy: 0.7710 - auc: 0.8795 - val_loss: 0.6755 - val_accuracy: 0.6518 - val_auc: 0.7889\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.80484\n",
      "Epoch 11/100\n",
      "902/902 - 42s - loss: 0.4622 - accuracy: 0.7625 - auc: 0.8757 - val_loss: 0.7971 - val_accuracy: 0.8027 - val_auc: 0.8067\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.80484 to 0.80673, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 12/100\n",
      "902/902 - 42s - loss: 0.4260 - accuracy: 0.7881 - auc: 0.8948 - val_loss: 0.6536 - val_accuracy: 0.6286 - val_auc: 0.8043\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.80673\n",
      "Epoch 13/100\n",
      "902/902 - 42s - loss: 0.4340 - accuracy: 0.8004 - auc: 0.8924 - val_loss: 0.8241 - val_accuracy: 0.7872 - val_auc: 0.7841\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.80673\n",
      "Epoch 14/100\n",
      "902/902 - 42s - loss: 0.4334 - accuracy: 0.7910 - auc: 0.8975 - val_loss: 0.7145 - val_accuracy: 0.6576 - val_auc: 0.7951\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.80673\n",
      "Epoch 15/100\n",
      "902/902 - 42s - loss: 0.4167 - accuracy: 0.7914 - auc: 0.9009 - val_loss: 0.7934 - val_accuracy: 0.7872 - val_auc: 0.8044\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.80673\n",
      "Epoch 16/100\n",
      "902/902 - 42s - loss: 0.4159 - accuracy: 0.8091 - auc: 0.9075 - val_loss: 0.6673 - val_accuracy: 0.7234 - val_auc: 0.8145\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.80673 to 0.81450, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-Aromatase\n",
      "Epoch 17/100\n",
      "902/902 - 42s - loss: 0.4018 - accuracy: 0.8141 - auc: 0.9132 - val_loss: 0.8815 - val_accuracy: 0.7466 - val_auc: 0.7983\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.81450\n",
      "Epoch 18/100\n",
      "902/902 - 42s - loss: 0.4040 - accuracy: 0.8080 - auc: 0.9105 - val_loss: 0.9158 - val_accuracy: 0.8221 - val_auc: 0.7990\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.81450\n",
      "Epoch 19/100\n",
      "902/902 - 42s - loss: 0.4004 - accuracy: 0.8094 - auc: 0.9130 - val_loss: 0.6412 - val_accuracy: 0.6615 - val_auc: 0.8133\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.81450\n",
      "Epoch 20/100\n",
      "902/902 - 42s - loss: 0.4146 - accuracy: 0.7960 - auc: 0.9106 - val_loss: 1.0905 - val_accuracy: 0.7756 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.81450\n",
      "Epoch 21/100\n",
      "902/902 - 42s - loss: 0.4009 - accuracy: 0.8095 - auc: 0.9162 - val_loss: 1.0937 - val_accuracy: 0.8279 - val_auc: 0.7939\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.81450\n",
      "Epoch 22/100\n",
      "902/902 - 42s - loss: 0.3970 - accuracy: 0.8136 - auc: 0.9187 - val_loss: 1.3621 - val_accuracy: 0.8685 - val_auc: 0.7997\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.81450\n",
      "Epoch 23/100\n",
      "902/902 - 42s - loss: 0.4052 - accuracy: 0.8195 - auc: 0.9161 - val_loss: 0.7317 - val_accuracy: 0.7795 - val_auc: 0.7805\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.81450\n",
      "Epoch 24/100\n",
      "902/902 - 42s - loss: 0.3804 - accuracy: 0.8391 - auc: 0.9254 - val_loss: 1.0306 - val_accuracy: 0.7988 - val_auc: 0.7814\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.81450\n",
      "Epoch 25/100\n",
      "902/902 - 42s - loss: 0.3776 - accuracy: 0.8319 - auc: 0.9288 - val_loss: 0.7281 - val_accuracy: 0.7041 - val_auc: 0.7925\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.81450\n",
      "Epoch 26/100\n",
      "902/902 - 42s - loss: 0.3581 - accuracy: 0.8416 - auc: 0.9342 - val_loss: 0.7866 - val_accuracy: 0.7234 - val_auc: 0.7890\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.81450\n",
      "Epoch 27/100\n",
      "902/902 - 42s - loss: 0.3591 - accuracy: 0.8492 - auc: 0.9339 - val_loss: 1.3243 - val_accuracy: 0.8781 - val_auc: 0.7862\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.81450\n",
      "Epoch 28/100\n",
      "902/902 - 42s - loss: 0.3484 - accuracy: 0.8446 - auc: 0.9371 - val_loss: 1.3885 - val_accuracy: 0.8627 - val_auc: 0.7803\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.81450\n",
      "Epoch 29/100\n",
      "902/902 - 42s - loss: 0.3248 - accuracy: 0.8543 - auc: 0.9447 - val_loss: 1.0018 - val_accuracy: 0.7041 - val_auc: 0.7813\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.81450\n",
      "Epoch 30/100\n",
      "902/902 - 42s - loss: 0.3303 - accuracy: 0.8510 - auc: 0.9441 - val_loss: 1.6314 - val_accuracy: 0.8395 - val_auc: 0.7894\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.81450\n",
      "Epoch 31/100\n",
      "902/902 - 42s - loss: 0.3510 - accuracy: 0.8514 - auc: 0.9409 - val_loss: 1.1434 - val_accuracy: 0.7157 - val_auc: 0.7801\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.81450\n",
      "Epoch 32/100\n",
      "902/902 - 42s - loss: 0.3087 - accuracy: 0.8615 - auc: 0.9520 - val_loss: 0.9243 - val_accuracy: 0.6557 - val_auc: 0.7788\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.81450\n",
      "Epoch 33/100\n",
      "902/902 - 42s - loss: 0.3296 - accuracy: 0.8547 - auc: 0.9447 - val_loss: 1.0655 - val_accuracy: 0.8027 - val_auc: 0.7778\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.81450\n",
      "Epoch 34/100\n",
      "902/902 - 42s - loss: 0.3085 - accuracy: 0.8711 - auc: 0.9534 - val_loss: 1.0487 - val_accuracy: 0.8337 - val_auc: 0.7889\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.81450\n",
      "Epoch 35/100\n",
      "902/902 - 42s - loss: 0.2990 - accuracy: 0.8564 - auc: 0.9543 - val_loss: 0.8700 - val_accuracy: 0.7640 - val_auc: 0.7768\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.81450\n",
      "Epoch 36/100\n",
      "902/902 - 42s - loss: 0.3080 - accuracy: 0.8664 - auc: 0.9531 - val_loss: 1.3879 - val_accuracy: 0.8588 - val_auc: 0.7929\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.81450\n",
      "Epoch 37/100\n",
      "902/902 - 42s - loss: 0.2704 - accuracy: 0.8866 - auc: 0.9629 - val_loss: 2.5477 - val_accuracy: 0.8685 - val_auc: 0.7341\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.81450\n",
      "Epoch 38/100\n",
      "902/902 - 42s - loss: 0.2890 - accuracy: 0.8812 - auc: 0.9580 - val_loss: 0.7795 - val_accuracy: 0.7621 - val_auc: 0.8017\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.81450\n",
      "Epoch 39/100\n",
      "902/902 - 42s - loss: 0.2841 - accuracy: 0.8715 - auc: 0.9577 - val_loss: 1.3528 - val_accuracy: 0.8472 - val_auc: 0.7919\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.81450\n",
      "Epoch 40/100\n",
      "902/902 - 42s - loss: 0.2699 - accuracy: 0.8869 - auc: 0.9628 - val_loss: 2.0849 - val_accuracy: 0.8801 - val_auc: 0.7436\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.81450\n",
      "Epoch 41/100\n",
      "902/902 - 42s - loss: 0.2536 - accuracy: 0.8999 - auc: 0.9684 - val_loss: 1.5039 - val_accuracy: 0.8588 - val_auc: 0.8127\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.81450\n",
      "Epoch 42/100\n",
      "902/902 - 42s - loss: 0.2653 - accuracy: 0.8905 - auc: 0.9640 - val_loss: 1.6713 - val_accuracy: 0.8975 - val_auc: 0.7911\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.81450\n",
      "Epoch 43/100\n",
      "902/902 - 42s - loss: 0.2929 - accuracy: 0.8874 - auc: 0.9621 - val_loss: 1.2251 - val_accuracy: 0.7969 - val_auc: 0.7812\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.81450\n",
      "Epoch 44/100\n",
      "902/902 - 42s - loss: 0.2721 - accuracy: 0.8899 - auc: 0.9650 - val_loss: 0.7961 - val_accuracy: 0.7466 - val_auc: 0.8046\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.81450\n",
      "Epoch 45/100\n",
      "902/902 - 42s - loss: 0.2632 - accuracy: 0.8915 - auc: 0.9680 - val_loss: 2.4020 - val_accuracy: 0.8723 - val_auc: 0.7382\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.81450\n",
      "Epoch 46/100\n",
      "902/902 - 42s - loss: 0.2733 - accuracy: 0.8984 - auc: 0.9665 - val_loss: 1.1750 - val_accuracy: 0.7698 - val_auc: 0.7838\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.81450\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 - 42s - loss: 0.2409 - accuracy: 0.9109 - auc: 0.9723 - val_loss: 0.9685 - val_accuracy: 0.8221 - val_auc: 0.7652\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.81450\n",
      "Epoch 48/100\n",
      "902/902 - 42s - loss: 0.2399 - accuracy: 0.9068 - auc: 0.9721 - val_loss: 1.1423 - val_accuracy: 0.7776 - val_auc: 0.7834\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.81450\n",
      "Epoch 49/100\n",
      "902/902 - 42s - loss: 0.2375 - accuracy: 0.9002 - auc: 0.9720 - val_loss: 1.5038 - val_accuracy: 0.7698 - val_auc: 0.7482\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.81450\n",
      "Epoch 50/100\n",
      "902/902 - 42s - loss: 0.2362 - accuracy: 0.9113 - auc: 0.9725 - val_loss: 2.4959 - val_accuracy: 0.8298 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.81450\n",
      "Epoch 51/100\n",
      "902/902 - 42s - loss: 0.2278 - accuracy: 0.9159 - auc: 0.9741 - val_loss: 2.2557 - val_accuracy: 0.8743 - val_auc: 0.7410\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.81450\n",
      "Epoch 52/100\n",
      "902/902 - 42s - loss: 0.2391 - accuracy: 0.8895 - auc: 0.9690 - val_loss: 1.3957 - val_accuracy: 0.8104 - val_auc: 0.7775\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.81450\n",
      "Epoch 53/100\n",
      "902/902 - 42s - loss: 0.2674 - accuracy: 0.9156 - auc: 0.9681 - val_loss: 1.9767 - val_accuracy: 0.8665 - val_auc: 0.7544\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.81450\n",
      "Epoch 54/100\n",
      "902/902 - 42s - loss: 0.2653 - accuracy: 0.9050 - auc: 0.9693 - val_loss: 0.7308 - val_accuracy: 0.7331 - val_auc: 0.7940\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.81450\n",
      "Epoch 55/100\n",
      "902/902 - 42s - loss: 0.2285 - accuracy: 0.9077 - auc: 0.9757 - val_loss: 1.3433 - val_accuracy: 0.7544 - val_auc: 0.7769\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.81450\n",
      "Epoch 56/100\n",
      "902/902 - 42s - loss: 0.2111 - accuracy: 0.9080 - auc: 0.9773 - val_loss: 3.4329 - val_accuracy: 0.8685 - val_auc: 0.6914\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.81450\n",
      "Epoch 57/100\n",
      "902/902 - 42s - loss: 0.2263 - accuracy: 0.9163 - auc: 0.9767 - val_loss: 3.2944 - val_accuracy: 0.8588 - val_auc: 0.6809\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.81450\n",
      "Epoch 58/100\n",
      "902/902 - 42s - loss: 0.1805 - accuracy: 0.9299 - auc: 0.9841 - val_loss: 3.5425 - val_accuracy: 0.8646 - val_auc: 0.6619\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.81450\n",
      "Epoch 59/100\n",
      "902/902 - 42s - loss: 0.1892 - accuracy: 0.9281 - auc: 0.9826 - val_loss: 1.9005 - val_accuracy: 0.8820 - val_auc: 0.7253\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.81450\n",
      "Epoch 60/100\n",
      "902/902 - 42s - loss: 0.2026 - accuracy: 0.9127 - auc: 0.9777 - val_loss: 2.6327 - val_accuracy: 0.8511 - val_auc: 0.7157\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.81450\n",
      "Epoch 61/100\n",
      "902/902 - 42s - loss: 0.1977 - accuracy: 0.9098 - auc: 0.9785 - val_loss: 1.7011 - val_accuracy: 0.7408 - val_auc: 0.7709\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.81450\n",
      "Epoch 62/100\n",
      "902/902 - 42s - loss: 0.2247 - accuracy: 0.9113 - auc: 0.9742 - val_loss: 2.0054 - val_accuracy: 0.8356 - val_auc: 0.7854\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.81450\n",
      "Epoch 63/100\n",
      "902/902 - 42s - loss: 0.2403 - accuracy: 0.8944 - auc: 0.9703 - val_loss: 1.3708 - val_accuracy: 0.8375 - val_auc: 0.7848\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.81450\n",
      "Epoch 64/100\n",
      "902/902 - 42s - loss: 0.2069 - accuracy: 0.9246 - auc: 0.9783 - val_loss: 2.6419 - val_accuracy: 0.8685 - val_auc: 0.7292\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.81450\n",
      "Epoch 65/100\n",
      "902/902 - 42s - loss: 0.1939 - accuracy: 0.9261 - auc: 0.9812 - val_loss: 1.4037 - val_accuracy: 0.8375 - val_auc: 0.8069\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.81450\n",
      "Epoch 66/100\n",
      "902/902 - 42s - loss: 0.1837 - accuracy: 0.9325 - auc: 0.9833 - val_loss: 3.0154 - val_accuracy: 0.8665 - val_auc: 0.6930\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.81450\n",
      "Epoch 67/100\n",
      "902/902 - 42s - loss: 0.1875 - accuracy: 0.9125 - auc: 0.9795 - val_loss: 1.2714 - val_accuracy: 0.6286 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.81450\n",
      "Epoch 68/100\n",
      "902/902 - 42s - loss: 0.2080 - accuracy: 0.9189 - auc: 0.9806 - val_loss: 2.8470 - val_accuracy: 0.8530 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.81450\n",
      "Epoch 69/100\n",
      "902/902 - 42s - loss: 0.1886 - accuracy: 0.9293 - auc: 0.9833 - val_loss: 3.8593 - val_accuracy: 0.8878 - val_auc: 0.6590\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.81450\n",
      "Epoch 70/100\n",
      "902/902 - 42s - loss: 0.2138 - accuracy: 0.9185 - auc: 0.9760 - val_loss: 1.8788 - val_accuracy: 0.8259 - val_auc: 0.7485\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.81450\n",
      "Epoch 71/100\n",
      "902/902 - 42s - loss: 0.1829 - accuracy: 0.9206 - auc: 0.9826 - val_loss: 3.4701 - val_accuracy: 0.8356 - val_auc: 0.6932\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.81450\n",
      "Epoch 72/100\n",
      "902/902 - 42s - loss: 0.1912 - accuracy: 0.9264 - auc: 0.9813 - val_loss: 1.2545 - val_accuracy: 0.8511 - val_auc: 0.8015\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.81450\n",
      "Epoch 73/100\n",
      "902/902 - 42s - loss: 0.1466 - accuracy: 0.9469 - auc: 0.9883 - val_loss: 2.1414 - val_accuracy: 0.8897 - val_auc: 0.7492\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.81450\n",
      "Epoch 74/100\n",
      "902/902 - 42s - loss: 0.1862 - accuracy: 0.9328 - auc: 0.9814 - val_loss: 2.1594 - val_accuracy: 0.8569 - val_auc: 0.7774\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.81450\n",
      "Epoch 75/100\n",
      "902/902 - 42s - loss: 0.1859 - accuracy: 0.9265 - auc: 0.9833 - val_loss: 2.4649 - val_accuracy: 0.8221 - val_auc: 0.7190\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.81450\n",
      "Epoch 76/100\n",
      "902/902 - 42s - loss: 0.1695 - accuracy: 0.9285 - auc: 0.9849 - val_loss: 3.1116 - val_accuracy: 0.8046 - val_auc: 0.7052\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.81450\n",
      "Epoch 77/100\n",
      "902/902 - 42s - loss: 0.2150 - accuracy: 0.9269 - auc: 0.9796 - val_loss: 6.3108 - val_accuracy: 0.8994 - val_auc: 0.6071\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.81450\n",
      "Epoch 78/100\n",
      "902/902 - 42s - loss: 0.2197 - accuracy: 0.9202 - auc: 0.9778 - val_loss: 3.7359 - val_accuracy: 0.8839 - val_auc: 0.6568\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.81450\n",
      "Epoch 79/100\n",
      "902/902 - 42s - loss: 0.1911 - accuracy: 0.9308 - auc: 0.9825 - val_loss: 1.2421 - val_accuracy: 0.7408 - val_auc: 0.7680\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.81450\n",
      "Epoch 80/100\n",
      "902/902 - 42s - loss: 0.1616 - accuracy: 0.9407 - auc: 0.9869 - val_loss: 3.8167 - val_accuracy: 0.8704 - val_auc: 0.6962\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.81450\n",
      "Epoch 81/100\n",
      "902/902 - 42s - loss: 0.1718 - accuracy: 0.9301 - auc: 0.9833 - val_loss: 5.1018 - val_accuracy: 0.8607 - val_auc: 0.6321\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.81450\n",
      "Epoch 82/100\n",
      "902/902 - 42s - loss: 0.1793 - accuracy: 0.9376 - auc: 0.9848 - val_loss: 3.6391 - val_accuracy: 0.8897 - val_auc: 0.6560\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.81450\n",
      "Epoch 83/100\n",
      "902/902 - 42s - loss: 0.1555 - accuracy: 0.9428 - auc: 0.9870 - val_loss: 3.0004 - val_accuracy: 0.8607 - val_auc: 0.7061\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.81450\n",
      "Epoch 84/100\n",
      "902/902 - 42s - loss: 0.1594 - accuracy: 0.9354 - auc: 0.9862 - val_loss: 5.2065 - val_accuracy: 0.8839 - val_auc: 0.6438\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.81450\n",
      "Epoch 85/100\n",
      "902/902 - 42s - loss: 0.1630 - accuracy: 0.9397 - auc: 0.9868 - val_loss: 4.3073 - val_accuracy: 0.8897 - val_auc: 0.6527\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.81450\n",
      "Epoch 86/100\n",
      "902/902 - 42s - loss: 0.1561 - accuracy: 0.9386 - auc: 0.9874 - val_loss: 2.3479 - val_accuracy: 0.8046 - val_auc: 0.7558\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.81450\n",
      "Epoch 87/100\n",
      "902/902 - 42s - loss: 0.1293 - accuracy: 0.9519 - auc: 0.9908 - val_loss: 5.3471 - val_accuracy: 0.8665 - val_auc: 0.6339\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.81450\n",
      "Epoch 88/100\n",
      "902/902 - 42s - loss: 0.2144 - accuracy: 0.9232 - auc: 0.9778 - val_loss: 0.9718 - val_accuracy: 0.7969 - val_auc: 0.7932\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.81450\n",
      "Epoch 89/100\n",
      "902/902 - 42s - loss: 0.1802 - accuracy: 0.9382 - auc: 0.9860 - val_loss: 4.7737 - val_accuracy: 0.8994 - val_auc: 0.6357\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.81450\n",
      "Epoch 90/100\n",
      "902/902 - 42s - loss: 0.1786 - accuracy: 0.9458 - auc: 0.9870 - val_loss: 3.7891 - val_accuracy: 0.8762 - val_auc: 0.6879\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.81450\n",
      "Epoch 91/100\n",
      "902/902 - 42s - loss: 0.2129 - accuracy: 0.9315 - auc: 0.9803 - val_loss: 2.9524 - val_accuracy: 0.8897 - val_auc: 0.7313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_auc did not improve from 0.81450\n",
      "Epoch 92/100\n",
      "902/902 - 42s - loss: 0.1412 - accuracy: 0.9555 - auc: 0.9908 - val_loss: 4.8747 - val_accuracy: 0.8704 - val_auc: 0.6355\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.81450\n",
      "Epoch 93/100\n",
      "902/902 - 42s - loss: 0.1467 - accuracy: 0.9457 - auc: 0.9900 - val_loss: 5.1327 - val_accuracy: 0.8839 - val_auc: 0.6059\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.81450\n",
      "Epoch 94/100\n",
      "902/902 - 42s - loss: 0.1712 - accuracy: 0.9387 - auc: 0.9860 - val_loss: 2.8918 - val_accuracy: 0.8569 - val_auc: 0.7413\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.81450\n",
      "Epoch 95/100\n",
      "902/902 - 42s - loss: 0.1667 - accuracy: 0.9355 - auc: 0.9863 - val_loss: 5.1958 - val_accuracy: 0.8801 - val_auc: 0.6285\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.81450\n",
      "Epoch 96/100\n",
      "902/902 - 42s - loss: 0.1498 - accuracy: 0.9367 - auc: 0.9875 - val_loss: 4.8705 - val_accuracy: 0.8801 - val_auc: 0.6343\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.81450\n",
      "Epoch 97/100\n",
      "902/902 - 42s - loss: 0.1506 - accuracy: 0.9426 - auc: 0.9885 - val_loss: 4.7001 - val_accuracy: 0.8897 - val_auc: 0.6878\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.81450\n",
      "Epoch 98/100\n",
      "902/902 - 42s - loss: 0.1659 - accuracy: 0.9416 - auc: 0.9874 - val_loss: 2.9259 - val_accuracy: 0.8743 - val_auc: 0.6972\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.81450\n",
      "Epoch 99/100\n",
      "902/902 - 42s - loss: 0.1930 - accuracy: 0.9350 - auc: 0.9848 - val_loss: 3.2723 - val_accuracy: 0.8665 - val_auc: 0.6829\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.81450\n",
      "Epoch 100/100\n",
      "902/902 - 42s - loss: 0.2158 - accuracy: 0.9228 - auc: 0.9808 - val_loss: 1.5163 - val_accuracy: 0.9091 - val_auc: 0.7912\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.81450\n",
      "Epoch 1/100\n",
      "1025/1025 - 58s - loss: 0.9599 - accuracy: 0.5162 - auc: 0.5209 - val_loss: 1.1159 - val_accuracy: 0.6678 - val_auc: 0.7537\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.75370, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-PPAR-gamma\n",
      "Epoch 2/100\n",
      "1025/1025 - 48s - loss: 0.7910 - accuracy: 0.5919 - auc: 0.6691 - val_loss: 1.2561 - val_accuracy: 0.8870 - val_auc: 0.7573\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.75370 to 0.75728, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-PPAR-gamma\n",
      "Epoch 3/100\n",
      "1025/1025 - 48s - loss: 0.7046 - accuracy: 0.6927 - auc: 0.7264 - val_loss: 0.9118 - val_accuracy: 0.7032 - val_auc: 0.7741\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.75728 to 0.77407, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-PPAR-gamma\n",
      "Epoch 4/100\n",
      "1025/1025 - 48s - loss: 0.6665 - accuracy: 0.7368 - auc: 0.7575 - val_loss: 0.8636 - val_accuracy: 0.6408 - val_auc: 0.7766\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.77407 to 0.77661, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-PPAR-gamma\n",
      "Epoch 5/100\n",
      "1025/1025 - 48s - loss: 0.6362 - accuracy: 0.7201 - auc: 0.7599 - val_loss: 0.9486 - val_accuracy: 0.6324 - val_auc: 0.7677\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.77661\n",
      "Epoch 6/100\n",
      "1025/1025 - 48s - loss: 0.5786 - accuracy: 0.7424 - auc: 0.8074 - val_loss: 0.9612 - val_accuracy: 0.6965 - val_auc: 0.7563\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.77661\n",
      "Epoch 7/100\n",
      "1025/1025 - 48s - loss: 0.5712 - accuracy: 0.7435 - auc: 0.8123 - val_loss: 1.0063 - val_accuracy: 0.7926 - val_auc: 0.7480\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.77661\n",
      "Epoch 8/100\n",
      "1025/1025 - 48s - loss: 0.5688 - accuracy: 0.7542 - auc: 0.8137 - val_loss: 1.1199 - val_accuracy: 0.7723 - val_auc: 0.7600\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77661\n",
      "Epoch 9/100\n",
      "1025/1025 - 48s - loss: 0.5013 - accuracy: 0.7536 - auc: 0.8563 - val_loss: 1.2013 - val_accuracy: 0.7791 - val_auc: 0.7320\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.77661\n",
      "Epoch 10/100\n",
      "1025/1025 - 48s - loss: 0.5347 - accuracy: 0.7399 - auc: 0.8383 - val_loss: 1.1617 - val_accuracy: 0.7403 - val_auc: 0.7428\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.77661\n",
      "Epoch 11/100\n",
      "1025/1025 - 48s - loss: 0.4961 - accuracy: 0.7635 - auc: 0.8615 - val_loss: 0.9506 - val_accuracy: 0.5885 - val_auc: 0.7451\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77661\n",
      "Epoch 12/100\n",
      "1025/1025 - 48s - loss: 0.5373 - accuracy: 0.7614 - auc: 0.8440 - val_loss: 0.8705 - val_accuracy: 0.5683 - val_auc: 0.7712\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.77661\n",
      "Epoch 13/100\n",
      "1025/1025 - 47s - loss: 0.5268 - accuracy: 0.7681 - auc: 0.8525 - val_loss: 0.8790 - val_accuracy: 0.6172 - val_auc: 0.7472\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77661\n",
      "Epoch 14/100\n",
      "1025/1025 - 48s - loss: 0.4890 - accuracy: 0.7715 - auc: 0.8678 - val_loss: 0.8503 - val_accuracy: 0.6172 - val_auc: 0.7618\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.77661\n",
      "Epoch 15/100\n",
      "1025/1025 - 48s - loss: 0.4715 - accuracy: 0.8053 - auc: 0.8790 - val_loss: 1.1525 - val_accuracy: 0.7538 - val_auc: 0.7681\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77661\n",
      "Epoch 16/100\n",
      "1025/1025 - 48s - loss: 0.4492 - accuracy: 0.8068 - auc: 0.8883 - val_loss: 1.0370 - val_accuracy: 0.7622 - val_auc: 0.7168\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77661\n",
      "Epoch 17/100\n",
      "1025/1025 - 48s - loss: 0.4276 - accuracy: 0.8064 - auc: 0.8983 - val_loss: 1.5709 - val_accuracy: 0.7066 - val_auc: 0.7369\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77661\n",
      "Epoch 18/100\n",
      "1025/1025 - 48s - loss: 0.4987 - accuracy: 0.8151 - auc: 0.8799 - val_loss: 0.8977 - val_accuracy: 0.6560 - val_auc: 0.7629\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.77661\n",
      "Epoch 19/100\n",
      "1025/1025 - 48s - loss: 0.4688 - accuracy: 0.8051 - auc: 0.8866 - val_loss: 1.1227 - val_accuracy: 0.7454 - val_auc: 0.7444\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.77661\n",
      "Epoch 20/100\n",
      "1025/1025 - 48s - loss: 0.4725 - accuracy: 0.8058 - auc: 0.8895 - val_loss: 1.1608 - val_accuracy: 0.7437 - val_auc: 0.7380\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.77661\n",
      "Epoch 21/100\n",
      "1025/1025 - 48s - loss: 0.4764 - accuracy: 0.8093 - auc: 0.8864 - val_loss: 1.2124 - val_accuracy: 0.7740 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.77661\n",
      "Epoch 22/100\n",
      "1025/1025 - 48s - loss: 0.4388 - accuracy: 0.8464 - auc: 0.9063 - val_loss: 1.3266 - val_accuracy: 0.8196 - val_auc: 0.7351\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.77661\n",
      "Epoch 23/100\n",
      "1025/1025 - 48s - loss: 0.4243 - accuracy: 0.8433 - auc: 0.9089 - val_loss: 1.7113 - val_accuracy: 0.7555 - val_auc: 0.7386\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.77661\n",
      "Epoch 24/100\n",
      "1025/1025 - 48s - loss: 0.4053 - accuracy: 0.8536 - auc: 0.9180 - val_loss: 1.6266 - val_accuracy: 0.7032 - val_auc: 0.7284\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.77661\n",
      "Epoch 25/100\n",
      "1025/1025 - 48s - loss: 0.4253 - accuracy: 0.8042 - auc: 0.9053 - val_loss: 1.4130 - val_accuracy: 0.7774 - val_auc: 0.7420\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.77661\n",
      "Epoch 26/100\n",
      "1025/1025 - 48s - loss: 0.3861 - accuracy: 0.8331 - auc: 0.9214 - val_loss: 1.0079 - val_accuracy: 0.6779 - val_auc: 0.7658\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.77661\n",
      "Epoch 27/100\n",
      "1025/1025 - 48s - loss: 0.4103 - accuracy: 0.8125 - auc: 0.9141 - val_loss: 2.4597 - val_accuracy: 0.8550 - val_auc: 0.7333\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.77661\n",
      "Epoch 28/100\n",
      "1025/1025 - 48s - loss: 0.4108 - accuracy: 0.8590 - auc: 0.9192 - val_loss: 1.1521 - val_accuracy: 0.6391 - val_auc: 0.7240\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.77661\n",
      "Epoch 29/100\n",
      "1025/1025 - 48s - loss: 0.4963 - accuracy: 0.8315 - auc: 0.8942 - val_loss: 1.2197 - val_accuracy: 0.6358 - val_auc: 0.7246\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.77661\n",
      "Epoch 30/100\n",
      "1025/1025 - 48s - loss: 0.4169 - accuracy: 0.8309 - auc: 0.9180 - val_loss: 2.3798 - val_accuracy: 0.8027 - val_auc: 0.7313\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.77661\n",
      "Epoch 31/100\n",
      "1025/1025 - 48s - loss: 0.3756 - accuracy: 0.8611 - auc: 0.9321 - val_loss: 1.5342 - val_accuracy: 0.5497 - val_auc: 0.7327\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.77661\n",
      "Epoch 32/100\n",
      "1025/1025 - 48s - loss: 0.3874 - accuracy: 0.8505 - auc: 0.9316 - val_loss: 1.6753 - val_accuracy: 0.6189 - val_auc: 0.7257\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.77661\n",
      "Epoch 33/100\n",
      "1025/1025 - 48s - loss: 0.3752 - accuracy: 0.8603 - auc: 0.9326 - val_loss: 1.8657 - val_accuracy: 0.7841 - val_auc: 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_auc did not improve from 0.77661\n",
      "Epoch 34/100\n",
      "1025/1025 - 48s - loss: 0.3591 - accuracy: 0.8519 - auc: 0.9358 - val_loss: 2.8793 - val_accuracy: 0.7875 - val_auc: 0.7533\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.77661\n",
      "Epoch 35/100\n",
      "1025/1025 - 48s - loss: 0.3686 - accuracy: 0.8539 - auc: 0.9363 - val_loss: 2.2742 - val_accuracy: 0.8651 - val_auc: 0.7441\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.77661\n",
      "Epoch 36/100\n",
      "1025/1025 - 48s - loss: 0.3814 - accuracy: 0.8489 - auc: 0.9312 - val_loss: 2.0784 - val_accuracy: 0.8516 - val_auc: 0.7311\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.77661\n",
      "Epoch 37/100\n",
      "1025/1025 - 48s - loss: 0.3401 - accuracy: 0.8614 - auc: 0.9445 - val_loss: 2.9824 - val_accuracy: 0.7808 - val_auc: 0.7511\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.77661\n",
      "Epoch 38/100\n",
      "1025/1025 - 48s - loss: 0.3646 - accuracy: 0.8631 - auc: 0.9407 - val_loss: 2.0814 - val_accuracy: 0.7673 - val_auc: 0.7320\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.77661\n",
      "Epoch 39/100\n",
      "1025/1025 - 48s - loss: 0.3185 - accuracy: 0.8722 - auc: 0.9513 - val_loss: 2.4621 - val_accuracy: 0.7538 - val_auc: 0.7591\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.77661\n",
      "Epoch 40/100\n",
      "1025/1025 - 48s - loss: 0.3427 - accuracy: 0.8535 - auc: 0.9442 - val_loss: 2.2808 - val_accuracy: 0.8145 - val_auc: 0.7433\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.77661\n",
      "Epoch 41/100\n",
      "1025/1025 - 48s - loss: 0.2980 - accuracy: 0.8679 - auc: 0.9533 - val_loss: 2.4154 - val_accuracy: 0.8347 - val_auc: 0.7424\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.77661\n",
      "Epoch 42/100\n",
      "1025/1025 - 48s - loss: 0.2913 - accuracy: 0.8713 - auc: 0.9536 - val_loss: 1.7588 - val_accuracy: 0.5801 - val_auc: 0.7294\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.77661\n",
      "Epoch 43/100\n",
      "1025/1025 - 48s - loss: 0.3893 - accuracy: 0.8134 - auc: 0.9261 - val_loss: 2.1307 - val_accuracy: 0.7504 - val_auc: 0.7473\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.77661\n",
      "Epoch 44/100\n",
      "1025/1025 - 48s - loss: 0.3320 - accuracy: 0.8641 - auc: 0.9452 - val_loss: 3.0034 - val_accuracy: 0.8465 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.77661\n",
      "Epoch 45/100\n",
      "1025/1025 - 48s - loss: 0.3409 - accuracy: 0.8762 - auc: 0.9452 - val_loss: 1.9829 - val_accuracy: 0.7538 - val_auc: 0.7226\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.77661\n",
      "Epoch 46/100\n",
      "1025/1025 - 48s - loss: 0.3493 - accuracy: 0.8819 - auc: 0.9471 - val_loss: 3.7016 - val_accuracy: 0.8398 - val_auc: 0.7109\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.77661\n",
      "Epoch 47/100\n",
      "1025/1025 - 48s - loss: 0.3400 - accuracy: 0.8501 - auc: 0.9452 - val_loss: 2.5580 - val_accuracy: 0.7825 - val_auc: 0.7411\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.77661\n",
      "Epoch 48/100\n",
      "1025/1025 - 48s - loss: 0.3019 - accuracy: 0.8753 - auc: 0.9560 - val_loss: 3.2284 - val_accuracy: 0.7960 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.77661\n",
      "Epoch 49/100\n",
      "1025/1025 - 48s - loss: 0.2698 - accuracy: 0.8792 - auc: 0.9645 - val_loss: 3.5186 - val_accuracy: 0.8347 - val_auc: 0.7262\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.77661\n",
      "Epoch 50/100\n",
      "1025/1025 - 48s - loss: 0.2776 - accuracy: 0.8741 - auc: 0.9617 - val_loss: 3.8171 - val_accuracy: 0.8280 - val_auc: 0.7444\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.77661\n",
      "Epoch 51/100\n",
      "1025/1025 - 48s - loss: 0.2689 - accuracy: 0.8977 - auc: 0.9624 - val_loss: 1.7412 - val_accuracy: 0.7521 - val_auc: 0.7314\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.77661\n",
      "Epoch 52/100\n",
      "1025/1025 - 48s - loss: 0.3406 - accuracy: 0.8870 - auc: 0.9491 - val_loss: 4.2242 - val_accuracy: 0.9359 - val_auc: 0.7140\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.77661\n",
      "Epoch 53/100\n",
      "1025/1025 - 48s - loss: 0.3647 - accuracy: 0.8962 - auc: 0.9503 - val_loss: 2.3111 - val_accuracy: 0.8331 - val_auc: 0.7260\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.77661\n",
      "Epoch 54/100\n",
      "1025/1025 - 48s - loss: 0.2794 - accuracy: 0.8911 - auc: 0.9641 - val_loss: 3.1736 - val_accuracy: 0.8432 - val_auc: 0.7340\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.77661\n",
      "Epoch 55/100\n",
      "1025/1025 - 48s - loss: 0.2423 - accuracy: 0.9011 - auc: 0.9718 - val_loss: 2.8795 - val_accuracy: 0.8516 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.77661\n",
      "Epoch 56/100\n",
      "1025/1025 - 48s - loss: 0.2655 - accuracy: 0.8983 - auc: 0.9672 - val_loss: 3.0047 - val_accuracy: 0.8145 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.77661\n",
      "Epoch 57/100\n",
      "1025/1025 - 48s - loss: 0.2918 - accuracy: 0.8796 - auc: 0.9607 - val_loss: 3.0127 - val_accuracy: 0.8111 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.77661\n",
      "Epoch 58/100\n",
      "1025/1025 - 48s - loss: 0.2500 - accuracy: 0.8969 - auc: 0.9709 - val_loss: 3.5301 - val_accuracy: 0.8550 - val_auc: 0.7379\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.77661\n",
      "Epoch 59/100\n",
      "1025/1025 - 48s - loss: 0.2689 - accuracy: 0.8996 - auc: 0.9639 - val_loss: 2.1095 - val_accuracy: 0.8280 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.77661\n",
      "Epoch 60/100\n",
      "1025/1025 - 48s - loss: 0.2601 - accuracy: 0.9002 - auc: 0.9690 - val_loss: 6.0273 - val_accuracy: 0.8971 - val_auc: 0.7009\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.77661\n",
      "Epoch 61/100\n",
      "1025/1025 - 48s - loss: 0.2468 - accuracy: 0.9086 - auc: 0.9719 - val_loss: 2.3795 - val_accuracy: 0.8617 - val_auc: 0.7259\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.77661\n",
      "Epoch 62/100\n",
      "1025/1025 - 48s - loss: 0.3169 - accuracy: 0.8881 - auc: 0.9565 - val_loss: 2.0226 - val_accuracy: 0.6290 - val_auc: 0.7496\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.77661\n",
      "Epoch 63/100\n",
      "1025/1025 - 48s - loss: 0.2516 - accuracy: 0.9225 - auc: 0.9733 - val_loss: 3.8045 - val_accuracy: 0.8735 - val_auc: 0.7076\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.77661\n",
      "Epoch 64/100\n",
      "1025/1025 - 48s - loss: 0.2368 - accuracy: 0.9214 - auc: 0.9740 - val_loss: 5.0266 - val_accuracy: 0.8836 - val_auc: 0.6950\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.77661\n",
      "Epoch 65/100\n",
      "1025/1025 - 48s - loss: 0.2633 - accuracy: 0.8838 - auc: 0.9663 - val_loss: 3.4339 - val_accuracy: 0.7437 - val_auc: 0.7254\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.77661\n",
      "Epoch 66/100\n",
      "1025/1025 - 48s - loss: 0.2544 - accuracy: 0.8905 - auc: 0.9701 - val_loss: 2.6259 - val_accuracy: 0.8094 - val_auc: 0.7594\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.77661\n",
      "Epoch 67/100\n",
      "1025/1025 - 48s - loss: 0.2310 - accuracy: 0.9023 - auc: 0.9745 - val_loss: 0.9879 - val_accuracy: 0.4840 - val_auc: 0.7676\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.77661\n",
      "Epoch 68/100\n",
      "1025/1025 - 48s - loss: 0.2974 - accuracy: 0.8933 - auc: 0.9618 - val_loss: 1.3769 - val_accuracy: 0.7504 - val_auc: 0.7902\n",
      "\n",
      "Epoch 00068: val_auc improved from 0.77661 to 0.79023, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_NR-PPAR-gamma\n",
      "Epoch 69/100\n",
      "1025/1025 - 48s - loss: 0.2470 - accuracy: 0.9114 - auc: 0.9720 - val_loss: 4.0719 - val_accuracy: 0.8634 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.79023\n",
      "Epoch 70/100\n",
      "1025/1025 - 48s - loss: 0.2488 - accuracy: 0.9050 - auc: 0.9697 - val_loss: 2.8447 - val_accuracy: 0.8094 - val_auc: 0.7593\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.79023\n",
      "Epoch 71/100\n",
      "1025/1025 - 48s - loss: 0.2693 - accuracy: 0.8974 - auc: 0.9676 - val_loss: 3.7160 - val_accuracy: 0.8145 - val_auc: 0.7317\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.79023\n",
      "Epoch 72/100\n",
      "1025/1025 - 48s - loss: 0.2188 - accuracy: 0.9246 - auc: 0.9773 - val_loss: 4.0853 - val_accuracy: 0.8870 - val_auc: 0.7213\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.79023\n",
      "Epoch 73/100\n",
      "1025/1025 - 48s - loss: 0.2235 - accuracy: 0.9185 - auc: 0.9770 - val_loss: 3.3028 - val_accuracy: 0.8347 - val_auc: 0.7287\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.79023\n",
      "Epoch 74/100\n",
      "1025/1025 - 48s - loss: 0.2155 - accuracy: 0.9169 - auc: 0.9750 - val_loss: 1.3653 - val_accuracy: 0.7521 - val_auc: 0.7773\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.79023\n",
      "Epoch 75/100\n",
      "1025/1025 - 48s - loss: 0.2402 - accuracy: 0.9090 - auc: 0.9730 - val_loss: 4.3028 - val_accuracy: 0.8921 - val_auc: 0.7294\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.79023\n",
      "Epoch 76/100\n",
      "1025/1025 - 48s - loss: 0.2431 - accuracy: 0.9133 - auc: 0.9711 - val_loss: 3.7957 - val_accuracy: 0.8836 - val_auc: 0.7165\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.79023\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025/1025 - 48s - loss: 0.2242 - accuracy: 0.9173 - auc: 0.9753 - val_loss: 3.0049 - val_accuracy: 0.8263 - val_auc: 0.7149\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.79023\n",
      "Epoch 78/100\n",
      "1025/1025 - 48s - loss: 0.2194 - accuracy: 0.9080 - auc: 0.9777 - val_loss: 3.8709 - val_accuracy: 0.8617 - val_auc: 0.7310\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.79023\n",
      "Epoch 79/100\n",
      "1025/1025 - 48s - loss: 0.2796 - accuracy: 0.9018 - auc: 0.9659 - val_loss: 2.8746 - val_accuracy: 0.8263 - val_auc: 0.7489\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.79023\n",
      "Epoch 80/100\n",
      "1025/1025 - 48s - loss: 0.2199 - accuracy: 0.9228 - auc: 0.9779 - val_loss: 3.4507 - val_accuracy: 0.8331 - val_auc: 0.7456\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.79023\n",
      "Epoch 81/100\n",
      "1025/1025 - 48s - loss: 0.1858 - accuracy: 0.9336 - auc: 0.9839 - val_loss: 4.8605 - val_accuracy: 0.8128 - val_auc: 0.7228\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.79023\n",
      "Epoch 82/100\n",
      "1025/1025 - 48s - loss: 0.1869 - accuracy: 0.9249 - auc: 0.9815 - val_loss: 5.7130 - val_accuracy: 0.8938 - val_auc: 0.6676\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.79023\n",
      "Epoch 83/100\n",
      "1025/1025 - 48s - loss: 0.2056 - accuracy: 0.9219 - auc: 0.9776 - val_loss: 6.0654 - val_accuracy: 0.8887 - val_auc: 0.6731\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.79023\n",
      "Epoch 84/100\n",
      "1025/1025 - 48s - loss: 0.2346 - accuracy: 0.8961 - auc: 0.9744 - val_loss: 5.2969 - val_accuracy: 0.9224 - val_auc: 0.7275\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.79023\n",
      "Epoch 85/100\n",
      "1025/1025 - 48s - loss: 0.2503 - accuracy: 0.8862 - auc: 0.9672 - val_loss: 2.9719 - val_accuracy: 0.7943 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.79023\n",
      "Epoch 86/100\n",
      "1025/1025 - 48s - loss: 0.1893 - accuracy: 0.9089 - auc: 0.9806 - val_loss: 6.9291 - val_accuracy: 0.8853 - val_auc: 0.6528\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.79023\n",
      "Epoch 87/100\n",
      "1025/1025 - 48s - loss: 0.2580 - accuracy: 0.9207 - auc: 0.9723 - val_loss: 4.5019 - val_accuracy: 0.8718 - val_auc: 0.6978\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.79023\n",
      "Epoch 88/100\n",
      "1025/1025 - 48s - loss: 0.1933 - accuracy: 0.9401 - auc: 0.9827 - val_loss: 4.5752 - val_accuracy: 0.8229 - val_auc: 0.7093\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.79023\n",
      "Epoch 89/100\n",
      "1025/1025 - 48s - loss: 0.2228 - accuracy: 0.9207 - auc: 0.9786 - val_loss: 6.1539 - val_accuracy: 0.9089 - val_auc: 0.6660\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.79023\n",
      "Epoch 90/100\n",
      "1025/1025 - 48s - loss: 0.2066 - accuracy: 0.9245 - auc: 0.9802 - val_loss: 3.8577 - val_accuracy: 0.7926 - val_auc: 0.6983\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.79023\n",
      "Epoch 91/100\n",
      "1025/1025 - 48s - loss: 0.1861 - accuracy: 0.9344 - auc: 0.9823 - val_loss: 5.8631 - val_accuracy: 0.8836 - val_auc: 0.7051\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.79023\n",
      "Epoch 92/100\n",
      "1025/1025 - 48s - loss: 0.2192 - accuracy: 0.9092 - auc: 0.9760 - val_loss: 4.0877 - val_accuracy: 0.8128 - val_auc: 0.7426\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.79023\n",
      "Epoch 93/100\n",
      "1025/1025 - 48s - loss: 0.1673 - accuracy: 0.9293 - auc: 0.9853 - val_loss: 6.0862 - val_accuracy: 0.8870 - val_auc: 0.6748\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.79023\n",
      "Epoch 94/100\n",
      "1025/1025 - 48s - loss: 0.2051 - accuracy: 0.9214 - auc: 0.9808 - val_loss: 6.7347 - val_accuracy: 0.9056 - val_auc: 0.6984\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.79023\n",
      "Epoch 95/100\n",
      "1025/1025 - 48s - loss: 0.2350 - accuracy: 0.8874 - auc: 0.9733 - val_loss: 2.6662 - val_accuracy: 0.7049 - val_auc: 0.7051\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.79023\n",
      "Epoch 96/100\n",
      "1025/1025 - 48s - loss: 0.2111 - accuracy: 0.9253 - auc: 0.9808 - val_loss: 6.9800 - val_accuracy: 0.9073 - val_auc: 0.6572\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.79023\n",
      "Epoch 97/100\n",
      "1025/1025 - 48s - loss: 0.2349 - accuracy: 0.9207 - auc: 0.9753 - val_loss: 4.0193 - val_accuracy: 0.8583 - val_auc: 0.7320\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.79023\n",
      "Epoch 98/100\n",
      "1025/1025 - 48s - loss: 0.2200 - accuracy: 0.9175 - auc: 0.9786 - val_loss: 5.1093 - val_accuracy: 0.8921 - val_auc: 0.6993\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.79023\n",
      "Epoch 99/100\n",
      "1025/1025 - 48s - loss: 0.2070 - accuracy: 0.9238 - auc: 0.9813 - val_loss: 2.7750 - val_accuracy: 0.8921 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.79023\n",
      "Epoch 100/100\n",
      "1025/1025 - 48s - loss: 0.1863 - accuracy: 0.9389 - auc: 0.9851 - val_loss: 4.6581 - val_accuracy: 0.8752 - val_auc: 0.7219\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.79023\n",
      "Epoch 1/100\n",
      "905/905 - 52s - loss: 0.8152 - accuracy: 0.5847 - auc: 0.6267 - val_loss: 0.7441 - val_accuracy: 0.6100 - val_auc: 0.7171\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.71709, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 2/100\n",
      "905/905 - 42s - loss: 0.6986 - accuracy: 0.6753 - auc: 0.7143 - val_loss: 0.7201 - val_accuracy: 0.6728 - val_auc: 0.7407\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.71709 to 0.74074, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 3/100\n",
      "905/905 - 42s - loss: 0.6305 - accuracy: 0.6699 - auc: 0.7517 - val_loss: 0.6753 - val_accuracy: 0.7283 - val_auc: 0.7450\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.74074 to 0.74504, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 4/100\n",
      "905/905 - 42s - loss: 0.5969 - accuracy: 0.6843 - auc: 0.7689 - val_loss: 0.6249 - val_accuracy: 0.6414 - val_auc: 0.7646\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.74504 to 0.76460, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 5/100\n",
      "905/905 - 42s - loss: 0.5642 - accuracy: 0.7125 - auc: 0.7938 - val_loss: 0.6547 - val_accuracy: 0.6876 - val_auc: 0.7635\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.76460\n",
      "Epoch 6/100\n",
      "905/905 - 42s - loss: 0.5543 - accuracy: 0.7197 - auc: 0.8004 - val_loss: 0.6142 - val_accuracy: 0.7024 - val_auc: 0.7715\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.76460 to 0.77150, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 7/100\n",
      "905/905 - 42s - loss: 0.5529 - accuracy: 0.7127 - auc: 0.7992 - val_loss: 0.6188 - val_accuracy: 0.6026 - val_auc: 0.7733\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.77150 to 0.77333, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 8/100\n",
      "905/905 - 42s - loss: 0.5326 - accuracy: 0.7311 - auc: 0.8157 - val_loss: 0.7418 - val_accuracy: 0.8115 - val_auc: 0.7665\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77333\n",
      "Epoch 9/100\n",
      "905/905 - 42s - loss: 0.5300 - accuracy: 0.7282 - auc: 0.8223 - val_loss: 0.6432 - val_accuracy: 0.7412 - val_auc: 0.7628\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.77333\n",
      "Epoch 10/100\n",
      "905/905 - 42s - loss: 0.5204 - accuracy: 0.7347 - auc: 0.8305 - val_loss: 0.6265 - val_accuracy: 0.6396 - val_auc: 0.7762\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.77333 to 0.77615, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 11/100\n",
      "905/905 - 42s - loss: 0.5175 - accuracy: 0.7484 - auc: 0.8378 - val_loss: 0.6023 - val_accuracy: 0.6654 - val_auc: 0.7759\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77615\n",
      "Epoch 12/100\n",
      "905/905 - 42s - loss: 0.5105 - accuracy: 0.7600 - auc: 0.8424 - val_loss: 0.6518 - val_accuracy: 0.8059 - val_auc: 0.7768\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.77615 to 0.77677, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 13/100\n",
      "905/905 - 42s - loss: 0.4907 - accuracy: 0.7698 - auc: 0.8515 - val_loss: 0.6781 - val_accuracy: 0.6026 - val_auc: 0.7698\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77677\n",
      "Epoch 14/100\n",
      "905/905 - 42s - loss: 0.4847 - accuracy: 0.7860 - auc: 0.8562 - val_loss: 0.5983 - val_accuracy: 0.6932 - val_auc: 0.7778\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.77677 to 0.77779, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 15/100\n",
      "905/905 - 42s - loss: 0.4745 - accuracy: 0.7784 - auc: 0.8615 - val_loss: 0.7034 - val_accuracy: 0.7616 - val_auc: 0.7677\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77779\n",
      "Epoch 16/100\n",
      "905/905 - 42s - loss: 0.4721 - accuracy: 0.7850 - auc: 0.8608 - val_loss: 0.6949 - val_accuracy: 0.7689 - val_auc: 0.7638\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77779\n",
      "Epoch 17/100\n",
      "905/905 - 42s - loss: 0.4624 - accuracy: 0.7849 - auc: 0.8700 - val_loss: 0.6371 - val_accuracy: 0.7153 - val_auc: 0.7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77779\n",
      "Epoch 18/100\n",
      "905/905 - 43s - loss: 0.4549 - accuracy: 0.7939 - auc: 0.8768 - val_loss: 0.6518 - val_accuracy: 0.7616 - val_auc: 0.7725\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.77779\n",
      "Epoch 19/100\n",
      "905/905 - 43s - loss: 0.4432 - accuracy: 0.7902 - auc: 0.8815 - val_loss: 0.5955 - val_accuracy: 0.6599 - val_auc: 0.7855\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.77779 to 0.78553, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 20/100\n",
      "905/905 - 42s - loss: 0.4495 - accuracy: 0.8009 - auc: 0.8788 - val_loss: 0.7274 - val_accuracy: 0.5675 - val_auc: 0.7894\n",
      "\n",
      "Epoch 00020: val_auc improved from 0.78553 to 0.78938, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ARE\n",
      "Epoch 21/100\n",
      "905/905 - 42s - loss: 0.4351 - accuracy: 0.8135 - auc: 0.8883 - val_loss: 0.6423 - val_accuracy: 0.6396 - val_auc: 0.7718\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.78938\n",
      "Epoch 22/100\n",
      "905/905 - 43s - loss: 0.4178 - accuracy: 0.8168 - auc: 0.8967 - val_loss: 0.6777 - val_accuracy: 0.7283 - val_auc: 0.7707\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.78938\n",
      "Epoch 23/100\n",
      "905/905 - 43s - loss: 0.4111 - accuracy: 0.8218 - auc: 0.8990 - val_loss: 0.6940 - val_accuracy: 0.7153 - val_auc: 0.7615\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.78938\n",
      "Epoch 24/100\n",
      "905/905 - 42s - loss: 0.4097 - accuracy: 0.8123 - auc: 0.9000 - val_loss: 0.6832 - val_accuracy: 0.8004 - val_auc: 0.7627\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.78938\n",
      "Epoch 25/100\n",
      "905/905 - 42s - loss: 0.4044 - accuracy: 0.8173 - auc: 0.9034 - val_loss: 0.6940 - val_accuracy: 0.7486 - val_auc: 0.7683\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.78938\n",
      "Epoch 26/100\n",
      "905/905 - 42s - loss: 0.3816 - accuracy: 0.8363 - auc: 0.9148 - val_loss: 0.7402 - val_accuracy: 0.7449 - val_auc: 0.7549\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.78938\n",
      "Epoch 27/100\n",
      "905/905 - 42s - loss: 0.3836 - accuracy: 0.8240 - auc: 0.9133 - val_loss: 0.7558 - val_accuracy: 0.5915 - val_auc: 0.7597\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.78938\n",
      "Epoch 28/100\n",
      "905/905 - 42s - loss: 0.3760 - accuracy: 0.8361 - auc: 0.9175 - val_loss: 0.8244 - val_accuracy: 0.7856 - val_auc: 0.7605\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.78938\n",
      "Epoch 29/100\n",
      "905/905 - 42s - loss: 0.3680 - accuracy: 0.8387 - auc: 0.9218 - val_loss: 0.7485 - val_accuracy: 0.7985 - val_auc: 0.7518\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.78938\n",
      "Epoch 30/100\n",
      "905/905 - 42s - loss: 0.3769 - accuracy: 0.8311 - auc: 0.9170 - val_loss: 0.7097 - val_accuracy: 0.7135 - val_auc: 0.7588\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.78938\n",
      "Epoch 31/100\n",
      "905/905 - 42s - loss: 0.3888 - accuracy: 0.8291 - auc: 0.9153 - val_loss: 0.8520 - val_accuracy: 0.7449 - val_auc: 0.7510\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.78938\n",
      "Epoch 32/100\n",
      "905/905 - 43s - loss: 0.3484 - accuracy: 0.8489 - auc: 0.9300 - val_loss: 0.8243 - val_accuracy: 0.7190 - val_auc: 0.7639\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.78938\n",
      "Epoch 33/100\n",
      "905/905 - 42s - loss: 0.3748 - accuracy: 0.8425 - auc: 0.9192 - val_loss: 0.9596 - val_accuracy: 0.7190 - val_auc: 0.7497\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.78938\n",
      "Epoch 34/100\n",
      "905/905 - 42s - loss: 0.3581 - accuracy: 0.8383 - auc: 0.9263 - val_loss: 0.7349 - val_accuracy: 0.6654 - val_auc: 0.7520\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.78938\n",
      "Epoch 35/100\n",
      "905/905 - 43s - loss: 0.3418 - accuracy: 0.8558 - auc: 0.9330 - val_loss: 0.7015 - val_accuracy: 0.6654 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.78938\n",
      "Epoch 36/100\n",
      "905/905 - 43s - loss: 0.3311 - accuracy: 0.8540 - auc: 0.9369 - val_loss: 0.6979 - val_accuracy: 0.6433 - val_auc: 0.7519\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.78938\n",
      "Epoch 37/100\n",
      "905/905 - 42s - loss: 0.3315 - accuracy: 0.8670 - auc: 0.9375 - val_loss: 0.9024 - val_accuracy: 0.7689 - val_auc: 0.7432\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.78938\n",
      "Epoch 38/100\n",
      "905/905 - 42s - loss: 0.3301 - accuracy: 0.8504 - auc: 0.9369 - val_loss: 0.9181 - val_accuracy: 0.7893 - val_auc: 0.7548\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.78938\n",
      "Epoch 39/100\n",
      "905/905 - 42s - loss: 0.3143 - accuracy: 0.8633 - auc: 0.9440 - val_loss: 1.0203 - val_accuracy: 0.7616 - val_auc: 0.7575\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.78938\n",
      "Epoch 40/100\n",
      "905/905 - 42s - loss: 0.3288 - accuracy: 0.8536 - auc: 0.9387 - val_loss: 0.8818 - val_accuracy: 0.7486 - val_auc: 0.7399\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.78938\n",
      "Epoch 41/100\n",
      "905/905 - 42s - loss: 0.3130 - accuracy: 0.8618 - auc: 0.9439 - val_loss: 0.8619 - val_accuracy: 0.5823 - val_auc: 0.7515\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.78938\n",
      "Epoch 42/100\n",
      "905/905 - 42s - loss: 0.3103 - accuracy: 0.8597 - auc: 0.9445 - val_loss: 0.9346 - val_accuracy: 0.7542 - val_auc: 0.7500\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.78938\n",
      "Epoch 43/100\n",
      "905/905 - 42s - loss: 0.2970 - accuracy: 0.8712 - auc: 0.9498 - val_loss: 1.0192 - val_accuracy: 0.7782 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.78938\n",
      "Epoch 44/100\n",
      "905/905 - 42s - loss: 0.3019 - accuracy: 0.8616 - auc: 0.9471 - val_loss: 0.9269 - val_accuracy: 0.7264 - val_auc: 0.7336\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.78938\n",
      "Epoch 45/100\n",
      "905/905 - 42s - loss: 0.2836 - accuracy: 0.8814 - auc: 0.9536 - val_loss: 1.0983 - val_accuracy: 0.7874 - val_auc: 0.7512\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.78938\n",
      "Epoch 46/100\n",
      "905/905 - 42s - loss: 0.2912 - accuracy: 0.8695 - auc: 0.9516 - val_loss: 1.3521 - val_accuracy: 0.7449 - val_auc: 0.7199\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.78938\n",
      "Epoch 47/100\n",
      "905/905 - 42s - loss: 0.2784 - accuracy: 0.8759 - auc: 0.9567 - val_loss: 1.0016 - val_accuracy: 0.7301 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.78938\n",
      "Epoch 48/100\n",
      "905/905 - 42s - loss: 0.2792 - accuracy: 0.8785 - auc: 0.9555 - val_loss: 1.1232 - val_accuracy: 0.7357 - val_auc: 0.7551\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.78938\n",
      "Epoch 49/100\n",
      "905/905 - 42s - loss: 0.2900 - accuracy: 0.8662 - auc: 0.9511 - val_loss: 1.1076 - val_accuracy: 0.7726 - val_auc: 0.7580\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.78938\n",
      "Epoch 50/100\n",
      "905/905 - 42s - loss: 0.2741 - accuracy: 0.8743 - auc: 0.9578 - val_loss: 1.2121 - val_accuracy: 0.7874 - val_auc: 0.7543\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.78938\n",
      "Epoch 51/100\n",
      "905/905 - 42s - loss: 0.2688 - accuracy: 0.8772 - auc: 0.9577 - val_loss: 1.0373 - val_accuracy: 0.7431 - val_auc: 0.7647\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.78938\n",
      "Epoch 52/100\n",
      "905/905 - 42s - loss: 0.2621 - accuracy: 0.8860 - auc: 0.9611 - val_loss: 1.1224 - val_accuracy: 0.7745 - val_auc: 0.7515\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.78938\n",
      "Epoch 53/100\n",
      "905/905 - 42s - loss: 0.2563 - accuracy: 0.8840 - auc: 0.9625 - val_loss: 1.2381 - val_accuracy: 0.7320 - val_auc: 0.7401\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.78938\n",
      "Epoch 54/100\n",
      "905/905 - 42s - loss: 0.2504 - accuracy: 0.8882 - auc: 0.9637 - val_loss: 0.8894 - val_accuracy: 0.7098 - val_auc: 0.7706\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.78938\n",
      "Epoch 55/100\n",
      "905/905 - 42s - loss: 0.2585 - accuracy: 0.8844 - auc: 0.9627 - val_loss: 1.2013 - val_accuracy: 0.8041 - val_auc: 0.7410\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.78938\n",
      "Epoch 56/100\n",
      "905/905 - 42s - loss: 0.2558 - accuracy: 0.8905 - auc: 0.9624 - val_loss: 1.3046 - val_accuracy: 0.7616 - val_auc: 0.7389\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.78938\n",
      "Epoch 57/100\n",
      "905/905 - 42s - loss: 0.2537 - accuracy: 0.8889 - auc: 0.9632 - val_loss: 1.8827 - val_accuracy: 0.7856 - val_auc: 0.7415\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.78938\n",
      "Epoch 58/100\n",
      "905/905 - 42s - loss: 0.2434 - accuracy: 0.8913 - auc: 0.9660 - val_loss: 1.2701 - val_accuracy: 0.7227 - val_auc: 0.7220\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.78938\n",
      "Epoch 59/100\n",
      "905/905 - 42s - loss: 0.2201 - accuracy: 0.9089 - auc: 0.9723 - val_loss: 1.3550 - val_accuracy: 0.7468 - val_auc: 0.7599\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.78938\n",
      "Epoch 60/100\n",
      "905/905 - 42s - loss: 0.2318 - accuracy: 0.8973 - auc: 0.9693 - val_loss: 1.2903 - val_accuracy: 0.7616 - val_auc: 0.7610\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.78938\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 - 42s - loss: 0.2372 - accuracy: 0.8985 - auc: 0.9688 - val_loss: 1.4588 - val_accuracy: 0.7671 - val_auc: 0.7479\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.78938\n",
      "Epoch 62/100\n",
      "905/905 - 43s - loss: 0.2199 - accuracy: 0.9050 - auc: 0.9723 - val_loss: 1.3245 - val_accuracy: 0.7431 - val_auc: 0.7587\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.78938\n",
      "Epoch 63/100\n",
      "905/905 - 42s - loss: 0.2235 - accuracy: 0.9034 - auc: 0.9718 - val_loss: 1.5808 - val_accuracy: 0.7800 - val_auc: 0.7264\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.78938\n",
      "Epoch 64/100\n",
      "905/905 - 42s - loss: 0.2146 - accuracy: 0.9074 - auc: 0.9733 - val_loss: 1.2533 - val_accuracy: 0.7597 - val_auc: 0.7593\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.78938\n",
      "Epoch 65/100\n",
      "905/905 - 42s - loss: 0.2197 - accuracy: 0.9042 - auc: 0.9723 - val_loss: 1.5601 - val_accuracy: 0.7782 - val_auc: 0.7094\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.78938\n",
      "Epoch 66/100\n",
      "905/905 - 42s - loss: 0.2290 - accuracy: 0.8995 - auc: 0.9698 - val_loss: 1.2531 - val_accuracy: 0.8041 - val_auc: 0.7418\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.78938\n",
      "Epoch 67/100\n",
      "905/905 - 42s - loss: 0.2025 - accuracy: 0.9108 - auc: 0.9759 - val_loss: 1.2219 - val_accuracy: 0.7763 - val_auc: 0.7620\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.78938\n",
      "Epoch 68/100\n",
      "905/905 - 42s - loss: 0.2216 - accuracy: 0.9009 - auc: 0.9716 - val_loss: 1.1837 - val_accuracy: 0.7357 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.78938\n",
      "Epoch 69/100\n",
      "905/905 - 42s - loss: 0.2085 - accuracy: 0.9077 - auc: 0.9746 - val_loss: 1.4201 - val_accuracy: 0.7782 - val_auc: 0.7406\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.78938\n",
      "Epoch 70/100\n",
      "905/905 - 42s - loss: 0.1898 - accuracy: 0.9171 - auc: 0.9788 - val_loss: 1.4301 - val_accuracy: 0.7689 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.78938\n",
      "Epoch 71/100\n",
      "905/905 - 42s - loss: 0.1966 - accuracy: 0.9097 - auc: 0.9767 - val_loss: 0.9537 - val_accuracy: 0.7098 - val_auc: 0.7328\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.78938\n",
      "Epoch 72/100\n",
      "905/905 - 42s - loss: 0.2080 - accuracy: 0.9072 - auc: 0.9740 - val_loss: 1.4292 - val_accuracy: 0.7468 - val_auc: 0.7351\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.78938\n",
      "Epoch 73/100\n",
      "905/905 - 42s - loss: 0.1945 - accuracy: 0.9103 - auc: 0.9777 - val_loss: 1.5812 - val_accuracy: 0.7893 - val_auc: 0.7388\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.78938\n",
      "Epoch 74/100\n",
      "905/905 - 42s - loss: 0.1887 - accuracy: 0.9130 - auc: 0.9785 - val_loss: 1.3438 - val_accuracy: 0.7375 - val_auc: 0.7387\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.78938\n",
      "Epoch 75/100\n",
      "905/905 - 42s - loss: 0.2030 - accuracy: 0.9124 - auc: 0.9758 - val_loss: 1.4971 - val_accuracy: 0.7837 - val_auc: 0.7350\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.78938\n",
      "Epoch 76/100\n",
      "905/905 - 42s - loss: 0.1778 - accuracy: 0.9265 - auc: 0.9819 - val_loss: 1.5441 - val_accuracy: 0.7763 - val_auc: 0.7432\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.78938\n",
      "Epoch 77/100\n",
      "905/905 - 42s - loss: 0.1760 - accuracy: 0.9273 - auc: 0.9813 - val_loss: 1.7270 - val_accuracy: 0.7874 - val_auc: 0.7479\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.78938\n",
      "Epoch 78/100\n",
      "905/905 - 42s - loss: 0.1645 - accuracy: 0.9294 - auc: 0.9824 - val_loss: 2.2798 - val_accuracy: 0.7745 - val_auc: 0.7328\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.78938\n",
      "Epoch 79/100\n",
      "905/905 - 42s - loss: 0.1774 - accuracy: 0.9197 - auc: 0.9805 - val_loss: 2.2445 - val_accuracy: 0.7856 - val_auc: 0.7110\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.78938\n",
      "Epoch 80/100\n",
      "905/905 - 42s - loss: 0.1823 - accuracy: 0.9195 - auc: 0.9802 - val_loss: 1.9197 - val_accuracy: 0.7579 - val_auc: 0.7344\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.78938\n",
      "Epoch 81/100\n",
      "905/905 - 42s - loss: 0.1716 - accuracy: 0.9247 - auc: 0.9824 - val_loss: 1.4846 - val_accuracy: 0.7283 - val_auc: 0.7455\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.78938\n",
      "Epoch 82/100\n",
      "905/905 - 42s - loss: 0.1749 - accuracy: 0.9184 - auc: 0.9818 - val_loss: 1.6400 - val_accuracy: 0.7985 - val_auc: 0.7357\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.78938\n",
      "Epoch 83/100\n",
      "905/905 - 44s - loss: 0.1700 - accuracy: 0.9263 - auc: 0.9831 - val_loss: 1.7111 - val_accuracy: 0.7726 - val_auc: 0.7170\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.78938\n",
      "Epoch 84/100\n",
      "905/905 - 43s - loss: 0.1620 - accuracy: 0.9309 - auc: 0.9847 - val_loss: 1.5557 - val_accuracy: 0.7209 - val_auc: 0.7342\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.78938\n",
      "Epoch 85/100\n",
      "905/905 - 42s - loss: 0.1797 - accuracy: 0.9252 - auc: 0.9812 - val_loss: 2.5275 - val_accuracy: 0.7967 - val_auc: 0.7222\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.78938\n",
      "Epoch 86/100\n",
      "905/905 - 42s - loss: 0.1956 - accuracy: 0.9106 - auc: 0.9758 - val_loss: 1.9308 - val_accuracy: 0.7948 - val_auc: 0.7478\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.78938\n",
      "Epoch 87/100\n",
      "905/905 - 42s - loss: 0.1596 - accuracy: 0.9348 - auc: 0.9848 - val_loss: 1.6016 - val_accuracy: 0.7708 - val_auc: 0.7224\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.78938\n",
      "Epoch 88/100\n",
      "905/905 - 42s - loss: 0.1572 - accuracy: 0.9346 - auc: 0.9850 - val_loss: 1.6944 - val_accuracy: 0.7837 - val_auc: 0.7181\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.78938\n",
      "Epoch 89/100\n",
      "905/905 - 42s - loss: 0.1472 - accuracy: 0.9375 - auc: 0.9863 - val_loss: 1.4647 - val_accuracy: 0.7227 - val_auc: 0.7404\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.78938\n",
      "Epoch 90/100\n",
      "905/905 - 42s - loss: 0.1488 - accuracy: 0.9331 - auc: 0.9862 - val_loss: 1.8747 - val_accuracy: 0.7930 - val_auc: 0.7355\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.78938\n",
      "Epoch 91/100\n",
      "905/905 - 42s - loss: 0.1453 - accuracy: 0.9332 - auc: 0.9864 - val_loss: 1.7076 - val_accuracy: 0.7412 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.78938\n",
      "Epoch 92/100\n",
      "905/905 - 42s - loss: 0.1496 - accuracy: 0.9378 - auc: 0.9854 - val_loss: 1.4647 - val_accuracy: 0.7874 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.78938\n",
      "Epoch 93/100\n",
      "905/905 - 42s - loss: 0.1341 - accuracy: 0.9404 - auc: 0.9882 - val_loss: 2.3338 - val_accuracy: 0.8133 - val_auc: 0.7074\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.78938\n",
      "Epoch 94/100\n",
      "905/905 - 42s - loss: 0.1615 - accuracy: 0.9321 - auc: 0.9841 - val_loss: 1.7204 - val_accuracy: 0.7837 - val_auc: 0.7361\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.78938\n",
      "Epoch 95/100\n",
      "905/905 - 42s - loss: 0.1561 - accuracy: 0.9301 - auc: 0.9842 - val_loss: 2.5512 - val_accuracy: 0.8041 - val_auc: 0.7013\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.78938\n",
      "Epoch 96/100\n",
      "905/905 - 42s - loss: 0.1676 - accuracy: 0.9277 - auc: 0.9834 - val_loss: 1.3548 - val_accuracy: 0.7967 - val_auc: 0.7471\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.78938\n",
      "Epoch 97/100\n",
      "905/905 - 43s - loss: 0.1456 - accuracy: 0.9400 - auc: 0.9868 - val_loss: 1.6111 - val_accuracy: 0.7689 - val_auc: 0.7468\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.78938\n",
      "Epoch 98/100\n",
      "905/905 - 42s - loss: 0.1314 - accuracy: 0.9475 - auc: 0.9893 - val_loss: 1.8880 - val_accuracy: 0.8078 - val_auc: 0.7330\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.78938\n",
      "Epoch 99/100\n",
      "905/905 - 42s - loss: 0.1507 - accuracy: 0.9354 - auc: 0.9855 - val_loss: 1.4756 - val_accuracy: 0.7190 - val_auc: 0.7429\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.78938\n",
      "Epoch 100/100\n",
      "905/905 - 42s - loss: 0.1347 - accuracy: 0.9433 - auc: 0.9887 - val_loss: 1.7024 - val_accuracy: 0.7708 - val_auc: 0.7283\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.78938\n",
      "Epoch 1/100\n",
      "1136/1136 - 63s - loss: 0.9086 - accuracy: 0.4562 - auc: 0.5116 - val_loss: 0.9620 - val_accuracy: 0.4647 - val_auc: 0.7264\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.72644, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 2/100\n",
      "1136/1136 - 53s - loss: 0.7908 - accuracy: 0.6210 - auc: 0.6358 - val_loss: 0.9195 - val_accuracy: 0.8046 - val_auc: 0.7552\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.72644 to 0.75516, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 3/100\n",
      "1136/1136 - 53s - loss: 0.6804 - accuracy: 0.6589 - auc: 0.7393 - val_loss: 0.7643 - val_accuracy: 0.6223 - val_auc: 0.7680\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.75516 to 0.76803, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 - 53s - loss: 0.6070 - accuracy: 0.6803 - auc: 0.7799 - val_loss: 0.7152 - val_accuracy: 0.5993 - val_auc: 0.7903\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.76803 to 0.79033, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 5/100\n",
      "1136/1136 - 53s - loss: 0.5678 - accuracy: 0.7060 - auc: 0.8070 - val_loss: 0.7290 - val_accuracy: 0.6847 - val_auc: 0.7947\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.79033 to 0.79474, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 6/100\n",
      "1136/1136 - 53s - loss: 0.5308 - accuracy: 0.7049 - auc: 0.8289 - val_loss: 0.7042 - val_accuracy: 0.7044 - val_auc: 0.7957\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.79474 to 0.79574, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 7/100\n",
      "1136/1136 - 53s - loss: 0.5177 - accuracy: 0.7352 - auc: 0.8389 - val_loss: 0.7669 - val_accuracy: 0.6749 - val_auc: 0.7954\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.79574\n",
      "Epoch 8/100\n",
      "1136/1136 - 53s - loss: 0.4977 - accuracy: 0.7560 - auc: 0.8535 - val_loss: 0.7832 - val_accuracy: 0.7521 - val_auc: 0.7904\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79574\n",
      "Epoch 9/100\n",
      "1136/1136 - 53s - loss: 0.4863 - accuracy: 0.7716 - auc: 0.8649 - val_loss: 0.7253 - val_accuracy: 0.5993 - val_auc: 0.8057\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.79574 to 0.80573, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-ATAD5\n",
      "Epoch 10/100\n",
      "1136/1136 - 53s - loss: 0.4461 - accuracy: 0.7701 - auc: 0.8853 - val_loss: 0.7194 - val_accuracy: 0.6371 - val_auc: 0.7979\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.80573\n",
      "Epoch 11/100\n",
      "1136/1136 - 53s - loss: 0.4364 - accuracy: 0.7926 - auc: 0.8926 - val_loss: 0.7513 - val_accuracy: 0.6076 - val_auc: 0.7840\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.80573\n",
      "Epoch 12/100\n",
      "1136/1136 - 53s - loss: 0.4268 - accuracy: 0.7997 - auc: 0.8973 - val_loss: 0.8463 - val_accuracy: 0.7438 - val_auc: 0.7827\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.80573\n",
      "Epoch 13/100\n",
      "1136/1136 - 53s - loss: 0.4318 - accuracy: 0.7794 - auc: 0.8950 - val_loss: 1.1893 - val_accuracy: 0.7488 - val_auc: 0.7740\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.80573\n",
      "Epoch 14/100\n",
      "1136/1136 - 53s - loss: 0.4084 - accuracy: 0.8072 - auc: 0.9096 - val_loss: 1.0128 - val_accuracy: 0.7028 - val_auc: 0.7816\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.80573\n",
      "Epoch 15/100\n",
      "1136/1136 - 53s - loss: 0.4177 - accuracy: 0.7946 - auc: 0.9071 - val_loss: 0.7429 - val_accuracy: 0.5665 - val_auc: 0.7867\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.80573\n",
      "Epoch 16/100\n",
      "1136/1136 - 53s - loss: 0.4166 - accuracy: 0.8119 - auc: 0.9124 - val_loss: 1.4512 - val_accuracy: 0.7422 - val_auc: 0.7640\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.80573\n",
      "Epoch 17/100\n",
      "1136/1136 - 53s - loss: 0.3955 - accuracy: 0.8077 - auc: 0.9169 - val_loss: 0.9440 - val_accuracy: 0.7603 - val_auc: 0.7860\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.80573\n",
      "Epoch 18/100\n",
      "1136/1136 - 53s - loss: 0.3767 - accuracy: 0.8284 - auc: 0.9230 - val_loss: 0.8812 - val_accuracy: 0.6847 - val_auc: 0.8017\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.80573\n",
      "Epoch 19/100\n",
      "1136/1136 - 53s - loss: 0.4281 - accuracy: 0.8358 - auc: 0.9140 - val_loss: 1.2180 - val_accuracy: 0.7980 - val_auc: 0.7706\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.80573\n",
      "Epoch 20/100\n",
      "1136/1136 - 53s - loss: 0.3722 - accuracy: 0.8326 - auc: 0.9287 - val_loss: 1.1137 - val_accuracy: 0.8325 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.80573\n",
      "Epoch 21/100\n",
      "1136/1136 - 53s - loss: 0.3507 - accuracy: 0.8295 - auc: 0.9325 - val_loss: 1.1646 - val_accuracy: 0.8112 - val_auc: 0.7573\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.80573\n",
      "Epoch 22/100\n",
      "1136/1136 - 53s - loss: 0.3661 - accuracy: 0.8330 - auc: 0.9283 - val_loss: 1.3550 - val_accuracy: 0.7291 - val_auc: 0.7811\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.80573\n",
      "Epoch 23/100\n",
      "1136/1136 - 53s - loss: 0.3609 - accuracy: 0.8212 - auc: 0.9304 - val_loss: 1.7163 - val_accuracy: 0.7816 - val_auc: 0.7641\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.80573\n",
      "Epoch 24/100\n",
      "1136/1136 - 53s - loss: 0.3347 - accuracy: 0.8349 - auc: 0.9389 - val_loss: 0.8992 - val_accuracy: 0.4975 - val_auc: 0.7928\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.80573\n",
      "Epoch 25/100\n",
      "1136/1136 - 53s - loss: 0.4000 - accuracy: 0.8436 - auc: 0.9232 - val_loss: 1.4278 - val_accuracy: 0.7898 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.80573\n",
      "Epoch 26/100\n",
      "1136/1136 - 53s - loss: 0.3633 - accuracy: 0.8423 - auc: 0.9355 - val_loss: 1.4786 - val_accuracy: 0.7931 - val_auc: 0.7524\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.80573\n",
      "Epoch 27/100\n",
      "1136/1136 - 53s - loss: 0.3278 - accuracy: 0.8468 - auc: 0.9443 - val_loss: 1.2062 - val_accuracy: 0.8522 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.80573\n",
      "Epoch 28/100\n",
      "1136/1136 - 53s - loss: 0.3331 - accuracy: 0.8470 - auc: 0.9425 - val_loss: 1.6018 - val_accuracy: 0.8276 - val_auc: 0.7707\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.80573\n",
      "Epoch 29/100\n",
      "1136/1136 - 53s - loss: 0.3210 - accuracy: 0.8595 - auc: 0.9457 - val_loss: 0.9707 - val_accuracy: 0.6158 - val_auc: 0.7735\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.80573\n",
      "Epoch 30/100\n",
      "1136/1136 - 53s - loss: 0.3093 - accuracy: 0.8590 - auc: 0.9491 - val_loss: 1.4054 - val_accuracy: 0.8342 - val_auc: 0.7768\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.80573\n",
      "Epoch 31/100\n",
      "1136/1136 - 53s - loss: 0.3021 - accuracy: 0.8577 - auc: 0.9489 - val_loss: 1.5603 - val_accuracy: 0.7635 - val_auc: 0.7854\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.80573\n",
      "Epoch 32/100\n",
      "1136/1136 - 53s - loss: 0.2949 - accuracy: 0.8544 - auc: 0.9530 - val_loss: 1.0339 - val_accuracy: 0.6732 - val_auc: 0.7762\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.80573\n",
      "Epoch 33/100\n",
      "1136/1136 - 53s - loss: 0.2834 - accuracy: 0.8677 - auc: 0.9555 - val_loss: 2.6539 - val_accuracy: 0.7422 - val_auc: 0.7371\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.80573\n",
      "Epoch 34/100\n",
      "1136/1136 - 53s - loss: 0.3130 - accuracy: 0.8341 - auc: 0.9453 - val_loss: 3.3966 - val_accuracy: 0.8966 - val_auc: 0.7116\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.80573\n",
      "Epoch 35/100\n",
      "1136/1136 - 53s - loss: 0.2869 - accuracy: 0.8652 - auc: 0.9531 - val_loss: 1.1521 - val_accuracy: 0.8407 - val_auc: 0.7926\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.80573\n",
      "Epoch 36/100\n",
      "1136/1136 - 53s - loss: 0.2640 - accuracy: 0.8673 - auc: 0.9592 - val_loss: 1.2609 - val_accuracy: 0.6700 - val_auc: 0.7731\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.80573\n",
      "Epoch 37/100\n",
      "1136/1136 - 53s - loss: 0.2995 - accuracy: 0.8577 - auc: 0.9520 - val_loss: 1.2629 - val_accuracy: 0.7668 - val_auc: 0.7705\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.80573\n",
      "Epoch 38/100\n",
      "1136/1136 - 53s - loss: 0.2544 - accuracy: 0.8896 - auc: 0.9658 - val_loss: 3.6802 - val_accuracy: 0.8095 - val_auc: 0.7281\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.80573\n",
      "Epoch 39/100\n",
      "1136/1136 - 53s - loss: 0.3135 - accuracy: 0.8862 - auc: 0.9535 - val_loss: 2.1500 - val_accuracy: 0.8046 - val_auc: 0.7609\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.80573\n",
      "Epoch 40/100\n",
      "1136/1136 - 53s - loss: 0.2697 - accuracy: 0.8686 - auc: 0.9613 - val_loss: 4.9475 - val_accuracy: 0.8966 - val_auc: 0.6980\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.80573\n",
      "Epoch 41/100\n",
      "1136/1136 - 53s - loss: 0.2806 - accuracy: 0.8600 - auc: 0.9569 - val_loss: 2.1338 - val_accuracy: 0.8013 - val_auc: 0.7118\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.80573\n",
      "Epoch 42/100\n",
      "1136/1136 - 53s - loss: 0.2538 - accuracy: 0.8842 - auc: 0.9650 - val_loss: 3.2911 - val_accuracy: 0.8342 - val_auc: 0.7505\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.80573\n",
      "Epoch 43/100\n",
      "1136/1136 - 53s - loss: 0.2953 - accuracy: 0.8622 - auc: 0.9543 - val_loss: 2.9321 - val_accuracy: 0.8588 - val_auc: 0.7606\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.80573\n",
      "Epoch 44/100\n",
      "1136/1136 - 53s - loss: 0.2248 - accuracy: 0.8995 - auc: 0.9703 - val_loss: 2.3519 - val_accuracy: 0.7635 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.80573\n",
      "Epoch 45/100\n",
      "1136/1136 - 53s - loss: 0.2290 - accuracy: 0.8783 - auc: 0.9673 - val_loss: 2.4656 - val_accuracy: 0.8292 - val_auc: 0.7350\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.80573\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1136 - 53s - loss: 0.2852 - accuracy: 0.8735 - auc: 0.9572 - val_loss: 1.4272 - val_accuracy: 0.8489 - val_auc: 0.7791\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.80573\n",
      "Epoch 47/100\n",
      "1136/1136 - 53s - loss: 0.2731 - accuracy: 0.8783 - auc: 0.9608 - val_loss: 2.4968 - val_accuracy: 0.8686 - val_auc: 0.7131\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.80573\n",
      "Epoch 48/100\n",
      "1136/1136 - 53s - loss: 0.2280 - accuracy: 0.8926 - auc: 0.9681 - val_loss: 4.4666 - val_accuracy: 0.8883 - val_auc: 0.7312\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.80573\n",
      "Epoch 49/100\n",
      "1136/1136 - 53s - loss: 0.2757 - accuracy: 0.8764 - auc: 0.9594 - val_loss: 2.2944 - val_accuracy: 0.8456 - val_auc: 0.7540\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.80573\n",
      "Epoch 50/100\n",
      "1136/1136 - 53s - loss: 0.2326 - accuracy: 0.8785 - auc: 0.9653 - val_loss: 4.4018 - val_accuracy: 0.8604 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.80573\n",
      "Epoch 51/100\n",
      "1136/1136 - 53s - loss: 0.2544 - accuracy: 0.8571 - auc: 0.9626 - val_loss: 3.1662 - val_accuracy: 0.8292 - val_auc: 0.7403\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.80573\n",
      "Epoch 52/100\n",
      "1136/1136 - 53s - loss: 0.2386 - accuracy: 0.8721 - auc: 0.9658 - val_loss: 3.3251 - val_accuracy: 0.8424 - val_auc: 0.7499\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.80573\n",
      "Epoch 53/100\n",
      "1136/1136 - 53s - loss: 0.2240 - accuracy: 0.8799 - auc: 0.9691 - val_loss: 4.2319 - val_accuracy: 0.9031 - val_auc: 0.6988\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.80573\n",
      "Epoch 54/100\n",
      "1136/1136 - 53s - loss: 0.2872 - accuracy: 0.8923 - auc: 0.9626 - val_loss: 4.4106 - val_accuracy: 0.8555 - val_auc: 0.6857\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.80573\n",
      "Epoch 55/100\n",
      "1136/1136 - 53s - loss: 0.2152 - accuracy: 0.8916 - auc: 0.9722 - val_loss: 5.0404 - val_accuracy: 0.8818 - val_auc: 0.6791\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.80573\n",
      "Epoch 56/100\n",
      "1136/1136 - 53s - loss: 0.3132 - accuracy: 0.9022 - auc: 0.9584 - val_loss: 3.2098 - val_accuracy: 0.8768 - val_auc: 0.7153\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.80573\n",
      "Epoch 57/100\n",
      "1136/1136 - 53s - loss: 0.1990 - accuracy: 0.9161 - auc: 0.9782 - val_loss: 2.6823 - val_accuracy: 0.7816 - val_auc: 0.7349\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.80573\n",
      "Epoch 58/100\n",
      "1136/1136 - 53s - loss: 0.2225 - accuracy: 0.8897 - auc: 0.9736 - val_loss: 2.5916 - val_accuracy: 0.8473 - val_auc: 0.7340\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.80573\n",
      "Epoch 59/100\n",
      "1136/1136 - 53s - loss: 0.2061 - accuracy: 0.9089 - auc: 0.9740 - val_loss: 1.6775 - val_accuracy: 0.6256 - val_auc: 0.7213\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.80573\n",
      "Epoch 60/100\n",
      "1136/1136 - 53s - loss: 0.2521 - accuracy: 0.8739 - auc: 0.9636 - val_loss: 2.2889 - val_accuracy: 0.8079 - val_auc: 0.7622\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.80573\n",
      "Epoch 61/100\n",
      "1136/1136 - 53s - loss: 0.2132 - accuracy: 0.8892 - auc: 0.9723 - val_loss: 1.8734 - val_accuracy: 0.7553 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.80573\n",
      "Epoch 62/100\n",
      "1136/1136 - 53s - loss: 0.2267 - accuracy: 0.8938 - auc: 0.9696 - val_loss: 2.9041 - val_accuracy: 0.7422 - val_auc: 0.7138\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.80573\n",
      "Epoch 63/100\n",
      "1136/1136 - 53s - loss: 0.2033 - accuracy: 0.9079 - auc: 0.9770 - val_loss: 4.4302 - val_accuracy: 0.8506 - val_auc: 0.7123\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.80573\n",
      "Epoch 64/100\n",
      "1136/1136 - 53s - loss: 0.2014 - accuracy: 0.8998 - auc: 0.9751 - val_loss: 4.3074 - val_accuracy: 0.8177 - val_auc: 0.7024\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.80573\n",
      "Epoch 65/100\n",
      "1136/1136 - 53s - loss: 0.1964 - accuracy: 0.9120 - auc: 0.9766 - val_loss: 3.0691 - val_accuracy: 0.8456 - val_auc: 0.7464\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.80573\n",
      "Epoch 66/100\n",
      "1136/1136 - 53s - loss: 0.2141 - accuracy: 0.8986 - auc: 0.9720 - val_loss: 2.0412 - val_accuracy: 0.7947 - val_auc: 0.7583\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.80573\n",
      "Epoch 67/100\n",
      "1136/1136 - 53s - loss: 0.2097 - accuracy: 0.9143 - auc: 0.9753 - val_loss: 3.0171 - val_accuracy: 0.8654 - val_auc: 0.7247\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.80573\n",
      "Epoch 68/100\n",
      "1136/1136 - 53s - loss: 0.2256 - accuracy: 0.8959 - auc: 0.9721 - val_loss: 1.9116 - val_accuracy: 0.7865 - val_auc: 0.7393\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.80573\n",
      "Epoch 69/100\n",
      "1136/1136 - 53s - loss: 0.2144 - accuracy: 0.9089 - auc: 0.9765 - val_loss: 3.6748 - val_accuracy: 0.8506 - val_auc: 0.7345\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.80573\n",
      "Epoch 70/100\n",
      "1136/1136 - 53s - loss: 0.1855 - accuracy: 0.9155 - auc: 0.9791 - val_loss: 3.0156 - val_accuracy: 0.8637 - val_auc: 0.6810\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.80573\n",
      "Epoch 71/100\n",
      "1136/1136 - 53s - loss: 0.2186 - accuracy: 0.8981 - auc: 0.9735 - val_loss: 3.5546 - val_accuracy: 0.8440 - val_auc: 0.7168\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.80573\n",
      "Epoch 72/100\n",
      "1136/1136 - 53s - loss: 0.1843 - accuracy: 0.9263 - auc: 0.9788 - val_loss: 4.7017 - val_accuracy: 0.8654 - val_auc: 0.6982\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.80573\n",
      "Epoch 73/100\n",
      "1136/1136 - 53s - loss: 0.1713 - accuracy: 0.9191 - auc: 0.9808 - val_loss: 4.4886 - val_accuracy: 0.8686 - val_auc: 0.7034\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.80573\n",
      "Epoch 74/100\n",
      "1136/1136 - 53s - loss: 0.1860 - accuracy: 0.9137 - auc: 0.9782 - val_loss: 4.0035 - val_accuracy: 0.8768 - val_auc: 0.6657\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.80573\n",
      "Epoch 75/100\n",
      "1136/1136 - 53s - loss: 0.1773 - accuracy: 0.9310 - auc: 0.9787 - val_loss: 5.4534 - val_accuracy: 0.8949 - val_auc: 0.6926\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.80573\n",
      "Epoch 76/100\n",
      "1136/1136 - 53s - loss: 0.2121 - accuracy: 0.9037 - auc: 0.9738 - val_loss: 4.2133 - val_accuracy: 0.7734 - val_auc: 0.6961\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.80573\n",
      "Epoch 77/100\n",
      "1136/1136 - 53s - loss: 0.2087 - accuracy: 0.9115 - auc: 0.9778 - val_loss: 5.7360 - val_accuracy: 0.8966 - val_auc: 0.6898\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.80573\n",
      "Epoch 78/100\n",
      "1136/1136 - 53s - loss: 0.1658 - accuracy: 0.9403 - auc: 0.9826 - val_loss: 3.5906 - val_accuracy: 0.8768 - val_auc: 0.7025\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.80573\n",
      "Epoch 79/100\n",
      "1136/1136 - 52s - loss: 0.1927 - accuracy: 0.9112 - auc: 0.9787 - val_loss: 3.3305 - val_accuracy: 0.8062 - val_auc: 0.7587\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.80573\n",
      "Epoch 80/100\n",
      "1136/1136 - 53s - loss: 0.2070 - accuracy: 0.8980 - auc: 0.9769 - val_loss: 2.8926 - val_accuracy: 0.7635 - val_auc: 0.7043\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.80573\n",
      "Epoch 81/100\n",
      "1136/1136 - 53s - loss: 0.1802 - accuracy: 0.9170 - auc: 0.9816 - val_loss: 2.3966 - val_accuracy: 0.8194 - val_auc: 0.7612\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.80573\n",
      "Epoch 82/100\n",
      "1136/1136 - 53s - loss: 0.1935 - accuracy: 0.9143 - auc: 0.9758 - val_loss: 5.8832 - val_accuracy: 0.8933 - val_auc: 0.6636\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.80573\n",
      "Epoch 83/100\n",
      "1136/1136 - 53s - loss: 0.2067 - accuracy: 0.9081 - auc: 0.9751 - val_loss: 2.8172 - val_accuracy: 0.7734 - val_auc: 0.7315\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.80573\n",
      "Epoch 84/100\n",
      "1136/1136 - 53s - loss: 0.1759 - accuracy: 0.9151 - auc: 0.9800 - val_loss: 4.3649 - val_accuracy: 0.8571 - val_auc: 0.7000\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.80573\n",
      "Epoch 85/100\n",
      "1136/1136 - 53s - loss: 0.1586 - accuracy: 0.9363 - auc: 0.9835 - val_loss: 2.2770 - val_accuracy: 0.8785 - val_auc: 0.7519\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.80573\n",
      "Epoch 86/100\n",
      "1136/1136 - 53s - loss: 0.1768 - accuracy: 0.9187 - auc: 0.9812 - val_loss: 5.4054 - val_accuracy: 0.8736 - val_auc: 0.7135\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.80573\n",
      "Epoch 87/100\n",
      "1136/1136 - 53s - loss: 0.2029 - accuracy: 0.9164 - auc: 0.9784 - val_loss: 2.8560 - val_accuracy: 0.8046 - val_auc: 0.7180\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.80573\n",
      "Epoch 88/100\n",
      "1136/1136 - 53s - loss: 0.1881 - accuracy: 0.9238 - auc: 0.9802 - val_loss: 3.2705 - val_accuracy: 0.8555 - val_auc: 0.7236\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.80573\n",
      "Epoch 89/100\n",
      "1136/1136 - 53s - loss: 0.1321 - accuracy: 0.9476 - auc: 0.9872 - val_loss: 2.7558 - val_accuracy: 0.7406 - val_auc: 0.7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: val_auc did not improve from 0.80573\n",
      "Epoch 90/100\n",
      "1136/1136 - 53s - loss: 0.1709 - accuracy: 0.9164 - auc: 0.9817 - val_loss: 6.2167 - val_accuracy: 0.8867 - val_auc: 0.6980\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.80573\n",
      "Epoch 91/100\n",
      "1136/1136 - 53s - loss: 0.1858 - accuracy: 0.9166 - auc: 0.9820 - val_loss: 4.6859 - val_accuracy: 0.8719 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.80573\n",
      "Epoch 92/100\n",
      "1136/1136 - 53s - loss: 0.1794 - accuracy: 0.9211 - auc: 0.9810 - val_loss: 4.0455 - val_accuracy: 0.7980 - val_auc: 0.7156\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.80573\n",
      "Epoch 93/100\n",
      "1136/1136 - 53s - loss: 0.1708 - accuracy: 0.9228 - auc: 0.9827 - val_loss: 5.0493 - val_accuracy: 0.8670 - val_auc: 0.6740\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.80573\n",
      "Epoch 94/100\n",
      "1136/1136 - 53s - loss: 0.1702 - accuracy: 0.9255 - auc: 0.9824 - val_loss: 4.9486 - val_accuracy: 0.8588 - val_auc: 0.6985\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.80573\n",
      "Epoch 95/100\n",
      "1136/1136 - 53s - loss: 0.1998 - accuracy: 0.9072 - auc: 0.9795 - val_loss: 3.4565 - val_accuracy: 0.8309 - val_auc: 0.6969\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.80573\n",
      "Epoch 96/100\n",
      "1136/1136 - 53s - loss: 0.1647 - accuracy: 0.9336 - auc: 0.9856 - val_loss: 4.9308 - val_accuracy: 0.8998 - val_auc: 0.6722\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.80573\n",
      "Epoch 97/100\n",
      "1136/1136 - 53s - loss: 0.1427 - accuracy: 0.9442 - auc: 0.9863 - val_loss: 6.1062 - val_accuracy: 0.8916 - val_auc: 0.6822\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.80573\n",
      "Epoch 98/100\n",
      "1136/1136 - 53s - loss: 0.1339 - accuracy: 0.9429 - auc: 0.9877 - val_loss: 5.5447 - val_accuracy: 0.8818 - val_auc: 0.6778\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.80573\n",
      "Epoch 99/100\n",
      "1136/1136 - 53s - loss: 0.2130 - accuracy: 0.9172 - auc: 0.9773 - val_loss: 4.1862 - val_accuracy: 0.8736 - val_auc: 0.7044\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.80573\n",
      "Epoch 100/100\n",
      "1136/1136 - 53s - loss: 0.1414 - accuracy: 0.9411 - auc: 0.9871 - val_loss: 6.0904 - val_accuracy: 0.8916 - val_auc: 0.6872\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.80573\n",
      "Epoch 1/100\n",
      "1028/1028 - 58s - loss: 0.8708 - accuracy: 0.4243 - auc: 0.4938 - val_loss: 0.6997 - val_accuracy: 0.0436 - val_auc: 0.7040\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.70396, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 2/100\n",
      "1028/1028 - 48s - loss: 0.8141 - accuracy: 0.4876 - auc: 0.5333 - val_loss: 0.6594 - val_accuracy: 0.2735 - val_auc: 0.7171\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.70396 to 0.71714, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 3/100\n",
      "1028/1028 - 48s - loss: 0.7077 - accuracy: 0.6200 - auc: 0.6802 - val_loss: 0.5679 - val_accuracy: 0.6258 - val_auc: 0.7839\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.71714 to 0.78386, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 4/100\n",
      "1028/1028 - 48s - loss: 0.6374 - accuracy: 0.6673 - auc: 0.7392 - val_loss: 0.4685 - val_accuracy: 0.7584 - val_auc: 0.8120\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.78386 to 0.81196, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 5/100\n",
      "1028/1028 - 48s - loss: 0.6055 - accuracy: 0.7132 - auc: 0.7624 - val_loss: 0.4692 - val_accuracy: 0.8356 - val_auc: 0.8071\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.81196\n",
      "Epoch 6/100\n",
      "1028/1028 - 48s - loss: 0.5770 - accuracy: 0.7131 - auc: 0.7888 - val_loss: 0.4908 - val_accuracy: 0.6678 - val_auc: 0.7880\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.81196\n",
      "Epoch 7/100\n",
      "1028/1028 - 48s - loss: 0.5534 - accuracy: 0.7132 - auc: 0.8036 - val_loss: 0.4479 - val_accuracy: 0.6913 - val_auc: 0.8232\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.81196 to 0.82318, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 8/100\n",
      "1028/1028 - 48s - loss: 0.5544 - accuracy: 0.7217 - auc: 0.8063 - val_loss: 0.6029 - val_accuracy: 0.1074 - val_auc: 0.7951\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.82318\n",
      "Epoch 9/100\n",
      "1028/1028 - 48s - loss: 0.5531 - accuracy: 0.7560 - auc: 0.8056 - val_loss: 0.4774 - val_accuracy: 0.7114 - val_auc: 0.8264\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.82318 to 0.82642, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 10/100\n",
      "1028/1028 - 48s - loss: 0.5246 - accuracy: 0.7520 - auc: 0.8253 - val_loss: 0.5170 - val_accuracy: 0.5587 - val_auc: 0.7892\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.82642\n",
      "Epoch 11/100\n",
      "1028/1028 - 48s - loss: 0.5394 - accuracy: 0.7649 - auc: 0.8194 - val_loss: 0.4785 - val_accuracy: 0.7315 - val_auc: 0.8142\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.82642\n",
      "Epoch 12/100\n",
      "1028/1028 - 48s - loss: 0.5205 - accuracy: 0.7936 - auc: 0.8378 - val_loss: 0.4528 - val_accuracy: 0.7903 - val_auc: 0.8267\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.82642 to 0.82669, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 13/100\n",
      "1028/1028 - 48s - loss: 0.5063 - accuracy: 0.7778 - auc: 0.8415 - val_loss: 0.4352 - val_accuracy: 0.7869 - val_auc: 0.8345\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.82669 to 0.83449, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-HSE\n",
      "Epoch 14/100\n",
      "1028/1028 - 48s - loss: 0.4967 - accuracy: 0.7829 - auc: 0.8474 - val_loss: 0.4696 - val_accuracy: 0.7299 - val_auc: 0.8207\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.83449\n",
      "Epoch 15/100\n",
      "1028/1028 - 48s - loss: 0.5117 - accuracy: 0.7816 - auc: 0.8456 - val_loss: 0.5232 - val_accuracy: 0.7013 - val_auc: 0.8020\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.83449\n",
      "Epoch 16/100\n",
      "1028/1028 - 48s - loss: 0.5060 - accuracy: 0.7979 - auc: 0.8467 - val_loss: 0.4962 - val_accuracy: 0.7215 - val_auc: 0.8040\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.83449\n",
      "Epoch 17/100\n",
      "1028/1028 - 48s - loss: 0.4757 - accuracy: 0.8161 - auc: 0.8658 - val_loss: 0.5734 - val_accuracy: 0.6208 - val_auc: 0.7948\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.83449\n",
      "Epoch 18/100\n",
      "1028/1028 - 48s - loss: 0.4806 - accuracy: 0.8165 - auc: 0.8649 - val_loss: 0.4852 - val_accuracy: 0.8003 - val_auc: 0.7984\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.83449\n",
      "Epoch 19/100\n",
      "1028/1028 - 48s - loss: 0.5036 - accuracy: 0.8026 - auc: 0.8513 - val_loss: 0.4557 - val_accuracy: 0.8221 - val_auc: 0.8134\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.83449\n",
      "Epoch 20/100\n",
      "1028/1028 - 48s - loss: 0.4691 - accuracy: 0.8182 - auc: 0.8653 - val_loss: 0.4866 - val_accuracy: 0.7315 - val_auc: 0.8031\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.83449\n",
      "Epoch 21/100\n",
      "1028/1028 - 48s - loss: 0.4484 - accuracy: 0.8312 - auc: 0.8792 - val_loss: 0.4989 - val_accuracy: 0.7768 - val_auc: 0.8143\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.83449\n",
      "Epoch 22/100\n",
      "1028/1028 - 48s - loss: 0.4542 - accuracy: 0.8202 - auc: 0.8786 - val_loss: 0.5305 - val_accuracy: 0.6980 - val_auc: 0.7939\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.83449\n",
      "Epoch 23/100\n",
      "1028/1028 - 48s - loss: 0.4425 - accuracy: 0.7986 - auc: 0.8816 - val_loss: 0.6488 - val_accuracy: 0.5990 - val_auc: 0.7966\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.83449\n",
      "Epoch 24/100\n",
      "1028/1028 - 48s - loss: 0.4532 - accuracy: 0.8167 - auc: 0.8811 - val_loss: 0.5476 - val_accuracy: 0.6409 - val_auc: 0.8036\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.83449\n",
      "Epoch 25/100\n",
      "1028/1028 - 48s - loss: 0.4444 - accuracy: 0.8248 - auc: 0.8854 - val_loss: 0.5956 - val_accuracy: 0.7047 - val_auc: 0.8192\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.83449\n",
      "Epoch 26/100\n",
      "1028/1028 - 48s - loss: 0.4304 - accuracy: 0.8184 - auc: 0.8912 - val_loss: 0.5851 - val_accuracy: 0.8003 - val_auc: 0.7825\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.83449\n",
      "Epoch 27/100\n",
      "1028/1028 - 48s - loss: 0.4329 - accuracy: 0.8384 - auc: 0.8881 - val_loss: 0.6832 - val_accuracy: 0.8674 - val_auc: 0.7762\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.83449\n",
      "Epoch 28/100\n",
      "1028/1028 - 48s - loss: 0.4267 - accuracy: 0.8550 - auc: 0.8933 - val_loss: 0.5658 - val_accuracy: 0.6527 - val_auc: 0.7989\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.83449\n",
      "Epoch 29/100\n",
      "1028/1028 - 48s - loss: 0.4144 - accuracy: 0.8388 - auc: 0.9035 - val_loss: 0.5924 - val_accuracy: 0.6191 - val_auc: 0.7888\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.83449\n",
      "Epoch 30/100\n",
      "1028/1028 - 48s - loss: 0.4320 - accuracy: 0.8343 - auc: 0.8925 - val_loss: 0.5087 - val_accuracy: 0.8138 - val_auc: 0.7659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_auc did not improve from 0.83449\n",
      "Epoch 31/100\n",
      "1028/1028 - 48s - loss: 0.4341 - accuracy: 0.8397 - auc: 0.8903 - val_loss: 0.5625 - val_accuracy: 0.8121 - val_auc: 0.7673\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.83449\n",
      "Epoch 32/100\n",
      "1028/1028 - 48s - loss: 0.4057 - accuracy: 0.8489 - auc: 0.9042 - val_loss: 0.5878 - val_accuracy: 0.7584 - val_auc: 0.7605\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.83449\n",
      "Epoch 33/100\n",
      "1028/1028 - 48s - loss: 0.4130 - accuracy: 0.8275 - auc: 0.9006 - val_loss: 0.4886 - val_accuracy: 0.7886 - val_auc: 0.7658\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.83449\n",
      "Epoch 34/100\n",
      "1028/1028 - 48s - loss: 0.3895 - accuracy: 0.8525 - auc: 0.9131 - val_loss: 0.6485 - val_accuracy: 0.7450 - val_auc: 0.7074\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.83449\n",
      "Epoch 35/100\n",
      "1028/1028 - 48s - loss: 0.3828 - accuracy: 0.8592 - auc: 0.9173 - val_loss: 0.6138 - val_accuracy: 0.7282 - val_auc: 0.7794\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.83449\n",
      "Epoch 36/100\n",
      "1028/1028 - 48s - loss: 0.3706 - accuracy: 0.8588 - auc: 0.9203 - val_loss: 0.9033 - val_accuracy: 0.8070 - val_auc: 0.7095\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.83449\n",
      "Epoch 37/100\n",
      "1028/1028 - 48s - loss: 0.3665 - accuracy: 0.8629 - auc: 0.9236 - val_loss: 0.7224 - val_accuracy: 0.6057 - val_auc: 0.7662\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.83449\n",
      "Epoch 38/100\n",
      "1028/1028 - 48s - loss: 0.4147 - accuracy: 0.7940 - auc: 0.9027 - val_loss: 0.7118 - val_accuracy: 0.5940 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.83449\n",
      "Epoch 39/100\n",
      "1028/1028 - 48s - loss: 0.3987 - accuracy: 0.8082 - auc: 0.9138 - val_loss: 0.6494 - val_accuracy: 0.4916 - val_auc: 0.7765\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.83449\n",
      "Epoch 40/100\n",
      "1028/1028 - 48s - loss: 0.3934 - accuracy: 0.8020 - auc: 0.9151 - val_loss: 0.8653 - val_accuracy: 0.8574 - val_auc: 0.7188\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.83449\n",
      "Epoch 41/100\n",
      "1028/1028 - 48s - loss: 0.3737 - accuracy: 0.8376 - auc: 0.9221 - val_loss: 0.7585 - val_accuracy: 0.8691 - val_auc: 0.7668\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.83449\n",
      "Epoch 42/100\n",
      "1028/1028 - 48s - loss: 0.3580 - accuracy: 0.8323 - auc: 0.9266 - val_loss: 1.0037 - val_accuracy: 0.6862 - val_auc: 0.7100\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.83449\n",
      "Epoch 43/100\n",
      "1028/1028 - 48s - loss: 0.3596 - accuracy: 0.8276 - auc: 0.9306 - val_loss: 0.6753 - val_accuracy: 0.7416 - val_auc: 0.7715\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.83449\n",
      "Epoch 44/100\n",
      "1028/1028 - 48s - loss: 0.3398 - accuracy: 0.8478 - auc: 0.9363 - val_loss: 0.9937 - val_accuracy: 0.8087 - val_auc: 0.7320\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.83449\n",
      "Epoch 45/100\n",
      "1028/1028 - 48s - loss: 0.3284 - accuracy: 0.8562 - auc: 0.9411 - val_loss: 1.0892 - val_accuracy: 0.8960 - val_auc: 0.6947\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.83449\n",
      "Epoch 46/100\n",
      "1028/1028 - 48s - loss: 0.3185 - accuracy: 0.8377 - auc: 0.9429 - val_loss: 0.8651 - val_accuracy: 0.7517 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.83449\n",
      "Epoch 47/100\n",
      "1028/1028 - 48s - loss: 0.3180 - accuracy: 0.8485 - auc: 0.9439 - val_loss: 1.0091 - val_accuracy: 0.8003 - val_auc: 0.7274\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.83449\n",
      "Epoch 48/100\n",
      "1028/1028 - 48s - loss: 0.3148 - accuracy: 0.8478 - auc: 0.9449 - val_loss: 1.1487 - val_accuracy: 0.7919 - val_auc: 0.7409\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.83449\n",
      "Epoch 49/100\n",
      "1028/1028 - 48s - loss: 0.3292 - accuracy: 0.8564 - auc: 0.9408 - val_loss: 0.6490 - val_accuracy: 0.8322 - val_auc: 0.7375\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.83449\n",
      "Epoch 50/100\n",
      "1028/1028 - 48s - loss: 0.3022 - accuracy: 0.8863 - auc: 0.9533 - val_loss: 1.0481 - val_accuracy: 0.7534 - val_auc: 0.7150\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.83449\n",
      "Epoch 51/100\n",
      "1028/1028 - 48s - loss: 0.3072 - accuracy: 0.8799 - auc: 0.9495 - val_loss: 0.7084 - val_accuracy: 0.6745 - val_auc: 0.7680\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.83449\n",
      "Epoch 52/100\n",
      "1028/1028 - 48s - loss: 0.2908 - accuracy: 0.8734 - auc: 0.9540 - val_loss: 0.6992 - val_accuracy: 0.8674 - val_auc: 0.7658\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.83449\n",
      "Epoch 53/100\n",
      "1028/1028 - 48s - loss: 0.3067 - accuracy: 0.8725 - auc: 0.9482 - val_loss: 0.6885 - val_accuracy: 0.7232 - val_auc: 0.7742\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.83449\n",
      "Epoch 54/100\n",
      "1028/1028 - 48s - loss: 0.2898 - accuracy: 0.8769 - auc: 0.9548 - val_loss: 1.0476 - val_accuracy: 0.6644 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.83449\n",
      "Epoch 55/100\n",
      "1028/1028 - 48s - loss: 0.3104 - accuracy: 0.8630 - auc: 0.9508 - val_loss: 0.8678 - val_accuracy: 0.8255 - val_auc: 0.7360\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.83449\n",
      "Epoch 56/100\n",
      "1028/1028 - 48s - loss: 0.2956 - accuracy: 0.8842 - auc: 0.9535 - val_loss: 1.0174 - val_accuracy: 0.8758 - val_auc: 0.7134\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.83449\n",
      "Epoch 57/100\n",
      "1028/1028 - 48s - loss: 0.2607 - accuracy: 0.8922 - auc: 0.9626 - val_loss: 1.5413 - val_accuracy: 0.8708 - val_auc: 0.6974\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.83449\n",
      "Epoch 58/100\n",
      "1028/1028 - 48s - loss: 0.2854 - accuracy: 0.8846 - auc: 0.9575 - val_loss: 1.0223 - val_accuracy: 0.8574 - val_auc: 0.7048\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.83449\n",
      "Epoch 59/100\n",
      "1028/1028 - 48s - loss: 0.2896 - accuracy: 0.8919 - auc: 0.9555 - val_loss: 0.7618 - val_accuracy: 0.8305 - val_auc: 0.7650\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.83449\n",
      "Epoch 60/100\n",
      "1028/1028 - 48s - loss: 0.2851 - accuracy: 0.8698 - auc: 0.9576 - val_loss: 0.7991 - val_accuracy: 0.8238 - val_auc: 0.7357\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.83449\n",
      "Epoch 61/100\n",
      "1028/1028 - 48s - loss: 0.2535 - accuracy: 0.9016 - auc: 0.9670 - val_loss: 1.2732 - val_accuracy: 0.8842 - val_auc: 0.7032\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.83449\n",
      "Epoch 62/100\n",
      "1028/1028 - 48s - loss: 0.2686 - accuracy: 0.8706 - auc: 0.9621 - val_loss: 0.6731 - val_accuracy: 0.7097 - val_auc: 0.7652\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.83449\n",
      "Epoch 63/100\n",
      "1028/1028 - 48s - loss: 0.3102 - accuracy: 0.8799 - auc: 0.9527 - val_loss: 0.7282 - val_accuracy: 0.7886 - val_auc: 0.7195\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.83449\n",
      "Epoch 64/100\n",
      "1028/1028 - 48s - loss: 0.2789 - accuracy: 0.8822 - auc: 0.9616 - val_loss: 1.0528 - val_accuracy: 0.7668 - val_auc: 0.7436\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.83449\n",
      "Epoch 65/100\n",
      "1028/1028 - 48s - loss: 0.2742 - accuracy: 0.8877 - auc: 0.9627 - val_loss: 0.6135 - val_accuracy: 0.7701 - val_auc: 0.7632\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.83449\n",
      "Epoch 66/100\n",
      "1028/1028 - 48s - loss: 0.2470 - accuracy: 0.8982 - auc: 0.9700 - val_loss: 0.7803 - val_accuracy: 0.8909 - val_auc: 0.7579\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.83449\n",
      "Epoch 67/100\n",
      "1028/1028 - 48s - loss: 0.2522 - accuracy: 0.9019 - auc: 0.9677 - val_loss: 0.9826 - val_accuracy: 0.6326 - val_auc: 0.7557\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.83449\n",
      "Epoch 68/100\n",
      "1028/1028 - 48s - loss: 0.2404 - accuracy: 0.8938 - auc: 0.9702 - val_loss: 1.1701 - val_accuracy: 0.8775 - val_auc: 0.7345\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.83449\n",
      "Epoch 69/100\n",
      "1028/1028 - 48s - loss: 0.2506 - accuracy: 0.8835 - auc: 0.9672 - val_loss: 0.9184 - val_accuracy: 0.8322 - val_auc: 0.7539\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.83449\n",
      "Epoch 70/100\n",
      "1028/1028 - 48s - loss: 0.2450 - accuracy: 0.9041 - auc: 0.9700 - val_loss: 0.6878 - val_accuracy: 0.8591 - val_auc: 0.7613\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.83449\n",
      "Epoch 71/100\n",
      "1028/1028 - 48s - loss: 0.2301 - accuracy: 0.8995 - auc: 0.9730 - val_loss: 1.0120 - val_accuracy: 0.8138 - val_auc: 0.7574\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.83449\n",
      "Epoch 72/100\n",
      "1028/1028 - 48s - loss: 0.2860 - accuracy: 0.8817 - auc: 0.9607 - val_loss: 1.0543 - val_accuracy: 0.8423 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.83449\n",
      "Epoch 73/100\n",
      "1028/1028 - 48s - loss: 0.2449 - accuracy: 0.8921 - auc: 0.9705 - val_loss: 1.5888 - val_accuracy: 0.8977 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.83449\n",
      "Epoch 74/100\n",
      "1028/1028 - 48s - loss: 0.2372 - accuracy: 0.8826 - auc: 0.9700 - val_loss: 1.5206 - val_accuracy: 0.7718 - val_auc: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_auc did not improve from 0.83449\n",
      "Epoch 75/100\n",
      "1028/1028 - 48s - loss: 0.2678 - accuracy: 0.8756 - auc: 0.9641 - val_loss: 0.9983 - val_accuracy: 0.8238 - val_auc: 0.7699\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.83449\n",
      "Epoch 76/100\n",
      "1028/1028 - 48s - loss: 0.2249 - accuracy: 0.8985 - auc: 0.9757 - val_loss: 1.4086 - val_accuracy: 0.8775 - val_auc: 0.7489\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.83449\n",
      "Epoch 77/100\n",
      "1028/1028 - 48s - loss: 0.2338 - accuracy: 0.8980 - auc: 0.9742 - val_loss: 1.0320 - val_accuracy: 0.7970 - val_auc: 0.6931\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.83449\n",
      "Epoch 78/100\n",
      "1028/1028 - 48s - loss: 0.2430 - accuracy: 0.8992 - auc: 0.9714 - val_loss: 1.0654 - val_accuracy: 0.8523 - val_auc: 0.7484\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.83449\n",
      "Epoch 79/100\n",
      "1028/1028 - 48s - loss: 0.2386 - accuracy: 0.9098 - auc: 0.9743 - val_loss: 1.0812 - val_accuracy: 0.8406 - val_auc: 0.7327\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.83449\n",
      "Epoch 80/100\n",
      "1028/1028 - 48s - loss: 0.2253 - accuracy: 0.9030 - auc: 0.9755 - val_loss: 1.1844 - val_accuracy: 0.8020 - val_auc: 0.7472\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.83449\n",
      "Epoch 81/100\n",
      "1028/1028 - 48s - loss: 0.2306 - accuracy: 0.9107 - auc: 0.9751 - val_loss: 0.7068 - val_accuracy: 0.8591 - val_auc: 0.7046\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.83449\n",
      "Epoch 82/100\n",
      "1028/1028 - 48s - loss: 0.2050 - accuracy: 0.9263 - auc: 0.9803 - val_loss: 1.9639 - val_accuracy: 0.9312 - val_auc: 0.6686\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.83449\n",
      "Epoch 83/100\n",
      "1028/1028 - 48s - loss: 0.2358 - accuracy: 0.9046 - auc: 0.9717 - val_loss: 0.9869 - val_accuracy: 0.5822 - val_auc: 0.7588\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.83449\n",
      "Epoch 84/100\n",
      "1028/1028 - 48s - loss: 0.2182 - accuracy: 0.9096 - auc: 0.9768 - val_loss: 1.0120 - val_accuracy: 0.8188 - val_auc: 0.7558\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.83449\n",
      "Epoch 85/100\n",
      "1028/1028 - 48s - loss: 0.2012 - accuracy: 0.9132 - auc: 0.9807 - val_loss: 0.9159 - val_accuracy: 0.7836 - val_auc: 0.7441\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.83449\n",
      "Epoch 86/100\n",
      "1028/1028 - 49s - loss: 0.2101 - accuracy: 0.9118 - auc: 0.9773 - val_loss: 1.4977 - val_accuracy: 0.8238 - val_auc: 0.7656\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.83449\n",
      "Epoch 87/100\n",
      "1028/1028 - 48s - loss: 0.2307 - accuracy: 0.9002 - auc: 0.9753 - val_loss: 0.9200 - val_accuracy: 0.8322 - val_auc: 0.7498\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.83449\n",
      "Epoch 88/100\n",
      "1028/1028 - 48s - loss: 0.1876 - accuracy: 0.9221 - auc: 0.9834 - val_loss: 2.1502 - val_accuracy: 0.9128 - val_auc: 0.6846\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.83449\n",
      "Epoch 89/100\n",
      "1028/1028 - 48s - loss: 0.2052 - accuracy: 0.9134 - auc: 0.9795 - val_loss: 1.5612 - val_accuracy: 0.7768 - val_auc: 0.7193\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.83449\n",
      "Epoch 90/100\n",
      "1028/1028 - 48s - loss: 0.1944 - accuracy: 0.9152 - auc: 0.9817 - val_loss: 1.7995 - val_accuracy: 0.8758 - val_auc: 0.6869\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.83449\n",
      "Epoch 91/100\n",
      "1028/1028 - 48s - loss: 0.2019 - accuracy: 0.9123 - auc: 0.9796 - val_loss: 1.5024 - val_accuracy: 0.8456 - val_auc: 0.6917\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.83449\n",
      "Epoch 92/100\n",
      "1028/1028 - 48s - loss: 0.1973 - accuracy: 0.9271 - auc: 0.9816 - val_loss: 1.6132 - val_accuracy: 0.8289 - val_auc: 0.7034\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.83449\n",
      "Epoch 93/100\n",
      "1028/1028 - 48s - loss: 0.2626 - accuracy: 0.8843 - auc: 0.9684 - val_loss: 1.0429 - val_accuracy: 0.8238 - val_auc: 0.7424\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.83449\n",
      "Epoch 94/100\n",
      "1028/1028 - 48s - loss: 0.1804 - accuracy: 0.9286 - auc: 0.9844 - val_loss: 1.4875 - val_accuracy: 0.7970 - val_auc: 0.7195\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.83449\n",
      "Epoch 95/100\n",
      "1028/1028 - 48s - loss: 0.2081 - accuracy: 0.9135 - auc: 0.9796 - val_loss: 1.0755 - val_accuracy: 0.7349 - val_auc: 0.7696\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.83449\n",
      "Epoch 96/100\n",
      "1028/1028 - 48s - loss: 0.1868 - accuracy: 0.9297 - auc: 0.9828 - val_loss: 1.6520 - val_accuracy: 0.8725 - val_auc: 0.7053\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.83449\n",
      "Epoch 97/100\n",
      "1028/1028 - 48s - loss: 0.1823 - accuracy: 0.9276 - auc: 0.9840 - val_loss: 1.7762 - val_accuracy: 0.8993 - val_auc: 0.6957\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.83449\n",
      "Epoch 98/100\n",
      "1028/1028 - 48s - loss: 0.1879 - accuracy: 0.9232 - auc: 0.9836 - val_loss: 1.7497 - val_accuracy: 0.8943 - val_auc: 0.7020\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.83449\n",
      "Epoch 99/100\n",
      "1028/1028 - 48s - loss: 0.1872 - accuracy: 0.9164 - auc: 0.9827 - val_loss: 1.5600 - val_accuracy: 0.9094 - val_auc: 0.6921\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.83449\n",
      "Epoch 100/100\n",
      "1028/1028 - 48s - loss: 0.1789 - accuracy: 0.9282 - auc: 0.9837 - val_loss: 1.6639 - val_accuracy: 0.8725 - val_auc: 0.6978\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.83449\n",
      "Epoch 1/100\n",
      "918/918 - 39s - loss: 0.7396 - accuracy: 0.6458 - auc: 0.7412 - val_loss: 0.6073 - val_accuracy: 0.5179 - val_auc: 0.8667\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.86666, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 2/100\n",
      "918/918 - 32s - loss: 0.5597 - accuracy: 0.7352 - auc: 0.8461 - val_loss: 0.4431 - val_accuracy: 0.7382 - val_auc: 0.8888\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.86666 to 0.88881, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 3/100\n",
      "918/918 - 32s - loss: 0.5211 - accuracy: 0.7440 - auc: 0.8565 - val_loss: 0.3717 - val_accuracy: 0.8230 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.88881 to 0.90258, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 4/100\n",
      "918/918 - 32s - loss: 0.4725 - accuracy: 0.7717 - auc: 0.8730 - val_loss: 0.4580 - val_accuracy: 0.6497 - val_auc: 0.8956\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.90258\n",
      "Epoch 5/100\n",
      "918/918 - 32s - loss: 0.4425 - accuracy: 0.7877 - auc: 0.8846 - val_loss: 0.3774 - val_accuracy: 0.7872 - val_auc: 0.8929\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.90258\n",
      "Epoch 6/100\n",
      "918/918 - 32s - loss: 0.4230 - accuracy: 0.7998 - auc: 0.8938 - val_loss: 0.3887 - val_accuracy: 0.7326 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.90258\n",
      "Epoch 7/100\n",
      "918/918 - 33s - loss: 0.4038 - accuracy: 0.8087 - auc: 0.9029 - val_loss: 0.3765 - val_accuracy: 0.8889 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.90258\n",
      "Epoch 8/100\n",
      "918/918 - 32s - loss: 0.3950 - accuracy: 0.8121 - auc: 0.9072 - val_loss: 0.3689 - val_accuracy: 0.7571 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.90258 to 0.90382, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 9/100\n",
      "918/918 - 32s - loss: 0.3902 - accuracy: 0.8133 - auc: 0.9088 - val_loss: 0.3774 - val_accuracy: 0.8889 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.90382\n",
      "Epoch 10/100\n",
      "918/918 - 31s - loss: 0.3715 - accuracy: 0.8268 - auc: 0.9181 - val_loss: 0.3799 - val_accuracy: 0.8908 - val_auc: 0.9115\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.90382 to 0.91148, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 11/100\n",
      "918/918 - 32s - loss: 0.3761 - accuracy: 0.8333 - auc: 0.9181 - val_loss: 0.3993 - val_accuracy: 0.7853 - val_auc: 0.9073\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.91148\n",
      "Epoch 12/100\n",
      "918/918 - 32s - loss: 0.3664 - accuracy: 0.8340 - auc: 0.9222 - val_loss: 0.4017 - val_accuracy: 0.7307 - val_auc: 0.9104\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.91148\n",
      "Epoch 13/100\n",
      "918/918 - 32s - loss: 0.3504 - accuracy: 0.8474 - auc: 0.9294 - val_loss: 0.3769 - val_accuracy: 0.8286 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.91148\n",
      "Epoch 14/100\n",
      "918/918 - 32s - loss: 0.3424 - accuracy: 0.8531 - auc: 0.9318 - val_loss: 0.3483 - val_accuracy: 0.8136 - val_auc: 0.9115\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.91148 to 0.91153, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 15/100\n",
      "918/918 - 32s - loss: 0.3359 - accuracy: 0.8576 - auc: 0.9338 - val_loss: 0.3514 - val_accuracy: 0.7834 - val_auc: 0.9180\n",
      "\n",
      "Epoch 00015: val_auc improved from 0.91153 to 0.91797, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918/918 - 32s - loss: 0.3296 - accuracy: 0.8576 - auc: 0.9355 - val_loss: 0.3424 - val_accuracy: 0.8324 - val_auc: 0.9114\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.91797\n",
      "Epoch 17/100\n",
      "918/918 - 32s - loss: 0.3105 - accuracy: 0.8611 - auc: 0.9436 - val_loss: 0.4066 - val_accuracy: 0.8870 - val_auc: 0.9133\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.91797\n",
      "Epoch 18/100\n",
      "918/918 - 32s - loss: 0.3235 - accuracy: 0.8633 - auc: 0.9404 - val_loss: 0.4940 - val_accuracy: 0.6610 - val_auc: 0.9175\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.91797\n",
      "Epoch 19/100\n",
      "918/918 - 32s - loss: 0.3007 - accuracy: 0.8745 - auc: 0.9484 - val_loss: 0.3907 - val_accuracy: 0.7721 - val_auc: 0.9220\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.91797 to 0.92198, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-MMP\n",
      "Epoch 20/100\n",
      "918/918 - 32s - loss: 0.3007 - accuracy: 0.8686 - auc: 0.9475 - val_loss: 0.3273 - val_accuracy: 0.8324 - val_auc: 0.9164\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.92198\n",
      "Epoch 21/100\n",
      "918/918 - 32s - loss: 0.2998 - accuracy: 0.8723 - auc: 0.9487 - val_loss: 0.3392 - val_accuracy: 0.8569 - val_auc: 0.9168\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.92198\n",
      "Epoch 22/100\n",
      "918/918 - 32s - loss: 0.2971 - accuracy: 0.8713 - auc: 0.9495 - val_loss: 0.3671 - val_accuracy: 0.8757 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.92198\n",
      "Epoch 23/100\n",
      "918/918 - 32s - loss: 0.2811 - accuracy: 0.8843 - auc: 0.9543 - val_loss: 0.3730 - val_accuracy: 0.8889 - val_auc: 0.9139\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.92198\n",
      "Epoch 24/100\n",
      "918/918 - 32s - loss: 0.2766 - accuracy: 0.8855 - auc: 0.9562 - val_loss: 0.3602 - val_accuracy: 0.8512 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.92198\n",
      "Epoch 25/100\n",
      "918/918 - 32s - loss: 0.2842 - accuracy: 0.8859 - auc: 0.9546 - val_loss: 0.3672 - val_accuracy: 0.8437 - val_auc: 0.9138\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.92198\n",
      "Epoch 26/100\n",
      "918/918 - 32s - loss: 0.2589 - accuracy: 0.8896 - auc: 0.9610 - val_loss: 0.3717 - val_accuracy: 0.7721 - val_auc: 0.9181\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.92198\n",
      "Epoch 27/100\n",
      "918/918 - 32s - loss: 0.2552 - accuracy: 0.8968 - auc: 0.9622 - val_loss: 0.4473 - val_accuracy: 0.7665 - val_auc: 0.9149\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.92198\n",
      "Epoch 28/100\n",
      "918/918 - 32s - loss: 0.2637 - accuracy: 0.8901 - auc: 0.9599 - val_loss: 0.3760 - val_accuracy: 0.8983 - val_auc: 0.9122\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.92198\n",
      "Epoch 29/100\n",
      "918/918 - 33s - loss: 0.2506 - accuracy: 0.8972 - auc: 0.9634 - val_loss: 0.3567 - val_accuracy: 0.8832 - val_auc: 0.9117\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.92198\n",
      "Epoch 30/100\n",
      "918/918 - 32s - loss: 0.2505 - accuracy: 0.8971 - auc: 0.9635 - val_loss: 0.3984 - val_accuracy: 0.7891 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.92198\n",
      "Epoch 31/100\n",
      "918/918 - 32s - loss: 0.2398 - accuracy: 0.8992 - auc: 0.9663 - val_loss: 0.4990 - val_accuracy: 0.6836 - val_auc: 0.9103\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.92198\n",
      "Epoch 32/100\n",
      "918/918 - 32s - loss: 0.2410 - accuracy: 0.9045 - auc: 0.9662 - val_loss: 0.3820 - val_accuracy: 0.8399 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.92198\n",
      "Epoch 33/100\n",
      "918/918 - 32s - loss: 0.2416 - accuracy: 0.9010 - auc: 0.9664 - val_loss: 0.4054 - val_accuracy: 0.8173 - val_auc: 0.9122\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.92198\n",
      "Epoch 34/100\n",
      "918/918 - 32s - loss: 0.2335 - accuracy: 0.9043 - auc: 0.9676 - val_loss: 0.5099 - val_accuracy: 0.8814 - val_auc: 0.9010\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.92198\n",
      "Epoch 35/100\n",
      "918/918 - 32s - loss: 0.2198 - accuracy: 0.9097 - auc: 0.9709 - val_loss: 0.3390 - val_accuracy: 0.8512 - val_auc: 0.9135\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.92198\n",
      "Epoch 36/100\n",
      "918/918 - 32s - loss: 0.2203 - accuracy: 0.9099 - auc: 0.9714 - val_loss: 0.3812 - val_accuracy: 0.8663 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.92198\n",
      "Epoch 37/100\n",
      "918/918 - 32s - loss: 0.2159 - accuracy: 0.9101 - auc: 0.9722 - val_loss: 0.4615 - val_accuracy: 0.8757 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.92198\n",
      "Epoch 38/100\n",
      "918/918 - 32s - loss: 0.2153 - accuracy: 0.9165 - auc: 0.9720 - val_loss: 0.3969 - val_accuracy: 0.8701 - val_auc: 0.9187\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.92198\n",
      "Epoch 39/100\n",
      "918/918 - 32s - loss: 0.2201 - accuracy: 0.9067 - auc: 0.9706 - val_loss: 0.3745 - val_accuracy: 0.8663 - val_auc: 0.9114\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.92198\n",
      "Epoch 40/100\n",
      "918/918 - 32s - loss: 0.2149 - accuracy: 0.9129 - auc: 0.9727 - val_loss: 0.4544 - val_accuracy: 0.8757 - val_auc: 0.8941\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.92198\n",
      "Epoch 41/100\n",
      "918/918 - 32s - loss: 0.2095 - accuracy: 0.9167 - auc: 0.9736 - val_loss: 0.5065 - val_accuracy: 0.8851 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.92198\n",
      "Epoch 42/100\n",
      "918/918 - 32s - loss: 0.1970 - accuracy: 0.9243 - auc: 0.9761 - val_loss: 0.4569 - val_accuracy: 0.8832 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.92198\n",
      "Epoch 43/100\n",
      "918/918 - 32s - loss: 0.2020 - accuracy: 0.9141 - auc: 0.9752 - val_loss: 0.4130 - val_accuracy: 0.8832 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.92198\n",
      "Epoch 44/100\n",
      "918/918 - 32s - loss: 0.1910 - accuracy: 0.9218 - auc: 0.9772 - val_loss: 0.6355 - val_accuracy: 0.8908 - val_auc: 0.8802\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.92198\n",
      "Epoch 45/100\n",
      "918/918 - 32s - loss: 0.2052 - accuracy: 0.9164 - auc: 0.9753 - val_loss: 0.4118 - val_accuracy: 0.8569 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.92198\n",
      "Epoch 46/100\n",
      "918/918 - 33s - loss: 0.2065 - accuracy: 0.9164 - auc: 0.9744 - val_loss: 0.5009 - val_accuracy: 0.8418 - val_auc: 0.9121\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.92198\n",
      "Epoch 47/100\n",
      "918/918 - 32s - loss: 0.1960 - accuracy: 0.9217 - auc: 0.9766 - val_loss: 0.6749 - val_accuracy: 0.8682 - val_auc: 0.8722\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.92198\n",
      "Epoch 48/100\n",
      "918/918 - 32s - loss: 0.1882 - accuracy: 0.9252 - auc: 0.9781 - val_loss: 0.4830 - val_accuracy: 0.7928 - val_auc: 0.8952\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.92198\n",
      "Epoch 49/100\n",
      "918/918 - 32s - loss: 0.1770 - accuracy: 0.9321 - auc: 0.9796 - val_loss: 0.4508 - val_accuracy: 0.8776 - val_auc: 0.8964\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.92198\n",
      "Epoch 50/100\n",
      "918/918 - 32s - loss: 0.1833 - accuracy: 0.9252 - auc: 0.9790 - val_loss: 0.4923 - val_accuracy: 0.8927 - val_auc: 0.8882\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.92198\n",
      "Epoch 51/100\n",
      "918/918 - 32s - loss: 0.1801 - accuracy: 0.9321 - auc: 0.9803 - val_loss: 0.5327 - val_accuracy: 0.8908 - val_auc: 0.8942\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.92198\n",
      "Epoch 52/100\n",
      "918/918 - 32s - loss: 0.1817 - accuracy: 0.9308 - auc: 0.9795 - val_loss: 0.4088 - val_accuracy: 0.8606 - val_auc: 0.8937\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.92198\n",
      "Epoch 53/100\n",
      "918/918 - 32s - loss: 0.1733 - accuracy: 0.9247 - auc: 0.9821 - val_loss: 0.5775 - val_accuracy: 0.8550 - val_auc: 0.8907\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.92198\n",
      "Epoch 54/100\n",
      "918/918 - 32s - loss: 0.1795 - accuracy: 0.9240 - auc: 0.9801 - val_loss: 0.5027 - val_accuracy: 0.8230 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.92198\n",
      "Epoch 55/100\n",
      "918/918 - 32s - loss: 0.1694 - accuracy: 0.9299 - auc: 0.9825 - val_loss: 0.4867 - val_accuracy: 0.8380 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.92198\n",
      "Epoch 56/100\n",
      "918/918 - 31s - loss: 0.1696 - accuracy: 0.9295 - auc: 0.9824 - val_loss: 0.9487 - val_accuracy: 0.8945 - val_auc: 0.8374\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.92198\n",
      "Epoch 57/100\n",
      "918/918 - 32s - loss: 0.1612 - accuracy: 0.9331 - auc: 0.9838 - val_loss: 0.7525 - val_accuracy: 0.8908 - val_auc: 0.8639\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.92198\n",
      "Epoch 58/100\n",
      "918/918 - 32s - loss: 0.1716 - accuracy: 0.9315 - auc: 0.9822 - val_loss: 0.5888 - val_accuracy: 0.8889 - val_auc: 0.8849\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.92198\n",
      "Epoch 59/100\n",
      "918/918 - 32s - loss: 0.1637 - accuracy: 0.9375 - auc: 0.9835 - val_loss: 0.6282 - val_accuracy: 0.8418 - val_auc: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_auc did not improve from 0.92198\n",
      "Epoch 60/100\n",
      "918/918 - 32s - loss: 0.1658 - accuracy: 0.9353 - auc: 0.9833 - val_loss: 0.4390 - val_accuracy: 0.8267 - val_auc: 0.8893\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.92198\n",
      "Epoch 61/100\n",
      "918/918 - 32s - loss: 0.1457 - accuracy: 0.9409 - auc: 0.9854 - val_loss: 0.5192 - val_accuracy: 0.8060 - val_auc: 0.8665\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.92198\n",
      "Epoch 62/100\n",
      "918/918 - 32s - loss: 0.1611 - accuracy: 0.9337 - auc: 0.9833 - val_loss: 0.7180 - val_accuracy: 0.8908 - val_auc: 0.8852\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.92198\n",
      "Epoch 63/100\n",
      "918/918 - 32s - loss: 0.1449 - accuracy: 0.9417 - auc: 0.9862 - val_loss: 0.7311 - val_accuracy: 0.8832 - val_auc: 0.8863\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.92198\n",
      "Epoch 64/100\n",
      "918/918 - 32s - loss: 0.1580 - accuracy: 0.9345 - auc: 0.9844 - val_loss: 0.6087 - val_accuracy: 0.8757 - val_auc: 0.8979\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.92198\n",
      "Epoch 65/100\n",
      "918/918 - 32s - loss: 0.1492 - accuracy: 0.9416 - auc: 0.9858 - val_loss: 0.5191 - val_accuracy: 0.8832 - val_auc: 0.8950\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.92198\n",
      "Epoch 66/100\n",
      "918/918 - 32s - loss: 0.1494 - accuracy: 0.9372 - auc: 0.9862 - val_loss: 0.4607 - val_accuracy: 0.8814 - val_auc: 0.8941\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.92198\n",
      "Epoch 67/100\n",
      "918/918 - 32s - loss: 0.1422 - accuracy: 0.9424 - auc: 0.9877 - val_loss: 0.6637 - val_accuracy: 0.8832 - val_auc: 0.8865\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.92198\n",
      "Epoch 68/100\n",
      "918/918 - 32s - loss: 0.1513 - accuracy: 0.9432 - auc: 0.9860 - val_loss: 0.3922 - val_accuracy: 0.8682 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.92198\n",
      "Epoch 69/100\n",
      "918/918 - 32s - loss: 0.1517 - accuracy: 0.9428 - auc: 0.9862 - val_loss: 0.4919 - val_accuracy: 0.8701 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.92198\n",
      "Epoch 70/100\n",
      "918/918 - 32s - loss: 0.1446 - accuracy: 0.9447 - auc: 0.9877 - val_loss: 0.7553 - val_accuracy: 0.8945 - val_auc: 0.8739\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.92198\n",
      "Epoch 71/100\n",
      "918/918 - 32s - loss: 0.1474 - accuracy: 0.9434 - auc: 0.9868 - val_loss: 0.4036 - val_accuracy: 0.8738 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.92198\n",
      "Epoch 72/100\n",
      "918/918 - 32s - loss: 0.1414 - accuracy: 0.9438 - auc: 0.9868 - val_loss: 0.4262 - val_accuracy: 0.7495 - val_auc: 0.9151\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.92198\n",
      "Epoch 73/100\n",
      "918/918 - 32s - loss: 0.1413 - accuracy: 0.9464 - auc: 0.9875 - val_loss: 0.5689 - val_accuracy: 0.8908 - val_auc: 0.8924\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.92198\n",
      "Epoch 74/100\n",
      "918/918 - 32s - loss: 0.1260 - accuracy: 0.9511 - auc: 0.9902 - val_loss: 0.5667 - val_accuracy: 0.8738 - val_auc: 0.8960\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.92198\n",
      "Epoch 75/100\n",
      "918/918 - 32s - loss: 0.1583 - accuracy: 0.9360 - auc: 0.9849 - val_loss: 0.5148 - val_accuracy: 0.9002 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.92198\n",
      "Epoch 76/100\n",
      "918/918 - 32s - loss: 0.1333 - accuracy: 0.9502 - auc: 0.9891 - val_loss: 0.6018 - val_accuracy: 0.8682 - val_auc: 0.8834\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.92198\n",
      "Epoch 77/100\n",
      "918/918 - 32s - loss: 0.1413 - accuracy: 0.9474 - auc: 0.9877 - val_loss: 0.4605 - val_accuracy: 0.8569 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.92198\n",
      "Epoch 78/100\n",
      "918/918 - 32s - loss: 0.1432 - accuracy: 0.9459 - auc: 0.9873 - val_loss: 0.5122 - val_accuracy: 0.8701 - val_auc: 0.9147\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.92198\n",
      "Epoch 79/100\n",
      "918/918 - 32s - loss: 0.1229 - accuracy: 0.9518 - auc: 0.9905 - val_loss: 0.5749 - val_accuracy: 0.8776 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.92198\n",
      "Epoch 80/100\n",
      "918/918 - 32s - loss: 0.1240 - accuracy: 0.9536 - auc: 0.9901 - val_loss: 0.6357 - val_accuracy: 0.8757 - val_auc: 0.8868\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.92198\n",
      "Epoch 81/100\n",
      "918/918 - 32s - loss: 0.1346 - accuracy: 0.9442 - auc: 0.9886 - val_loss: 0.7541 - val_accuracy: 0.9096 - val_auc: 0.8785\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.92198\n",
      "Epoch 82/100\n",
      "918/918 - 32s - loss: 0.1130 - accuracy: 0.9577 - auc: 0.9915 - val_loss: 0.9083 - val_accuracy: 0.8983 - val_auc: 0.8671\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.92198\n",
      "Epoch 83/100\n",
      "918/918 - 32s - loss: 0.1217 - accuracy: 0.9553 - auc: 0.9894 - val_loss: 0.9200 - val_accuracy: 0.8908 - val_auc: 0.8451\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.92198\n",
      "Epoch 84/100\n",
      "918/918 - 32s - loss: 0.1167 - accuracy: 0.9523 - auc: 0.9909 - val_loss: 0.7533 - val_accuracy: 0.8738 - val_auc: 0.8817\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.92198\n",
      "Epoch 85/100\n",
      "918/918 - 32s - loss: 0.1132 - accuracy: 0.9552 - auc: 0.9913 - val_loss: 0.6246 - val_accuracy: 0.8851 - val_auc: 0.8937\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.92198\n",
      "Epoch 86/100\n",
      "918/918 - 32s - loss: 0.1260 - accuracy: 0.9511 - auc: 0.9900 - val_loss: 0.7166 - val_accuracy: 0.8945 - val_auc: 0.8789\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.92198\n",
      "Epoch 87/100\n",
      "918/918 - 32s - loss: 0.1300 - accuracy: 0.9485 - auc: 0.9896 - val_loss: 0.4106 - val_accuracy: 0.8625 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.92198\n",
      "Epoch 88/100\n",
      "918/918 - 32s - loss: 0.1417 - accuracy: 0.9406 - auc: 0.9882 - val_loss: 0.3478 - val_accuracy: 0.8908 - val_auc: 0.9165\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.92198\n",
      "Epoch 89/100\n",
      "918/918 - 32s - loss: 0.1197 - accuracy: 0.9596 - auc: 0.9915 - val_loss: 0.6640 - val_accuracy: 0.8757 - val_auc: 0.8960\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.92198\n",
      "Epoch 90/100\n",
      "918/918 - 32s - loss: 0.1212 - accuracy: 0.9513 - auc: 0.9908 - val_loss: 0.5443 - val_accuracy: 0.8418 - val_auc: 0.8993\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.92198\n",
      "Epoch 91/100\n",
      "918/918 - 32s - loss: 0.1208 - accuracy: 0.9504 - auc: 0.9906 - val_loss: 0.6070 - val_accuracy: 0.8851 - val_auc: 0.8901\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.92198\n",
      "Epoch 92/100\n",
      "918/918 - 32s - loss: 0.1056 - accuracy: 0.9585 - auc: 0.9923 - val_loss: 0.7068 - val_accuracy: 0.9040 - val_auc: 0.8671\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.92198\n",
      "Epoch 93/100\n",
      "918/918 - 32s - loss: 0.1147 - accuracy: 0.9560 - auc: 0.9918 - val_loss: 0.5199 - val_accuracy: 0.8738 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.92198\n",
      "Epoch 94/100\n",
      "918/918 - 32s - loss: 0.1003 - accuracy: 0.9669 - auc: 0.9921 - val_loss: 0.5954 - val_accuracy: 0.8550 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.92198\n",
      "Epoch 95/100\n",
      "918/918 - 32s - loss: 0.0992 - accuracy: 0.9597 - auc: 0.9931 - val_loss: 0.9533 - val_accuracy: 0.8908 - val_auc: 0.8771\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.92198\n",
      "Epoch 96/100\n",
      "918/918 - 32s - loss: 0.1115 - accuracy: 0.9570 - auc: 0.9912 - val_loss: 0.5484 - val_accuracy: 0.8117 - val_auc: 0.8798\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.92198\n",
      "Epoch 97/100\n",
      "918/918 - 32s - loss: 0.1099 - accuracy: 0.9577 - auc: 0.9920 - val_loss: 0.7600 - val_accuracy: 0.8663 - val_auc: 0.8803\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.92198\n",
      "Epoch 98/100\n",
      "918/918 - 32s - loss: 0.1034 - accuracy: 0.9575 - auc: 0.9928 - val_loss: 0.6130 - val_accuracy: 0.8625 - val_auc: 0.8735\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.92198\n",
      "Epoch 99/100\n",
      "918/918 - 32s - loss: 0.1055 - accuracy: 0.9572 - auc: 0.9925 - val_loss: 0.7405 - val_accuracy: 0.9002 - val_auc: 0.8774\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.92198\n",
      "Epoch 100/100\n",
      "918/918 - 32s - loss: 0.0877 - accuracy: 0.9673 - auc: 0.9942 - val_loss: 1.0507 - val_accuracy: 0.8983 - val_auc: 0.8524\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.92198\n",
      "Epoch 1/100\n",
      "1081/1081 - 60s - loss: 0.8260 - accuracy: 0.5836 - auc: 0.6528 - val_loss: 0.7310 - val_accuracy: 0.4909 - val_auc: 0.7851\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.78508, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 2/100\n",
      "1081/1081 - 50s - loss: 0.6897 - accuracy: 0.6402 - auc: 0.7532 - val_loss: 0.7003 - val_accuracy: 0.4163 - val_auc: 0.8100\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.78508 to 0.81004, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081/1081 - 50s - loss: 0.6263 - accuracy: 0.6649 - auc: 0.7843 - val_loss: 0.6557 - val_accuracy: 0.4909 - val_auc: 0.8181\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.81004 to 0.81807, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 4/100\n",
      "1081/1081 - 51s - loss: 0.5785 - accuracy: 0.6551 - auc: 0.7944 - val_loss: 0.5519 - val_accuracy: 0.5970 - val_auc: 0.8291\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.81807 to 0.82909, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 5/100\n",
      "1081/1081 - 50s - loss: 0.5387 - accuracy: 0.6680 - auc: 0.8174 - val_loss: 0.5912 - val_accuracy: 0.4975 - val_auc: 0.8333\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.82909 to 0.83333, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 6/100\n",
      "1081/1081 - 51s - loss: 0.5506 - accuracy: 0.6617 - auc: 0.8053 - val_loss: 0.5708 - val_accuracy: 0.5572 - val_auc: 0.8354\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.83333 to 0.83539, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 7/100\n",
      "1081/1081 - 50s - loss: 0.5255 - accuracy: 0.7004 - auc: 0.8303 - val_loss: 0.6467 - val_accuracy: 0.4395 - val_auc: 0.8361\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.83539 to 0.83606, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 8/100\n",
      "1081/1081 - 50s - loss: 0.5056 - accuracy: 0.7044 - auc: 0.8401 - val_loss: 0.5358 - val_accuracy: 0.7446 - val_auc: 0.8369\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.83606 to 0.83686, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 9/100\n",
      "1081/1081 - 51s - loss: 0.4834 - accuracy: 0.7346 - auc: 0.8560 - val_loss: 0.5447 - val_accuracy: 0.6418 - val_auc: 0.8344\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.83686\n",
      "Epoch 10/100\n",
      "1081/1081 - 51s - loss: 0.4704 - accuracy: 0.6978 - auc: 0.8549 - val_loss: 0.5579 - val_accuracy: 0.6434 - val_auc: 0.8352\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.83686\n",
      "Epoch 11/100\n",
      "1081/1081 - 51s - loss: 0.4625 - accuracy: 0.7353 - auc: 0.8641 - val_loss: 0.5365 - val_accuracy: 0.6335 - val_auc: 0.8366\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.83686\n",
      "Epoch 12/100\n",
      "1081/1081 - 50s - loss: 0.4555 - accuracy: 0.7380 - auc: 0.8722 - val_loss: 0.6055 - val_accuracy: 0.6799 - val_auc: 0.8351\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.83686\n",
      "Epoch 13/100\n",
      "1081/1081 - 51s - loss: 0.4466 - accuracy: 0.7578 - auc: 0.8803 - val_loss: 0.5940 - val_accuracy: 0.7944 - val_auc: 0.8241\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.83686\n",
      "Epoch 14/100\n",
      "1081/1081 - 51s - loss: 0.4641 - accuracy: 0.7085 - auc: 0.8643 - val_loss: 0.5768 - val_accuracy: 0.6899 - val_auc: 0.8403\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.83686 to 0.84025, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 15/100\n",
      "1081/1081 - 51s - loss: 0.4474 - accuracy: 0.7394 - auc: 0.8814 - val_loss: 0.6957 - val_accuracy: 0.8391 - val_auc: 0.8339\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.84025\n",
      "Epoch 16/100\n",
      "1081/1081 - 51s - loss: 0.4618 - accuracy: 0.7339 - auc: 0.8752 - val_loss: 0.5673 - val_accuracy: 0.6584 - val_auc: 0.8263\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.84025\n",
      "Epoch 17/100\n",
      "1081/1081 - 51s - loss: 0.4397 - accuracy: 0.7527 - auc: 0.8865 - val_loss: 0.7596 - val_accuracy: 0.8010 - val_auc: 0.8371\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.84025\n",
      "Epoch 18/100\n",
      "1081/1081 - 50s - loss: 0.4387 - accuracy: 0.7477 - auc: 0.8891 - val_loss: 0.6173 - val_accuracy: 0.6982 - val_auc: 0.8339\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.84025\n",
      "Epoch 19/100\n",
      "1081/1081 - 51s - loss: 0.4270 - accuracy: 0.7776 - auc: 0.8958 - val_loss: 0.6017 - val_accuracy: 0.7081 - val_auc: 0.8312\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.84025\n",
      "Epoch 20/100\n",
      "1081/1081 - 50s - loss: 0.4145 - accuracy: 0.7765 - auc: 0.8989 - val_loss: 0.6016 - val_accuracy: 0.6501 - val_auc: 0.8094\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.84025\n",
      "Epoch 21/100\n",
      "1081/1081 - 50s - loss: 0.3994 - accuracy: 0.8038 - auc: 0.9090 - val_loss: 0.6108 - val_accuracy: 0.7032 - val_auc: 0.8367\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.84025\n",
      "Epoch 22/100\n",
      "1081/1081 - 50s - loss: 0.3917 - accuracy: 0.7878 - auc: 0.9071 - val_loss: 0.6943 - val_accuracy: 0.6451 - val_auc: 0.8264\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.84025\n",
      "Epoch 23/100\n",
      "1081/1081 - 50s - loss: 0.3714 - accuracy: 0.7972 - auc: 0.9148 - val_loss: 0.7629 - val_accuracy: 0.7993 - val_auc: 0.8383\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.84025\n",
      "Epoch 24/100\n",
      "1081/1081 - 51s - loss: 0.3771 - accuracy: 0.7854 - auc: 0.9130 - val_loss: 0.6136 - val_accuracy: 0.7728 - val_auc: 0.8299\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.84025\n",
      "Epoch 25/100\n",
      "1081/1081 - 51s - loss: 0.3661 - accuracy: 0.8144 - auc: 0.9228 - val_loss: 0.6815 - val_accuracy: 0.7678 - val_auc: 0.8356\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.84025\n",
      "Epoch 26/100\n",
      "1081/1081 - 51s - loss: 0.3970 - accuracy: 0.7716 - auc: 0.9067 - val_loss: 0.6673 - val_accuracy: 0.6501 - val_auc: 0.8285\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.84025\n",
      "Epoch 27/100\n",
      "1081/1081 - 51s - loss: 0.3544 - accuracy: 0.7991 - auc: 0.9239 - val_loss: 0.8008 - val_accuracy: 0.7114 - val_auc: 0.8281\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.84025\n",
      "Epoch 28/100\n",
      "1081/1081 - 51s - loss: 0.3589 - accuracy: 0.8002 - auc: 0.9249 - val_loss: 0.5640 - val_accuracy: 0.7612 - val_auc: 0.8274\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.84025\n",
      "Epoch 29/100\n",
      "1081/1081 - 50s - loss: 0.3597 - accuracy: 0.8118 - auc: 0.9241 - val_loss: 0.7967 - val_accuracy: 0.7993 - val_auc: 0.8283\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.84025\n",
      "Epoch 30/100\n",
      "1081/1081 - 51s - loss: 0.3582 - accuracy: 0.8045 - auc: 0.9236 - val_loss: 0.8087 - val_accuracy: 0.8060 - val_auc: 0.8315\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.84025\n",
      "Epoch 31/100\n",
      "1081/1081 - 50s - loss: 0.3463 - accuracy: 0.8281 - auc: 0.9333 - val_loss: 0.6994 - val_accuracy: 0.5970 - val_auc: 0.8207\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.84025\n",
      "Epoch 32/100\n",
      "1081/1081 - 50s - loss: 0.3359 - accuracy: 0.8266 - auc: 0.9350 - val_loss: 0.7975 - val_accuracy: 0.8275 - val_auc: 0.8375\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.84025\n",
      "Epoch 33/100\n",
      "1081/1081 - 50s - loss: 0.3318 - accuracy: 0.8368 - auc: 0.9364 - val_loss: 0.6824 - val_accuracy: 0.7032 - val_auc: 0.8280\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.84025\n",
      "Epoch 34/100\n",
      "1081/1081 - 51s - loss: 0.3225 - accuracy: 0.8348 - auc: 0.9406 - val_loss: 0.6027 - val_accuracy: 0.6965 - val_auc: 0.8214\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.84025\n",
      "Epoch 35/100\n",
      "1081/1081 - 50s - loss: 0.3508 - accuracy: 0.8009 - auc: 0.9248 - val_loss: 0.7409 - val_accuracy: 0.6318 - val_auc: 0.8287\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.84025\n",
      "Epoch 36/100\n",
      "1081/1081 - 52s - loss: 0.3003 - accuracy: 0.8428 - auc: 0.9478 - val_loss: 0.8955 - val_accuracy: 0.7960 - val_auc: 0.8379\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.84025\n",
      "Epoch 37/100\n",
      "1081/1081 - 53s - loss: 0.3299 - accuracy: 0.8199 - auc: 0.9356 - val_loss: 0.9286 - val_accuracy: 0.7662 - val_auc: 0.8296\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.84025\n",
      "Epoch 38/100\n",
      "1081/1081 - 52s - loss: 0.3182 - accuracy: 0.8423 - auc: 0.9458 - val_loss: 0.7364 - val_accuracy: 0.8226 - val_auc: 0.8472\n",
      "\n",
      "Epoch 00038: val_auc improved from 0.84025 to 0.84725, saving model to 210126_TrainingLocalitySensitivewFW\\210127_LSwFW_SR-p53\n",
      "Epoch 39/100\n",
      "1081/1081 - 53s - loss: 0.3174 - accuracy: 0.8408 - auc: 0.9435 - val_loss: 0.7404 - val_accuracy: 0.8408 - val_auc: 0.8298\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.84725\n",
      "Epoch 40/100\n",
      "1081/1081 - 52s - loss: 0.2936 - accuracy: 0.8531 - auc: 0.9518 - val_loss: 0.8211 - val_accuracy: 0.7231 - val_auc: 0.8184\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.84725\n",
      "Epoch 41/100\n",
      "1081/1081 - 52s - loss: 0.2847 - accuracy: 0.8592 - auc: 0.9548 - val_loss: 0.8376 - val_accuracy: 0.7811 - val_auc: 0.8399\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.84725\n",
      "Epoch 42/100\n",
      "1081/1081 - 52s - loss: 0.2810 - accuracy: 0.8645 - auc: 0.9559 - val_loss: 0.7482 - val_accuracy: 0.6534 - val_auc: 0.8213\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.84725\n",
      "Epoch 43/100\n",
      "1081/1081 - 52s - loss: 0.2763 - accuracy: 0.8613 - auc: 0.9569 - val_loss: 0.6626 - val_accuracy: 0.8060 - val_auc: 0.8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_auc did not improve from 0.84725\n",
      "Epoch 44/100\n",
      "1081/1081 - 53s - loss: 0.2717 - accuracy: 0.8701 - auc: 0.9574 - val_loss: 0.7838 - val_accuracy: 0.7894 - val_auc: 0.8385\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.84725\n",
      "Epoch 45/100\n",
      "1081/1081 - 53s - loss: 0.2700 - accuracy: 0.8705 - auc: 0.9588 - val_loss: 0.8627 - val_accuracy: 0.7512 - val_auc: 0.8313\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.84725\n",
      "Epoch 46/100\n",
      "1081/1081 - 52s - loss: 0.2747 - accuracy: 0.8841 - auc: 0.9606 - val_loss: 0.7859 - val_accuracy: 0.8441 - val_auc: 0.8441\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.84725\n",
      "Epoch 47/100\n",
      "1081/1081 - 52s - loss: 0.2800 - accuracy: 0.8673 - auc: 0.9566 - val_loss: 0.6299 - val_accuracy: 0.7678 - val_auc: 0.8086\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.84725\n",
      "Epoch 48/100\n",
      "1081/1081 - 52s - loss: 0.2547 - accuracy: 0.8776 - auc: 0.9638 - val_loss: 0.8683 - val_accuracy: 0.7993 - val_auc: 0.8423\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.84725\n",
      "Epoch 49/100\n",
      "1081/1081 - 52s - loss: 0.2619 - accuracy: 0.8763 - auc: 0.9620 - val_loss: 1.0217 - val_accuracy: 0.8773 - val_auc: 0.8323\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.84725\n",
      "Epoch 50/100\n",
      "1081/1081 - 52s - loss: 0.2517 - accuracy: 0.8811 - auc: 0.9626 - val_loss: 0.7719 - val_accuracy: 0.8060 - val_auc: 0.8241\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.84725\n",
      "Epoch 51/100\n",
      "1081/1081 - 52s - loss: 0.2319 - accuracy: 0.8878 - auc: 0.9679 - val_loss: 0.7705 - val_accuracy: 0.7380 - val_auc: 0.8160\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.84725\n",
      "Epoch 52/100\n",
      "1081/1081 - 52s - loss: 0.2485 - accuracy: 0.8931 - auc: 0.9655 - val_loss: 1.3746 - val_accuracy: 0.8358 - val_auc: 0.8216\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.84725\n",
      "Epoch 53/100\n",
      "1081/1081 - 52s - loss: 0.2507 - accuracy: 0.8970 - auc: 0.9659 - val_loss: 0.8771 - val_accuracy: 0.7430 - val_auc: 0.8240\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.84725\n",
      "Epoch 54/100\n",
      "1081/1081 - 52s - loss: 0.2263 - accuracy: 0.8923 - auc: 0.9722 - val_loss: 1.0139 - val_accuracy: 0.8226 - val_auc: 0.8226\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.84725\n",
      "Epoch 55/100\n",
      "1081/1081 - 52s - loss: 0.2315 - accuracy: 0.8801 - auc: 0.9695 - val_loss: 0.7338 - val_accuracy: 0.7778 - val_auc: 0.8049\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.84725\n",
      "Epoch 56/100\n",
      "1081/1081 - 52s - loss: 0.2261 - accuracy: 0.8950 - auc: 0.9708 - val_loss: 0.9631 - val_accuracy: 0.7645 - val_auc: 0.8140\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.84725\n",
      "Epoch 57/100\n",
      "1081/1081 - 52s - loss: 0.2451 - accuracy: 0.8775 - auc: 0.9666 - val_loss: 0.8801 - val_accuracy: 0.7977 - val_auc: 0.8187\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.84725\n",
      "Epoch 58/100\n",
      "1081/1081 - 52s - loss: 0.2499 - accuracy: 0.8862 - auc: 0.9657 - val_loss: 0.7882 - val_accuracy: 0.8076 - val_auc: 0.8128\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.84725\n",
      "Epoch 59/100\n",
      "1081/1081 - 52s - loss: 0.2428 - accuracy: 0.8936 - auc: 0.9681 - val_loss: 0.8724 - val_accuracy: 0.7313 - val_auc: 0.8171\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.84725\n",
      "Epoch 60/100\n",
      "1081/1081 - 52s - loss: 0.2608 - accuracy: 0.8803 - auc: 0.9630 - val_loss: 0.7169 - val_accuracy: 0.8823 - val_auc: 0.8113\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.84725\n",
      "Epoch 61/100\n",
      "1081/1081 - 52s - loss: 0.2257 - accuracy: 0.9018 - auc: 0.9712 - val_loss: 1.2541 - val_accuracy: 0.8524 - val_auc: 0.8100\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.84725\n",
      "Epoch 62/100\n",
      "1081/1081 - 52s - loss: 0.2182 - accuracy: 0.8948 - auc: 0.9728 - val_loss: 1.2827 - val_accuracy: 0.8789 - val_auc: 0.8157\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.84725\n",
      "Epoch 63/100\n",
      "1081/1081 - 52s - loss: 0.2490 - accuracy: 0.8919 - auc: 0.9664 - val_loss: 0.9247 - val_accuracy: 0.7877 - val_auc: 0.8317\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.84725\n",
      "Epoch 64/100\n",
      "1081/1081 - 52s - loss: 0.2157 - accuracy: 0.8906 - auc: 0.9740 - val_loss: 1.1777 - val_accuracy: 0.8425 - val_auc: 0.8331\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.84725\n",
      "Epoch 65/100\n",
      "1081/1081 - 52s - loss: 0.2029 - accuracy: 0.9106 - auc: 0.9767 - val_loss: 0.9523 - val_accuracy: 0.8590 - val_auc: 0.8320\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.84725\n",
      "Epoch 66/100\n",
      "1081/1081 - 52s - loss: 0.1892 - accuracy: 0.9134 - auc: 0.9791 - val_loss: 1.0534 - val_accuracy: 0.8408 - val_auc: 0.8267\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.84725\n",
      "Epoch 67/100\n",
      "1081/1081 - 52s - loss: 0.2127 - accuracy: 0.9013 - auc: 0.9743 - val_loss: 0.8005 - val_accuracy: 0.7960 - val_auc: 0.8399\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.84725\n",
      "Epoch 68/100\n",
      "1081/1081 - 53s - loss: 0.2003 - accuracy: 0.9190 - auc: 0.9776 - val_loss: 1.0282 - val_accuracy: 0.8690 - val_auc: 0.8313\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.84725\n",
      "Epoch 69/100\n",
      "1081/1081 - 52s - loss: 0.2090 - accuracy: 0.9125 - auc: 0.9761 - val_loss: 0.9604 - val_accuracy: 0.8640 - val_auc: 0.8213\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.84725\n",
      "Epoch 70/100\n",
      "1081/1081 - 52s - loss: 0.1978 - accuracy: 0.9093 - auc: 0.9777 - val_loss: 0.9190 - val_accuracy: 0.8292 - val_auc: 0.8232\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.84725\n",
      "Epoch 71/100\n",
      "1081/1081 - 52s - loss: 0.2124 - accuracy: 0.9181 - auc: 0.9759 - val_loss: 1.0201 - val_accuracy: 0.8308 - val_auc: 0.8302\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.84725\n",
      "Epoch 72/100\n",
      "1081/1081 - 52s - loss: 0.1928 - accuracy: 0.9113 - auc: 0.9793 - val_loss: 1.0615 - val_accuracy: 0.8441 - val_auc: 0.8230\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.84725\n",
      "Epoch 73/100\n",
      "1081/1081 - 52s - loss: 0.1944 - accuracy: 0.9125 - auc: 0.9795 - val_loss: 0.6786 - val_accuracy: 0.8358 - val_auc: 0.7950\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.84725\n",
      "Epoch 74/100\n",
      "1081/1081 - 52s - loss: 0.1781 - accuracy: 0.9295 - auc: 0.9827 - val_loss: 1.3767 - val_accuracy: 0.8690 - val_auc: 0.8241\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.84725\n",
      "Epoch 75/100\n",
      "1081/1081 - 52s - loss: 0.1985 - accuracy: 0.9159 - auc: 0.9784 - val_loss: 1.3573 - val_accuracy: 0.8408 - val_auc: 0.8114\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.84725\n",
      "Epoch 76/100\n",
      "1081/1081 - 52s - loss: 0.1936 - accuracy: 0.9256 - auc: 0.9795 - val_loss: 0.9611 - val_accuracy: 0.8159 - val_auc: 0.8250\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.84725\n",
      "Epoch 77/100\n",
      "1081/1081 - 52s - loss: 0.1895 - accuracy: 0.9216 - auc: 0.9801 - val_loss: 1.0106 - val_accuracy: 0.8590 - val_auc: 0.8248\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.84725\n",
      "Epoch 78/100\n",
      "1081/1081 - 52s - loss: 0.1897 - accuracy: 0.9221 - auc: 0.9808 - val_loss: 0.6333 - val_accuracy: 0.8275 - val_auc: 0.8233\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.84725\n",
      "Epoch 79/100\n",
      "1081/1081 - 53s - loss: 0.1719 - accuracy: 0.9241 - auc: 0.9838 - val_loss: 1.4208 - val_accuracy: 0.8292 - val_auc: 0.7942\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.84725\n",
      "Epoch 80/100\n",
      "1081/1081 - 57s - loss: 0.1779 - accuracy: 0.9212 - auc: 0.9804 - val_loss: 2.0151 - val_accuracy: 0.8590 - val_auc: 0.7543\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.84725\n",
      "Epoch 81/100\n",
      "1081/1081 - 57s - loss: 0.1753 - accuracy: 0.9282 - auc: 0.9819 - val_loss: 1.8396 - val_accuracy: 0.8905 - val_auc: 0.7962\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.84725\n",
      "Epoch 82/100\n",
      "1081/1081 - 54s - loss: 0.1791 - accuracy: 0.9186 - auc: 0.9820 - val_loss: 1.3508 - val_accuracy: 0.8723 - val_auc: 0.8045\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.84725\n",
      "Epoch 83/100\n",
      "1081/1081 - 54s - loss: 0.1808 - accuracy: 0.9166 - auc: 0.9804 - val_loss: 1.4323 - val_accuracy: 0.8275 - val_auc: 0.7685\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.84725\n",
      "Epoch 84/100\n",
      "1081/1081 - 54s - loss: 0.1815 - accuracy: 0.9187 - auc: 0.9799 - val_loss: 0.8669 - val_accuracy: 0.6866 - val_auc: 0.7980\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.84725\n",
      "Epoch 85/100\n",
      "1081/1081 - 54s - loss: 0.1844 - accuracy: 0.9228 - auc: 0.9814 - val_loss: 0.7844 - val_accuracy: 0.7695 - val_auc: 0.7960\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.84725\n",
      "Epoch 86/100\n",
      "1081/1081 - 70s - loss: 0.1825 - accuracy: 0.9245 - auc: 0.9814 - val_loss: 0.7701 - val_accuracy: 0.8574 - val_auc: 0.8272\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.84725\n",
      "Epoch 87/100\n",
      "1081/1081 - 104s - loss: 0.1644 - accuracy: 0.9365 - auc: 0.9860 - val_loss: 0.6315 - val_accuracy: 0.7363 - val_auc: 0.7934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_auc did not improve from 0.84725\n",
      "Epoch 88/100\n",
      "1081/1081 - 104s - loss: 0.1487 - accuracy: 0.9460 - auc: 0.9880 - val_loss: 1.6576 - val_accuracy: 0.8839 - val_auc: 0.8025\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.84725\n",
      "Epoch 89/100\n",
      "1081/1081 - 104s - loss: 0.1456 - accuracy: 0.9413 - auc: 0.9874 - val_loss: 2.5087 - val_accuracy: 0.9104 - val_auc: 0.7628\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.84725\n",
      "Epoch 90/100\n",
      "1081/1081 - 103s - loss: 0.1640 - accuracy: 0.9386 - auc: 0.9842 - val_loss: 1.1958 - val_accuracy: 0.8640 - val_auc: 0.7971\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.84725\n",
      "Epoch 91/100\n",
      "1081/1081 - 98s - loss: 0.1639 - accuracy: 0.9305 - auc: 0.9847 - val_loss: 0.9593 - val_accuracy: 0.8657 - val_auc: 0.8151\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.84725\n",
      "Epoch 92/100\n",
      "1081/1081 - 102s - loss: 0.1585 - accuracy: 0.9366 - auc: 0.9855 - val_loss: 1.4752 - val_accuracy: 0.8242 - val_auc: 0.7986\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.84725\n",
      "Epoch 93/100\n",
      "1081/1081 - 104s - loss: 0.1637 - accuracy: 0.9335 - auc: 0.9845 - val_loss: 1.4476 - val_accuracy: 0.8624 - val_auc: 0.7755\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.84725\n",
      "Epoch 94/100\n",
      "1081/1081 - 104s - loss: 0.1541 - accuracy: 0.9394 - auc: 0.9866 - val_loss: 0.6792 - val_accuracy: 0.7579 - val_auc: 0.7838\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.84725\n",
      "Epoch 95/100\n",
      "1081/1081 - 104s - loss: 0.1433 - accuracy: 0.9459 - auc: 0.9875 - val_loss: 1.4623 - val_accuracy: 0.8574 - val_auc: 0.8026\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.84725\n",
      "Epoch 96/100\n",
      "1081/1081 - 102s - loss: 0.1416 - accuracy: 0.9408 - auc: 0.9875 - val_loss: 1.3987 - val_accuracy: 0.7396 - val_auc: 0.7854\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.84725\n",
      "Epoch 97/100\n",
      "1081/1081 - 98s - loss: 0.1719 - accuracy: 0.9205 - auc: 0.9817 - val_loss: 1.4301 - val_accuracy: 0.8375 - val_auc: 0.8083\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.84725\n",
      "Epoch 98/100\n",
      "1081/1081 - 104s - loss: 0.1545 - accuracy: 0.9335 - auc: 0.9863 - val_loss: 1.4703 - val_accuracy: 0.8557 - val_auc: 0.7909\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.84725\n",
      "Epoch 99/100\n",
      "1081/1081 - 104s - loss: 0.1694 - accuracy: 0.9334 - auc: 0.9846 - val_loss: 1.2600 - val_accuracy: 0.8756 - val_auc: 0.8332\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.84725\n",
      "Epoch 100/100\n",
      "1081/1081 - 104s - loss: 0.1301 - accuracy: 0.9479 - auc: 0.9893 - val_loss: 0.9587 - val_accuracy: 0.7496 - val_auc: 0.7752\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.84725\n"
     ]
    }
   ],
   "source": [
    "# Repeat above for all labels\n",
    "n_epoch = 100\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewFW\",\n",
    "                                       time.localtime()))\n",
    "tmp_file = os.path.join(save_folder,\n",
    "\"{}_LSwFW_tmpfile.csv\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     ))\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error)   \n",
    "    \n",
    "with open(tmp_file, 'w') as tmpfile:\n",
    "    tmpfile.write(\",\".join([\"Label\", \"Best_valAUC\\n\"]))\n",
    "\n",
    "for label in y_train.columns:\n",
    "    # Load data\n",
    "    train_inds = ~np.isnan(y_train[label])\n",
    "    test_inds = ~np.isnan(y_test[label])\n",
    "\n",
    "    train_data = X_train[train_inds, :]\n",
    "    train_targets = y_train[label][train_inds].astype(np.float32)\n",
    "    test_data = X_test[test_inds, :]\n",
    "    test_targets = y_test[label][test_inds].astype(np.float32)\n",
    "    train_Fweights = Fweights_train[train_inds,:]\n",
    "    test_Fweights = Fweights_test[test_inds,:]\n",
    "    \n",
    "    train_tensor=np.hstack([train_data, train_Fweights])\n",
    "    test_tensor=np.hstack([test_data, test_Fweights])\n",
    "\n",
    "    weights_dicts = get_weights_dicts(np.expand_dims(train_targets, 1))\n",
    "\n",
    "    # Set save folders\n",
    "    \n",
    "    checkpoint_path = os.path.join(save_folder, \"{}_LSwFW_{}\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     label)\n",
    "                                  )   \n",
    "\n",
    "    try:\n",
    "        os.mkdir(checkpoint_path)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    LSwFW_model_=initialize_LSwFWmodel(weights_dicts = weights_dicts)\n",
    "\n",
    "\n",
    "    cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 monitor = 'val_auc',\n",
    "                                                 mode = 'max',\n",
    "                                                 save_best_only = True,\n",
    "                                                 save_weights_only = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "    csv_filename=os.path.join(checkpoint_path, \"training_log.csv\")\n",
    "    csvlogger_callback=tf.keras.callbacks.CSVLogger(\n",
    "        filename = csv_filename, append = True)\n",
    "\n",
    "    LSwFW_model_.fit(train_tensor,\n",
    "                    train_targets,\n",
    "                    epochs=n_epoch, \n",
    "                    batch_size=n_batch, \n",
    "                    validation_data=(test_tensor, test_targets),\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[csvlogger_callback,\n",
    "                               cp_callback\n",
    "                              ])\n",
    "    \n",
    "    with open(tmp_file, 'a') as tmpfile:\n",
    "        tmpfile.write(\",\".join([label, str(cp_callback.best)+\"/n\"]))\n",
    "    \n",
    "    del LSwFW_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='210128_TrainingLocalitySensitivewoFW\\\\210128_LS_tmpfile.csv' mode='a' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "print(tmpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='NR-PPAR-gamma'\n",
    "\n",
    "#File names\n",
    "load_folder=\"210126_TrainingLocalitySensitivewFW\"\n",
    "checkpoint_path=os.path.join(load_folder, \n",
    "                             \"210127_LSwFW_NR-PPAR-gamma\"\n",
    "                            )\n",
    "\n",
    "#Get data\n",
    "train_inds = ~np.isnan(y_train[label])\n",
    "test_inds = ~np.isnan(y_test[label])\n",
    "\n",
    "train_data = X_train[train_inds, :]\n",
    "train_targets = y_train[label][train_inds].astype(np.float32)\n",
    "test_data = X_test[test_inds, :]\n",
    "test_targets = y_test[label][test_inds].astype(np.float32)\n",
    "train_Fweights = Fweights_train[train_inds,:]\n",
    "test_Fweights = Fweights_test[test_inds,:]\n",
    "\n",
    "train_tensor=np.hstack([train_data, train_Fweights])\n",
    "test_tensor=np.hstack([test_data, test_Fweights])\n",
    "\n",
    "weights_dicts = get_weights_dicts(np.expand_dims(train_targets, 1))\n",
    "\n",
    "#Initialize model\n",
    "LSwFW_PPARg=initialize_LSwFWmodel(weights_dicts)\n",
    "\n",
    "#Load model weights\n",
    "LSwFW_PPARg.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 43ms/step - loss: 1.3769 - accuracy: 0.7504 - auc: 0.7902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.376907467842102, 0.7504215836524963, 0.7902308702468872]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSwFW_PPARg.evaluate(test_tensor, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PPARg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"ATG_PPARg_CDKPaDEL_processed.csv\"\n",
    "df=pd.read_csv(os.path.join(\"..\", \n",
    "                            \"..\",\n",
    "                            \"rawdata\", \n",
    "                            dataset_name), \n",
    "               index_col=0\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ATG=df.iloc[:,3:]\n",
    "y_ATG=df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import COSA\n",
    "from importlib import reload\n",
    "reload(COSA)\n",
    "cosa_mdl=COSA.NNCosa(Fweight_init=\"uniform\", lam=0.2, n_iter=1,\n",
    "                                distance_measure=\"inv_exp_dist\",\n",
    "                     calc_D_ijk=False, threads=3\n",
    "                    )\n",
    "cosa_mdl.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Locality-Sensitive Model without Feature Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='NR-AR'\n",
    "\n",
    "train_ind=~np.isnan(y_train_ARE[label])\n",
    "test_ind=~np.isnan(y_test[label])\n",
    "train_targets=y_train_ARE[label][train_ind]\n",
    "test_targets=y_test_ARE[label][test_ind]\n",
    "\n",
    "# train_tensor=np.hstack([train_data, train_Fweights\n",
    "#                        ])[train_ind]\n",
    "# test_tensor=np.hstack([test_data, test_Fweights\n",
    "#                       ])[test_ind]\n",
    "\n",
    "train_tensor=train_data[train_ind]\n",
    "test_tensor=test_data[test_ind]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = train_tensor.shape[1]\n",
    "n_attention = 20 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=20\n",
    "n_attention_out=1\n",
    "n_concat_hidden=2048\n",
    "n_hidden1 =1024\n",
    "n_hidden2 = 128 #Added 2nd hidden layer\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=32\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewoFW\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"LocalitySensitivewoFW_{}\".format(label),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"gelu\"\n",
    "attention_hidden_activation=\"gelu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"gelu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "input_layer=Input(shape=(n_feat, ))\n",
    "attentions_layer=attention_model.ConcatAttentions(\n",
    "    n_attention=n_attention,\n",
    "    n_attention_hidden=n_attention_hidden,\n",
    "    n_attention_out=n_attention_out,\n",
    "    n_feat=n_feat,\n",
    "    n_hidden=n_concat_hidden,\n",
    "    activation=concat_activation,\n",
    "    kernel_initializer=kernel_initializer,\n",
    "    kernel_regularizer=l1(1E-5),\n",
    "    bias_regularizer=l1(1E-5),\n",
    "    attention_initializer=kernel_initializer,\n",
    "    attention_hidden_activation=attention_hidden_activation,\n",
    "    attention_output_activation=attention_output_activation\n",
    ")(input_layer)\n",
    "\n",
    "# attentions_layer=attention_model.ConcatAttentionswFeatWeights(\n",
    "#     n_attention=n_attention,\n",
    "#     n_attention_hidden=n_attention_hidden,\n",
    "#     n_attention_out=n_attention_out,\n",
    "#     n_feat=n_feat,\n",
    "#     n_hidden=n_concat_hidden,\n",
    "#     activation=concat_activation, \n",
    "#     kernel_initializer=kernel_initializer,\n",
    "#     kernel_regularizer=l1(1E-5),\n",
    "#     bias_regularizer=l1(1E-5),\n",
    "#     attention_initializer=kernel_initializer,\n",
    "#     attention_hidden_activation=attention_hidden_activation,\n",
    "#     attention_output_activation=attention_output_activation\n",
    "# )(input_layer)\n",
    "dropout0=Dropout(0.1)(attentions_layer)\n",
    "dense_layer1=Dense(n_hidden1, \n",
    "                   activation=hidden_activation, \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l1(1E-5),\n",
    "                   bias_regularizer=l1(1E-5),\n",
    "                  )(dropout0)\n",
    "dropout1=Dropout(0.1)(dense_layer1)\n",
    "dense_layer2=Dense(n_hidden2,\n",
    "                   activation=hidden_activation,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l1(1E-5),\n",
    "                   bias_regularizer=l1(1E-5)\n",
    "                  )(dropout1)\n",
    "dropout2=Dropout(0.1)(dense_layer2)\n",
    "output_layer=Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "LS_model=Model(inputs=input_layer, \n",
    "                  outputs=output_layer\n",
    "                 )\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "LS_model.compile(loss=loss_fn, \n",
    "              optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy', 'AUC']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "195/195 - 20s - loss: 4.3347 - accuracy: 0.7292 - auc: 0.5129 - val_loss: 1.1057 - val_accuracy: 0.4817 - val_auc: 0.7046\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.70463, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewoFW_NR-AR\n",
      "Epoch 2/100\n",
      "195/195 - 10s - loss: 0.9603 - accuracy: 0.6769 - auc: 0.7162 - val_loss: 0.8231 - val_accuracy: 0.6087 - val_auc: 0.7250\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.70463 to 0.72499, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewoFW_NR-AR\n",
      "Epoch 3/100\n",
      "195/195 - 9s - loss: 0.7575 - accuracy: 0.7761 - auc: 0.7628 - val_loss: 0.7304 - val_accuracy: 0.6626 - val_auc: 0.7297\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.72499 to 0.72972, saving model to 210120_TrainingLocalitySensitivewFW\\LocalitySensitivewoFW_NR-AR\n",
      "Epoch 4/100\n",
      "195/195 - 9s - loss: 0.6759 - accuracy: 0.7879 - auc: 0.7875 - val_loss: 0.7385 - val_accuracy: 0.9478 - val_auc: 0.7216\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.72972\n",
      "Epoch 5/100\n",
      "195/195 - 9s - loss: 0.6352 - accuracy: 0.8317 - auc: 0.8068 - val_loss: 0.7220 - val_accuracy: 0.8365 - val_auc: 0.7128\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.72972\n",
      "Epoch 6/100\n",
      "195/195 - 9s - loss: 0.6318 - accuracy: 0.8574 - auc: 0.7883 - val_loss: 0.7264 - val_accuracy: 0.6835 - val_auc: 0.7169\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.72972\n",
      "Epoch 7/100\n",
      "195/195 - 9s - loss: 0.5841 - accuracy: 0.8216 - auc: 0.8339 - val_loss: 0.7443 - val_accuracy: 0.6417 - val_auc: 0.7156\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.72972\n",
      "Epoch 8/100\n",
      "195/195 - 9s - loss: 0.5752 - accuracy: 0.8503 - auc: 0.8350 - val_loss: 0.7451 - val_accuracy: 0.6852 - val_auc: 0.7217\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.72972\n",
      "Epoch 9/100\n",
      "195/195 - 9s - loss: 0.5863 - accuracy: 0.8447 - auc: 0.8158 - val_loss: 0.7955 - val_accuracy: 0.8017 - val_auc: 0.7037\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.72972\n",
      "Epoch 10/100\n",
      "195/195 - 9s - loss: 0.5649 - accuracy: 0.8303 - auc: 0.8450 - val_loss: 0.8101 - val_accuracy: 0.8835 - val_auc: 0.6949\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.72972\n",
      "Epoch 11/100\n",
      "195/195 - 9s - loss: 0.5508 - accuracy: 0.8303 - auc: 0.8521 - val_loss: 0.7739 - val_accuracy: 0.8922 - val_auc: 0.6962\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.72972\n",
      "Epoch 12/100\n",
      "195/195 - 9s - loss: 0.5879 - accuracy: 0.8311 - auc: 0.8365 - val_loss: 0.7642 - val_accuracy: 0.8296 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.72972\n",
      "Epoch 13/100\n",
      "195/195 - 9s - loss: 0.5626 - accuracy: 0.8487 - auc: 0.8377 - val_loss: 0.7858 - val_accuracy: 0.7809 - val_auc: 0.7167\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.72972\n",
      "Epoch 14/100\n",
      "195/195 - 9s - loss: 0.5291 - accuracy: 0.8600 - auc: 0.8624 - val_loss: 0.8226 - val_accuracy: 0.8765 - val_auc: 0.7026\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.72972\n",
      "Epoch 15/100\n",
      "195/195 - 9s - loss: 0.5211 - accuracy: 0.8799 - auc: 0.8689 - val_loss: 0.8237 - val_accuracy: 0.9061 - val_auc: 0.6992\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.72972\n",
      "Epoch 16/100\n",
      "195/195 - 9s - loss: 0.5044 - accuracy: 0.8457 - auc: 0.8819 - val_loss: 1.0973 - val_accuracy: 0.8191 - val_auc: 0.7017\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.72972\n",
      "Epoch 17/100\n",
      "195/195 - 9s - loss: 0.5030 - accuracy: 0.8446 - auc: 0.8803 - val_loss: 0.8301 - val_accuracy: 0.7043 - val_auc: 0.7124\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.72972\n",
      "Epoch 18/100\n",
      "195/195 - 9s - loss: 0.4904 - accuracy: 0.8460 - auc: 0.8903 - val_loss: 0.9547 - val_accuracy: 0.6487 - val_auc: 0.7026\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.72972\n",
      "Epoch 19/100\n",
      "195/195 - 9s - loss: 0.5054 - accuracy: 0.8672 - auc: 0.8785 - val_loss: 0.8895 - val_accuracy: 0.8157 - val_auc: 0.6992\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.72972\n",
      "Epoch 20/100\n",
      "195/195 - 9s - loss: 0.4898 - accuracy: 0.8638 - auc: 0.8879 - val_loss: 1.1737 - val_accuracy: 0.8748 - val_auc: 0.6917\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.72972\n",
      "Epoch 21/100\n",
      "195/195 - 9s - loss: 0.4715 - accuracy: 0.8738 - auc: 0.8958 - val_loss: 1.4607 - val_accuracy: 0.7496 - val_auc: 0.6977\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.72972\n",
      "Epoch 22/100\n",
      "195/195 - 9s - loss: 0.4838 - accuracy: 0.8470 - auc: 0.8935 - val_loss: 1.6028 - val_accuracy: 0.8626 - val_auc: 0.6721\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.72972\n",
      "Epoch 23/100\n",
      "195/195 - 9s - loss: 0.4684 - accuracy: 0.8625 - auc: 0.9042 - val_loss: 1.5231 - val_accuracy: 0.6209 - val_auc: 0.6949\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.72972\n",
      "Epoch 24/100\n",
      "195/195 - 9s - loss: 0.4768 - accuracy: 0.8410 - auc: 0.9027 - val_loss: 1.3066 - val_accuracy: 0.8730 - val_auc: 0.6575\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.72972\n",
      "Epoch 25/100\n",
      "195/195 - 9s - loss: 0.4699 - accuracy: 0.8699 - auc: 0.9091 - val_loss: 1.8276 - val_accuracy: 0.8470 - val_auc: 0.6761\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.72972\n",
      "Epoch 26/100\n",
      "195/195 - 9s - loss: 0.4795 - accuracy: 0.8614 - auc: 0.9087 - val_loss: 1.4988 - val_accuracy: 0.8835 - val_auc: 0.6555\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.72972\n",
      "Epoch 27/100\n",
      "195/195 - 9s - loss: 0.4426 - accuracy: 0.8718 - auc: 0.9181 - val_loss: 1.4965 - val_accuracy: 0.8157 - val_auc: 0.6650\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.72972\n",
      "Epoch 28/100\n",
      "195/195 - 9s - loss: 0.4457 - accuracy: 0.8802 - auc: 0.9179 - val_loss: 1.2417 - val_accuracy: 0.8922 - val_auc: 0.6745\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.72972\n",
      "Epoch 29/100\n",
      "195/195 - 9s - loss: 0.4741 - accuracy: 0.8388 - auc: 0.9143 - val_loss: 1.6353 - val_accuracy: 0.8713 - val_auc: 0.6943\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.72972\n",
      "Epoch 30/100\n",
      "195/195 - 9s - loss: 0.4756 - accuracy: 0.8534 - auc: 0.9145 - val_loss: 1.6171 - val_accuracy: 0.8017 - val_auc: 0.6593\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.72972\n",
      "Epoch 31/100\n",
      "195/195 - 9s - loss: 0.4200 - accuracy: 0.8859 - auc: 0.9287 - val_loss: 2.1086 - val_accuracy: 0.8817 - val_auc: 0.6681\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.72972\n",
      "Epoch 32/100\n",
      "195/195 - 9s - loss: 0.4332 - accuracy: 0.8508 - auc: 0.9299 - val_loss: 1.7819 - val_accuracy: 0.8800 - val_auc: 0.6658\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.72972\n",
      "Epoch 33/100\n",
      "195/195 - 9s - loss: 0.3960 - accuracy: 0.8920 - auc: 0.9396 - val_loss: 2.2962 - val_accuracy: 0.8591 - val_auc: 0.6442\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.72972\n",
      "Epoch 34/100\n",
      "195/195 - 9s - loss: 0.3977 - accuracy: 0.8665 - auc: 0.9406 - val_loss: 2.4494 - val_accuracy: 0.8939 - val_auc: 0.6536\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.72972\n",
      "Epoch 35/100\n",
      "195/195 - 9s - loss: 0.4305 - accuracy: 0.8807 - auc: 0.9299 - val_loss: 1.9907 - val_accuracy: 0.8157 - val_auc: 0.6522\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.72972\n",
      "Epoch 36/100\n",
      "195/195 - 9s - loss: 0.4224 - accuracy: 0.8770 - auc: 0.9378 - val_loss: 2.4078 - val_accuracy: 0.5078 - val_auc: 0.6752\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.72972\n",
      "Epoch 37/100\n",
      "195/195 - 9s - loss: 0.4532 - accuracy: 0.8638 - auc: 0.9383 - val_loss: 2.5471 - val_accuracy: 0.9200 - val_auc: 0.6395\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.72972\n",
      "Epoch 38/100\n",
      "195/195 - 9s - loss: 0.4084 - accuracy: 0.8625 - auc: 0.9419 - val_loss: 2.9572 - val_accuracy: 0.9322 - val_auc: 0.6441\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.72972\n",
      "Epoch 39/100\n",
      "195/195 - 9s - loss: 0.4327 - accuracy: 0.8260 - auc: 0.9358 - val_loss: 2.5501 - val_accuracy: 0.7826 - val_auc: 0.6239\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.72972\n",
      "Epoch 40/100\n",
      "195/195 - 10s - loss: 0.4518 - accuracy: 0.8715 - auc: 0.9287 - val_loss: 2.3578 - val_accuracy: 0.7252 - val_auc: 0.6602\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.72972\n",
      "Epoch 41/100\n",
      "195/195 - 9s - loss: 0.3953 - accuracy: 0.8784 - auc: 0.9443 - val_loss: 2.1174 - val_accuracy: 0.8174 - val_auc: 0.6897\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.72972\n",
      "Epoch 42/100\n",
      "195/195 - 9s - loss: 0.3663 - accuracy: 0.8646 - auc: 0.9511 - val_loss: 2.4232 - val_accuracy: 0.8261 - val_auc: 0.6483\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.72972\n",
      "Epoch 43/100\n",
      "195/195 - 9s - loss: 0.3893 - accuracy: 0.8691 - auc: 0.9437 - val_loss: 2.2660 - val_accuracy: 0.8817 - val_auc: 0.6943\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.72972\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 - 9s - loss: 0.3615 - accuracy: 0.8673 - auc: 0.9535 - val_loss: 3.0091 - val_accuracy: 0.8991 - val_auc: 0.6126\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.72972\n",
      "Epoch 45/100\n",
      "195/195 - 9s - loss: 0.3346 - accuracy: 0.8829 - auc: 0.9615 - val_loss: 2.6276 - val_accuracy: 0.8470 - val_auc: 0.6567\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.72972\n",
      "Epoch 46/100\n",
      "195/195 - 9s - loss: 0.3342 - accuracy: 0.8765 - auc: 0.9611 - val_loss: 3.1609 - val_accuracy: 0.9217 - val_auc: 0.6368\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.72972\n",
      "Epoch 47/100\n",
      "195/195 - 9s - loss: 0.3643 - accuracy: 0.8810 - auc: 0.9533 - val_loss: 2.7434 - val_accuracy: 0.8296 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.72972\n",
      "Epoch 48/100\n",
      "195/195 - 9s - loss: 0.3316 - accuracy: 0.8771 - auc: 0.9647 - val_loss: 2.9363 - val_accuracy: 0.8783 - val_auc: 0.6630\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.72972\n",
      "Epoch 49/100\n",
      "195/195 - 10s - loss: 0.3524 - accuracy: 0.8763 - auc: 0.9602 - val_loss: 3.0238 - val_accuracy: 0.9113 - val_auc: 0.6334\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.72972\n",
      "Epoch 50/100\n",
      "195/195 - 9s - loss: 0.3205 - accuracy: 0.8957 - auc: 0.9680 - val_loss: 3.0273 - val_accuracy: 0.7948 - val_auc: 0.6174\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.72972\n",
      "Epoch 51/100\n",
      "195/195 - 10s - loss: 0.2939 - accuracy: 0.8941 - auc: 0.9736 - val_loss: 2.8982 - val_accuracy: 0.9339 - val_auc: 0.6679\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.72972\n",
      "Epoch 52/100\n",
      "195/195 - 10s - loss: 0.3491 - accuracy: 0.8758 - auc: 0.9624 - val_loss: 2.8577 - val_accuracy: 0.7322 - val_auc: 0.6101\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.72972\n",
      "Epoch 53/100\n",
      "195/195 - 10s - loss: 0.3415 - accuracy: 0.8710 - auc: 0.9650 - val_loss: 3.2534 - val_accuracy: 0.9217 - val_auc: 0.6465\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.72972\n",
      "Epoch 54/100\n",
      "195/195 - 10s - loss: 0.3095 - accuracy: 0.8906 - auc: 0.9696 - val_loss: 3.0837 - val_accuracy: 0.8574 - val_auc: 0.6518\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.72972\n",
      "Epoch 55/100\n",
      "195/195 - 9s - loss: 0.3127 - accuracy: 0.8733 - auc: 0.9680 - val_loss: 3.1643 - val_accuracy: 0.8226 - val_auc: 0.5919\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.72972\n",
      "Epoch 56/100\n",
      "195/195 - 9s - loss: 0.2893 - accuracy: 0.8956 - auc: 0.9745 - val_loss: 3.7034 - val_accuracy: 0.9235 - val_auc: 0.6173\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.72972\n",
      "Epoch 57/100\n",
      "195/195 - 9s - loss: 0.2716 - accuracy: 0.9026 - auc: 0.9785 - val_loss: 3.4318 - val_accuracy: 0.8504 - val_auc: 0.5927\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.72972\n",
      "Epoch 58/100\n",
      "195/195 - 9s - loss: 0.2628 - accuracy: 0.9058 - auc: 0.9793 - val_loss: 3.8140 - val_accuracy: 0.8330 - val_auc: 0.5488\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.72972\n",
      "Epoch 59/100\n",
      "195/195 - 9s - loss: 0.2844 - accuracy: 0.8904 - auc: 0.9744 - val_loss: 3.9258 - val_accuracy: 0.9148 - val_auc: 0.6333\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.72972\n",
      "Epoch 60/100\n",
      "195/195 - 9s - loss: 0.2667 - accuracy: 0.8981 - auc: 0.9783 - val_loss: 4.6240 - val_accuracy: 0.9652 - val_auc: 0.5517\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.72972\n",
      "Epoch 61/100\n",
      "195/195 - 9s - loss: 0.2998 - accuracy: 0.9068 - auc: 0.9750 - val_loss: 3.3674 - val_accuracy: 0.8626 - val_auc: 0.6327\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.72972\n",
      "Epoch 62/100\n",
      "195/195 - 9s - loss: 0.2906 - accuracy: 0.9068 - auc: 0.9773 - val_loss: 3.5230 - val_accuracy: 0.8765 - val_auc: 0.6063\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.72972\n",
      "Epoch 63/100\n",
      "195/195 - 9s - loss: 0.2885 - accuracy: 0.8978 - auc: 0.9752 - val_loss: 3.6262 - val_accuracy: 0.8226 - val_auc: 0.5996\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.72972\n",
      "Epoch 64/100\n",
      "195/195 - 9s - loss: 0.2765 - accuracy: 0.9121 - auc: 0.9790 - val_loss: 4.1751 - val_accuracy: 0.9009 - val_auc: 0.5910\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.72972\n",
      "Epoch 65/100\n",
      "195/195 - 9s - loss: 0.2664 - accuracy: 0.9129 - auc: 0.9802 - val_loss: 3.3688 - val_accuracy: 0.9061 - val_auc: 0.6635\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.72972\n",
      "Epoch 66/100\n",
      "195/195 - 9s - loss: 0.2954 - accuracy: 0.9118 - auc: 0.9787 - val_loss: 3.3497 - val_accuracy: 0.8609 - val_auc: 0.6306\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.72972\n",
      "Epoch 67/100\n",
      "195/195 - 10s - loss: 0.2610 - accuracy: 0.9195 - auc: 0.9828 - val_loss: 3.4001 - val_accuracy: 0.8070 - val_auc: 0.5925\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.72972\n",
      "Epoch 68/100\n",
      "195/195 - 9s - loss: 0.2402 - accuracy: 0.9227 - auc: 0.9846 - val_loss: 4.1042 - val_accuracy: 0.8452 - val_auc: 0.5947\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.72972\n",
      "Epoch 69/100\n",
      "195/195 - 9s - loss: 0.2600 - accuracy: 0.9013 - auc: 0.9793 - val_loss: 3.9108 - val_accuracy: 0.8783 - val_auc: 0.5915\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.72972\n",
      "Epoch 70/100\n",
      "195/195 - 9s - loss: 0.2308 - accuracy: 0.9196 - auc: 0.9850 - val_loss: 4.6117 - val_accuracy: 0.9478 - val_auc: 0.5940\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.72972\n",
      "Epoch 71/100\n",
      "195/195 - 9s - loss: 0.2705 - accuracy: 0.8975 - auc: 0.9775 - val_loss: 3.5847 - val_accuracy: 0.8643 - val_auc: 0.6303\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.72972\n",
      "Epoch 72/100\n",
      "195/195 - 9s - loss: 0.2568 - accuracy: 0.9139 - auc: 0.9832 - val_loss: 4.3692 - val_accuracy: 0.9513 - val_auc: 0.6070\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.72972\n",
      "Epoch 73/100\n",
      "195/195 - 9s - loss: 0.2697 - accuracy: 0.9159 - auc: 0.9825 - val_loss: 4.6944 - val_accuracy: 0.9565 - val_auc: 0.5689\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.72972\n",
      "Epoch 74/100\n",
      "195/195 - 9s - loss: 0.2708 - accuracy: 0.9111 - auc: 0.9816 - val_loss: 3.4314 - val_accuracy: 0.8887 - val_auc: 0.6646\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.72972\n",
      "Epoch 75/100\n",
      "195/195 - 9s - loss: 0.2793 - accuracy: 0.9100 - auc: 0.9790 - val_loss: 3.3990 - val_accuracy: 0.7757 - val_auc: 0.6520\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.72972\n",
      "Epoch 76/100\n",
      "195/195 - 9s - loss: 0.2850 - accuracy: 0.8964 - auc: 0.9780 - val_loss: 3.5950 - val_accuracy: 0.8870 - val_auc: 0.6259\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.72972\n",
      "Epoch 77/100\n",
      "195/195 - 9s - loss: 0.2667 - accuracy: 0.9105 - auc: 0.9803 - val_loss: 4.3634 - val_accuracy: 0.8765 - val_auc: 0.6015\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.72972\n",
      "Epoch 78/100\n",
      "195/195 - 9s - loss: 0.2083 - accuracy: 0.9341 - auc: 0.9889 - val_loss: 5.0288 - val_accuracy: 0.9078 - val_auc: 0.5589\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.72972\n",
      "Epoch 79/100\n",
      "195/195 - 9s - loss: 0.2294 - accuracy: 0.9172 - auc: 0.9854 - val_loss: 3.7290 - val_accuracy: 0.8661 - val_auc: 0.6320\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.72972\n",
      "Epoch 80/100\n",
      "195/195 - 9s - loss: 0.2204 - accuracy: 0.9254 - auc: 0.9879 - val_loss: 4.8815 - val_accuracy: 0.9183 - val_auc: 0.5740\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.72972\n",
      "Epoch 81/100\n",
      "195/195 - 9s - loss: 0.2085 - accuracy: 0.9321 - auc: 0.9886 - val_loss: 4.7626 - val_accuracy: 0.9478 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.72972\n",
      "Epoch 82/100\n",
      "195/195 - 9s - loss: 0.2295 - accuracy: 0.9198 - auc: 0.9849 - val_loss: 4.6183 - val_accuracy: 0.9270 - val_auc: 0.5992\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.72972\n",
      "Epoch 83/100\n",
      "195/195 - 9s - loss: 0.2621 - accuracy: 0.9071 - auc: 0.9812 - val_loss: 3.7898 - val_accuracy: 0.9061 - val_auc: 0.6315\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.72972\n",
      "Epoch 84/100\n",
      "195/195 - 9s - loss: 0.2571 - accuracy: 0.9224 - auc: 0.9837 - val_loss: 4.3583 - val_accuracy: 0.9009 - val_auc: 0.5806\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.72972\n",
      "Epoch 85/100\n",
      "195/195 - 9s - loss: 0.2541 - accuracy: 0.9328 - auc: 0.9869 - val_loss: 4.2495 - val_accuracy: 0.8904 - val_auc: 0.6015\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.72972\n",
      "Epoch 86/100\n",
      "195/195 - 9s - loss: 0.2194 - accuracy: 0.9355 - auc: 0.9887 - val_loss: 4.6077 - val_accuracy: 0.9322 - val_auc: 0.6019\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.72972\n",
      "Epoch 87/100\n",
      "195/195 - 9s - loss: 0.2292 - accuracy: 0.9305 - auc: 0.9866 - val_loss: 3.4935 - val_accuracy: 0.9026 - val_auc: 0.6459\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.72972\n",
      "Epoch 88/100\n",
      "195/195 - 9s - loss: 0.2457 - accuracy: 0.9148 - auc: 0.9827 - val_loss: 4.7372 - val_accuracy: 0.9339 - val_auc: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_auc did not improve from 0.72972\n",
      "Epoch 89/100\n",
      "195/195 - 10s - loss: 0.2295 - accuracy: 0.9320 - auc: 0.9868 - val_loss: 4.1075 - val_accuracy: 0.9096 - val_auc: 0.6317\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.72972\n",
      "Epoch 90/100\n",
      "195/195 - 9s - loss: 0.3439 - accuracy: 0.8842 - auc: 0.9689 - val_loss: 3.5172 - val_accuracy: 0.9165 - val_auc: 0.6472\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.72972\n",
      "Epoch 91/100\n",
      "195/195 - 10s - loss: 0.2451 - accuracy: 0.9259 - auc: 0.9853 - val_loss: 4.6613 - val_accuracy: 0.9183 - val_auc: 0.6328\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.72972\n",
      "Epoch 92/100\n",
      "195/195 - 9s - loss: 0.2138 - accuracy: 0.9304 - auc: 0.9893 - val_loss: 4.6815 - val_accuracy: 0.9235 - val_auc: 0.6044\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.72972\n",
      "Epoch 93/100\n",
      "195/195 - 10s - loss: 0.2248 - accuracy: 0.9302 - auc: 0.9877 - val_loss: 3.9253 - val_accuracy: 0.8261 - val_auc: 0.5850\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.72972\n",
      "Epoch 94/100\n",
      "195/195 - 9s - loss: 0.2022 - accuracy: 0.9362 - auc: 0.9896 - val_loss: 4.8421 - val_accuracy: 0.9252 - val_auc: 0.6081\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.72972\n",
      "Epoch 95/100\n",
      "195/195 - 9s - loss: 3.8649 - accuracy: 0.9439 - auc: 0.7234 - val_loss: 7.2074 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.72972\n",
      "Epoch 96/100\n",
      "195/195 - 9s - loss: 7.9218 - accuracy: 0.9740 - auc: 0.4897 - val_loss: 7.3278 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.72972\n",
      "Epoch 97/100\n",
      "195/195 - 9s - loss: 7.8652 - accuracy: 0.9759 - auc: 0.5048 - val_loss: 7.3037 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.72972\n",
      "Epoch 98/100\n",
      "195/195 - 9s - loss: 7.9038 - accuracy: 0.9727 - auc: 0.4957 - val_loss: 7.3869 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.72972\n",
      "Epoch 99/100\n",
      "195/195 - 9s - loss: 7.9346 - accuracy: 0.9517 - auc: 0.5079 - val_loss: 8.1043 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.72972\n",
      "Epoch 100/100\n",
      "195/195 - 9s - loss: 8.3517 - accuracy: 0.9774 - auc: 0.5000 - val_loss: 7.5414 - val_accuracy: 0.9791 - val_auc: 0.5000\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.72972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c07ba58b20>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_auc',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "\n",
    "n_epoch=100\n",
    "\n",
    "\n",
    "LS_model.fit(train_tensor, \n",
    "                train_targets, \n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_tensor, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop training for all single-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = X_train.shape[1]\n",
    "n_attention = 10 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=20\n",
    "n_attention_out=1\n",
    "n_concat_hidden=2048\n",
    "n_hidden1 =1024\n",
    "n_hidden2 = 128 #Added 2nd hidden layer\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=32\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"gelu\"\n",
    "attention_hidden_activation=\"gelu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=\"glorot_uniform\"\n",
    "hidden_activation=\"gelu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 6th Jan 2021 (Edited Line 71 to Line 72. Reduce_mean instead of mean, to preserve the required rank)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "epsilon=K.epsilon\n",
    "\n",
    "def get_weights_dicts(Y):\n",
    "    weights_dicts=[]\n",
    "    for j in range(Y.shape[1]):\n",
    "        weight_zero, weight_one = _get_label_weights(Y[:,j])\n",
    "        d={'weight_zero':weight_zero,\n",
    "           'weight_one':weight_one\n",
    "          }\n",
    "        weights_dicts.append(d)\n",
    "    return weights_dicts\n",
    "def _get_label_weights(y):\n",
    "    #Get label weights for majority and minority class using the following:\n",
    "        #major_weight=n/(n_major*2)\n",
    "        #minor_weight=n*(n_major/n_minor)/(n_major*2)\n",
    "        #NaN weights are set to zero\n",
    "    y1=y[~np.isnan(y)]\n",
    "    n=len(y1)\n",
    "    n_zero=np.count_nonzero(np.isclose(y1,0))\n",
    "    n_one=np.count_nonzero(np.isclose(y1,1))\n",
    "    if n_zero>n_one:\n",
    "        weight_zero=n/(n_zero*2)\n",
    "        weight_one=n*(n_zero/n_one)/(n_zero*2)\n",
    "    else:\n",
    "        weight_zero=n*(n_one/n_zero)/(n_one*2)\n",
    "        weight_one=n/(n_one*2)\n",
    "    return weight_zero, weight_one    \n",
    "\n",
    "class BinaryCrossEntropyIgnoreNaN(tf.keras.losses.Loss):\n",
    "    def __init__(self, weights_dicts=None, axis=0, **kwargs):\n",
    "        super(BinaryCrossEntropyIgnoreNaN, self).__init__(**kwargs)\n",
    "        self.weights_dicts=weights_dicts\n",
    "        self.axis=axis        \n",
    "\n",
    "    def __call__(self, target, output, sample_weight=None):\n",
    "        #Binary cross entropy that ignores Nan and replaces with mini-batch Nan with 0\n",
    "        #modified from tf.python.keras.backend.binary_crossentropy\n",
    "        \n",
    "        ##NEED TO TEST THIS CODE MORE THOROUGHLY\n",
    "        target=tf.convert_to_tensor(target)\n",
    "        output=tf.convert_to_tensor(output)\n",
    "        if len(target.shape)==1:\n",
    "            target=tf.expand_dims(target, 1)\n",
    "            output=tf.expand_dims(output, 1)\n",
    "        epsilon_ = tf.constant(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output=tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "\n",
    "        #Compute cross entropy from probabilities\n",
    "        bce=target * tf.math.log(output+epsilon_)\n",
    "        bce+=(1-target)* tf.math.log(1-output+epsilon_)\n",
    "\n",
    "        bce=tf.where(tf.math.is_nan(-bce), epsilon(), -bce)\n",
    "        if self.weights_dicts is not None:\n",
    "            sample_weight=tf.cast(tf.where(target==0.,1.,0.)*[self.weights_dicts[i]['weight_zero'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            sample_weight+=tf.cast(tf.where(target==1., 1., 0.)*[self.weights_dicts[i]['weight_one'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            bce=tf.multiply(sample_weight, bce)\n",
    "#         return tf.keras.backend.mean(bce, axis=self.axis)  \n",
    "        return tf.math.reduce_mean(bce)\n",
    "\n",
    "    def call(self, target, output, sample_weight=None):\n",
    "        return self(target, output, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "def initialize_LSmodel(weights_dicts,\n",
    "                     n_attention=n_attention, \n",
    "                     n_attention_hidden=n_attention_hidden, \n",
    "                     n_feat=n_feat,\n",
    "                     n_concat_hidden=n_concat_hidden,\n",
    "                     n_hidden1=n_hidden1, \n",
    "                     n_hidden2=n_hidden2,\n",
    "                      ):\n",
    "    input_layer=Input(shape=(n_feat, ))\n",
    "    attentions_layer=attention_model.ConcatAttentions(\n",
    "        n_attention=n_attention,\n",
    "        n_attention_hidden=n_attention_hidden,\n",
    "        n_attention_out=n_attention_out,\n",
    "        n_feat=n_feat,\n",
    "        n_hidden=n_concat_hidden,\n",
    "        activation=concat_activation,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=l1(1E-5),\n",
    "        bias_regularizer=l1(1E-5),\n",
    "        attention_initializer=kernel_initializer,\n",
    "        attention_hidden_activation=attention_hidden_activation,\n",
    "        attention_output_activation=attention_output_activation\n",
    "    )(input_layer)\n",
    "\n",
    "    # attentions_layer=attention_model.ConcatAttentionswFeatWeights(\n",
    "    #     n_attention=n_attention,\n",
    "    #     n_attention_hidden=n_attention_hidden,\n",
    "    #     n_attention_out=n_attention_out,\n",
    "    #     n_feat=n_feat,\n",
    "    #     n_hidden=n_concat_hidden,\n",
    "    #     activation=concat_activation, \n",
    "    #     kernel_initializer=kernel_initializer,\n",
    "    #     kernel_regularizer=l1(1E-5),\n",
    "    #     bias_regularizer=l1(1E-5),\n",
    "    #     attention_initializer=kernel_initializer,\n",
    "    #     attention_hidden_activation=attention_hidden_activation,\n",
    "    #     attention_output_activation=attention_output_activation\n",
    "    # )(input_layer)\n",
    "    dropout0=Dropout(0.1)(attentions_layer)\n",
    "    dense_layer1=Dense(n_hidden1, \n",
    "                       activation=hidden_activation, \n",
    "                       kernel_initializer=kernel_initializer,\n",
    "                       kernel_regularizer=l1(1E-5),\n",
    "                       bias_regularizer=l1(1E-5),\n",
    "                      )(dropout0)\n",
    "    dropout1=Dropout(0.1)(dense_layer1)\n",
    "    dense_layer2=Dense(n_hidden2,\n",
    "                       activation=hidden_activation,\n",
    "                       kernel_initializer=kernel_initializer,\n",
    "                       kernel_regularizer=l1(1E-5),\n",
    "                       bias_regularizer=l1(1E-5)\n",
    "                      )(dropout1)\n",
    "    dropout2=Dropout(0.1)(dense_layer2)\n",
    "    output_layer=Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "    LS_model=Model(inputs=input_layer, \n",
    "                      outputs=output_layer\n",
    "                     )\n",
    "\n",
    "    weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "    loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "    LS_model.compile(loss=loss_fn, \n",
    "#                   optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      optimizer=tf.keras.optimizers.Adagrad(\n",
    "                          learning_rate=learning_rate\n",
    "                      ),\n",
    "                     metrics=['accuracy', 'AUC']\n",
    "                 )\n",
    "    \n",
    "    return LS_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: '210128_TrainingLocalitySensitivewoFW'\n",
      "[WinError 183] Cannot create a file when that file already exists: '210128_TrainingLocalitySensitivewoFW\\\\210128_LS_NR-AR'\n",
      "Epoch 1/100\n",
      "292/292 - 18s - loss: 3.2246 - accuracy: 0.8007 - auc: 0.8165 - val_loss: 3.1682 - val_accuracy: 0.8591 - val_auc: 0.7234\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.72343, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AR\n",
      "Epoch 2/100\n",
      "292/292 - 14s - loss: 3.1270 - accuracy: 0.9002 - auc: 0.8819 - val_loss: 3.1935 - val_accuracy: 0.8400 - val_auc: 0.7157\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.72343\n",
      "Epoch 3/100\n",
      "292/292 - 14s - loss: 3.0876 - accuracy: 0.9059 - auc: 0.9134 - val_loss: 3.1910 - val_accuracy: 0.8852 - val_auc: 0.7317\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.72343 to 0.73172, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AR\n",
      "Epoch 4/100\n",
      "292/292 - 14s - loss: 3.0639 - accuracy: 0.9078 - auc: 0.9228 - val_loss: 3.2039 - val_accuracy: 0.8678 - val_auc: 0.7233\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.73172\n",
      "Epoch 5/100\n",
      "292/292 - 13s - loss: 3.0390 - accuracy: 0.9144 - auc: 0.9355 - val_loss: 3.2092 - val_accuracy: 0.8783 - val_auc: 0.7159\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.73172\n",
      "Epoch 6/100\n",
      "292/292 - 13s - loss: 3.0037 - accuracy: 0.9241 - auc: 0.9521 - val_loss: 3.2335 - val_accuracy: 0.8974 - val_auc: 0.7150\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.73172\n",
      "Epoch 7/100\n",
      "292/292 - 13s - loss: 2.9780 - accuracy: 0.9259 - auc: 0.9620 - val_loss: 3.2672 - val_accuracy: 0.9304 - val_auc: 0.7070\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.73172\n",
      "Epoch 8/100\n",
      "292/292 - 13s - loss: 2.9710 - accuracy: 0.9278 - auc: 0.9629 - val_loss: 3.2726 - val_accuracy: 0.8957 - val_auc: 0.7217\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.73172\n",
      "Epoch 9/100\n",
      "292/292 - 13s - loss: 2.9446 - accuracy: 0.9318 - auc: 0.9701 - val_loss: 3.3057 - val_accuracy: 0.9183 - val_auc: 0.7257\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.73172\n",
      "Epoch 10/100\n",
      "292/292 - 13s - loss: 2.9232 - accuracy: 0.9356 - auc: 0.9760 - val_loss: 3.3127 - val_accuracy: 0.8887 - val_auc: 0.7265\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.73172\n",
      "Epoch 11/100\n",
      "292/292 - 13s - loss: 2.9043 - accuracy: 0.9405 - auc: 0.9797 - val_loss: 3.4359 - val_accuracy: 0.9426 - val_auc: 0.6792\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.73172\n",
      "Epoch 12/100\n",
      "292/292 - 13s - loss: 2.8898 - accuracy: 0.9427 - auc: 0.9832 - val_loss: 3.4605 - val_accuracy: 0.9426 - val_auc: 0.6740\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.73172\n",
      "Epoch 13/100\n",
      "292/292 - 13s - loss: 2.8647 - accuracy: 0.9486 - auc: 0.9875 - val_loss: 3.4853 - val_accuracy: 0.9339 - val_auc: 0.7051\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.73172\n",
      "Epoch 14/100\n",
      "292/292 - 13s - loss: 2.8586 - accuracy: 0.9504 - auc: 0.9874 - val_loss: 3.5284 - val_accuracy: 0.9304 - val_auc: 0.6645\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.73172\n",
      "Epoch 15/100\n",
      "292/292 - 12s - loss: 2.8433 - accuracy: 0.9509 - auc: 0.9892 - val_loss: 3.5249 - val_accuracy: 0.9287 - val_auc: 0.6844\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.73172\n",
      "Epoch 16/100\n",
      "292/292 - 12s - loss: 2.8323 - accuracy: 0.9530 - auc: 0.9904 - val_loss: 3.5959 - val_accuracy: 0.9339 - val_auc: 0.6765\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.73172\n",
      "Epoch 17/100\n",
      "292/292 - 12s - loss: 2.8249 - accuracy: 0.9541 - auc: 0.9907 - val_loss: 3.7017 - val_accuracy: 0.9496 - val_auc: 0.6522\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.73172\n",
      "Epoch 18/100\n",
      "292/292 - 12s - loss: 2.8079 - accuracy: 0.9566 - auc: 0.9925 - val_loss: 3.6764 - val_accuracy: 0.9426 - val_auc: 0.6995\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.73172\n",
      "Epoch 19/100\n",
      "292/292 - 12s - loss: 2.8043 - accuracy: 0.9588 - auc: 0.9921 - val_loss: 3.7276 - val_accuracy: 0.9357 - val_auc: 0.6881\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.73172\n",
      "Epoch 20/100\n",
      "292/292 - 13s - loss: 2.7965 - accuracy: 0.9594 - auc: 0.9927 - val_loss: 3.7768 - val_accuracy: 0.9391 - val_auc: 0.6388\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.73172\n",
      "Epoch 21/100\n",
      "292/292 - 13s - loss: 2.7850 - accuracy: 0.9592 - auc: 0.9940 - val_loss: 3.8890 - val_accuracy: 0.9496 - val_auc: 0.6595\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.73172\n",
      "Epoch 22/100\n",
      "292/292 - 13s - loss: 2.7800 - accuracy: 0.9603 - auc: 0.9940 - val_loss: 3.9275 - val_accuracy: 0.9513 - val_auc: 0.6243\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.73172\n",
      "Epoch 23/100\n",
      "292/292 - 13s - loss: 2.7774 - accuracy: 0.9611 - auc: 0.9938 - val_loss: 3.8827 - val_accuracy: 0.9391 - val_auc: 0.6494\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.73172\n",
      "Epoch 24/100\n",
      "292/292 - 13s - loss: 2.7676 - accuracy: 0.9652 - auc: 0.9944 - val_loss: 4.0561 - val_accuracy: 0.9496 - val_auc: 0.5645\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.73172\n",
      "Epoch 25/100\n",
      "292/292 - 13s - loss: 2.7574 - accuracy: 0.9682 - auc: 0.9955 - val_loss: 4.1266 - val_accuracy: 0.9617 - val_auc: 0.6331\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.73172\n",
      "Epoch 26/100\n",
      "292/292 - 14s - loss: 2.7504 - accuracy: 0.9694 - auc: 0.9956 - val_loss: 4.1890 - val_accuracy: 0.9583 - val_auc: 0.6448\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.73172\n",
      "Epoch 27/100\n",
      "292/292 - 14s - loss: 2.7480 - accuracy: 0.9719 - auc: 0.9959 - val_loss: 4.0617 - val_accuracy: 0.9426 - val_auc: 0.6362\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.73172\n",
      "Epoch 28/100\n",
      "292/292 - 14s - loss: 2.7462 - accuracy: 0.9691 - auc: 0.9958 - val_loss: 4.0651 - val_accuracy: 0.9478 - val_auc: 0.6312\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.73172\n",
      "Epoch 29/100\n",
      "292/292 - 14s - loss: 2.7391 - accuracy: 0.9701 - auc: 0.9963 - val_loss: 4.0918 - val_accuracy: 0.9513 - val_auc: 0.6505\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.73172\n",
      "Epoch 30/100\n",
      "292/292 - 14s - loss: 2.7394 - accuracy: 0.9696 - auc: 0.9957 - val_loss: 4.1389 - val_accuracy: 0.9496 - val_auc: 0.6478\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.73172\n",
      "Epoch 31/100\n",
      "292/292 - 13s - loss: 2.7358 - accuracy: 0.9714 - auc: 0.9958 - val_loss: 4.3144 - val_accuracy: 0.9617 - val_auc: 0.6166\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.73172\n",
      "Epoch 32/100\n",
      "292/292 - 14s - loss: 2.7297 - accuracy: 0.9729 - auc: 0.9961 - val_loss: 4.2194 - val_accuracy: 0.9496 - val_auc: 0.6080\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.73172\n",
      "Epoch 33/100\n",
      "292/292 - 14s - loss: 2.7257 - accuracy: 0.9736 - auc: 0.9962 - val_loss: 4.2958 - val_accuracy: 0.9565 - val_auc: 0.6238\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.73172\n",
      "Epoch 34/100\n",
      "292/292 - 14s - loss: 2.7270 - accuracy: 0.9743 - auc: 0.9960 - val_loss: 4.2172 - val_accuracy: 0.9530 - val_auc: 0.6180\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.73172\n",
      "Epoch 35/100\n",
      "292/292 - 14s - loss: 2.7210 - accuracy: 0.9733 - auc: 0.9960 - val_loss: 4.2991 - val_accuracy: 0.9565 - val_auc: 0.6180\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.73172\n",
      "Epoch 36/100\n",
      "292/292 - 14s - loss: 2.7211 - accuracy: 0.9739 - auc: 0.9961 - val_loss: 4.3424 - val_accuracy: 0.9583 - val_auc: 0.6224\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.73172\n",
      "Epoch 37/100\n",
      "292/292 - 13s - loss: 2.7119 - accuracy: 0.9758 - auc: 0.9962 - val_loss: 4.3971 - val_accuracy: 0.9635 - val_auc: 0.6142\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.73172\n",
      "Epoch 38/100\n",
      "292/292 - 13s - loss: 2.7098 - accuracy: 0.9777 - auc: 0.9963 - val_loss: 4.2374 - val_accuracy: 0.9478 - val_auc: 0.6349\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.73172\n",
      "Epoch 39/100\n",
      "292/292 - 13s - loss: 2.7127 - accuracy: 0.9743 - auc: 0.9961 - val_loss: 4.3805 - val_accuracy: 0.9583 - val_auc: 0.6046\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.73172\n",
      "Epoch 40/100\n",
      "292/292 - 13s - loss: 2.7057 - accuracy: 0.9772 - auc: 0.9971 - val_loss: 4.4320 - val_accuracy: 0.9635 - val_auc: 0.5997\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.73172\n",
      "Epoch 41/100\n",
      "292/292 - 13s - loss: 2.6997 - accuracy: 0.9786 - auc: 0.9968 - val_loss: 4.4231 - val_accuracy: 0.9652 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.73172\n",
      "Epoch 42/100\n",
      "292/292 - 13s - loss: 2.6975 - accuracy: 0.9779 - auc: 0.9969 - val_loss: 4.4516 - val_accuracy: 0.9600 - val_auc: 0.6141\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.73172\n",
      "Epoch 43/100\n",
      "292/292 - 13s - loss: 2.6951 - accuracy: 0.9780 - auc: 0.9968 - val_loss: 4.4991 - val_accuracy: 0.9670 - val_auc: 0.6064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_auc did not improve from 0.73172\n",
      "Epoch 44/100\n",
      "292/292 - 13s - loss: 2.6916 - accuracy: 0.9785 - auc: 0.9972 - val_loss: 4.3772 - val_accuracy: 0.9548 - val_auc: 0.6112\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.73172\n",
      "Epoch 45/100\n",
      "292/292 - 13s - loss: 2.6871 - accuracy: 0.9802 - auc: 0.9973 - val_loss: 4.4767 - val_accuracy: 0.9635 - val_auc: 0.6067\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.73172\n",
      "Epoch 46/100\n",
      "292/292 - 13s - loss: 2.6857 - accuracy: 0.9809 - auc: 0.9975 - val_loss: 4.3715 - val_accuracy: 0.9565 - val_auc: 0.6214\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.73172\n",
      "Epoch 47/100\n",
      "292/292 - 13s - loss: 2.6883 - accuracy: 0.9793 - auc: 0.9968 - val_loss: 4.4750 - val_accuracy: 0.9600 - val_auc: 0.6078\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.73172\n",
      "Epoch 48/100\n",
      "292/292 - 14s - loss: 2.6814 - accuracy: 0.9810 - auc: 0.9973 - val_loss: 4.4958 - val_accuracy: 0.9652 - val_auc: 0.6137\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.73172\n",
      "Epoch 49/100\n",
      "292/292 - 14s - loss: 2.6801 - accuracy: 0.9798 - auc: 0.9974 - val_loss: 4.5830 - val_accuracy: 0.9670 - val_auc: 0.5491\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.73172\n",
      "Epoch 50/100\n",
      "292/292 - 14s - loss: 2.6834 - accuracy: 0.9783 - auc: 0.9969 - val_loss: 4.5287 - val_accuracy: 0.9583 - val_auc: 0.6079\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.73172\n",
      "Epoch 51/100\n",
      "292/292 - 14s - loss: 2.6747 - accuracy: 0.9810 - auc: 0.9972 - val_loss: 4.5471 - val_accuracy: 0.9670 - val_auc: 0.6300\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.73172\n",
      "Epoch 52/100\n",
      "292/292 - 14s - loss: 2.6767 - accuracy: 0.9817 - auc: 0.9970 - val_loss: 4.3761 - val_accuracy: 0.9583 - val_auc: 0.6249\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.73172\n",
      "Epoch 53/100\n",
      "292/292 - 13s - loss: 2.6729 - accuracy: 0.9800 - auc: 0.9974 - val_loss: 4.4985 - val_accuracy: 0.9548 - val_auc: 0.6265\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.73172\n",
      "Epoch 54/100\n",
      "292/292 - 12s - loss: 2.6692 - accuracy: 0.9813 - auc: 0.9974 - val_loss: 4.5761 - val_accuracy: 0.9670 - val_auc: 0.5527\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.73172\n",
      "Epoch 55/100\n",
      "292/292 - 13s - loss: 2.6668 - accuracy: 0.9813 - auc: 0.9973 - val_loss: 4.6656 - val_accuracy: 0.9670 - val_auc: 0.5548\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.73172\n",
      "Epoch 56/100\n",
      "292/292 - 12s - loss: 2.6642 - accuracy: 0.9819 - auc: 0.9972 - val_loss: 4.6275 - val_accuracy: 0.9635 - val_auc: 0.5941\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.73172\n",
      "Epoch 57/100\n",
      "292/292 - 13s - loss: 2.6618 - accuracy: 0.9835 - auc: 0.9971 - val_loss: 4.6743 - val_accuracy: 0.9652 - val_auc: 0.5595\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.73172\n",
      "Epoch 58/100\n",
      "292/292 - 14s - loss: 2.6591 - accuracy: 0.9831 - auc: 0.9974 - val_loss: 4.5227 - val_accuracy: 0.9617 - val_auc: 0.5893\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.73172\n",
      "Epoch 59/100\n",
      "292/292 - 14s - loss: 2.6574 - accuracy: 0.9821 - auc: 0.9975 - val_loss: 4.6462 - val_accuracy: 0.9652 - val_auc: 0.5563\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.73172\n",
      "Epoch 60/100\n",
      "292/292 - 14s - loss: 2.6552 - accuracy: 0.9830 - auc: 0.9975 - val_loss: 4.6382 - val_accuracy: 0.9635 - val_auc: 0.5523\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.73172\n",
      "Epoch 61/100\n",
      "292/292 - 13s - loss: 2.6554 - accuracy: 0.9825 - auc: 0.9971 - val_loss: 4.6418 - val_accuracy: 0.9600 - val_auc: 0.6298\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.73172\n",
      "Epoch 62/100\n",
      "292/292 - 14s - loss: 2.6504 - accuracy: 0.9824 - auc: 0.9976 - val_loss: 4.6359 - val_accuracy: 0.9617 - val_auc: 0.5870\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.73172\n",
      "Epoch 63/100\n",
      "292/292 - 14s - loss: 2.6483 - accuracy: 0.9833 - auc: 0.9974 - val_loss: 4.6721 - val_accuracy: 0.9687 - val_auc: 0.5588\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.73172\n",
      "Epoch 64/100\n",
      "292/292 - 14s - loss: 2.6466 - accuracy: 0.9833 - auc: 0.9974 - val_loss: 4.5856 - val_accuracy: 0.9600 - val_auc: 0.5987\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.73172\n",
      "Epoch 65/100\n",
      "292/292 - 14s - loss: 2.6428 - accuracy: 0.9839 - auc: 0.9976 - val_loss: 4.5859 - val_accuracy: 0.9635 - val_auc: 0.5949\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.73172\n",
      "Epoch 66/100\n",
      "292/292 - 14s - loss: 2.6412 - accuracy: 0.9834 - auc: 0.9979 - val_loss: 4.7194 - val_accuracy: 0.9687 - val_auc: 0.5707\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.73172\n",
      "Epoch 67/100\n",
      "292/292 - 14s - loss: 2.6383 - accuracy: 0.9843 - auc: 0.9978 - val_loss: 4.7928 - val_accuracy: 0.9687 - val_auc: 0.5749\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.73172\n",
      "Epoch 68/100\n",
      "292/292 - 14s - loss: 2.6360 - accuracy: 0.9843 - auc: 0.9980 - val_loss: 4.6639 - val_accuracy: 0.9600 - val_auc: 0.5665\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.73172\n",
      "Epoch 69/100\n",
      "292/292 - 14s - loss: 2.6328 - accuracy: 0.9844 - auc: 0.9982 - val_loss: 4.7040 - val_accuracy: 0.9652 - val_auc: 0.5639\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.73172\n",
      "Epoch 70/100\n",
      "292/292 - 14s - loss: 2.6335 - accuracy: 0.9844 - auc: 0.9977 - val_loss: 4.7408 - val_accuracy: 0.9670 - val_auc: 0.5653\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.73172\n",
      "Epoch 71/100\n",
      "292/292 - 14s - loss: 2.6322 - accuracy: 0.9843 - auc: 0.9977 - val_loss: 4.6289 - val_accuracy: 0.9600 - val_auc: 0.5615\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.73172\n",
      "Epoch 72/100\n",
      "292/292 - 14s - loss: 2.6277 - accuracy: 0.9849 - auc: 0.9982 - val_loss: 4.6937 - val_accuracy: 0.9635 - val_auc: 0.6113\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.73172\n",
      "Epoch 73/100\n",
      "292/292 - 14s - loss: 2.6323 - accuracy: 0.9827 - auc: 0.9974 - val_loss: 4.6921 - val_accuracy: 0.9652 - val_auc: 0.5690\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.73172\n",
      "Epoch 74/100\n",
      "292/292 - 14s - loss: 2.6276 - accuracy: 0.9836 - auc: 0.9979 - val_loss: 4.6789 - val_accuracy: 0.9687 - val_auc: 0.5687\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.73172\n",
      "Epoch 75/100\n",
      "292/292 - 14s - loss: 2.6241 - accuracy: 0.9845 - auc: 0.9978 - val_loss: 4.5732 - val_accuracy: 0.9600 - val_auc: 0.5990\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.73172\n",
      "Epoch 76/100\n",
      "292/292 - 14s - loss: 2.6233 - accuracy: 0.9843 - auc: 0.9981 - val_loss: 4.6710 - val_accuracy: 0.9635 - val_auc: 0.6011\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.73172\n",
      "Epoch 77/100\n",
      "292/292 - 14s - loss: 2.6209 - accuracy: 0.9849 - auc: 0.9978 - val_loss: 4.7167 - val_accuracy: 0.9704 - val_auc: 0.5730\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.73172\n",
      "Epoch 78/100\n",
      "292/292 - 14s - loss: 2.6203 - accuracy: 0.9845 - auc: 0.9979 - val_loss: 4.6400 - val_accuracy: 0.9617 - val_auc: 0.5659\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.73172\n",
      "Epoch 79/100\n",
      "292/292 - 14s - loss: 2.6193 - accuracy: 0.9845 - auc: 0.9977 - val_loss: 4.7340 - val_accuracy: 0.9652 - val_auc: 0.5655\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.73172\n",
      "Epoch 80/100\n",
      "292/292 - 14s - loss: 2.6115 - accuracy: 0.9842 - auc: 0.9982 - val_loss: 4.7025 - val_accuracy: 0.9635 - val_auc: 0.5734\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.73172\n",
      "Epoch 81/100\n",
      "292/292 - 14s - loss: 2.6137 - accuracy: 0.9850 - auc: 0.9978 - val_loss: 4.5426 - val_accuracy: 0.9496 - val_auc: 0.5918\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.73172\n",
      "Epoch 82/100\n",
      "292/292 - 14s - loss: 2.6099 - accuracy: 0.9852 - auc: 0.9980 - val_loss: 4.7145 - val_accuracy: 0.9652 - val_auc: 0.5696\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.73172\n",
      "Epoch 83/100\n",
      "292/292 - 14s - loss: 2.6075 - accuracy: 0.9860 - auc: 0.9980 - val_loss: 4.6885 - val_accuracy: 0.9652 - val_auc: 0.5668\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.73172\n",
      "Epoch 84/100\n",
      "292/292 - 14s - loss: 2.6044 - accuracy: 0.9862 - auc: 0.9980 - val_loss: 4.6648 - val_accuracy: 0.9617 - val_auc: 0.5677\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.73172\n",
      "Epoch 85/100\n",
      "292/292 - 14s - loss: 2.6031 - accuracy: 0.9861 - auc: 0.9979 - val_loss: 4.7123 - val_accuracy: 0.9635 - val_auc: 0.5691\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.73172\n",
      "Epoch 86/100\n",
      "292/292 - 14s - loss: 2.6028 - accuracy: 0.9852 - auc: 0.9981 - val_loss: 4.7429 - val_accuracy: 0.9652 - val_auc: 0.5771\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.73172\n",
      "Epoch 87/100\n",
      "292/292 - 14s - loss: 2.5994 - accuracy: 0.9861 - auc: 0.9982 - val_loss: 4.6670 - val_accuracy: 0.9635 - val_auc: 0.5691\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.73172\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 - 14s - loss: 2.5968 - accuracy: 0.9861 - auc: 0.9983 - val_loss: 4.7453 - val_accuracy: 0.9652 - val_auc: 0.5684\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.73172\n",
      "Epoch 89/100\n",
      "292/292 - 14s - loss: 2.5939 - accuracy: 0.9862 - auc: 0.9983 - val_loss: 4.8117 - val_accuracy: 0.9687 - val_auc: 0.5767\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.73172\n",
      "Epoch 90/100\n",
      "292/292 - 14s - loss: 2.5945 - accuracy: 0.9863 - auc: 0.9982 - val_loss: 4.7867 - val_accuracy: 0.9670 - val_auc: 0.5713\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.73172\n",
      "Epoch 91/100\n",
      "292/292 - 13s - loss: 2.5919 - accuracy: 0.9865 - auc: 0.9982 - val_loss: 4.7439 - val_accuracy: 0.9617 - val_auc: 0.5741\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.73172\n",
      "Epoch 92/100\n",
      "292/292 - 13s - loss: 2.5934 - accuracy: 0.9851 - auc: 0.9981 - val_loss: 4.6579 - val_accuracy: 0.9583 - val_auc: 0.5633\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.73172\n",
      "Epoch 93/100\n",
      "292/292 - 13s - loss: 2.5884 - accuracy: 0.9866 - auc: 0.9980 - val_loss: 4.7452 - val_accuracy: 0.9635 - val_auc: 0.5742\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.73172\n",
      "Epoch 94/100\n",
      "292/292 - 12s - loss: 2.5861 - accuracy: 0.9865 - auc: 0.9980 - val_loss: 4.8398 - val_accuracy: 0.9687 - val_auc: 0.5807\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.73172\n",
      "Epoch 95/100\n",
      "292/292 - 13s - loss: 2.5874 - accuracy: 0.9861 - auc: 0.9981 - val_loss: 4.7575 - val_accuracy: 0.9652 - val_auc: 0.5739\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.73172\n",
      "Epoch 96/100\n",
      "292/292 - 14s - loss: 2.5822 - accuracy: 0.9865 - auc: 0.9981 - val_loss: 4.7676 - val_accuracy: 0.9670 - val_auc: 0.5751\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.73172\n",
      "Epoch 97/100\n",
      "292/292 - 14s - loss: 2.5828 - accuracy: 0.9861 - auc: 0.9981 - val_loss: 4.7808 - val_accuracy: 0.9670 - val_auc: 0.5728\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.73172\n",
      "Epoch 98/100\n",
      "292/292 - 14s - loss: 2.5774 - accuracy: 0.9869 - auc: 0.9983 - val_loss: 4.7679 - val_accuracy: 0.9635 - val_auc: 0.5770\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.73172\n",
      "Epoch 99/100\n",
      "292/292 - 14s - loss: 2.5783 - accuracy: 0.9859 - auc: 0.9980 - val_loss: 4.6959 - val_accuracy: 0.9617 - val_auc: 0.5725\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.73172\n",
      "Epoch 100/100\n",
      "292/292 - 14s - loss: 2.5743 - accuracy: 0.9858 - auc: 0.9983 - val_loss: 4.8564 - val_accuracy: 0.9687 - val_auc: 0.5837\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.73172\n",
      "[WinError 183] Cannot create a file when that file already exists: '210128_TrainingLocalitySensitivewoFW\\\\210128_LS_NR-AhR'\n",
      "Epoch 1/100\n",
      "257/257 - 16s - loss: 3.2293 - accuracy: 0.6836 - auc: 0.8435 - val_loss: 3.2078 - val_accuracy: 0.7466 - val_auc: 0.8773\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.87728, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 2/100\n",
      "257/257 - 12s - loss: 3.1300 - accuracy: 0.7689 - auc: 0.8991 - val_loss: 3.2036 - val_accuracy: 0.7836 - val_auc: 0.8823\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.87728 to 0.88229, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 3/100\n",
      "257/257 - 12s - loss: 3.0903 - accuracy: 0.8098 - auc: 0.9173 - val_loss: 3.2076 - val_accuracy: 0.8188 - val_auc: 0.8845\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.88229 to 0.88454, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 4/100\n",
      "257/257 - 12s - loss: 3.0654 - accuracy: 0.8312 - auc: 0.9264 - val_loss: 3.1996 - val_accuracy: 0.8272 - val_auc: 0.8862\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.88454 to 0.88621, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 5/100\n",
      "257/257 - 12s - loss: 3.0435 - accuracy: 0.8461 - auc: 0.9353 - val_loss: 3.2012 - val_accuracy: 0.8255 - val_auc: 0.8900\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.88621 to 0.88998, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 6/100\n",
      "257/257 - 12s - loss: 3.0203 - accuracy: 0.8568 - auc: 0.9438 - val_loss: 3.2095 - val_accuracy: 0.8423 - val_auc: 0.8923\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.88998 to 0.89231, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 7/100\n",
      "257/257 - 12s - loss: 3.0032 - accuracy: 0.8692 - auc: 0.9496 - val_loss: 3.2373 - val_accuracy: 0.8523 - val_auc: 0.8895\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.89231\n",
      "Epoch 8/100\n",
      "257/257 - 12s - loss: 2.9838 - accuracy: 0.8782 - auc: 0.9558 - val_loss: 3.2349 - val_accuracy: 0.8507 - val_auc: 0.8927\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.89231 to 0.89270, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 9/100\n",
      "257/257 - 12s - loss: 2.9648 - accuracy: 0.8881 - auc: 0.9612 - val_loss: 3.3102 - val_accuracy: 0.8322 - val_auc: 0.8712\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.89270\n",
      "Epoch 10/100\n",
      "257/257 - 12s - loss: 2.9554 - accuracy: 0.8916 - auc: 0.9634 - val_loss: 3.2599 - val_accuracy: 0.8574 - val_auc: 0.8947\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.89270 to 0.89475, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 11/100\n",
      "257/257 - 12s - loss: 2.9381 - accuracy: 0.9013 - auc: 0.9684 - val_loss: 3.2680 - val_accuracy: 0.8574 - val_auc: 0.8928\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.89475\n",
      "Epoch 12/100\n",
      "257/257 - 12s - loss: 2.9213 - accuracy: 0.9085 - auc: 0.9722 - val_loss: 3.3138 - val_accuracy: 0.8725 - val_auc: 0.8860\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.89475\n",
      "Epoch 13/100\n",
      "257/257 - 12s - loss: 2.9154 - accuracy: 0.9097 - auc: 0.9731 - val_loss: 3.2759 - val_accuracy: 0.8725 - val_auc: 0.8965\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.89475 to 0.89650, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AhR\n",
      "Epoch 14/100\n",
      "257/257 - 12s - loss: 2.8983 - accuracy: 0.9168 - auc: 0.9770 - val_loss: 3.3264 - val_accuracy: 0.8674 - val_auc: 0.8884\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.89650\n",
      "Epoch 15/100\n",
      "257/257 - 12s - loss: 2.8901 - accuracy: 0.9210 - auc: 0.9782 - val_loss: 3.3178 - val_accuracy: 0.8708 - val_auc: 0.8916\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.89650\n",
      "Epoch 16/100\n",
      "257/257 - 12s - loss: 2.8758 - accuracy: 0.9268 - auc: 0.9811 - val_loss: 3.3783 - val_accuracy: 0.8792 - val_auc: 0.8868\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.89650\n",
      "Epoch 17/100\n",
      "257/257 - 12s - loss: 2.8643 - accuracy: 0.9314 - auc: 0.9831 - val_loss: 3.3501 - val_accuracy: 0.8708 - val_auc: 0.8899\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.89650\n",
      "Epoch 18/100\n",
      "257/257 - 12s - loss: 2.8533 - accuracy: 0.9336 - auc: 0.9851 - val_loss: 3.3614 - val_accuracy: 0.8742 - val_auc: 0.8950\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.89650\n",
      "Epoch 19/100\n",
      "257/257 - 12s - loss: 2.8468 - accuracy: 0.9373 - auc: 0.9858 - val_loss: 3.3714 - val_accuracy: 0.8691 - val_auc: 0.8916\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.89650\n",
      "Epoch 20/100\n",
      "257/257 - 12s - loss: 2.8397 - accuracy: 0.9410 - auc: 0.9864 - val_loss: 3.3614 - val_accuracy: 0.8591 - val_auc: 0.8913\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.89650\n",
      "Epoch 21/100\n",
      "257/257 - 12s - loss: 2.8324 - accuracy: 0.9414 - auc: 0.9874 - val_loss: 3.4038 - val_accuracy: 0.8691 - val_auc: 0.8867\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.89650\n",
      "Epoch 22/100\n",
      "257/257 - 12s - loss: 2.8230 - accuracy: 0.9453 - auc: 0.9884 - val_loss: 3.4357 - val_accuracy: 0.8775 - val_auc: 0.8833\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.89650\n",
      "Epoch 23/100\n",
      "257/257 - 12s - loss: 2.8170 - accuracy: 0.9445 - auc: 0.9891 - val_loss: 3.4584 - val_accuracy: 0.8859 - val_auc: 0.8849\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.89650\n",
      "Epoch 24/100\n",
      "257/257 - 13s - loss: 2.8093 - accuracy: 0.9492 - auc: 0.9902 - val_loss: 3.4639 - val_accuracy: 0.8725 - val_auc: 0.8836\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.89650\n",
      "Epoch 25/100\n",
      "257/257 - 12s - loss: 2.7999 - accuracy: 0.9518 - auc: 0.9912 - val_loss: 3.4204 - val_accuracy: 0.8775 - val_auc: 0.8911\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.89650\n",
      "Epoch 26/100\n",
      "257/257 - 13s - loss: 2.7911 - accuracy: 0.9553 - auc: 0.9920 - val_loss: 3.5042 - val_accuracy: 0.8809 - val_auc: 0.8862\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.89650\n",
      "Epoch 27/100\n",
      "257/257 - 16s - loss: 2.7888 - accuracy: 0.9574 - auc: 0.9922 - val_loss: 3.4873 - val_accuracy: 0.8792 - val_auc: 0.8820\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.89650\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 12s - loss: 2.7808 - accuracy: 0.9594 - auc: 0.9927 - val_loss: 3.4992 - val_accuracy: 0.8708 - val_auc: 0.8845\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.89650\n",
      "Epoch 29/100\n",
      "257/257 - 12s - loss: 2.7762 - accuracy: 0.9592 - auc: 0.9934 - val_loss: 3.5398 - val_accuracy: 0.8859 - val_auc: 0.8833\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.89650\n",
      "Epoch 30/100\n",
      "257/257 - 12s - loss: 2.7734 - accuracy: 0.9602 - auc: 0.9933 - val_loss: 3.4732 - val_accuracy: 0.8775 - val_auc: 0.8909\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.89650\n",
      "Epoch 31/100\n",
      "257/257 - 10s - loss: 2.7693 - accuracy: 0.9605 - auc: 0.9935 - val_loss: 3.5163 - val_accuracy: 0.8742 - val_auc: 0.8838\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.89650\n",
      "Epoch 32/100\n",
      "257/257 - 11s - loss: 2.7594 - accuracy: 0.9641 - auc: 0.9942 - val_loss: 3.5147 - val_accuracy: 0.8826 - val_auc: 0.8848\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.89650\n",
      "Epoch 33/100\n",
      "257/257 - 11s - loss: 2.7561 - accuracy: 0.9653 - auc: 0.9946 - val_loss: 3.5746 - val_accuracy: 0.8893 - val_auc: 0.8838\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.89650\n",
      "Epoch 34/100\n",
      "257/257 - 10s - loss: 2.7503 - accuracy: 0.9672 - auc: 0.9948 - val_loss: 3.5607 - val_accuracy: 0.8826 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.89650\n",
      "Epoch 35/100\n",
      "257/257 - 10s - loss: 2.7446 - accuracy: 0.9677 - auc: 0.9954 - val_loss: 3.6212 - val_accuracy: 0.8909 - val_auc: 0.8822\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.89650\n",
      "Epoch 36/100\n",
      "257/257 - 12s - loss: 2.7369 - accuracy: 0.9716 - auc: 0.9960 - val_loss: 3.6802 - val_accuracy: 0.8809 - val_auc: 0.8679\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.89650\n",
      "Epoch 37/100\n",
      "257/257 - 12s - loss: 2.7424 - accuracy: 0.9695 - auc: 0.9952 - val_loss: 3.6154 - val_accuracy: 0.8826 - val_auc: 0.8797\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.89650\n",
      "Epoch 38/100\n",
      "257/257 - 12s - loss: 2.7331 - accuracy: 0.9720 - auc: 0.9961 - val_loss: 3.6077 - val_accuracy: 0.8842 - val_auc: 0.8845\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.89650\n",
      "Epoch 39/100\n",
      "257/257 - 12s - loss: 2.7279 - accuracy: 0.9717 - auc: 0.9966 - val_loss: 3.6518 - val_accuracy: 0.8926 - val_auc: 0.8865\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.89650\n",
      "Epoch 40/100\n",
      "257/257 - 12s - loss: 2.7251 - accuracy: 0.9716 - auc: 0.9965 - val_loss: 3.6601 - val_accuracy: 0.8893 - val_auc: 0.8769\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.89650\n",
      "Epoch 41/100\n",
      "257/257 - 12s - loss: 2.7225 - accuracy: 0.9757 - auc: 0.9963 - val_loss: 3.6959 - val_accuracy: 0.8943 - val_auc: 0.8782\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.89650\n",
      "Epoch 42/100\n",
      "257/257 - 12s - loss: 2.7209 - accuracy: 0.9730 - auc: 0.9964 - val_loss: 3.7146 - val_accuracy: 0.8909 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.89650\n",
      "Epoch 43/100\n",
      "257/257 - 12s - loss: 2.7153 - accuracy: 0.9736 - auc: 0.9969 - val_loss: 3.6870 - val_accuracy: 0.8842 - val_auc: 0.8760\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.89650\n",
      "Epoch 44/100\n",
      "257/257 - 12s - loss: 2.7123 - accuracy: 0.9760 - auc: 0.9966 - val_loss: 3.7280 - val_accuracy: 0.8859 - val_auc: 0.8753\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.89650\n",
      "Epoch 45/100\n",
      "257/257 - 12s - loss: 2.7065 - accuracy: 0.9779 - auc: 0.9970 - val_loss: 3.7927 - val_accuracy: 0.8943 - val_auc: 0.8657\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.89650\n",
      "Epoch 46/100\n",
      "257/257 - 12s - loss: 2.7040 - accuracy: 0.9766 - auc: 0.9974 - val_loss: 3.7615 - val_accuracy: 0.8859 - val_auc: 0.8688\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.89650\n",
      "Epoch 47/100\n",
      "257/257 - 12s - loss: 2.7016 - accuracy: 0.9785 - auc: 0.9975 - val_loss: 3.7980 - val_accuracy: 0.8859 - val_auc: 0.8594\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.89650\n",
      "Epoch 48/100\n",
      "257/257 - 12s - loss: 2.6970 - accuracy: 0.9797 - auc: 0.9976 - val_loss: 3.7916 - val_accuracy: 0.8926 - val_auc: 0.8644\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.89650\n",
      "Epoch 49/100\n",
      "257/257 - 12s - loss: 2.6961 - accuracy: 0.9795 - auc: 0.9973 - val_loss: 3.7776 - val_accuracy: 0.8960 - val_auc: 0.8675\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.89650\n",
      "Epoch 50/100\n",
      "257/257 - 12s - loss: 2.6912 - accuracy: 0.9796 - auc: 0.9978 - val_loss: 3.7295 - val_accuracy: 0.8909 - val_auc: 0.8774\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.89650\n",
      "Epoch 51/100\n",
      "257/257 - 12s - loss: 2.6883 - accuracy: 0.9810 - auc: 0.9979 - val_loss: 3.8724 - val_accuracy: 0.8960 - val_auc: 0.8557\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.89650\n",
      "Epoch 52/100\n",
      "257/257 - 12s - loss: 2.6889 - accuracy: 0.9800 - auc: 0.9977 - val_loss: 3.8166 - val_accuracy: 0.8909 - val_auc: 0.8620\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.89650\n",
      "Epoch 53/100\n",
      "257/257 - 12s - loss: 2.6872 - accuracy: 0.9810 - auc: 0.9974 - val_loss: 3.9168 - val_accuracy: 0.8876 - val_auc: 0.8473\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.89650\n",
      "Epoch 54/100\n",
      "257/257 - 12s - loss: 2.6835 - accuracy: 0.9825 - auc: 0.9976 - val_loss: 3.8867 - val_accuracy: 0.8893 - val_auc: 0.8497\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.89650\n",
      "Epoch 55/100\n",
      "257/257 - 12s - loss: 2.6805 - accuracy: 0.9808 - auc: 0.9978 - val_loss: 3.9513 - val_accuracy: 0.8977 - val_auc: 0.8450\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.89650\n",
      "Epoch 56/100\n",
      "257/257 - 12s - loss: 2.6757 - accuracy: 0.9828 - auc: 0.9982 - val_loss: 5.5975 - val_accuracy: 0.8859 - val_auc: 0.7229\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.89650\n",
      "Epoch 57/100\n",
      "257/257 - 12s - loss: 2.7133 - accuracy: 0.9768 - auc: 0.9945 - val_loss: 3.7828 - val_accuracy: 0.9027 - val_auc: 0.8756\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.89650\n",
      "Epoch 58/100\n",
      "257/257 - 12s - loss: 2.6733 - accuracy: 0.9808 - auc: 0.9981 - val_loss: 3.8629 - val_accuracy: 0.8960 - val_auc: 0.8643\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.89650\n",
      "Epoch 59/100\n",
      "257/257 - 12s - loss: 2.6746 - accuracy: 0.9818 - auc: 0.9977 - val_loss: 3.7341 - val_accuracy: 0.8893 - val_auc: 0.8804\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.89650\n",
      "Epoch 60/100\n",
      "257/257 - 12s - loss: 2.6676 - accuracy: 0.9843 - auc: 0.9981 - val_loss: 3.9165 - val_accuracy: 0.8943 - val_auc: 0.8488\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.89650\n",
      "Epoch 61/100\n",
      "257/257 - 12s - loss: 2.6653 - accuracy: 0.9839 - auc: 0.9981 - val_loss: 3.9314 - val_accuracy: 0.8977 - val_auc: 0.8529\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.89650\n",
      "Epoch 62/100\n",
      "257/257 - 12s - loss: 2.6628 - accuracy: 0.9846 - auc: 0.9983 - val_loss: 3.8600 - val_accuracy: 0.8943 - val_auc: 0.8552\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.89650\n",
      "Epoch 63/100\n",
      "257/257 - 12s - loss: 2.6604 - accuracy: 0.9861 - auc: 0.9983 - val_loss: 3.9162 - val_accuracy: 0.8909 - val_auc: 0.8452\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.89650\n",
      "Epoch 64/100\n",
      "257/257 - 12s - loss: 2.6603 - accuracy: 0.9840 - auc: 0.9984 - val_loss: 3.8348 - val_accuracy: 0.8943 - val_auc: 0.8661\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.89650\n",
      "Epoch 65/100\n",
      "257/257 - 12s - loss: 2.6591 - accuracy: 0.9833 - auc: 0.9982 - val_loss: 3.9481 - val_accuracy: 0.8960 - val_auc: 0.8409\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.89650\n",
      "Epoch 66/100\n",
      "257/257 - 12s - loss: 2.6570 - accuracy: 0.9847 - auc: 0.9980 - val_loss: 3.8787 - val_accuracy: 0.8943 - val_auc: 0.8603\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.89650\n",
      "Epoch 67/100\n",
      "257/257 - 12s - loss: 2.6539 - accuracy: 0.9843 - auc: 0.9982 - val_loss: 3.8964 - val_accuracy: 0.8893 - val_auc: 0.8502\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.89650\n",
      "Epoch 68/100\n",
      "257/257 - 12s - loss: 2.6535 - accuracy: 0.9861 - auc: 0.9979 - val_loss: 3.8811 - val_accuracy: 0.8943 - val_auc: 0.8608\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.89650\n",
      "Epoch 69/100\n",
      "257/257 - 12s - loss: 2.6468 - accuracy: 0.9869 - auc: 0.9983 - val_loss: 3.9378 - val_accuracy: 0.9010 - val_auc: 0.8412\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.89650\n",
      "Epoch 70/100\n",
      "257/257 - 12s - loss: 2.6461 - accuracy: 0.9857 - auc: 0.9983 - val_loss: 3.9503 - val_accuracy: 0.8926 - val_auc: 0.8381\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.89650\n",
      "Epoch 71/100\n",
      "257/257 - 12s - loss: 2.6444 - accuracy: 0.9865 - auc: 0.9985 - val_loss: 3.9660 - val_accuracy: 0.9027 - val_auc: 0.8496\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.89650\n",
      "Epoch 72/100\n",
      "257/257 - 12s - loss: 2.6398 - accuracy: 0.9867 - auc: 0.9986 - val_loss: 4.0297 - val_accuracy: 0.8943 - val_auc: 0.8323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_auc did not improve from 0.89650\n",
      "Epoch 73/100\n",
      "257/257 - 11s - loss: 2.6386 - accuracy: 0.9868 - auc: 0.9989 - val_loss: 4.0098 - val_accuracy: 0.8960 - val_auc: 0.8326\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.89650\n",
      "Epoch 74/100\n",
      "257/257 - 10s - loss: 2.6398 - accuracy: 0.9855 - auc: 0.9984 - val_loss: 3.9248 - val_accuracy: 0.8926 - val_auc: 0.8529\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.89650\n",
      "Epoch 75/100\n",
      "257/257 - 10s - loss: 2.6345 - accuracy: 0.9876 - auc: 0.9986 - val_loss: 4.3747 - val_accuracy: 0.9010 - val_auc: 0.8137\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.89650\n",
      "Epoch 76/100\n",
      "257/257 - 10s - loss: 2.6368 - accuracy: 0.9857 - auc: 0.9985 - val_loss: 3.9939 - val_accuracy: 0.8960 - val_auc: 0.8488\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.89650\n",
      "Epoch 77/100\n",
      "257/257 - 10s - loss: 2.6338 - accuracy: 0.9862 - auc: 0.9986 - val_loss: 3.9084 - val_accuracy: 0.8960 - val_auc: 0.8531\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.89650\n",
      "Epoch 78/100\n",
      "257/257 - 11s - loss: 2.6287 - accuracy: 0.9880 - auc: 0.9986 - val_loss: 4.0049 - val_accuracy: 0.8993 - val_auc: 0.8264\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.89650\n",
      "Epoch 79/100\n",
      "257/257 - 12s - loss: 2.6275 - accuracy: 0.9883 - auc: 0.9987 - val_loss: 4.0083 - val_accuracy: 0.9027 - val_auc: 0.8364\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.89650\n",
      "Epoch 80/100\n",
      "257/257 - 12s - loss: 2.6266 - accuracy: 0.9877 - auc: 0.9985 - val_loss: 4.1015 - val_accuracy: 0.8926 - val_auc: 0.8191\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.89650\n",
      "Epoch 81/100\n",
      "257/257 - 12s - loss: 2.6263 - accuracy: 0.9869 - auc: 0.9981 - val_loss: 4.0270 - val_accuracy: 0.8809 - val_auc: 0.8323\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.89650\n",
      "Epoch 82/100\n",
      "257/257 - 12s - loss: 2.6234 - accuracy: 0.9869 - auc: 0.9987 - val_loss: 3.9973 - val_accuracy: 0.9010 - val_auc: 0.8327\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.89650\n",
      "Epoch 83/100\n",
      "257/257 - 12s - loss: 2.6198 - accuracy: 0.9876 - auc: 0.9989 - val_loss: 3.9748 - val_accuracy: 0.8993 - val_auc: 0.8511\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.89650\n",
      "Epoch 84/100\n",
      "257/257 - 12s - loss: 2.6181 - accuracy: 0.9885 - auc: 0.9987 - val_loss: 3.9353 - val_accuracy: 0.8993 - val_auc: 0.8530\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.89650\n",
      "Epoch 85/100\n",
      "257/257 - 12s - loss: 2.6159 - accuracy: 0.9884 - auc: 0.9988 - val_loss: 4.0541 - val_accuracy: 0.8909 - val_auc: 0.8327\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.89650\n",
      "Epoch 86/100\n",
      "257/257 - 12s - loss: 2.6183 - accuracy: 0.9868 - auc: 0.9986 - val_loss: 3.9233 - val_accuracy: 0.8960 - val_auc: 0.8475\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.89650\n",
      "Epoch 87/100\n",
      "257/257 - 12s - loss: 2.6123 - accuracy: 0.9879 - auc: 0.9989 - val_loss: 4.1855 - val_accuracy: 0.9027 - val_auc: 0.8168\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.89650\n",
      "Epoch 88/100\n",
      "257/257 - 12s - loss: 2.6101 - accuracy: 0.9893 - auc: 0.9991 - val_loss: 4.0081 - val_accuracy: 0.8926 - val_auc: 0.8310\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.89650\n",
      "Epoch 89/100\n",
      "257/257 - 12s - loss: 2.6109 - accuracy: 0.9877 - auc: 0.9987 - val_loss: 3.9789 - val_accuracy: 0.9010 - val_auc: 0.8341\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.89650\n",
      "Epoch 90/100\n",
      "257/257 - 12s - loss: 2.6078 - accuracy: 0.9880 - auc: 0.9988 - val_loss: 3.9532 - val_accuracy: 0.8926 - val_auc: 0.8432\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.89650\n",
      "Epoch 91/100\n",
      "257/257 - 12s - loss: 2.6058 - accuracy: 0.9889 - auc: 0.9988 - val_loss: 4.1856 - val_accuracy: 0.8926 - val_auc: 0.8272\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.89650\n",
      "Epoch 92/100\n",
      "257/257 - 12s - loss: 2.6051 - accuracy: 0.9888 - auc: 0.9987 - val_loss: 3.9926 - val_accuracy: 0.8977 - val_auc: 0.8387\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.89650\n",
      "Epoch 93/100\n",
      "257/257 - 12s - loss: 2.6018 - accuracy: 0.9886 - auc: 0.9989 - val_loss: 4.0505 - val_accuracy: 0.8926 - val_auc: 0.8342\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.89650\n",
      "Epoch 94/100\n",
      "257/257 - 12s - loss: 2.5994 - accuracy: 0.9879 - auc: 0.9992 - val_loss: 4.1460 - val_accuracy: 0.9010 - val_auc: 0.8153\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.89650\n",
      "Epoch 95/100\n",
      "257/257 - 12s - loss: 2.5989 - accuracy: 0.9889 - auc: 0.9990 - val_loss: 4.1084 - val_accuracy: 0.8960 - val_auc: 0.8203\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.89650\n",
      "Epoch 96/100\n",
      "257/257 - 12s - loss: 2.5953 - accuracy: 0.9896 - auc: 0.9990 - val_loss: 4.0521 - val_accuracy: 0.8977 - val_auc: 0.8316\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.89650\n",
      "Epoch 97/100\n",
      "257/257 - 12s - loss: 2.5953 - accuracy: 0.9889 - auc: 0.9987 - val_loss: 4.1101 - val_accuracy: 0.8909 - val_auc: 0.8199\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.89650\n",
      "Epoch 98/100\n",
      "257/257 - 12s - loss: 2.5918 - accuracy: 0.9891 - auc: 0.9991 - val_loss: 4.0975 - val_accuracy: 0.8926 - val_auc: 0.8256\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.89650\n",
      "Epoch 99/100\n",
      "257/257 - 12s - loss: 2.5914 - accuracy: 0.9884 - auc: 0.9990 - val_loss: 4.1241 - val_accuracy: 0.8943 - val_auc: 0.8301\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.89650\n",
      "Epoch 100/100\n",
      "257/257 - 12s - loss: 2.5910 - accuracy: 0.9896 - auc: 0.9988 - val_loss: 4.0066 - val_accuracy: 0.8876 - val_auc: 0.8474\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.89650\n",
      "[WinError 183] Cannot create a file when that file already exists: '210128_TrainingLocalitySensitivewoFW\\\\210128_LS_NR-AR-LBD'\n",
      "Epoch 1/100\n",
      "269/269 - 17s - loss: 3.1765 - accuracy: 0.7858 - auc: 0.8634 - val_loss: 3.1171 - val_accuracy: 0.8612 - val_auc: 0.7198\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.71981, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AR-LBD\n",
      "Epoch 2/100\n",
      "269/269 - 12s - loss: 3.0448 - accuracy: 0.9261 - auc: 0.9348 - val_loss: 3.1107 - val_accuracy: 0.9262 - val_auc: 0.7478\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.71981 to 0.74777, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AR-LBD\n",
      "Epoch 3/100\n",
      "269/269 - 12s - loss: 2.9917 - accuracy: 0.9431 - auc: 0.9592 - val_loss: 3.0916 - val_accuracy: 0.9315 - val_auc: 0.7750\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.74777 to 0.77496, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-AR-LBD\n",
      "Epoch 4/100\n",
      "269/269 - 12s - loss: 2.9474 - accuracy: 0.9567 - auc: 0.9692 - val_loss: 3.1197 - val_accuracy: 0.9420 - val_auc: 0.7605\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.77496\n",
      "Epoch 5/100\n",
      "269/269 - 12s - loss: 2.9142 - accuracy: 0.9596 - auc: 0.9793 - val_loss: 3.1377 - val_accuracy: 0.9438 - val_auc: 0.7656\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.77496\n",
      "Epoch 6/100\n",
      "269/269 - 12s - loss: 2.8888 - accuracy: 0.9651 - auc: 0.9844 - val_loss: 3.1447 - val_accuracy: 0.9455 - val_auc: 0.7715\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.77496\n",
      "Epoch 7/100\n",
      "269/269 - 12s - loss: 2.8658 - accuracy: 0.9666 - auc: 0.9880 - val_loss: 3.1982 - val_accuracy: 0.9508 - val_auc: 0.7372\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.77496\n",
      "Epoch 8/100\n",
      "269/269 - 12s - loss: 2.8447 - accuracy: 0.9732 - auc: 0.9910 - val_loss: 3.2163 - val_accuracy: 0.9438 - val_auc: 0.7350\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77496\n",
      "Epoch 9/100\n",
      "269/269 - 12s - loss: 2.8342 - accuracy: 0.9729 - auc: 0.9915 - val_loss: 3.2368 - val_accuracy: 0.9438 - val_auc: 0.7258\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.77496\n",
      "Epoch 10/100\n",
      "269/269 - 12s - loss: 2.8154 - accuracy: 0.9742 - auc: 0.9940 - val_loss: 3.2429 - val_accuracy: 0.9420 - val_auc: 0.7598\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.77496\n",
      "Epoch 11/100\n",
      "269/269 - 13s - loss: 2.8063 - accuracy: 0.9782 - auc: 0.9949 - val_loss: 3.2833 - val_accuracy: 0.9455 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.77496\n",
      "Epoch 12/100\n",
      "269/269 - 13s - loss: 2.7877 - accuracy: 0.9806 - auc: 0.9963 - val_loss: 3.3937 - val_accuracy: 0.9490 - val_auc: 0.6761\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.77496\n",
      "Epoch 13/100\n",
      "269/269 - 12s - loss: 2.7862 - accuracy: 0.9789 - auc: 0.9961 - val_loss: 3.4254 - val_accuracy: 0.9596 - val_auc: 0.6962\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.77496\n",
      "Epoch 14/100\n",
      "269/269 - 12s - loss: 2.7752 - accuracy: 0.9814 - auc: 0.9968 - val_loss: 3.4415 - val_accuracy: 0.9455 - val_auc: 0.6848\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.77496\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 - 11s - loss: 2.7635 - accuracy: 0.9821 - auc: 0.9976 - val_loss: 3.5064 - val_accuracy: 0.9578 - val_auc: 0.7055\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.77496\n",
      "Epoch 16/100\n",
      "269/269 - 11s - loss: 2.7618 - accuracy: 0.9836 - auc: 0.9973 - val_loss: 3.4047 - val_accuracy: 0.9508 - val_auc: 0.7156\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.77496\n",
      "Epoch 17/100\n",
      "269/269 - 11s - loss: 2.7533 - accuracy: 0.9820 - auc: 0.9977 - val_loss: 3.5749 - val_accuracy: 0.9701 - val_auc: 0.7182\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.77496\n",
      "Epoch 18/100\n",
      "269/269 - 11s - loss: 2.7451 - accuracy: 0.9844 - auc: 0.9979 - val_loss: 3.6709 - val_accuracy: 0.9684 - val_auc: 0.6180\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.77496\n",
      "Epoch 19/100\n",
      "269/269 - 16s - loss: 2.7423 - accuracy: 0.9844 - auc: 0.9979 - val_loss: 3.6245 - val_accuracy: 0.9701 - val_auc: 0.6917\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.77496\n",
      "Epoch 20/100\n",
      "269/269 - 20s - loss: 2.7357 - accuracy: 0.9852 - auc: 0.9981 - val_loss: 3.6634 - val_accuracy: 0.9701 - val_auc: 0.6745\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.77496\n",
      "Epoch 21/100\n",
      "269/269 - 20s - loss: 2.7283 - accuracy: 0.9886 - auc: 0.9985 - val_loss: 3.7508 - val_accuracy: 0.9701 - val_auc: 0.5938\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.77496\n",
      "Epoch 22/100\n",
      "269/269 - 18s - loss: 2.7274 - accuracy: 0.9856 - auc: 0.9983 - val_loss: 3.7209 - val_accuracy: 0.9807 - val_auc: 0.6777\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.77496\n",
      "Epoch 23/100\n",
      "269/269 - 20s - loss: 2.7258 - accuracy: 0.9859 - auc: 0.9983 - val_loss: 3.6581 - val_accuracy: 0.9649 - val_auc: 0.6771\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.77496\n",
      "Epoch 24/100\n",
      "269/269 - 19s - loss: 2.7202 - accuracy: 0.9878 - auc: 0.9984 - val_loss: 3.7137 - val_accuracy: 0.9736 - val_auc: 0.6719\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.77496\n",
      "Epoch 25/100\n",
      "269/269 - 20s - loss: 2.7154 - accuracy: 0.9882 - auc: 0.9986 - val_loss: 3.7914 - val_accuracy: 0.9701 - val_auc: 0.6826\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.77496\n",
      "Epoch 26/100\n",
      "269/269 - 20s - loss: 2.7141 - accuracy: 0.9887 - auc: 0.9983 - val_loss: 3.6728 - val_accuracy: 0.9666 - val_auc: 0.6830\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.77496\n",
      "Epoch 27/100\n",
      "269/269 - 19s - loss: 2.7074 - accuracy: 0.9886 - auc: 0.9986 - val_loss: 3.8933 - val_accuracy: 0.9789 - val_auc: 0.6857\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.77496\n",
      "Epoch 28/100\n",
      "269/269 - 20s - loss: 2.7069 - accuracy: 0.9896 - auc: 0.9987 - val_loss: 3.7814 - val_accuracy: 0.9736 - val_auc: 0.6876\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.77496\n",
      "Epoch 29/100\n",
      "269/269 - 20s - loss: 2.7027 - accuracy: 0.9894 - auc: 0.9987 - val_loss: 3.7915 - val_accuracy: 0.9736 - val_auc: 0.6917\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.77496\n",
      "Epoch 30/100\n",
      "269/269 - 20s - loss: 2.7013 - accuracy: 0.9895 - auc: 0.9988 - val_loss: 3.7433 - val_accuracy: 0.9754 - val_auc: 0.6907\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.77496\n",
      "Epoch 31/100\n",
      "269/269 - 20s - loss: 2.7010 - accuracy: 0.9881 - auc: 0.9984 - val_loss: 3.9195 - val_accuracy: 0.9807 - val_auc: 0.6462\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.77496\n",
      "Epoch 32/100\n",
      "269/269 - 20s - loss: 2.6965 - accuracy: 0.9906 - auc: 0.9987 - val_loss: 3.9014 - val_accuracy: 0.9754 - val_auc: 0.6367\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.77496\n",
      "Epoch 33/100\n",
      "269/269 - 20s - loss: 2.6926 - accuracy: 0.9903 - auc: 0.9987 - val_loss: 3.9511 - val_accuracy: 0.9789 - val_auc: 0.6493\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.77496\n",
      "Epoch 34/100\n",
      "269/269 - 20s - loss: 2.6903 - accuracy: 0.9913 - auc: 0.9987 - val_loss: 3.8600 - val_accuracy: 0.9736 - val_auc: 0.6446\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.77496\n",
      "Epoch 35/100\n",
      "269/269 - 19s - loss: 2.6889 - accuracy: 0.9907 - auc: 0.9988 - val_loss: 3.9518 - val_accuracy: 0.9736 - val_auc: 0.6581\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.77496\n",
      "Epoch 36/100\n",
      "269/269 - 19s - loss: 2.6915 - accuracy: 0.9891 - auc: 0.9983 - val_loss: 3.9576 - val_accuracy: 0.9807 - val_auc: 0.6570\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.77496\n",
      "Epoch 37/100\n",
      "269/269 - 18s - loss: 2.6835 - accuracy: 0.9905 - auc: 0.9990 - val_loss: 4.0973 - val_accuracy: 0.9807 - val_auc: 0.6076\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.77496\n",
      "Epoch 38/100\n",
      "269/269 - 19s - loss: 2.6807 - accuracy: 0.9909 - auc: 0.9990 - val_loss: 3.9888 - val_accuracy: 0.9789 - val_auc: 0.6547\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.77496\n",
      "Epoch 39/100\n",
      "269/269 - 19s - loss: 2.6785 - accuracy: 0.9913 - auc: 0.9990 - val_loss: 4.0410 - val_accuracy: 0.9807 - val_auc: 0.6613\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.77496\n",
      "Epoch 40/100\n",
      "269/269 - 19s - loss: 2.6771 - accuracy: 0.9914 - auc: 0.9987 - val_loss: 4.0503 - val_accuracy: 0.9789 - val_auc: 0.6070\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.77496\n",
      "Epoch 41/100\n",
      "269/269 - 19s - loss: 2.6722 - accuracy: 0.9919 - auc: 0.9990 - val_loss: 4.1268 - val_accuracy: 0.9807 - val_auc: 0.6113\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.77496\n",
      "Epoch 42/100\n",
      "269/269 - 19s - loss: 2.6753 - accuracy: 0.9912 - auc: 0.9989 - val_loss: 3.9158 - val_accuracy: 0.9789 - val_auc: 0.6670\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.77496\n",
      "Epoch 43/100\n",
      "269/269 - 19s - loss: 2.6721 - accuracy: 0.9908 - auc: 0.9988 - val_loss: 3.9833 - val_accuracy: 0.9807 - val_auc: 0.6639\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.77496\n",
      "Epoch 44/100\n",
      "269/269 - 19s - loss: 2.6707 - accuracy: 0.9908 - auc: 0.9990 - val_loss: 3.9928 - val_accuracy: 0.9772 - val_auc: 0.6677\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.77496\n",
      "Epoch 45/100\n",
      "269/269 - 19s - loss: 2.6664 - accuracy: 0.9923 - auc: 0.9989 - val_loss: 3.9792 - val_accuracy: 0.9754 - val_auc: 0.6788\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.77496\n",
      "Epoch 46/100\n",
      "269/269 - 19s - loss: 2.6632 - accuracy: 0.9924 - auc: 0.9991 - val_loss: 4.0803 - val_accuracy: 0.9789 - val_auc: 0.6781\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.77496\n",
      "Epoch 47/100\n",
      "269/269 - 19s - loss: 2.6601 - accuracy: 0.9933 - auc: 0.9992 - val_loss: 4.1098 - val_accuracy: 0.9789 - val_auc: 0.6780\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.77496\n",
      "Epoch 48/100\n",
      "269/269 - 19s - loss: 2.6600 - accuracy: 0.9923 - auc: 0.9992 - val_loss: 4.1188 - val_accuracy: 0.9807 - val_auc: 0.6185\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.77496\n",
      "Epoch 49/100\n",
      "269/269 - 19s - loss: 2.6610 - accuracy: 0.9920 - auc: 0.9990 - val_loss: 4.0736 - val_accuracy: 0.9807 - val_auc: 0.6625\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.77496\n",
      "Epoch 50/100\n",
      "269/269 - 19s - loss: 2.6603 - accuracy: 0.9909 - auc: 0.9990 - val_loss: 4.1187 - val_accuracy: 0.9789 - val_auc: 0.6600\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.77496\n",
      "Epoch 51/100\n",
      "269/269 - 19s - loss: 2.6550 - accuracy: 0.9917 - auc: 0.9991 - val_loss: 4.1582 - val_accuracy: 0.9789 - val_auc: 0.6223\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.77496\n",
      "Epoch 52/100\n",
      "269/269 - 18s - loss: 2.6527 - accuracy: 0.9926 - auc: 0.9991 - val_loss: 4.1180 - val_accuracy: 0.9807 - val_auc: 0.6773\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.77496\n",
      "Epoch 53/100\n",
      "269/269 - 19s - loss: 2.6490 - accuracy: 0.9930 - auc: 0.9993 - val_loss: 4.1557 - val_accuracy: 0.9807 - val_auc: 0.5686\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.77496\n",
      "Epoch 54/100\n",
      "269/269 - 19s - loss: 2.6488 - accuracy: 0.9921 - auc: 0.9991 - val_loss: 4.1135 - val_accuracy: 0.9772 - val_auc: 0.6228\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.77496\n",
      "Epoch 55/100\n",
      "269/269 - 19s - loss: 2.6457 - accuracy: 0.9933 - auc: 0.9992 - val_loss: 4.1551 - val_accuracy: 0.9789 - val_auc: 0.6278\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.77496\n",
      "Epoch 56/100\n",
      "269/269 - 18s - loss: 2.6446 - accuracy: 0.9926 - auc: 0.9993 - val_loss: 4.1191 - val_accuracy: 0.9772 - val_auc: 0.6249\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.77496\n",
      "Epoch 57/100\n",
      "269/269 - 17s - loss: 2.6416 - accuracy: 0.9936 - auc: 0.9993 - val_loss: 4.0810 - val_accuracy: 0.9754 - val_auc: 0.6254\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.77496\n",
      "Epoch 58/100\n",
      "269/269 - 18s - loss: 2.6396 - accuracy: 0.9934 - auc: 0.9992 - val_loss: 4.1981 - val_accuracy: 0.9789 - val_auc: 0.6291\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.77496\n",
      "Epoch 59/100\n",
      "269/269 - 18s - loss: 2.6374 - accuracy: 0.9934 - auc: 0.9994 - val_loss: 4.1447 - val_accuracy: 0.9789 - val_auc: 0.5772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_auc did not improve from 0.77496\n",
      "Epoch 60/100\n",
      "269/269 - 18s - loss: 2.6360 - accuracy: 0.9941 - auc: 0.9993 - val_loss: 4.1205 - val_accuracy: 0.9754 - val_auc: 0.6271\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.77496\n",
      "Epoch 61/100\n",
      "269/269 - 19s - loss: 2.6355 - accuracy: 0.9935 - auc: 0.9991 - val_loss: 4.2041 - val_accuracy: 0.9789 - val_auc: 0.6364\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.77496\n",
      "Epoch 62/100\n",
      "269/269 - 19s - loss: 2.6333 - accuracy: 0.9931 - auc: 0.9992 - val_loss: 4.1332 - val_accuracy: 0.9789 - val_auc: 0.6252\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.77496\n",
      "Epoch 63/100\n",
      "269/269 - 19s - loss: 2.6314 - accuracy: 0.9935 - auc: 0.9994 - val_loss: 4.1697 - val_accuracy: 0.9789 - val_auc: 0.5672\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.77496\n",
      "Epoch 64/100\n",
      "269/269 - 19s - loss: 2.6289 - accuracy: 0.9928 - auc: 0.9994 - val_loss: 4.2062 - val_accuracy: 0.9789 - val_auc: 0.5748\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.77496\n",
      "Epoch 65/100\n",
      "269/269 - 19s - loss: 2.6269 - accuracy: 0.9930 - auc: 0.9995 - val_loss: 4.2285 - val_accuracy: 0.9807 - val_auc: 0.5787\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.77496\n",
      "Epoch 66/100\n",
      "269/269 - 19s - loss: 2.6297 - accuracy: 0.9923 - auc: 0.9990 - val_loss: 3.8729 - val_accuracy: 0.9525 - val_auc: 0.6605\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.77496\n",
      "Epoch 67/100\n",
      "269/269 - 19s - loss: 2.6287 - accuracy: 0.9912 - auc: 0.9992 - val_loss: 4.1215 - val_accuracy: 0.9684 - val_auc: 0.5662\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.77496\n",
      "Epoch 68/100\n",
      "269/269 - 19s - loss: 2.6225 - accuracy: 0.9938 - auc: 0.9994 - val_loss: 4.3070 - val_accuracy: 0.9789 - val_auc: 0.5176\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.77496\n",
      "Epoch 69/100\n",
      "269/269 - 19s - loss: 2.6217 - accuracy: 0.9923 - auc: 0.9993 - val_loss: 4.3227 - val_accuracy: 0.9789 - val_auc: 0.5167\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.77496\n",
      "Epoch 70/100\n",
      "269/269 - 19s - loss: 2.6251 - accuracy: 0.9915 - auc: 0.9990 - val_loss: 4.1364 - val_accuracy: 0.9772 - val_auc: 0.5693\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.77496\n",
      "Epoch 71/100\n",
      "269/269 - 19s - loss: 2.6173 - accuracy: 0.9930 - auc: 0.9992 - val_loss: 4.2512 - val_accuracy: 0.9807 - val_auc: 0.5833\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.77496\n",
      "Epoch 72/100\n",
      "269/269 - 19s - loss: 2.6151 - accuracy: 0.9939 - auc: 0.9993 - val_loss: 4.1540 - val_accuracy: 0.9772 - val_auc: 0.6263\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.77496\n",
      "Epoch 73/100\n",
      "269/269 - 19s - loss: 2.6117 - accuracy: 0.9941 - auc: 0.9995 - val_loss: 4.2143 - val_accuracy: 0.9772 - val_auc: 0.5772\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.77496\n",
      "Epoch 74/100\n",
      "269/269 - 19s - loss: 2.6116 - accuracy: 0.9936 - auc: 0.9993 - val_loss: 4.2248 - val_accuracy: 0.9789 - val_auc: 0.6368\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.77496\n",
      "Epoch 75/100\n",
      "269/269 - 19s - loss: 2.6093 - accuracy: 0.9936 - auc: 0.9993 - val_loss: 4.1704 - val_accuracy: 0.9789 - val_auc: 0.6459\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.77496\n",
      "Epoch 76/100\n",
      "269/269 - 19s - loss: 2.6071 - accuracy: 0.9935 - auc: 0.9995 - val_loss: 4.2068 - val_accuracy: 0.9807 - val_auc: 0.6414\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.77496\n",
      "Epoch 77/100\n",
      "269/269 - 19s - loss: 2.6043 - accuracy: 0.9942 - auc: 0.9994 - val_loss: 4.2322 - val_accuracy: 0.9807 - val_auc: 0.6436\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.77496\n",
      "Epoch 78/100\n",
      "269/269 - 19s - loss: 2.6035 - accuracy: 0.9939 - auc: 0.9994 - val_loss: 4.2803 - val_accuracy: 0.9807 - val_auc: 0.5846\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.77496\n",
      "Epoch 79/100\n",
      "269/269 - 19s - loss: 2.6021 - accuracy: 0.9941 - auc: 0.9994 - val_loss: 4.1583 - val_accuracy: 0.9754 - val_auc: 0.6383\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.77496\n",
      "Epoch 80/100\n",
      "269/269 - 19s - loss: 2.5999 - accuracy: 0.9941 - auc: 0.9994 - val_loss: 4.1743 - val_accuracy: 0.9772 - val_auc: 0.6387\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.77496\n",
      "Epoch 81/100\n",
      "269/269 - 19s - loss: 2.6001 - accuracy: 0.9939 - auc: 0.9994 - val_loss: 4.1359 - val_accuracy: 0.9684 - val_auc: 0.6291\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.77496\n",
      "Epoch 82/100\n",
      "269/269 - 19s - loss: 2.5963 - accuracy: 0.9942 - auc: 0.9993 - val_loss: 4.2656 - val_accuracy: 0.9772 - val_auc: 0.5762\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.77496\n",
      "Epoch 83/100\n",
      "269/269 - 19s - loss: 2.5934 - accuracy: 0.9942 - auc: 0.9996 - val_loss: 4.3093 - val_accuracy: 0.9807 - val_auc: 0.5824\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.77496\n",
      "Epoch 84/100\n",
      "269/269 - 19s - loss: 2.5924 - accuracy: 0.9944 - auc: 0.9994 - val_loss: 4.2824 - val_accuracy: 0.9772 - val_auc: 0.5793\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.77496\n",
      "Epoch 85/100\n",
      "269/269 - 19s - loss: 2.5919 - accuracy: 0.9937 - auc: 0.9995 - val_loss: 4.2035 - val_accuracy: 0.9789 - val_auc: 0.6441\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.77496\n",
      "Epoch 86/100\n",
      "269/269 - 19s - loss: 2.5881 - accuracy: 0.9946 - auc: 0.9994 - val_loss: 4.2603 - val_accuracy: 0.9807 - val_auc: 0.5832\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.77496\n",
      "Epoch 87/100\n",
      "269/269 - 19s - loss: 2.5880 - accuracy: 0.9937 - auc: 0.9994 - val_loss: 4.3091 - val_accuracy: 0.9807 - val_auc: 0.5844\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.77496\n",
      "Epoch 88/100\n",
      "269/269 - 19s - loss: 2.5854 - accuracy: 0.9950 - auc: 0.9995 - val_loss: 4.1988 - val_accuracy: 0.9736 - val_auc: 0.5772\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.77496\n",
      "Epoch 89/100\n",
      "269/269 - 19s - loss: 2.5839 - accuracy: 0.9941 - auc: 0.9996 - val_loss: 4.2385 - val_accuracy: 0.9789 - val_auc: 0.5804\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.77496\n",
      "Epoch 90/100\n",
      "269/269 - 19s - loss: 2.5813 - accuracy: 0.9941 - auc: 0.9996 - val_loss: 4.2437 - val_accuracy: 0.9772 - val_auc: 0.5851\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.77496\n",
      "Epoch 91/100\n",
      "269/269 - 19s - loss: 2.5794 - accuracy: 0.9946 - auc: 0.9995 - val_loss: 4.3105 - val_accuracy: 0.9772 - val_auc: 0.5842\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.77496\n",
      "Epoch 92/100\n",
      "269/269 - 19s - loss: 2.5778 - accuracy: 0.9939 - auc: 0.9996 - val_loss: 4.3146 - val_accuracy: 0.9789 - val_auc: 0.5886\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.77496\n",
      "Epoch 93/100\n",
      "269/269 - 19s - loss: 2.5761 - accuracy: 0.9949 - auc: 0.9994 - val_loss: 4.3449 - val_accuracy: 0.9807 - val_auc: 0.5921\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.77496\n",
      "Epoch 94/100\n",
      "269/269 - 19s - loss: 2.5746 - accuracy: 0.9948 - auc: 0.9996 - val_loss: 4.3244 - val_accuracy: 0.9807 - val_auc: 0.5862\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.77496\n",
      "Epoch 95/100\n",
      "269/269 - 19s - loss: 2.5741 - accuracy: 0.9936 - auc: 0.9995 - val_loss: 4.1747 - val_accuracy: 0.9789 - val_auc: 0.6532\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.77496\n",
      "Epoch 96/100\n",
      "269/269 - 19s - loss: 2.5726 - accuracy: 0.9943 - auc: 0.9995 - val_loss: 4.2972 - val_accuracy: 0.9789 - val_auc: 0.5868\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.77496\n",
      "Epoch 97/100\n",
      "269/269 - 18s - loss: 2.5750 - accuracy: 0.9930 - auc: 0.9991 - val_loss: 4.2187 - val_accuracy: 0.9789 - val_auc: 0.5804\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.77496\n",
      "Epoch 98/100\n",
      "269/269 - 18s - loss: 2.5673 - accuracy: 0.9946 - auc: 0.9994 - val_loss: 4.3087 - val_accuracy: 0.9807 - val_auc: 0.5892\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.77496\n",
      "Epoch 99/100\n",
      "269/269 - 18s - loss: 2.5657 - accuracy: 0.9948 - auc: 0.9994 - val_loss: 4.2156 - val_accuracy: 0.9789 - val_auc: 0.6464\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.77496\n",
      "Epoch 100/100\n",
      "269/269 - 18s - loss: 2.5636 - accuracy: 0.9948 - auc: 0.9995 - val_loss: 4.3253 - val_accuracy: 0.9807 - val_auc: 0.5906\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.77496\n",
      "[WinError 183] Cannot create a file when that file already exists: '210128_TrainingLocalitySensitivewoFW\\\\210128_LS_NR-ER'\n",
      "Epoch 1/100\n",
      "242/242 - 20s - loss: 3.3392 - accuracy: 0.6941 - auc: 0.7319 - val_loss: 3.2512 - val_accuracy: 0.7140 - val_auc: 0.7867\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.78672, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n",
      "Epoch 2/100\n",
      "242/242 - 17s - loss: 3.2655 - accuracy: 0.7532 - auc: 0.7967 - val_loss: 3.2314 - val_accuracy: 0.7318 - val_auc: 0.7951\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.78672 to 0.79508, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "242/242 - 17s - loss: 3.2309 - accuracy: 0.7784 - auc: 0.8216 - val_loss: 3.2155 - val_accuracy: 0.7751 - val_auc: 0.7957\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.79508 to 0.79573, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n",
      "Epoch 4/100\n",
      "242/242 - 17s - loss: 3.2166 - accuracy: 0.7940 - auc: 0.8312 - val_loss: 3.2033 - val_accuracy: 0.7791 - val_auc: 0.8062\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.79573 to 0.80617, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n",
      "Epoch 5/100\n",
      "242/242 - 17s - loss: 3.1886 - accuracy: 0.8122 - auc: 0.8538 - val_loss: 3.1974 - val_accuracy: 0.7850 - val_auc: 0.8091\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.80617 to 0.80906, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n",
      "Epoch 6/100\n",
      "242/242 - 18s - loss: 3.1691 - accuracy: 0.8218 - auc: 0.8674 - val_loss: 3.1882 - val_accuracy: 0.8225 - val_auc: 0.8074\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.80906\n",
      "Epoch 7/100\n",
      "242/242 - 18s - loss: 3.1572 - accuracy: 0.8287 - auc: 0.8736 - val_loss: 3.1865 - val_accuracy: 0.7909 - val_auc: 0.8142\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.80906 to 0.81420, saving model to 210128_TrainingLocalitySensitivewoFW\\210128_LS_NR-ER\n",
      "Epoch 8/100\n",
      "242/242 - 18s - loss: 3.1430 - accuracy: 0.8325 - auc: 0.8825 - val_loss: 3.1790 - val_accuracy: 0.8343 - val_auc: 0.8141\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.81420\n",
      "Epoch 9/100\n",
      "242/242 - 18s - loss: 3.1275 - accuracy: 0.8437 - auc: 0.8915 - val_loss: 3.1906 - val_accuracy: 0.7791 - val_auc: 0.8104\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.81420\n",
      "Epoch 10/100\n",
      "242/242 - 18s - loss: 3.1121 - accuracy: 0.8409 - auc: 0.9019 - val_loss: 3.1885 - val_accuracy: 0.8107 - val_auc: 0.8029\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.81420\n",
      "Epoch 11/100\n",
      "242/242 - 18s - loss: 3.0958 - accuracy: 0.8518 - auc: 0.9090 - val_loss: 3.1891 - val_accuracy: 0.8284 - val_auc: 0.7991\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.81420\n",
      "Epoch 12/100\n",
      "242/242 - 18s - loss: 3.0831 - accuracy: 0.8501 - auc: 0.9151 - val_loss: 3.1839 - val_accuracy: 0.8166 - val_auc: 0.8112\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.81420\n",
      "Epoch 13/100\n",
      "242/242 - 18s - loss: 3.0667 - accuracy: 0.8615 - auc: 0.9231 - val_loss: 3.1924 - val_accuracy: 0.8442 - val_auc: 0.8068\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.81420\n",
      "Epoch 14/100\n",
      "242/242 - 18s - loss: 3.0545 - accuracy: 0.8644 - auc: 0.9267 - val_loss: 3.2017 - val_accuracy: 0.8580 - val_auc: 0.8000\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.81420\n",
      "Epoch 15/100\n",
      "242/242 - 17s - loss: 3.0465 - accuracy: 0.8664 - auc: 0.9303 - val_loss: 3.2030 - val_accuracy: 0.8146 - val_auc: 0.7863\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.81420\n",
      "Epoch 16/100\n",
      "242/242 - 11s - loss: 3.0233 - accuracy: 0.8721 - auc: 0.9406 - val_loss: 3.2040 - val_accuracy: 0.8323 - val_auc: 0.7986\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.81420\n",
      "Epoch 17/100\n",
      "242/242 - 11s - loss: 3.0200 - accuracy: 0.8689 - auc: 0.9396 - val_loss: 3.2197 - val_accuracy: 0.8679 - val_auc: 0.7889\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.81420\n",
      "Epoch 18/100\n",
      "242/242 - 12s - loss: 3.0063 - accuracy: 0.8742 - auc: 0.9454 - val_loss: 3.2450 - val_accuracy: 0.8521 - val_auc: 0.7853\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.81420\n",
      "Epoch 19/100\n",
      "242/242 - 11s - loss: 2.9882 - accuracy: 0.8803 - auc: 0.9515 - val_loss: 3.2717 - val_accuracy: 0.8225 - val_auc: 0.7542\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.81420\n",
      "Epoch 20/100\n",
      "242/242 - 11s - loss: 2.9870 - accuracy: 0.8820 - auc: 0.9503 - val_loss: 3.2681 - val_accuracy: 0.8442 - val_auc: 0.7740\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.81420\n",
      "Epoch 21/100\n",
      "242/242 - 11s - loss: 2.9698 - accuracy: 0.8901 - auc: 0.9567 - val_loss: 3.2625 - val_accuracy: 0.8462 - val_auc: 0.7775\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.81420\n",
      "Epoch 22/100\n",
      "242/242 - 11s - loss: 2.9640 - accuracy: 0.8853 - auc: 0.9573 - val_loss: 3.2804 - val_accuracy: 0.8521 - val_auc: 0.7719\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.81420\n",
      "Epoch 23/100\n",
      "242/242 - 11s - loss: 2.9593 - accuracy: 0.8840 - auc: 0.9575 - val_loss: 3.3050 - val_accuracy: 0.8422 - val_auc: 0.7618\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.81420\n",
      "Epoch 24/100\n",
      "242/242 - 11s - loss: 2.9397 - accuracy: 0.8937 - auc: 0.9640 - val_loss: 3.2869 - val_accuracy: 0.8284 - val_auc: 0.7787\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.81420\n",
      "Epoch 25/100\n",
      "242/242 - 11s - loss: 2.9372 - accuracy: 0.8927 - auc: 0.9639 - val_loss: 3.3318 - val_accuracy: 0.8462 - val_auc: 0.7782\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.81420\n",
      "Epoch 26/100\n",
      "242/242 - 11s - loss: 2.9260 - accuracy: 0.8989 - auc: 0.9665 - val_loss: 3.3578 - val_accuracy: 0.8679 - val_auc: 0.7724\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.81420\n",
      "Epoch 27/100\n",
      "242/242 - 11s - loss: 2.9233 - accuracy: 0.8981 - auc: 0.9661 - val_loss: 3.3520 - val_accuracy: 0.8264 - val_auc: 0.7680\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.81420\n",
      "Epoch 28/100\n",
      "242/242 - 11s - loss: 2.9085 - accuracy: 0.9025 - auc: 0.9701 - val_loss: 3.3575 - val_accuracy: 0.8659 - val_auc: 0.7739\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.81420\n",
      "Epoch 29/100\n",
      "242/242 - 11s - loss: 2.9024 - accuracy: 0.9049 - auc: 0.9714 - val_loss: 3.4577 - val_accuracy: 0.8738 - val_auc: 0.7377\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.81420\n",
      "Epoch 30/100\n",
      "242/242 - 11s - loss: 2.9023 - accuracy: 0.9032 - auc: 0.9704 - val_loss: 3.3515 - val_accuracy: 0.8225 - val_auc: 0.7791\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.81420\n",
      "Epoch 31/100\n",
      "242/242 - 11s - loss: 2.8934 - accuracy: 0.9080 - auc: 0.9724 - val_loss: 3.4083 - val_accuracy: 0.8501 - val_auc: 0.7645\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.81420\n",
      "Epoch 32/100\n",
      "242/242 - 11s - loss: 2.8847 - accuracy: 0.9123 - auc: 0.9742 - val_loss: 3.4504 - val_accuracy: 0.8639 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.81420\n",
      "Epoch 33/100\n",
      "242/242 - 11s - loss: 2.8747 - accuracy: 0.9120 - auc: 0.9762 - val_loss: 3.4570 - val_accuracy: 0.8462 - val_auc: 0.7495\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.81420\n",
      "Epoch 34/100\n",
      "242/242 - 11s - loss: 2.8738 - accuracy: 0.9115 - auc: 0.9760 - val_loss: 3.4962 - val_accuracy: 0.8323 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.81420\n",
      "Epoch 35/100\n",
      "242/242 - 11s - loss: 2.8646 - accuracy: 0.9152 - auc: 0.9774 - val_loss: 3.5002 - val_accuracy: 0.8698 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.81420\n",
      "Epoch 36/100\n",
      "242/242 - 11s - loss: 2.8567 - accuracy: 0.9200 - auc: 0.9788 - val_loss: 3.5650 - val_accuracy: 0.8560 - val_auc: 0.7237\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.81420\n",
      "Epoch 37/100\n",
      "242/242 - 11s - loss: 2.8506 - accuracy: 0.9213 - auc: 0.9797 - val_loss: 3.5707 - val_accuracy: 0.8738 - val_auc: 0.7393\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.81420\n",
      "Epoch 38/100\n",
      "242/242 - 11s - loss: 2.8454 - accuracy: 0.9189 - auc: 0.9804 - val_loss: 3.5439 - val_accuracy: 0.8560 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.81420\n",
      "Epoch 39/100\n",
      "242/242 - 11s - loss: 2.8411 - accuracy: 0.9209 - auc: 0.9809 - val_loss: 3.5772 - val_accuracy: 0.8560 - val_auc: 0.7238\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.81420\n",
      "Epoch 40/100\n",
      "242/242 - 11s - loss: 2.8398 - accuracy: 0.9212 - auc: 0.9809 - val_loss: 3.6367 - val_accuracy: 0.8521 - val_auc: 0.7247\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.81420\n",
      "Epoch 41/100\n",
      "242/242 - 11s - loss: 2.8321 - accuracy: 0.9240 - auc: 0.9821 - val_loss: 3.6859 - val_accuracy: 0.8540 - val_auc: 0.7147\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.81420\n",
      "Epoch 42/100\n",
      "242/242 - 10s - loss: 2.8266 - accuracy: 0.9231 - auc: 0.9826 - val_loss: 3.6655 - val_accuracy: 0.8698 - val_auc: 0.7377\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.81420\n",
      "Epoch 43/100\n",
      "242/242 - 10s - loss: 2.8177 - accuracy: 0.9308 - auc: 0.9844 - val_loss: 3.6456 - val_accuracy: 0.8679 - val_auc: 0.7475\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.81420\n",
      "Epoch 44/100\n",
      "242/242 - 10s - loss: 2.8203 - accuracy: 0.9275 - auc: 0.9830 - val_loss: 3.6935 - val_accuracy: 0.8304 - val_auc: 0.7108\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.81420\n",
      "Epoch 45/100\n",
      "242/242 - 10s - loss: 2.8172 - accuracy: 0.9251 - auc: 0.9834 - val_loss: 3.6306 - val_accuracy: 0.8540 - val_auc: 0.7530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: val_auc did not improve from 0.81420\n",
      "Epoch 46/100\n",
      "242/242 - 10s - loss: 2.8116 - accuracy: 0.9277 - auc: 0.9843 - val_loss: 3.7587 - val_accuracy: 0.8639 - val_auc: 0.7139\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.81420\n",
      "Epoch 47/100\n",
      "242/242 - 10s - loss: 2.8025 - accuracy: 0.9358 - auc: 0.9856 - val_loss: 3.6988 - val_accuracy: 0.8679 - val_auc: 0.7348\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.81420\n",
      "Epoch 48/100\n",
      "242/242 - 11s - loss: 2.7992 - accuracy: 0.9340 - auc: 0.9858 - val_loss: 3.6889 - val_accuracy: 0.8698 - val_auc: 0.7422\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.81420\n",
      "Epoch 49/100\n",
      "242/242 - 11s - loss: 2.7991 - accuracy: 0.9336 - auc: 0.9852 - val_loss: 3.6927 - val_accuracy: 0.8718 - val_auc: 0.7341\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.81420\n",
      "Epoch 50/100\n",
      "242/242 - 11s - loss: 2.7894 - accuracy: 0.9375 - auc: 0.9873 - val_loss: 3.7403 - val_accuracy: 0.8619 - val_auc: 0.7247\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.81420\n",
      "Epoch 51/100\n",
      "242/242 - 11s - loss: 2.7944 - accuracy: 0.9327 - auc: 0.9858 - val_loss: 3.7418 - val_accuracy: 0.8698 - val_auc: 0.7197\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.81420\n",
      "Epoch 52/100\n",
      "242/242 - 11s - loss: 2.7876 - accuracy: 0.9366 - auc: 0.9864 - val_loss: 3.7314 - val_accuracy: 0.8580 - val_auc: 0.7281\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.81420\n",
      "Epoch 53/100\n",
      "242/242 - 11s - loss: 2.7861 - accuracy: 0.9368 - auc: 0.9866 - val_loss: 3.7880 - val_accuracy: 0.8659 - val_auc: 0.7112\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.81420\n",
      "Epoch 54/100\n",
      "242/242 - 11s - loss: 2.7799 - accuracy: 0.9393 - auc: 0.9870 - val_loss: 3.7765 - val_accuracy: 0.8738 - val_auc: 0.7279\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.81420\n",
      "Epoch 55/100\n",
      "242/242 - 11s - loss: 2.7785 - accuracy: 0.9393 - auc: 0.9872 - val_loss: 3.8135 - val_accuracy: 0.8738 - val_auc: 0.7140\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.81420\n",
      "Epoch 56/100\n",
      "242/242 - 11s - loss: 2.7733 - accuracy: 0.9385 - auc: 0.9877 - val_loss: 3.8706 - val_accuracy: 0.8698 - val_auc: 0.7163\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.81420\n",
      "Epoch 57/100\n",
      "242/242 - 11s - loss: 2.7669 - accuracy: 0.9407 - auc: 0.9885 - val_loss: 3.8432 - val_accuracy: 0.8757 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.81420\n",
      "Epoch 58/100\n",
      "242/242 - 11s - loss: 2.7705 - accuracy: 0.9396 - auc: 0.9876 - val_loss: 3.7493 - val_accuracy: 0.8501 - val_auc: 0.7297\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.81420\n",
      "Epoch 59/100\n",
      "242/242 - 11s - loss: 2.7606 - accuracy: 0.9458 - auc: 0.9890 - val_loss: 3.8043 - val_accuracy: 0.8383 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.81420\n",
      "Epoch 60/100\n",
      "242/242 - 11s - loss: 2.7585 - accuracy: 0.9429 - auc: 0.9892 - val_loss: 3.8022 - val_accuracy: 0.8639 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.81420\n",
      "Epoch 61/100\n",
      "242/242 - 11s - loss: 2.7591 - accuracy: 0.9425 - auc: 0.9887 - val_loss: 3.8895 - val_accuracy: 0.8777 - val_auc: 0.7202\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.81420\n",
      "Epoch 62/100\n",
      "242/242 - 11s - loss: 2.7504 - accuracy: 0.9444 - auc: 0.9898 - val_loss: 3.9126 - val_accuracy: 0.8639 - val_auc: 0.7074\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.81420\n",
      "Epoch 63/100\n",
      "242/242 - 11s - loss: 2.7528 - accuracy: 0.9464 - auc: 0.9895 - val_loss: 3.9346 - val_accuracy: 0.8698 - val_auc: 0.7150\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.81420\n",
      "Epoch 64/100\n",
      "242/242 - 11s - loss: 2.7465 - accuracy: 0.9451 - auc: 0.9905 - val_loss: 3.8487 - val_accuracy: 0.8619 - val_auc: 0.7253\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.81420\n",
      "Epoch 65/100\n",
      "242/242 - 11s - loss: 2.7473 - accuracy: 0.9437 - auc: 0.9899 - val_loss: 3.9210 - val_accuracy: 0.8738 - val_auc: 0.7227\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.81420\n",
      "Epoch 66/100\n",
      "242/242 - 11s - loss: 2.7433 - accuracy: 0.9455 - auc: 0.9904 - val_loss: 3.9038 - val_accuracy: 0.8817 - val_auc: 0.7194\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.81420\n",
      "Epoch 67/100\n",
      "242/242 - 11s - loss: 2.7413 - accuracy: 0.9463 - auc: 0.9904 - val_loss: 3.8801 - val_accuracy: 0.8738 - val_auc: 0.7277\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.81420\n",
      "Epoch 68/100\n",
      "242/242 - 11s - loss: 2.7369 - accuracy: 0.9455 - auc: 0.9904 - val_loss: 3.8533 - val_accuracy: 0.8501 - val_auc: 0.7222\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.81420\n",
      "Epoch 69/100\n",
      "242/242 - 11s - loss: 2.7368 - accuracy: 0.9475 - auc: 0.9900 - val_loss: 3.8996 - val_accuracy: 0.8679 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.81420\n",
      "Epoch 70/100\n",
      "242/242 - 11s - loss: 2.7324 - accuracy: 0.9481 - auc: 0.9907 - val_loss: 3.8903 - val_accuracy: 0.8698 - val_auc: 0.7370\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.81420\n",
      "Epoch 71/100\n",
      "242/242 - 11s - loss: 2.7336 - accuracy: 0.9466 - auc: 0.9903 - val_loss: 3.9344 - val_accuracy: 0.8738 - val_auc: 0.7107\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.81420\n",
      "Epoch 72/100\n",
      "242/242 - 11s - loss: 2.7297 - accuracy: 0.9481 - auc: 0.9908 - val_loss: 4.0163 - val_accuracy: 0.8718 - val_auc: 0.6985\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.81420\n",
      "Epoch 73/100\n",
      "242/242 - 11s - loss: 2.7230 - accuracy: 0.9491 - auc: 0.9915 - val_loss: 4.0341 - val_accuracy: 0.8856 - val_auc: 0.6991\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.81420\n",
      "Epoch 74/100\n",
      "242/242 - 11s - loss: 2.7271 - accuracy: 0.9471 - auc: 0.9905 - val_loss: 3.9087 - val_accuracy: 0.8679 - val_auc: 0.7065\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.81420\n",
      "Epoch 75/100\n",
      "242/242 - 11s - loss: 2.7233 - accuracy: 0.9486 - auc: 0.9911 - val_loss: 3.9708 - val_accuracy: 0.8698 - val_auc: 0.7203\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.81420\n",
      "Epoch 76/100\n",
      "242/242 - 11s - loss: 2.7186 - accuracy: 0.9510 - auc: 0.9910 - val_loss: 3.9859 - val_accuracy: 0.8619 - val_auc: 0.7028\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.81420\n",
      "Epoch 77/100\n",
      "242/242 - 11s - loss: 2.7199 - accuracy: 0.9485 - auc: 0.9908 - val_loss: 3.9716 - val_accuracy: 0.8659 - val_auc: 0.7098\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.81420\n",
      "Epoch 78/100\n",
      "242/242 - 11s - loss: 2.7142 - accuracy: 0.9506 - auc: 0.9916 - val_loss: 4.0535 - val_accuracy: 0.8659 - val_auc: 0.7018\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.81420\n",
      "Epoch 79/100\n",
      "242/242 - 11s - loss: 2.7108 - accuracy: 0.9511 - auc: 0.9919 - val_loss: 3.9326 - val_accuracy: 0.8560 - val_auc: 0.7221\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.81420\n",
      "Epoch 80/100\n",
      "242/242 - 11s - loss: 2.7083 - accuracy: 0.9511 - auc: 0.9920 - val_loss: 4.0828 - val_accuracy: 0.8698 - val_auc: 0.6810\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.81420\n",
      "Epoch 81/100\n",
      "242/242 - 11s - loss: 2.7142 - accuracy: 0.9495 - auc: 0.9912 - val_loss: 4.0816 - val_accuracy: 0.8718 - val_auc: 0.6798\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.81420\n",
      "Epoch 82/100\n",
      "242/242 - 11s - loss: 2.7067 - accuracy: 0.9504 - auc: 0.9920 - val_loss: 4.0104 - val_accuracy: 0.8777 - val_auc: 0.7011\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.81420\n",
      "Epoch 83/100\n",
      "242/242 - 11s - loss: 2.7036 - accuracy: 0.9524 - auc: 0.9919 - val_loss: 4.0169 - val_accuracy: 0.8777 - val_auc: 0.7081\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.81420\n",
      "Epoch 84/100\n",
      "242/242 - 11s - loss: 2.7007 - accuracy: 0.9556 - auc: 0.9920 - val_loss: 4.0405 - val_accuracy: 0.8659 - val_auc: 0.6810\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.81420\n",
      "Epoch 85/100\n",
      "242/242 - 11s - loss: 2.6959 - accuracy: 0.9538 - auc: 0.9925 - val_loss: 4.0466 - val_accuracy: 0.8777 - val_auc: 0.7090\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.81420\n",
      "Epoch 86/100\n",
      "242/242 - 10s - loss: 2.6988 - accuracy: 0.9530 - auc: 0.9919 - val_loss: 3.9942 - val_accuracy: 0.8639 - val_auc: 0.7129\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.81420\n",
      "Epoch 87/100\n",
      "242/242 - 10s - loss: 2.6944 - accuracy: 0.9534 - auc: 0.9927 - val_loss: 4.0301 - val_accuracy: 0.8639 - val_auc: 0.7023\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.81420\n",
      "Epoch 88/100\n",
      "242/242 - 10s - loss: 2.6928 - accuracy: 0.9517 - auc: 0.9927 - val_loss: 4.0781 - val_accuracy: 0.8639 - val_auc: 0.6736\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.81420\n",
      "Epoch 89/100\n",
      "242/242 - 10s - loss: 2.6969 - accuracy: 0.9502 - auc: 0.9919 - val_loss: 4.0996 - val_accuracy: 0.8817 - val_auc: 0.6886\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.81420\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 - 10s - loss: 2.6886 - accuracy: 0.9560 - auc: 0.9925 - val_loss: 3.9816 - val_accuracy: 0.8738 - val_auc: 0.7090\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.81420\n",
      "Epoch 91/100\n",
      "242/242 - 10s - loss: 2.6895 - accuracy: 0.9542 - auc: 0.9924 - val_loss: 4.0194 - val_accuracy: 0.8777 - val_auc: 0.6919\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.81420\n",
      "Epoch 92/100\n",
      "242/242 - 11s - loss: 2.6856 - accuracy: 0.9544 - auc: 0.9927 - val_loss: 4.0933 - val_accuracy: 0.8836 - val_auc: 0.6952\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.81420\n",
      "Epoch 93/100\n",
      "242/242 - 11s - loss: 2.6862 - accuracy: 0.9535 - auc: 0.9925 - val_loss: 4.0029 - val_accuracy: 0.8757 - val_auc: 0.7194\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.81420\n",
      "Epoch 94/100\n",
      "242/242 - 11s - loss: 2.6830 - accuracy: 0.9544 - auc: 0.9926 - val_loss: 4.1183 - val_accuracy: 0.8757 - val_auc: 0.6835\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.81420\n",
      "Epoch 95/100\n",
      "242/242 - 11s - loss: 2.6823 - accuracy: 0.9534 - auc: 0.9924 - val_loss: 4.1378 - val_accuracy: 0.8698 - val_auc: 0.6781\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.81420\n",
      "Epoch 96/100\n",
      "242/242 - 11s - loss: 2.6772 - accuracy: 0.9542 - auc: 0.9932 - val_loss: 4.0923 - val_accuracy: 0.8836 - val_auc: 0.6939\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.81420\n",
      "Epoch 97/100\n",
      "242/242 - 11s - loss: 2.6785 - accuracy: 0.9560 - auc: 0.9926 - val_loss: 4.0631 - val_accuracy: 0.8679 - val_auc: 0.6995\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.81420\n",
      "Epoch 98/100\n",
      "242/242 - 11s - loss: 2.6724 - accuracy: 0.9557 - auc: 0.9933 - val_loss: 4.1070 - val_accuracy: 0.8718 - val_auc: 0.6845\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.81420\n",
      "Epoch 99/100\n",
      "242/242 - 11s - loss: 2.6696 - accuracy: 0.9586 - auc: 0.9932 - val_loss: 4.1856 - val_accuracy: 0.8817 - val_auc: 0.6852\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.81420\n",
      "Epoch 100/100\n",
      "242/242 - 11s - loss: 2.6661 - accuracy: 0.9574 - auc: 0.9935 - val_loss: 4.1413 - val_accuracy: 0.8836 - val_auc: 0.6865\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.81420\n",
      "Epoch 1/100\n",
      "274/274 - 16s - loss: 3.2938 - accuracy: 0.6914 - auc: 0.7800 - val_loss: 3.2269 - val_accuracy: 0.7172 - val_auc: 0.7278\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.72782, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 2/100\n",
      "274/274 - 12s - loss: 3.1583 - accuracy: 0.8126 - auc: 0.8839 - val_loss: 3.2168 - val_accuracy: 0.8109 - val_auc: 0.7328\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.72782 to 0.73276, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 3/100\n",
      "274/274 - 12s - loss: 3.1043 - accuracy: 0.8444 - auc: 0.9098 - val_loss: 3.2342 - val_accuracy: 0.8484 - val_auc: 0.7249\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.73276\n",
      "Epoch 4/100\n",
      "274/274 - 12s - loss: 3.0511 - accuracy: 0.8744 - auc: 0.9353 - val_loss: 3.2542 - val_accuracy: 0.8552 - val_auc: 0.7389\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.73276 to 0.73893, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 5/100\n",
      "274/274 - 12s - loss: 3.0211 - accuracy: 0.8894 - auc: 0.9467 - val_loss: 3.3017 - val_accuracy: 0.8995 - val_auc: 0.7317\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.73893\n",
      "Epoch 6/100\n",
      "274/274 - 12s - loss: 2.9955 - accuracy: 0.9003 - auc: 0.9537 - val_loss: 3.3056 - val_accuracy: 0.8756 - val_auc: 0.7202\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.73893\n",
      "Epoch 7/100\n",
      "274/274 - 12s - loss: 2.9611 - accuracy: 0.9129 - auc: 0.9663 - val_loss: 3.3303 - val_accuracy: 0.8842 - val_auc: 0.7364\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.73893\n",
      "Epoch 8/100\n",
      "274/274 - 12s - loss: 2.9401 - accuracy: 0.9178 - auc: 0.9711 - val_loss: 3.3673 - val_accuracy: 0.9029 - val_auc: 0.7272\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.73893\n",
      "Epoch 9/100\n",
      "274/274 - 12s - loss: 2.9216 - accuracy: 0.9237 - auc: 0.9746 - val_loss: 3.3626 - val_accuracy: 0.9029 - val_auc: 0.7533\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.73893 to 0.75326, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 10/100\n",
      "274/274 - 12s - loss: 2.9059 - accuracy: 0.9295 - auc: 0.9780 - val_loss: 3.3930 - val_accuracy: 0.9029 - val_auc: 0.7497\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.75326\n",
      "Epoch 11/100\n",
      "274/274 - 12s - loss: 2.8889 - accuracy: 0.9301 - auc: 0.9809 - val_loss: 3.4837 - val_accuracy: 0.9216 - val_auc: 0.7398\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.75326\n",
      "Epoch 12/100\n",
      "274/274 - 12s - loss: 2.8745 - accuracy: 0.9387 - auc: 0.9835 - val_loss: 3.4470 - val_accuracy: 0.9097 - val_auc: 0.7506\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.75326\n",
      "Epoch 13/100\n",
      "274/274 - 12s - loss: 2.8611 - accuracy: 0.9369 - auc: 0.9853 - val_loss: 3.4904 - val_accuracy: 0.9114 - val_auc: 0.7470\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75326\n",
      "Epoch 14/100\n",
      "274/274 - 12s - loss: 2.8505 - accuracy: 0.9452 - auc: 0.9861 - val_loss: 3.6016 - val_accuracy: 0.9182 - val_auc: 0.7353\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.75326\n",
      "Epoch 15/100\n",
      "274/274 - 12s - loss: 2.8365 - accuracy: 0.9473 - auc: 0.9886 - val_loss: 3.6016 - val_accuracy: 0.9114 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75326\n",
      "Epoch 16/100\n",
      "274/274 - 12s - loss: 2.8274 - accuracy: 0.9463 - auc: 0.9895 - val_loss: 3.6480 - val_accuracy: 0.9353 - val_auc: 0.7378\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.75326\n",
      "Epoch 17/100\n",
      "274/274 - 12s - loss: 2.8159 - accuracy: 0.9522 - auc: 0.9908 - val_loss: 3.5917 - val_accuracy: 0.9302 - val_auc: 0.7656\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.75326 to 0.76561, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 18/100\n",
      "274/274 - 12s - loss: 2.8114 - accuracy: 0.9534 - auc: 0.9908 - val_loss: 3.6130 - val_accuracy: 0.9199 - val_auc: 0.7494\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.76561\n",
      "Epoch 19/100\n",
      "274/274 - 12s - loss: 2.8117 - accuracy: 0.9497 - auc: 0.9899 - val_loss: 3.6482 - val_accuracy: 0.9199 - val_auc: 0.7614\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.76561\n",
      "Epoch 20/100\n",
      "274/274 - 12s - loss: 2.7955 - accuracy: 0.9566 - auc: 0.9922 - val_loss: 3.5838 - val_accuracy: 0.9131 - val_auc: 0.7752\n",
      "\n",
      "Epoch 00020: val_auc improved from 0.76561 to 0.77522, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 21/100\n",
      "274/274 - 12s - loss: 2.7911 - accuracy: 0.9595 - auc: 0.9925 - val_loss: 3.7357 - val_accuracy: 0.9319 - val_auc: 0.7444\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.77522\n",
      "Epoch 22/100\n",
      "274/274 - 12s - loss: 2.7876 - accuracy: 0.9576 - auc: 0.9925 - val_loss: 3.7644 - val_accuracy: 0.9302 - val_auc: 0.7315\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.77522\n",
      "Epoch 23/100\n",
      "274/274 - 12s - loss: 2.7755 - accuracy: 0.9605 - auc: 0.9938 - val_loss: 3.7648 - val_accuracy: 0.9421 - val_auc: 0.7480\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.77522\n",
      "Epoch 24/100\n",
      "274/274 - 12s - loss: 2.7743 - accuracy: 0.9627 - auc: 0.9934 - val_loss: 3.7827 - val_accuracy: 0.9336 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.77522\n",
      "Epoch 25/100\n",
      "274/274 - 12s - loss: 2.7633 - accuracy: 0.9678 - auc: 0.9945 - val_loss: 3.8108 - val_accuracy: 0.9404 - val_auc: 0.7296\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.77522\n",
      "Epoch 26/100\n",
      "274/274 - 12s - loss: 2.7574 - accuracy: 0.9668 - auc: 0.9949 - val_loss: 3.9581 - val_accuracy: 0.9506 - val_auc: 0.7323\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.77522\n",
      "Epoch 27/100\n",
      "274/274 - 12s - loss: 2.7574 - accuracy: 0.9660 - auc: 0.9947 - val_loss: 3.7034 - val_accuracy: 0.9216 - val_auc: 0.7745\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.77522\n",
      "Epoch 28/100\n",
      "274/274 - 11s - loss: 2.7531 - accuracy: 0.9662 - auc: 0.9947 - val_loss: 3.7701 - val_accuracy: 0.9421 - val_auc: 0.7870\n",
      "\n",
      "Epoch 00028: val_auc improved from 0.77522 to 0.78704, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 29/100\n",
      "274/274 - 11s - loss: 2.7486 - accuracy: 0.9708 - auc: 0.9950 - val_loss: 3.8564 - val_accuracy: 0.9387 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.78704\n",
      "Epoch 30/100\n",
      "274/274 - 11s - loss: 2.7439 - accuracy: 0.9680 - auc: 0.9953 - val_loss: 3.9870 - val_accuracy: 0.9370 - val_auc: 0.7514\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.78704\n",
      "Epoch 31/100\n",
      "274/274 - 11s - loss: 2.7446 - accuracy: 0.9702 - auc: 0.9951 - val_loss: 3.8346 - val_accuracy: 0.9387 - val_auc: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_auc did not improve from 0.78704\n",
      "Epoch 32/100\n",
      "274/274 - 11s - loss: 2.7391 - accuracy: 0.9695 - auc: 0.9951 - val_loss: 4.0102 - val_accuracy: 0.9455 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.78704\n",
      "Epoch 33/100\n",
      "274/274 - 12s - loss: 2.7310 - accuracy: 0.9711 - auc: 0.9961 - val_loss: 3.9736 - val_accuracy: 0.9557 - val_auc: 0.7870\n",
      "\n",
      "Epoch 00033: val_auc improved from 0.78704 to 0.78704, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 34/100\n",
      "274/274 - 12s - loss: 2.7300 - accuracy: 0.9716 - auc: 0.9958 - val_loss: 3.9467 - val_accuracy: 0.9523 - val_auc: 0.7798\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.78704\n",
      "Epoch 35/100\n",
      "274/274 - 12s - loss: 2.7285 - accuracy: 0.9713 - auc: 0.9957 - val_loss: 4.0387 - val_accuracy: 0.9455 - val_auc: 0.7687\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.78704\n",
      "Epoch 36/100\n",
      "274/274 - 12s - loss: 2.7261 - accuracy: 0.9729 - auc: 0.9958 - val_loss: 3.9059 - val_accuracy: 0.9387 - val_auc: 0.7683\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.78704\n",
      "Epoch 37/100\n",
      "274/274 - 12s - loss: 2.7177 - accuracy: 0.9737 - auc: 0.9965 - val_loss: 3.8757 - val_accuracy: 0.9489 - val_auc: 0.7990\n",
      "\n",
      "Epoch 00037: val_auc improved from 0.78704 to 0.79899, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 38/100\n",
      "274/274 - 12s - loss: 2.7176 - accuracy: 0.9763 - auc: 0.9959 - val_loss: 4.0771 - val_accuracy: 0.9489 - val_auc: 0.7777\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.79899\n",
      "Epoch 39/100\n",
      "274/274 - 12s - loss: 2.7138 - accuracy: 0.9743 - auc: 0.9965 - val_loss: 4.0180 - val_accuracy: 0.9489 - val_auc: 0.7943\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.79899\n",
      "Epoch 40/100\n",
      "274/274 - 12s - loss: 2.7123 - accuracy: 0.9779 - auc: 0.9963 - val_loss: 4.0159 - val_accuracy: 0.9523 - val_auc: 0.7847\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.79899\n",
      "Epoch 41/100\n",
      "274/274 - 12s - loss: 2.7094 - accuracy: 0.9761 - auc: 0.9965 - val_loss: 4.0882 - val_accuracy: 0.9489 - val_auc: 0.7698\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.79899\n",
      "Epoch 42/100\n",
      "274/274 - 12s - loss: 2.7058 - accuracy: 0.9761 - auc: 0.9966 - val_loss: 3.9551 - val_accuracy: 0.9421 - val_auc: 0.7753\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.79899\n",
      "Epoch 43/100\n",
      "274/274 - 12s - loss: 2.7037 - accuracy: 0.9766 - auc: 0.9969 - val_loss: 3.9217 - val_accuracy: 0.9404 - val_auc: 0.8033\n",
      "\n",
      "Epoch 00043: val_auc improved from 0.79899 to 0.80331, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-ER-LBD\n",
      "Epoch 44/100\n",
      "274/274 - 12s - loss: 2.7026 - accuracy: 0.9776 - auc: 0.9964 - val_loss: 4.0923 - val_accuracy: 0.9489 - val_auc: 0.7730\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.80331\n",
      "Epoch 45/100\n",
      "274/274 - 12s - loss: 2.6974 - accuracy: 0.9773 - auc: 0.9968 - val_loss: 4.1553 - val_accuracy: 0.9540 - val_auc: 0.7635\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.80331\n",
      "Epoch 46/100\n",
      "274/274 - 12s - loss: 2.6977 - accuracy: 0.9774 - auc: 0.9968 - val_loss: 4.1553 - val_accuracy: 0.9489 - val_auc: 0.7624\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.80331\n",
      "Epoch 47/100\n",
      "274/274 - 12s - loss: 2.6941 - accuracy: 0.9767 - auc: 0.9968 - val_loss: 4.3247 - val_accuracy: 0.9523 - val_auc: 0.7036\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.80331\n",
      "Epoch 48/100\n",
      "274/274 - 12s - loss: 2.6900 - accuracy: 0.9789 - auc: 0.9971 - val_loss: 4.1223 - val_accuracy: 0.9523 - val_auc: 0.7761\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.80331\n",
      "Epoch 49/100\n",
      "274/274 - 12s - loss: 2.6893 - accuracy: 0.9788 - auc: 0.9966 - val_loss: 4.2471 - val_accuracy: 0.9574 - val_auc: 0.7813\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.80331\n",
      "Epoch 50/100\n",
      "274/274 - 12s - loss: 2.6867 - accuracy: 0.9789 - auc: 0.9971 - val_loss: 4.0235 - val_accuracy: 0.9421 - val_auc: 0.7799\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.80331\n",
      "Epoch 51/100\n",
      "274/274 - 12s - loss: 2.6839 - accuracy: 0.9782 - auc: 0.9972 - val_loss: 4.3123 - val_accuracy: 0.9523 - val_auc: 0.7139\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.80331\n",
      "Epoch 52/100\n",
      "274/274 - 12s - loss: 2.6808 - accuracy: 0.9792 - auc: 0.9973 - val_loss: 3.9042 - val_accuracy: 0.9455 - val_auc: 0.7929\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.80331\n",
      "Epoch 53/100\n",
      "274/274 - 12s - loss: 2.6807 - accuracy: 0.9796 - auc: 0.9970 - val_loss: 4.2420 - val_accuracy: 0.9557 - val_auc: 0.7142\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.80331\n",
      "Epoch 54/100\n",
      "274/274 - 12s - loss: 2.6740 - accuracy: 0.9805 - auc: 0.9972 - val_loss: 4.2673 - val_accuracy: 0.9557 - val_auc: 0.7478\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.80331\n",
      "Epoch 55/100\n",
      "274/274 - 12s - loss: 2.6748 - accuracy: 0.9803 - auc: 0.9972 - val_loss: 4.1047 - val_accuracy: 0.9523 - val_auc: 0.7819\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.80331\n",
      "Epoch 56/100\n",
      "274/274 - 12s - loss: 2.6716 - accuracy: 0.9807 - auc: 0.9975 - val_loss: 4.0150 - val_accuracy: 0.9557 - val_auc: 0.7727\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.80331\n",
      "Epoch 57/100\n",
      "274/274 - 12s - loss: 2.6707 - accuracy: 0.9799 - auc: 0.9973 - val_loss: 4.1971 - val_accuracy: 0.9421 - val_auc: 0.7787\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.80331\n",
      "Epoch 58/100\n",
      "274/274 - 12s - loss: 2.6668 - accuracy: 0.9797 - auc: 0.9974 - val_loss: 4.2502 - val_accuracy: 0.9557 - val_auc: 0.7027\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.80331\n",
      "Epoch 59/100\n",
      "274/274 - 12s - loss: 2.6663 - accuracy: 0.9809 - auc: 0.9974 - val_loss: 4.2921 - val_accuracy: 0.9523 - val_auc: 0.7283\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.80331\n",
      "Epoch 60/100\n",
      "274/274 - 12s - loss: 2.6634 - accuracy: 0.9816 - auc: 0.9975 - val_loss: 4.2992 - val_accuracy: 0.9574 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.80331\n",
      "Epoch 61/100\n",
      "274/274 - 12s - loss: 2.6612 - accuracy: 0.9798 - auc: 0.9976 - val_loss: 4.2106 - val_accuracy: 0.9540 - val_auc: 0.7347\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.80331\n",
      "Epoch 62/100\n",
      "274/274 - 12s - loss: 2.6613 - accuracy: 0.9805 - auc: 0.9975 - val_loss: 4.4054 - val_accuracy: 0.9540 - val_auc: 0.7075\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.80331\n",
      "Epoch 63/100\n",
      "274/274 - 12s - loss: 2.6596 - accuracy: 0.9799 - auc: 0.9973 - val_loss: 4.3212 - val_accuracy: 0.9540 - val_auc: 0.7250\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.80331\n",
      "Epoch 64/100\n",
      "274/274 - 12s - loss: 2.6569 - accuracy: 0.9816 - auc: 0.9976 - val_loss: 4.2596 - val_accuracy: 0.9489 - val_auc: 0.7196\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.80331\n",
      "Epoch 65/100\n",
      "274/274 - 12s - loss: 2.6543 - accuracy: 0.9815 - auc: 0.9973 - val_loss: 4.2548 - val_accuracy: 0.9540 - val_auc: 0.7257\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.80331\n",
      "Epoch 66/100\n",
      "274/274 - 12s - loss: 2.6508 - accuracy: 0.9828 - auc: 0.9974 - val_loss: 4.3821 - val_accuracy: 0.9557 - val_auc: 0.7293\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.80331\n",
      "Epoch 67/100\n",
      "274/274 - 12s - loss: 2.6509 - accuracy: 0.9814 - auc: 0.9975 - val_loss: 4.3292 - val_accuracy: 0.9506 - val_auc: 0.7186\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.80331\n",
      "Epoch 68/100\n",
      "274/274 - 12s - loss: 2.6471 - accuracy: 0.9823 - auc: 0.9977 - val_loss: 4.2974 - val_accuracy: 0.9540 - val_auc: 0.7337\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.80331\n",
      "Epoch 69/100\n",
      "274/274 - 11s - loss: 2.6458 - accuracy: 0.9820 - auc: 0.9978 - val_loss: 4.3512 - val_accuracy: 0.9523 - val_auc: 0.7068\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.80331\n",
      "Epoch 70/100\n",
      "274/274 - 11s - loss: 2.6433 - accuracy: 0.9824 - auc: 0.9976 - val_loss: 4.3543 - val_accuracy: 0.9557 - val_auc: 0.7071\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.80331\n",
      "Epoch 71/100\n",
      "274/274 - 11s - loss: 2.6411 - accuracy: 0.9824 - auc: 0.9979 - val_loss: 4.3726 - val_accuracy: 0.9506 - val_auc: 0.7243\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.80331\n",
      "Epoch 72/100\n",
      "274/274 - 11s - loss: 2.6401 - accuracy: 0.9824 - auc: 0.9977 - val_loss: 4.2848 - val_accuracy: 0.9523 - val_auc: 0.7299\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.80331\n",
      "Epoch 73/100\n",
      "274/274 - 11s - loss: 2.6382 - accuracy: 0.9825 - auc: 0.9979 - val_loss: 4.3388 - val_accuracy: 0.9540 - val_auc: 0.7272\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.80331\n",
      "Epoch 74/100\n",
      "274/274 - 12s - loss: 2.6356 - accuracy: 0.9824 - auc: 0.9977 - val_loss: 4.4244 - val_accuracy: 0.9574 - val_auc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_auc did not improve from 0.80331\n",
      "Epoch 75/100\n",
      "274/274 - 12s - loss: 2.6372 - accuracy: 0.9821 - auc: 0.9977 - val_loss: 4.4602 - val_accuracy: 0.9557 - val_auc: 0.6826\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.80331\n",
      "Epoch 76/100\n",
      "274/274 - 12s - loss: 2.6319 - accuracy: 0.9831 - auc: 0.9978 - val_loss: 4.5663 - val_accuracy: 0.9557 - val_auc: 0.6866\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.80331\n",
      "Epoch 77/100\n",
      "274/274 - 12s - loss: 2.6287 - accuracy: 0.9829 - auc: 0.9980 - val_loss: 4.4263 - val_accuracy: 0.9557 - val_auc: 0.7112\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.80331\n",
      "Epoch 78/100\n",
      "274/274 - 12s - loss: 2.6291 - accuracy: 0.9823 - auc: 0.9978 - val_loss: 4.4642 - val_accuracy: 0.9557 - val_auc: 0.7072\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.80331\n",
      "Epoch 79/100\n",
      "274/274 - 12s - loss: 2.6255 - accuracy: 0.9837 - auc: 0.9978 - val_loss: 4.3244 - val_accuracy: 0.9557 - val_auc: 0.7336\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.80331\n",
      "Epoch 80/100\n",
      "274/274 - 12s - loss: 2.6220 - accuracy: 0.9834 - auc: 0.9979 - val_loss: 4.5101 - val_accuracy: 0.9574 - val_auc: 0.6679\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.80331\n",
      "Epoch 81/100\n",
      "274/274 - 12s - loss: 2.6210 - accuracy: 0.9834 - auc: 0.9981 - val_loss: 4.4319 - val_accuracy: 0.9591 - val_auc: 0.6905\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.80331\n",
      "Epoch 82/100\n",
      "274/274 - 12s - loss: 2.6215 - accuracy: 0.9829 - auc: 0.9979 - val_loss: 4.5589 - val_accuracy: 0.9591 - val_auc: 0.6452\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.80331\n",
      "Epoch 83/100\n",
      "274/274 - 12s - loss: 2.6199 - accuracy: 0.9834 - auc: 0.9980 - val_loss: 4.5036 - val_accuracy: 0.9608 - val_auc: 0.6701\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.80331\n",
      "Epoch 84/100\n",
      "274/274 - 12s - loss: 2.6177 - accuracy: 0.9839 - auc: 0.9976 - val_loss: 4.5432 - val_accuracy: 0.9591 - val_auc: 0.6664\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.80331\n",
      "Epoch 85/100\n",
      "274/274 - 12s - loss: 2.6165 - accuracy: 0.9829 - auc: 0.9977 - val_loss: 4.4206 - val_accuracy: 0.9523 - val_auc: 0.6959\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.80331\n",
      "Epoch 86/100\n",
      "274/274 - 12s - loss: 2.6134 - accuracy: 0.9842 - auc: 0.9980 - val_loss: 4.3151 - val_accuracy: 0.9523 - val_auc: 0.7078\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.80331\n",
      "Epoch 87/100\n",
      "274/274 - 12s - loss: 2.6121 - accuracy: 0.9824 - auc: 0.9980 - val_loss: 4.4264 - val_accuracy: 0.9557 - val_auc: 0.7144\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.80331\n",
      "Epoch 88/100\n",
      "274/274 - 12s - loss: 2.6111 - accuracy: 0.9836 - auc: 0.9980 - val_loss: 4.4771 - val_accuracy: 0.9591 - val_auc: 0.6946\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.80331\n",
      "Epoch 89/100\n",
      "274/274 - 12s - loss: 2.6083 - accuracy: 0.9839 - auc: 0.9980 - val_loss: 4.5152 - val_accuracy: 0.9574 - val_auc: 0.6647\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.80331\n",
      "Epoch 90/100\n",
      "274/274 - 12s - loss: 2.6055 - accuracy: 0.9841 - auc: 0.9981 - val_loss: 4.5145 - val_accuracy: 0.9574 - val_auc: 0.6943\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.80331\n",
      "Epoch 91/100\n",
      "274/274 - 12s - loss: 2.6032 - accuracy: 0.9842 - auc: 0.9983 - val_loss: 4.4727 - val_accuracy: 0.9574 - val_auc: 0.6920\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.80331\n",
      "Epoch 92/100\n",
      "274/274 - 12s - loss: 2.6058 - accuracy: 0.9826 - auc: 0.9977 - val_loss: 4.4656 - val_accuracy: 0.9557 - val_auc: 0.7165\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.80331\n",
      "Epoch 93/100\n",
      "274/274 - 12s - loss: 2.6069 - accuracy: 0.9817 - auc: 0.9978 - val_loss: 4.4163 - val_accuracy: 0.9489 - val_auc: 0.6830\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.80331\n",
      "Epoch 94/100\n",
      "274/274 - 12s - loss: 2.5997 - accuracy: 0.9834 - auc: 0.9979 - val_loss: 4.5487 - val_accuracy: 0.9591 - val_auc: 0.6694\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.80331\n",
      "Epoch 95/100\n",
      "274/274 - 12s - loss: 2.5969 - accuracy: 0.9853 - auc: 0.9982 - val_loss: 4.4670 - val_accuracy: 0.9540 - val_auc: 0.6654\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.80331\n",
      "Epoch 96/100\n",
      "274/274 - 12s - loss: 2.5946 - accuracy: 0.9836 - auc: 0.9985 - val_loss: 4.5188 - val_accuracy: 0.9574 - val_auc: 0.6970\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.80331\n",
      "Epoch 97/100\n",
      "274/274 - 12s - loss: 2.5928 - accuracy: 0.9839 - auc: 0.9983 - val_loss: 4.6026 - val_accuracy: 0.9591 - val_auc: 0.6516\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.80331\n",
      "Epoch 98/100\n",
      "274/274 - 12s - loss: 2.5910 - accuracy: 0.9846 - auc: 0.9982 - val_loss: 4.5835 - val_accuracy: 0.9625 - val_auc: 0.6762\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.80331\n",
      "Epoch 99/100\n",
      "274/274 - 12s - loss: 2.5912 - accuracy: 0.9841 - auc: 0.9981 - val_loss: 4.6624 - val_accuracy: 0.9540 - val_auc: 0.6184\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.80331\n",
      "Epoch 100/100\n",
      "274/274 - 12s - loss: 2.5885 - accuracy: 0.9840 - auc: 0.9981 - val_loss: 4.6077 - val_accuracy: 0.9574 - val_auc: 0.6718\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.80331\n",
      "Epoch 1/100\n",
      "226/226 - 15s - loss: 3.2705 - accuracy: 0.6605 - auc: 0.8110 - val_loss: 3.3264 - val_accuracy: 0.6712 - val_auc: 0.8155\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.81554, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-Aromatase\n",
      "Epoch 2/100\n",
      "226/226 - 10s - loss: 3.1502 - accuracy: 0.7531 - auc: 0.8899 - val_loss: 3.3867 - val_accuracy: 0.7544 - val_auc: 0.8062\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.81554\n",
      "Epoch 3/100\n",
      "226/226 - 10s - loss: 3.0959 - accuracy: 0.8072 - auc: 0.9164 - val_loss: 3.4148 - val_accuracy: 0.7814 - val_auc: 0.8124\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.81554\n",
      "Epoch 4/100\n",
      "226/226 - 10s - loss: 3.0529 - accuracy: 0.8292 - auc: 0.9355 - val_loss: 3.4804 - val_accuracy: 0.8066 - val_auc: 0.8132\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.81554\n",
      "Epoch 5/100\n",
      "226/226 - 10s - loss: 3.0194 - accuracy: 0.8495 - auc: 0.9471 - val_loss: 3.6069 - val_accuracy: 0.8433 - val_auc: 0.8093\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.81554\n",
      "Epoch 6/100\n",
      "226/226 - 10s - loss: 2.9963 - accuracy: 0.8698 - auc: 0.9546 - val_loss: 3.6213 - val_accuracy: 0.8375 - val_auc: 0.8083\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.81554\n",
      "Epoch 7/100\n",
      "226/226 - 10s - loss: 2.9728 - accuracy: 0.8841 - auc: 0.9623 - val_loss: 3.5787 - val_accuracy: 0.8259 - val_auc: 0.8079\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.81554\n",
      "Epoch 8/100\n",
      "226/226 - 10s - loss: 2.9564 - accuracy: 0.8841 - auc: 0.9653 - val_loss: 3.7664 - val_accuracy: 0.8569 - val_auc: 0.7924\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.81554\n",
      "Epoch 9/100\n",
      "226/226 - 10s - loss: 2.9320 - accuracy: 0.8992 - auc: 0.9732 - val_loss: 3.8627 - val_accuracy: 0.8685 - val_auc: 0.8008\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.81554\n",
      "Epoch 10/100\n",
      "226/226 - 10s - loss: 2.9109 - accuracy: 0.9116 - auc: 0.9773 - val_loss: 3.8646 - val_accuracy: 0.8530 - val_auc: 0.7950\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.81554\n",
      "Epoch 11/100\n",
      "226/226 - 9s - loss: 2.8945 - accuracy: 0.9152 - auc: 0.9807 - val_loss: 4.0313 - val_accuracy: 0.8762 - val_auc: 0.8123\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.81554\n",
      "Epoch 12/100\n",
      "226/226 - 9s - loss: 2.8825 - accuracy: 0.9222 - auc: 0.9820 - val_loss: 4.0964 - val_accuracy: 0.8762 - val_auc: 0.8070\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.81554\n",
      "Epoch 13/100\n",
      "226/226 - 9s - loss: 2.8679 - accuracy: 0.9281 - auc: 0.9847 - val_loss: 4.0970 - val_accuracy: 0.8723 - val_auc: 0.8070\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.81554\n",
      "Epoch 14/100\n",
      "226/226 - 9s - loss: 2.8524 - accuracy: 0.9351 - auc: 0.9874 - val_loss: 4.2638 - val_accuracy: 0.8878 - val_auc: 0.8049\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.81554\n",
      "Epoch 15/100\n",
      "226/226 - 9s - loss: 2.8393 - accuracy: 0.9400 - auc: 0.9889 - val_loss: 4.2837 - val_accuracy: 0.8549 - val_auc: 0.7909\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.81554\n",
      "Epoch 16/100\n",
      "226/226 - 9s - loss: 2.8310 - accuracy: 0.9418 - auc: 0.9896 - val_loss: 4.2527 - val_accuracy: 0.8685 - val_auc: 0.8162\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.81554 to 0.81624, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-Aromatase\n",
      "Epoch 17/100\n",
      "226/226 - 10s - loss: 2.8144 - accuracy: 0.9480 - auc: 0.9922 - val_loss: 4.3071 - val_accuracy: 0.8762 - val_auc: 0.8286\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.81624 to 0.82863, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-Aromatase\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "226/226 - 10s - loss: 2.8120 - accuracy: 0.9468 - auc: 0.9919 - val_loss: 4.4703 - val_accuracy: 0.8975 - val_auc: 0.8228\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.82863\n",
      "Epoch 19/100\n",
      "226/226 - 10s - loss: 2.8021 - accuracy: 0.9561 - auc: 0.9926 - val_loss: 4.5627 - val_accuracy: 0.8975 - val_auc: 0.8142\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.82863\n",
      "Epoch 20/100\n",
      "226/226 - 10s - loss: 2.7938 - accuracy: 0.9579 - auc: 0.9935 - val_loss: 4.6355 - val_accuracy: 0.8878 - val_auc: 0.8104\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.82863\n",
      "Epoch 21/100\n",
      "226/226 - 10s - loss: 2.7859 - accuracy: 0.9602 - auc: 0.9942 - val_loss: 4.7060 - val_accuracy: 0.9033 - val_auc: 0.8084\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.82863\n",
      "Epoch 22/100\n",
      "226/226 - 10s - loss: 2.7769 - accuracy: 0.9653 - auc: 0.9949 - val_loss: 4.7073 - val_accuracy: 0.9052 - val_auc: 0.8108\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.82863\n",
      "Epoch 23/100\n",
      "226/226 - 10s - loss: 2.7714 - accuracy: 0.9648 - auc: 0.9952 - val_loss: 4.6570 - val_accuracy: 0.8936 - val_auc: 0.8045\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.82863\n",
      "Epoch 24/100\n",
      "226/226 - 10s - loss: 2.7640 - accuracy: 0.9676 - auc: 0.9961 - val_loss: 4.8098 - val_accuracy: 0.9033 - val_auc: 0.8014\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.82863\n",
      "Epoch 25/100\n",
      "226/226 - 10s - loss: 2.7625 - accuracy: 0.9666 - auc: 0.9955 - val_loss: 4.8680 - val_accuracy: 0.9033 - val_auc: 0.7852\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.82863\n",
      "Epoch 26/100\n",
      "226/226 - 10s - loss: 2.7531 - accuracy: 0.9737 - auc: 0.9966 - val_loss: 4.9057 - val_accuracy: 0.9033 - val_auc: 0.8013\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.82863\n",
      "Epoch 27/100\n",
      "226/226 - 10s - loss: 2.7589 - accuracy: 0.9651 - auc: 0.9955 - val_loss: 5.0752 - val_accuracy: 0.9052 - val_auc: 0.7655\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.82863\n",
      "Epoch 28/100\n",
      "226/226 - 10s - loss: 2.7513 - accuracy: 0.9728 - auc: 0.9962 - val_loss: 5.0441 - val_accuracy: 0.9052 - val_auc: 0.7726\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.82863\n",
      "Epoch 29/100\n",
      "226/226 - 10s - loss: 2.7424 - accuracy: 0.9741 - auc: 0.9967 - val_loss: 4.8794 - val_accuracy: 0.8956 - val_auc: 0.7760\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.82863\n",
      "Epoch 30/100\n",
      "226/226 - 10s - loss: 2.7381 - accuracy: 0.9756 - auc: 0.9968 - val_loss: 4.9654 - val_accuracy: 0.8994 - val_auc: 0.7809\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.82863\n",
      "Epoch 31/100\n",
      "226/226 - 10s - loss: 2.7383 - accuracy: 0.9732 - auc: 0.9969 - val_loss: 5.1234 - val_accuracy: 0.9052 - val_auc: 0.7742\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.82863\n",
      "Epoch 32/100\n",
      "226/226 - 10s - loss: 2.7338 - accuracy: 0.9763 - auc: 0.9968 - val_loss: 5.2062 - val_accuracy: 0.9052 - val_auc: 0.7606\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.82863\n",
      "Epoch 33/100\n",
      "226/226 - 10s - loss: 2.7265 - accuracy: 0.9802 - auc: 0.9972 - val_loss: 5.1993 - val_accuracy: 0.9052 - val_auc: 0.7697\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.82863\n",
      "Epoch 34/100\n",
      "226/226 - 10s - loss: 2.7229 - accuracy: 0.9793 - auc: 0.9976 - val_loss: 5.2641 - val_accuracy: 0.9033 - val_auc: 0.7596\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.82863\n",
      "Epoch 35/100\n",
      "226/226 - 10s - loss: 2.7194 - accuracy: 0.9795 - auc: 0.9977 - val_loss: 5.2310 - val_accuracy: 0.9052 - val_auc: 0.7755\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.82863\n",
      "Epoch 36/100\n",
      "226/226 - 10s - loss: 2.7133 - accuracy: 0.9824 - auc: 0.9980 - val_loss: 5.2743 - val_accuracy: 0.9033 - val_auc: 0.7744\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.82863\n",
      "Epoch 37/100\n",
      "226/226 - 10s - loss: 2.7152 - accuracy: 0.9810 - auc: 0.9978 - val_loss: 5.4022 - val_accuracy: 0.9110 - val_auc: 0.7799\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.82863\n",
      "Epoch 38/100\n",
      "226/226 - 10s - loss: 2.7102 - accuracy: 0.9828 - auc: 0.9977 - val_loss: 5.3703 - val_accuracy: 0.9052 - val_auc: 0.7715\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.82863\n",
      "Epoch 39/100\n",
      "226/226 - 10s - loss: 2.7114 - accuracy: 0.9800 - auc: 0.9977 - val_loss: 5.6089 - val_accuracy: 0.9091 - val_auc: 0.7515\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.82863\n",
      "Epoch 40/100\n",
      "226/226 - 10s - loss: 2.7077 - accuracy: 0.9825 - auc: 0.9977 - val_loss: 5.5765 - val_accuracy: 0.9130 - val_auc: 0.7607\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.82863\n",
      "Epoch 41/100\n",
      "226/226 - 10s - loss: 2.7041 - accuracy: 0.9850 - auc: 0.9980 - val_loss: 5.4126 - val_accuracy: 0.9014 - val_auc: 0.7593\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.82863\n",
      "Epoch 42/100\n",
      "226/226 - 10s - loss: 2.7063 - accuracy: 0.9810 - auc: 0.9976 - val_loss: 5.7532 - val_accuracy: 0.9188 - val_auc: 0.7386\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.82863\n",
      "Epoch 43/100\n",
      "226/226 - 10s - loss: 2.6979 - accuracy: 0.9857 - auc: 0.9980 - val_loss: 5.7365 - val_accuracy: 0.9130 - val_auc: 0.7475\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.82863\n",
      "Epoch 44/100\n",
      "226/226 - 10s - loss: 2.6964 - accuracy: 0.9841 - auc: 0.9982 - val_loss: 5.5290 - val_accuracy: 0.9072 - val_auc: 0.7763\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.82863\n",
      "Epoch 45/100\n",
      "226/226 - 10s - loss: 2.6921 - accuracy: 0.9849 - auc: 0.9984 - val_loss: 5.6715 - val_accuracy: 0.9072 - val_auc: 0.7690\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.82863\n",
      "Epoch 46/100\n",
      "226/226 - 10s - loss: 2.6967 - accuracy: 0.9845 - auc: 0.9981 - val_loss: 5.6127 - val_accuracy: 0.9072 - val_auc: 0.7671\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.82863\n",
      "Epoch 47/100\n",
      "226/226 - 10s - loss: 2.6893 - accuracy: 0.9857 - auc: 0.9984 - val_loss: 5.7833 - val_accuracy: 0.9091 - val_auc: 0.7583\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.82863\n",
      "Epoch 48/100\n",
      "226/226 - 10s - loss: 2.6881 - accuracy: 0.9877 - auc: 0.9984 - val_loss: 5.7634 - val_accuracy: 0.9110 - val_auc: 0.7534\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.82863\n",
      "Epoch 49/100\n",
      "226/226 - 10s - loss: 2.6853 - accuracy: 0.9861 - auc: 0.9981 - val_loss: 5.8742 - val_accuracy: 0.9130 - val_auc: 0.7652\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.82863\n",
      "Epoch 50/100\n",
      "226/226 - 10s - loss: 2.6840 - accuracy: 0.9868 - auc: 0.9981 - val_loss: 5.9440 - val_accuracy: 0.9188 - val_auc: 0.7583\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.82863\n",
      "Epoch 51/100\n",
      "226/226 - 10s - loss: 2.6837 - accuracy: 0.9857 - auc: 0.9982 - val_loss: 5.7238 - val_accuracy: 0.9072 - val_auc: 0.7820\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.82863\n",
      "Epoch 52/100\n",
      "226/226 - 10s - loss: 2.6770 - accuracy: 0.9893 - auc: 0.9986 - val_loss: 5.9172 - val_accuracy: 0.9168 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.82863\n",
      "Epoch 53/100\n",
      "226/226 - 10s - loss: 2.6807 - accuracy: 0.9856 - auc: 0.9985 - val_loss: 5.5804 - val_accuracy: 0.8994 - val_auc: 0.7690\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.82863\n",
      "Epoch 54/100\n",
      "226/226 - 10s - loss: 2.6787 - accuracy: 0.9870 - auc: 0.9984 - val_loss: 5.7541 - val_accuracy: 0.9033 - val_auc: 0.7722\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.82863\n",
      "Epoch 55/100\n",
      "226/226 - 10s - loss: 2.6761 - accuracy: 0.9870 - auc: 0.9985 - val_loss: 5.8900 - val_accuracy: 0.9072 - val_auc: 0.7709\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.82863\n",
      "Epoch 56/100\n",
      "226/226 - 10s - loss: 2.6728 - accuracy: 0.9872 - auc: 0.9988 - val_loss: 5.7713 - val_accuracy: 0.9014 - val_auc: 0.7701\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.82863\n",
      "Epoch 57/100\n",
      "226/226 - 10s - loss: 2.6686 - accuracy: 0.9885 - auc: 0.9986 - val_loss: 6.0263 - val_accuracy: 0.9168 - val_auc: 0.7627\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.82863\n",
      "Epoch 58/100\n",
      "226/226 - 10s - loss: 2.6688 - accuracy: 0.9892 - auc: 0.9987 - val_loss: 5.7712 - val_accuracy: 0.9072 - val_auc: 0.7499\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.82863\n",
      "Epoch 59/100\n",
      "226/226 - 9s - loss: 2.6695 - accuracy: 0.9861 - auc: 0.9985 - val_loss: 5.9523 - val_accuracy: 0.9110 - val_auc: 0.7617\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.82863\n",
      "Epoch 60/100\n",
      "226/226 - 9s - loss: 2.6642 - accuracy: 0.9888 - auc: 0.9986 - val_loss: 5.9092 - val_accuracy: 0.9110 - val_auc: 0.7465\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.82863\n",
      "Epoch 61/100\n",
      "226/226 - 9s - loss: 2.6613 - accuracy: 0.9890 - auc: 0.9989 - val_loss: 5.8852 - val_accuracy: 0.9130 - val_auc: 0.7708\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.82863\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 - 9s - loss: 2.6586 - accuracy: 0.9890 - auc: 0.9986 - val_loss: 6.0945 - val_accuracy: 0.9149 - val_auc: 0.7504\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.82863\n",
      "Epoch 63/100\n",
      "226/226 - 9s - loss: 2.6611 - accuracy: 0.9895 - auc: 0.9985 - val_loss: 6.1136 - val_accuracy: 0.9130 - val_auc: 0.7374\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.82863\n",
      "Epoch 64/100\n",
      "226/226 - 9s - loss: 2.6573 - accuracy: 0.9879 - auc: 0.9988 - val_loss: 5.9486 - val_accuracy: 0.9110 - val_auc: 0.7740\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.82863\n",
      "Epoch 65/100\n",
      "226/226 - 10s - loss: 2.6573 - accuracy: 0.9874 - auc: 0.9986 - val_loss: 6.1152 - val_accuracy: 0.9130 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.82863\n",
      "Epoch 66/100\n",
      "226/226 - 10s - loss: 2.6530 - accuracy: 0.9890 - auc: 0.9990 - val_loss: 6.2742 - val_accuracy: 0.9168 - val_auc: 0.7397\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.82863\n",
      "Epoch 67/100\n",
      "226/226 - 10s - loss: 2.6506 - accuracy: 0.9893 - auc: 0.9989 - val_loss: 6.0436 - val_accuracy: 0.9110 - val_auc: 0.7748\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.82863\n",
      "Epoch 68/100\n",
      "226/226 - 10s - loss: 2.6523 - accuracy: 0.9896 - auc: 0.9986 - val_loss: 5.7300 - val_accuracy: 0.9072 - val_auc: 0.7769\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.82863\n",
      "Epoch 69/100\n",
      "226/226 - 10s - loss: 2.6520 - accuracy: 0.9886 - auc: 0.9984 - val_loss: 6.1966 - val_accuracy: 0.9168 - val_auc: 0.7405\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.82863\n",
      "Epoch 70/100\n",
      "226/226 - 10s - loss: 2.6468 - accuracy: 0.9902 - auc: 0.9986 - val_loss: 6.1755 - val_accuracy: 0.9188 - val_auc: 0.7257\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.82863\n",
      "Epoch 71/100\n",
      "226/226 - 10s - loss: 2.6453 - accuracy: 0.9892 - auc: 0.9991 - val_loss: 5.9747 - val_accuracy: 0.9130 - val_auc: 0.7770\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.82863\n",
      "Epoch 72/100\n",
      "226/226 - 10s - loss: 2.6426 - accuracy: 0.9904 - auc: 0.9988 - val_loss: 6.2757 - val_accuracy: 0.9149 - val_auc: 0.7275\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.82863\n",
      "Epoch 73/100\n",
      "226/226 - 10s - loss: 2.6421 - accuracy: 0.9902 - auc: 0.9987 - val_loss: 6.1685 - val_accuracy: 0.9168 - val_auc: 0.7545\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.82863\n",
      "Epoch 74/100\n",
      "226/226 - 10s - loss: 2.6398 - accuracy: 0.9910 - auc: 0.9990 - val_loss: 6.2787 - val_accuracy: 0.9168 - val_auc: 0.7412\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.82863\n",
      "Epoch 75/100\n",
      "226/226 - 10s - loss: 2.6368 - accuracy: 0.9907 - auc: 0.9991 - val_loss: 6.1798 - val_accuracy: 0.9149 - val_auc: 0.7552\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.82863\n",
      "Epoch 76/100\n",
      "226/226 - 10s - loss: 2.6350 - accuracy: 0.9910 - auc: 0.9991 - val_loss: 6.1385 - val_accuracy: 0.9091 - val_auc: 0.7551\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.82863\n",
      "Epoch 77/100\n",
      "226/226 - 10s - loss: 2.6334 - accuracy: 0.9909 - auc: 0.9991 - val_loss: 6.1604 - val_accuracy: 0.9091 - val_auc: 0.7531\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.82863\n",
      "Epoch 78/100\n",
      "226/226 - 10s - loss: 2.6341 - accuracy: 0.9904 - auc: 0.9988 - val_loss: 6.5241 - val_accuracy: 0.9188 - val_auc: 0.7144\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.82863\n",
      "Epoch 79/100\n",
      "226/226 - 10s - loss: 2.6322 - accuracy: 0.9906 - auc: 0.9987 - val_loss: 6.1765 - val_accuracy: 0.9091 - val_auc: 0.7649\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.82863\n",
      "Epoch 80/100\n",
      "226/226 - 10s - loss: 2.6325 - accuracy: 0.9906 - auc: 0.9987 - val_loss: 6.2711 - val_accuracy: 0.9091 - val_auc: 0.7269\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.82863\n",
      "Epoch 81/100\n",
      "226/226 - 10s - loss: 2.6308 - accuracy: 0.9902 - auc: 0.9988 - val_loss: 6.3670 - val_accuracy: 0.9168 - val_auc: 0.7198\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.82863\n",
      "Epoch 82/100\n",
      "226/226 - 10s - loss: 2.6296 - accuracy: 0.9907 - auc: 0.9990 - val_loss: 6.2125 - val_accuracy: 0.9091 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.82863\n",
      "Epoch 83/100\n",
      "226/226 - 10s - loss: 2.6265 - accuracy: 0.9906 - auc: 0.9988 - val_loss: 6.3001 - val_accuracy: 0.9110 - val_auc: 0.7471\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.82863\n",
      "Epoch 84/100\n",
      "226/226 - 10s - loss: 2.6243 - accuracy: 0.9907 - auc: 0.9991 - val_loss: 6.3641 - val_accuracy: 0.9110 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.82863\n",
      "Epoch 85/100\n",
      "226/226 - 10s - loss: 2.6226 - accuracy: 0.9906 - auc: 0.9991 - val_loss: 6.4047 - val_accuracy: 0.9091 - val_auc: 0.7477\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.82863\n",
      "Epoch 86/100\n",
      "226/226 - 10s - loss: 2.6224 - accuracy: 0.9915 - auc: 0.9991 - val_loss: 6.2410 - val_accuracy: 0.9072 - val_auc: 0.7542\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.82863\n",
      "Epoch 87/100\n",
      "226/226 - 10s - loss: 2.6184 - accuracy: 0.9903 - auc: 0.9991 - val_loss: 6.3626 - val_accuracy: 0.9110 - val_auc: 0.7218\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.82863\n",
      "Epoch 88/100\n",
      "226/226 - 10s - loss: 2.6192 - accuracy: 0.9910 - auc: 0.9989 - val_loss: 6.2949 - val_accuracy: 0.9072 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.82863\n",
      "Epoch 89/100\n",
      "226/226 - 10s - loss: 2.6160 - accuracy: 0.9906 - auc: 0.9991 - val_loss: 6.2516 - val_accuracy: 0.9072 - val_auc: 0.7316\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.82863\n",
      "Epoch 90/100\n",
      "226/226 - 10s - loss: 2.6152 - accuracy: 0.9914 - auc: 0.9988 - val_loss: 6.5000 - val_accuracy: 0.9168 - val_auc: 0.7343\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.82863\n",
      "Epoch 91/100\n",
      "226/226 - 10s - loss: 2.6137 - accuracy: 0.9918 - auc: 0.9990 - val_loss: 6.4152 - val_accuracy: 0.9091 - val_auc: 0.7213\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.82863\n",
      "Epoch 92/100\n",
      "226/226 - 10s - loss: 2.6111 - accuracy: 0.9917 - auc: 0.9990 - val_loss: 6.3107 - val_accuracy: 0.9091 - val_auc: 0.7327\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.82863\n",
      "Epoch 93/100\n",
      "226/226 - 10s - loss: 2.6153 - accuracy: 0.9897 - auc: 0.9990 - val_loss: 6.2154 - val_accuracy: 0.9091 - val_auc: 0.7470\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.82863\n",
      "Epoch 94/100\n",
      "226/226 - 10s - loss: 2.6116 - accuracy: 0.9909 - auc: 0.9986 - val_loss: 6.3806 - val_accuracy: 0.9091 - val_auc: 0.7189\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.82863\n",
      "Epoch 95/100\n",
      "226/226 - 10s - loss: 2.6064 - accuracy: 0.9917 - auc: 0.9993 - val_loss: 6.5135 - val_accuracy: 0.9130 - val_auc: 0.7104\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.82863\n",
      "Epoch 96/100\n",
      "226/226 - 10s - loss: 2.6053 - accuracy: 0.9911 - auc: 0.9990 - val_loss: 6.4598 - val_accuracy: 0.9130 - val_auc: 0.7244\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.82863\n",
      "Epoch 97/100\n",
      "226/226 - 10s - loss: 2.6081 - accuracy: 0.9897 - auc: 0.9988 - val_loss: 6.4519 - val_accuracy: 0.9091 - val_auc: 0.7064\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.82863\n",
      "Epoch 98/100\n",
      "226/226 - 10s - loss: 2.6037 - accuracy: 0.9915 - auc: 0.9991 - val_loss: 6.2595 - val_accuracy: 0.9072 - val_auc: 0.7411\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.82863\n",
      "Epoch 99/100\n",
      "226/226 - 10s - loss: 2.6051 - accuracy: 0.9907 - auc: 0.9988 - val_loss: 6.1841 - val_accuracy: 0.9052 - val_auc: 0.7521\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.82863\n",
      "Epoch 100/100\n",
      "226/226 - 10s - loss: 2.6009 - accuracy: 0.9911 - auc: 0.9988 - val_loss: 6.3665 - val_accuracy: 0.9110 - val_auc: 0.7332\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.82863\n",
      "Epoch 1/100\n",
      "257/257 - 16s - loss: 3.3130 - accuracy: 0.6105 - auc: 0.7654 - val_loss: 3.5789 - val_accuracy: 0.6577 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.75382, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 2/100\n",
      "257/257 - 12s - loss: 3.1713 - accuracy: 0.7693 - auc: 0.8872 - val_loss: 3.5930 - val_accuracy: 0.7454 - val_auc: 0.7764\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.75382 to 0.77641, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 3/100\n",
      "257/257 - 12s - loss: 3.0978 - accuracy: 0.8272 - auc: 0.9224 - val_loss: 3.6461 - val_accuracy: 0.7976 - val_auc: 0.7896\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.77641 to 0.78955, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 4/100\n",
      "257/257 - 12s - loss: 3.0347 - accuracy: 0.8750 - auc: 0.9499 - val_loss: 3.6660 - val_accuracy: 0.8010 - val_auc: 0.7962\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.78955 to 0.79621, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "257/257 - 11s - loss: 2.9890 - accuracy: 0.9002 - auc: 0.9618 - val_loss: 3.8469 - val_accuracy: 0.8364 - val_auc: 0.7851\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.79621\n",
      "Epoch 6/100\n",
      "257/257 - 10s - loss: 2.9455 - accuracy: 0.9183 - auc: 0.9724 - val_loss: 3.9430 - val_accuracy: 0.8465 - val_auc: 0.7922\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.79621\n",
      "Epoch 7/100\n",
      "257/257 - 10s - loss: 2.9160 - accuracy: 0.9325 - auc: 0.9788 - val_loss: 4.0037 - val_accuracy: 0.8583 - val_auc: 0.7962\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.79621 to 0.79624, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 8/100\n",
      "257/257 - 10s - loss: 2.8821 - accuracy: 0.9436 - auc: 0.9843 - val_loss: 4.1513 - val_accuracy: 0.8702 - val_auc: 0.7990\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.79624 to 0.79896, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 9/100\n",
      "257/257 - 10s - loss: 2.8752 - accuracy: 0.9404 - auc: 0.9841 - val_loss: 4.1819 - val_accuracy: 0.8550 - val_auc: 0.7951\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.79896\n",
      "Epoch 10/100\n",
      "257/257 - 11s - loss: 2.8461 - accuracy: 0.9502 - auc: 0.9887 - val_loss: 4.3512 - val_accuracy: 0.8820 - val_auc: 0.7920\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.79896\n",
      "Epoch 11/100\n",
      "257/257 - 12s - loss: 2.8269 - accuracy: 0.9561 - auc: 0.9907 - val_loss: 4.4309 - val_accuracy: 0.8786 - val_auc: 0.7983\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.79896\n",
      "Epoch 12/100\n",
      "257/257 - 12s - loss: 2.8175 - accuracy: 0.9584 - auc: 0.9918 - val_loss: 4.6698 - val_accuracy: 0.8954 - val_auc: 0.7813\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.79896\n",
      "Epoch 13/100\n",
      "257/257 - 12s - loss: 2.8098 - accuracy: 0.9607 - auc: 0.9925 - val_loss: 4.5201 - val_accuracy: 0.8870 - val_auc: 0.7892\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.79896\n",
      "Epoch 14/100\n",
      "257/257 - 12s - loss: 2.7942 - accuracy: 0.9623 - auc: 0.9941 - val_loss: 5.0859 - val_accuracy: 0.9241 - val_auc: 0.7870\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.79896\n",
      "Epoch 15/100\n",
      "257/257 - 12s - loss: 2.7813 - accuracy: 0.9702 - auc: 0.9946 - val_loss: 5.0836 - val_accuracy: 0.9224 - val_auc: 0.7941\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.79896\n",
      "Epoch 16/100\n",
      "257/257 - 12s - loss: 2.7770 - accuracy: 0.9701 - auc: 0.9954 - val_loss: 5.2605 - val_accuracy: 0.9258 - val_auc: 0.7759\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.79896\n",
      "Epoch 17/100\n",
      "257/257 - 12s - loss: 2.7672 - accuracy: 0.9740 - auc: 0.9961 - val_loss: 5.3906 - val_accuracy: 0.9258 - val_auc: 0.7883\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.79896\n",
      "Epoch 18/100\n",
      "257/257 - 12s - loss: 2.7596 - accuracy: 0.9747 - auc: 0.9964 - val_loss: 5.6839 - val_accuracy: 0.9258 - val_auc: 0.7811\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.79896\n",
      "Epoch 19/100\n",
      "257/257 - 12s - loss: 2.7578 - accuracy: 0.9763 - auc: 0.9964 - val_loss: 5.0778 - val_accuracy: 0.9089 - val_auc: 0.7999\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.79896 to 0.79991, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 20/100\n",
      "257/257 - 12s - loss: 2.7512 - accuracy: 0.9765 - auc: 0.9965 - val_loss: 5.9495 - val_accuracy: 0.9292 - val_auc: 0.7685\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.79991\n",
      "Epoch 21/100\n",
      "257/257 - 12s - loss: 2.7433 - accuracy: 0.9806 - auc: 0.9971 - val_loss: 5.8010 - val_accuracy: 0.9325 - val_auc: 0.7964\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.79991\n",
      "Epoch 22/100\n",
      "257/257 - 12s - loss: 2.7422 - accuracy: 0.9799 - auc: 0.9970 - val_loss: 5.5524 - val_accuracy: 0.9309 - val_auc: 0.8045\n",
      "\n",
      "Epoch 00022: val_auc improved from 0.79991 to 0.80450, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_NR-PPAR-gamma\n",
      "Epoch 23/100\n",
      "257/257 - 12s - loss: 2.7326 - accuracy: 0.9824 - auc: 0.9978 - val_loss: 5.8273 - val_accuracy: 0.9224 - val_auc: 0.7905\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.80450\n",
      "Epoch 24/100\n",
      "257/257 - 12s - loss: 2.7277 - accuracy: 0.9832 - auc: 0.9981 - val_loss: 6.1589 - val_accuracy: 0.9292 - val_auc: 0.7824\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.80450\n",
      "Epoch 25/100\n",
      "257/257 - 12s - loss: 2.7234 - accuracy: 0.9843 - auc: 0.9982 - val_loss: 6.0984 - val_accuracy: 0.9275 - val_auc: 0.7801\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.80450\n",
      "Epoch 26/100\n",
      "257/257 - 12s - loss: 2.7191 - accuracy: 0.9855 - auc: 0.9982 - val_loss: 5.9216 - val_accuracy: 0.9241 - val_auc: 0.7973\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.80450\n",
      "Epoch 27/100\n",
      "257/257 - 12s - loss: 2.7172 - accuracy: 0.9869 - auc: 0.9981 - val_loss: 6.2845 - val_accuracy: 0.9359 - val_auc: 0.7615\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.80450\n",
      "Epoch 28/100\n",
      "257/257 - 12s - loss: 2.7121 - accuracy: 0.9869 - auc: 0.9984 - val_loss: 6.3209 - val_accuracy: 0.9325 - val_auc: 0.7688\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.80450\n",
      "Epoch 29/100\n",
      "257/257 - 12s - loss: 2.7084 - accuracy: 0.9868 - auc: 0.9986 - val_loss: 6.4565 - val_accuracy: 0.9376 - val_auc: 0.7645\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.80450\n",
      "Epoch 30/100\n",
      "257/257 - 12s - loss: 2.7057 - accuracy: 0.9890 - auc: 0.9985 - val_loss: 6.4510 - val_accuracy: 0.9275 - val_auc: 0.7644\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.80450\n",
      "Epoch 31/100\n",
      "257/257 - 12s - loss: 2.7064 - accuracy: 0.9873 - auc: 0.9984 - val_loss: 6.3126 - val_accuracy: 0.9241 - val_auc: 0.7487\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.80450\n",
      "Epoch 32/100\n",
      "257/257 - 12s - loss: 2.7031 - accuracy: 0.9885 - auc: 0.9983 - val_loss: 6.7277 - val_accuracy: 0.9342 - val_auc: 0.7581\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.80450\n",
      "Epoch 33/100\n",
      "257/257 - 12s - loss: 2.6954 - accuracy: 0.9899 - auc: 0.9988 - val_loss: 6.8649 - val_accuracy: 0.9342 - val_auc: 0.7590\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.80450\n",
      "Epoch 34/100\n",
      "257/257 - 12s - loss: 2.6967 - accuracy: 0.9898 - auc: 0.9988 - val_loss: 6.7997 - val_accuracy: 0.9325 - val_auc: 0.7571\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.80450\n",
      "Epoch 35/100\n",
      "257/257 - 12s - loss: 2.6960 - accuracy: 0.9877 - auc: 0.9988 - val_loss: 6.6957 - val_accuracy: 0.9292 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.80450\n",
      "Epoch 36/100\n",
      "257/257 - 12s - loss: 2.6912 - accuracy: 0.9902 - auc: 0.9985 - val_loss: 6.8808 - val_accuracy: 0.9292 - val_auc: 0.7604\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.80450\n",
      "Epoch 37/100\n",
      "257/257 - 12s - loss: 2.6904 - accuracy: 0.9909 - auc: 0.9987 - val_loss: 6.7833 - val_accuracy: 0.9292 - val_auc: 0.7687\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.80450\n",
      "Epoch 38/100\n",
      "257/257 - 12s - loss: 2.6849 - accuracy: 0.9900 - auc: 0.9988 - val_loss: 7.0218 - val_accuracy: 0.9309 - val_auc: 0.7355\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.80450\n",
      "Epoch 39/100\n",
      "257/257 - 12s - loss: 2.6849 - accuracy: 0.9919 - auc: 0.9987 - val_loss: 6.6966 - val_accuracy: 0.9292 - val_auc: 0.7469\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.80450\n",
      "Epoch 40/100\n",
      "257/257 - 12s - loss: 2.6814 - accuracy: 0.9913 - auc: 0.9986 - val_loss: 6.8362 - val_accuracy: 0.9359 - val_auc: 0.7530\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.80450\n",
      "Epoch 41/100\n",
      "257/257 - 12s - loss: 2.6801 - accuracy: 0.9916 - auc: 0.9984 - val_loss: 7.0087 - val_accuracy: 0.9325 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.80450\n",
      "Epoch 42/100\n",
      "257/257 - 12s - loss: 2.6786 - accuracy: 0.9921 - auc: 0.9987 - val_loss: 7.2941 - val_accuracy: 0.9342 - val_auc: 0.7231\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.80450\n",
      "Epoch 43/100\n",
      "257/257 - 12s - loss: 2.6742 - accuracy: 0.9921 - auc: 0.9990 - val_loss: 7.1974 - val_accuracy: 0.9359 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.80450\n",
      "Epoch 44/100\n",
      "257/257 - 12s - loss: 2.6721 - accuracy: 0.9926 - auc: 0.9989 - val_loss: 6.9687 - val_accuracy: 0.9342 - val_auc: 0.7538\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.80450\n",
      "Epoch 45/100\n",
      "257/257 - 12s - loss: 2.6695 - accuracy: 0.9937 - auc: 0.9989 - val_loss: 6.9716 - val_accuracy: 0.9342 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.80450\n",
      "Epoch 46/100\n",
      "257/257 - 11s - loss: 2.6736 - accuracy: 0.9913 - auc: 0.9986 - val_loss: 7.2718 - val_accuracy: 0.9325 - val_auc: 0.7247\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.80450\n",
      "Epoch 47/100\n",
      "257/257 - 10s - loss: 2.6667 - accuracy: 0.9934 - auc: 0.9988 - val_loss: 7.4076 - val_accuracy: 0.9359 - val_auc: 0.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_auc did not improve from 0.80450\n",
      "Epoch 48/100\n",
      "257/257 - 10s - loss: 2.6690 - accuracy: 0.9927 - auc: 0.9985 - val_loss: 6.5952 - val_accuracy: 0.9207 - val_auc: 0.7292\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.80450\n",
      "Epoch 49/100\n",
      "257/257 - 10s - loss: 2.6665 - accuracy: 0.9918 - auc: 0.9985 - val_loss: 7.1887 - val_accuracy: 0.9292 - val_auc: 0.7215\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.80450\n",
      "Epoch 50/100\n",
      "257/257 - 10s - loss: 2.6594 - accuracy: 0.9935 - auc: 0.9992 - val_loss: 7.3255 - val_accuracy: 0.9292 - val_auc: 0.7240\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.80450\n",
      "Epoch 51/100\n",
      "257/257 - 11s - loss: 2.6582 - accuracy: 0.9932 - auc: 0.9991 - val_loss: 7.5937 - val_accuracy: 0.9376 - val_auc: 0.7149\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.80450\n",
      "Epoch 52/100\n",
      "257/257 - 12s - loss: 2.6548 - accuracy: 0.9948 - auc: 0.9991 - val_loss: 7.4624 - val_accuracy: 0.9376 - val_auc: 0.7288\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.80450\n",
      "Epoch 53/100\n",
      "257/257 - 12s - loss: 2.6536 - accuracy: 0.9944 - auc: 0.9993 - val_loss: 7.4401 - val_accuracy: 0.9359 - val_auc: 0.7423\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.80450\n",
      "Epoch 54/100\n",
      "257/257 - 12s - loss: 2.6508 - accuracy: 0.9948 - auc: 0.9992 - val_loss: 7.6294 - val_accuracy: 0.9359 - val_auc: 0.7140\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.80450\n",
      "Epoch 55/100\n",
      "257/257 - 12s - loss: 2.6494 - accuracy: 0.9946 - auc: 0.9993 - val_loss: 7.7358 - val_accuracy: 0.9376 - val_auc: 0.6983\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.80450\n",
      "Epoch 56/100\n",
      "257/257 - 12s - loss: 2.6541 - accuracy: 0.9909 - auc: 0.9989 - val_loss: 7.6189 - val_accuracy: 0.9376 - val_auc: 0.7143\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.80450\n",
      "Epoch 57/100\n",
      "257/257 - 12s - loss: 2.6494 - accuracy: 0.9941 - auc: 0.9990 - val_loss: 7.2903 - val_accuracy: 0.9309 - val_auc: 0.7118\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.80450\n",
      "Epoch 58/100\n",
      "257/257 - 12s - loss: 2.6447 - accuracy: 0.9945 - auc: 0.9990 - val_loss: 7.4564 - val_accuracy: 0.9342 - val_auc: 0.7140\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.80450\n",
      "Epoch 59/100\n",
      "257/257 - 12s - loss: 2.6422 - accuracy: 0.9949 - auc: 0.9993 - val_loss: 7.6641 - val_accuracy: 0.9376 - val_auc: 0.7023\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.80450\n",
      "Epoch 60/100\n",
      "257/257 - 12s - loss: 2.6413 - accuracy: 0.9950 - auc: 0.9989 - val_loss: 7.6483 - val_accuracy: 0.9376 - val_auc: 0.7032\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.80450\n",
      "Epoch 61/100\n",
      "257/257 - 12s - loss: 2.6383 - accuracy: 0.9948 - auc: 0.9993 - val_loss: 7.3981 - val_accuracy: 0.9359 - val_auc: 0.7022\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.80450\n",
      "Epoch 62/100\n",
      "257/257 - 12s - loss: 2.6368 - accuracy: 0.9946 - auc: 0.9991 - val_loss: 7.7975 - val_accuracy: 0.9444 - val_auc: 0.7022\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.80450\n",
      "Epoch 63/100\n",
      "257/257 - 12s - loss: 2.6376 - accuracy: 0.9944 - auc: 0.9990 - val_loss: 7.4751 - val_accuracy: 0.9359 - val_auc: 0.7153\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.80450\n",
      "Epoch 64/100\n",
      "257/257 - 12s - loss: 2.6327 - accuracy: 0.9956 - auc: 0.9991 - val_loss: 7.6765 - val_accuracy: 0.9376 - val_auc: 0.7045\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.80450\n",
      "Epoch 65/100\n",
      "257/257 - 12s - loss: 2.6311 - accuracy: 0.9948 - auc: 0.9992 - val_loss: 7.7437 - val_accuracy: 0.9376 - val_auc: 0.7053\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.80450\n",
      "Epoch 66/100\n",
      "257/257 - 12s - loss: 2.6297 - accuracy: 0.9952 - auc: 0.9992 - val_loss: 7.7221 - val_accuracy: 0.9427 - val_auc: 0.7048\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.80450\n",
      "Epoch 67/100\n",
      "257/257 - 12s - loss: 2.6277 - accuracy: 0.9952 - auc: 0.9992 - val_loss: 7.9207 - val_accuracy: 0.9427 - val_auc: 0.7083\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.80450\n",
      "Epoch 68/100\n",
      "257/257 - 12s - loss: 2.6255 - accuracy: 0.9960 - auc: 0.9992 - val_loss: 7.6888 - val_accuracy: 0.9410 - val_auc: 0.7203\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.80450\n",
      "Epoch 69/100\n",
      "257/257 - 12s - loss: 2.6241 - accuracy: 0.9950 - auc: 0.9993 - val_loss: 7.9330 - val_accuracy: 0.9460 - val_auc: 0.7062\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.80450\n",
      "Epoch 70/100\n",
      "257/257 - 12s - loss: 2.6234 - accuracy: 0.9950 - auc: 0.9991 - val_loss: 7.8947 - val_accuracy: 0.9393 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.80450\n",
      "Epoch 71/100\n",
      "257/257 - 12s - loss: 2.6197 - accuracy: 0.9956 - auc: 0.9993 - val_loss: 7.7875 - val_accuracy: 0.9393 - val_auc: 0.7080\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.80450\n",
      "Epoch 72/100\n",
      "257/257 - 12s - loss: 2.6185 - accuracy: 0.9957 - auc: 0.9994 - val_loss: 7.6692 - val_accuracy: 0.9359 - val_auc: 0.7047\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.80450\n",
      "Epoch 73/100\n",
      "257/257 - 12s - loss: 2.6162 - accuracy: 0.9957 - auc: 0.9994 - val_loss: 8.1451 - val_accuracy: 0.9410 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.80450\n",
      "Epoch 74/100\n",
      "257/257 - 12s - loss: 2.6141 - accuracy: 0.9960 - auc: 0.9992 - val_loss: 7.9383 - val_accuracy: 0.9393 - val_auc: 0.7091\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.80450\n",
      "Epoch 75/100\n",
      "257/257 - 12s - loss: 2.6125 - accuracy: 0.9959 - auc: 0.9994 - val_loss: 7.7156 - val_accuracy: 0.9410 - val_auc: 0.7057\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.80450\n",
      "Epoch 76/100\n",
      "257/257 - 12s - loss: 2.6126 - accuracy: 0.9951 - auc: 0.9994 - val_loss: 7.9515 - val_accuracy: 0.9376 - val_auc: 0.7081\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.80450\n",
      "Epoch 77/100\n",
      "257/257 - 12s - loss: 2.6143 - accuracy: 0.9935 - auc: 0.9991 - val_loss: 7.8234 - val_accuracy: 0.9393 - val_auc: 0.7072\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.80450\n",
      "Epoch 78/100\n",
      "257/257 - 12s - loss: 2.6078 - accuracy: 0.9957 - auc: 0.9994 - val_loss: 8.0632 - val_accuracy: 0.9393 - val_auc: 0.7091\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.80450\n",
      "Epoch 79/100\n",
      "257/257 - 12s - loss: 2.6058 - accuracy: 0.9962 - auc: 0.9992 - val_loss: 8.1745 - val_accuracy: 0.9427 - val_auc: 0.7105\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.80450\n",
      "Epoch 80/100\n",
      "257/257 - 12s - loss: 2.6049 - accuracy: 0.9960 - auc: 0.9993 - val_loss: 8.0704 - val_accuracy: 0.9393 - val_auc: 0.7088\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.80450\n",
      "Epoch 81/100\n",
      "257/257 - 12s - loss: 2.6028 - accuracy: 0.9962 - auc: 0.9991 - val_loss: 8.1746 - val_accuracy: 0.9427 - val_auc: 0.7092\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.80450\n",
      "Epoch 82/100\n",
      "257/257 - 12s - loss: 2.6018 - accuracy: 0.9961 - auc: 0.9994 - val_loss: 8.0511 - val_accuracy: 0.9393 - val_auc: 0.7105\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.80450\n",
      "Epoch 83/100\n",
      "257/257 - 12s - loss: 2.5982 - accuracy: 0.9962 - auc: 0.9995 - val_loss: 8.1489 - val_accuracy: 0.9444 - val_auc: 0.7111\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.80450\n",
      "Epoch 84/100\n",
      "257/257 - 12s - loss: 2.5988 - accuracy: 0.9957 - auc: 0.9992 - val_loss: 8.1178 - val_accuracy: 0.9410 - val_auc: 0.7101\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.80450\n",
      "Epoch 85/100\n",
      "257/257 - 12s - loss: 2.5955 - accuracy: 0.9963 - auc: 0.9995 - val_loss: 8.0654 - val_accuracy: 0.9410 - val_auc: 0.7102\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.80450\n",
      "Epoch 86/100\n",
      "257/257 - 12s - loss: 2.5939 - accuracy: 0.9963 - auc: 0.9995 - val_loss: 8.0503 - val_accuracy: 0.9427 - val_auc: 0.7114\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.80450\n",
      "Epoch 87/100\n",
      "257/257 - 12s - loss: 2.5911 - accuracy: 0.9965 - auc: 0.9996 - val_loss: 8.3241 - val_accuracy: 0.9477 - val_auc: 0.7137\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.80450\n",
      "Epoch 88/100\n",
      "257/257 - 11s - loss: 2.5929 - accuracy: 0.9959 - auc: 0.9994 - val_loss: 7.9889 - val_accuracy: 0.9376 - val_auc: 0.7061\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.80450\n",
      "Epoch 89/100\n",
      "257/257 - 10s - loss: 2.5887 - accuracy: 0.9965 - auc: 0.9993 - val_loss: 8.0909 - val_accuracy: 0.9393 - val_auc: 0.7100\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.80450\n",
      "Epoch 90/100\n",
      "257/257 - 10s - loss: 2.5897 - accuracy: 0.9956 - auc: 0.9991 - val_loss: 8.1782 - val_accuracy: 0.9410 - val_auc: 0.7099\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.80450\n",
      "Epoch 91/100\n",
      "257/257 - 10s - loss: 2.5855 - accuracy: 0.9965 - auc: 0.9994 - val_loss: 8.2362 - val_accuracy: 0.9410 - val_auc: 0.7114\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.80450\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 10s - loss: 2.5833 - accuracy: 0.9966 - auc: 0.9995 - val_loss: 8.1241 - val_accuracy: 0.9393 - val_auc: 0.7092\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.80450\n",
      "Epoch 93/100\n",
      "257/257 - 10s - loss: 2.5820 - accuracy: 0.9962 - auc: 0.9995 - val_loss: 7.9147 - val_accuracy: 0.9359 - val_auc: 0.7093\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.80450\n",
      "Epoch 94/100\n",
      "257/257 - 12s - loss: 2.5813 - accuracy: 0.9961 - auc: 0.9994 - val_loss: 8.1372 - val_accuracy: 0.9427 - val_auc: 0.7093\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.80450\n",
      "Epoch 95/100\n",
      "257/257 - 12s - loss: 2.5805 - accuracy: 0.9959 - auc: 0.9995 - val_loss: 8.1911 - val_accuracy: 0.9376 - val_auc: 0.7106\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.80450\n",
      "Epoch 96/100\n",
      "257/257 - 12s - loss: 2.5785 - accuracy: 0.9959 - auc: 0.9995 - val_loss: 8.4887 - val_accuracy: 0.9460 - val_auc: 0.7125\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.80450\n",
      "Epoch 97/100\n",
      "257/257 - 12s - loss: 2.5753 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 8.2554 - val_accuracy: 0.9427 - val_auc: 0.7108\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.80450\n",
      "Epoch 98/100\n",
      "257/257 - 12s - loss: 2.5730 - accuracy: 0.9966 - auc: 0.9995 - val_loss: 8.4093 - val_accuracy: 0.9444 - val_auc: 0.7108\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.80450\n",
      "Epoch 99/100\n",
      "257/257 - 12s - loss: 2.5715 - accuracy: 0.9965 - auc: 0.9995 - val_loss: 8.3922 - val_accuracy: 0.9444 - val_auc: 0.7107\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.80450\n",
      "Epoch 100/100\n",
      "257/257 - 12s - loss: 2.5707 - accuracy: 0.9967 - auc: 0.9997 - val_loss: 8.3060 - val_accuracy: 0.9410 - val_auc: 0.7089\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.80450\n",
      "Epoch 1/100\n",
      "227/227 - 14s - loss: 3.3429 - accuracy: 0.6385 - auc: 0.7247 - val_loss: 3.3456 - val_accuracy: 0.6137 - val_auc: 0.7465\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.74653, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 2/100\n",
      "227/227 - 10s - loss: 3.2728 - accuracy: 0.6819 - auc: 0.8011 - val_loss: 3.3302 - val_accuracy: 0.6543 - val_auc: 0.7567\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.74653 to 0.75674, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 3/100\n",
      "227/227 - 10s - loss: 3.2320 - accuracy: 0.7278 - auc: 0.8352 - val_loss: 3.3096 - val_accuracy: 0.6710 - val_auc: 0.7741\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.75674 to 0.77406, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 4/100\n",
      "227/227 - 10s - loss: 3.2004 - accuracy: 0.7607 - auc: 0.8575 - val_loss: 3.3186 - val_accuracy: 0.7024 - val_auc: 0.7723\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.77406\n",
      "Epoch 5/100\n",
      "227/227 - 10s - loss: 3.1753 - accuracy: 0.7819 - auc: 0.8712 - val_loss: 3.3158 - val_accuracy: 0.7135 - val_auc: 0.7775\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.77406 to 0.77746, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 6/100\n",
      "227/227 - 10s - loss: 3.1506 - accuracy: 0.7980 - auc: 0.8854 - val_loss: 3.3256 - val_accuracy: 0.7283 - val_auc: 0.7815\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.77746 to 0.78151, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 7/100\n",
      "227/227 - 10s - loss: 3.1290 - accuracy: 0.8149 - auc: 0.8961 - val_loss: 3.3143 - val_accuracy: 0.7394 - val_auc: 0.7913\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.78151 to 0.79134, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 8/100\n",
      "227/227 - 10s - loss: 3.1073 - accuracy: 0.8330 - auc: 0.9075 - val_loss: 3.3207 - val_accuracy: 0.7357 - val_auc: 0.7898\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79134\n",
      "Epoch 9/100\n",
      "227/227 - 10s - loss: 3.0891 - accuracy: 0.8402 - auc: 0.9156 - val_loss: 3.3014 - val_accuracy: 0.7449 - val_auc: 0.7960\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.79134 to 0.79600, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ARE\n",
      "Epoch 10/100\n",
      "227/227 - 10s - loss: 3.0752 - accuracy: 0.8461 - auc: 0.9204 - val_loss: 3.3399 - val_accuracy: 0.7338 - val_auc: 0.7848\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.79600\n",
      "Epoch 11/100\n",
      "227/227 - 10s - loss: 3.0519 - accuracy: 0.8533 - auc: 0.9304 - val_loss: 3.3491 - val_accuracy: 0.7671 - val_auc: 0.7918\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.79600\n",
      "Epoch 12/100\n",
      "227/227 - 10s - loss: 3.0319 - accuracy: 0.8669 - auc: 0.9389 - val_loss: 3.3465 - val_accuracy: 0.7597 - val_auc: 0.7909\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.79600\n",
      "Epoch 13/100\n",
      "227/227 - 10s - loss: 3.0206 - accuracy: 0.8753 - auc: 0.9416 - val_loss: 3.3921 - val_accuracy: 0.7616 - val_auc: 0.7824\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.79600\n",
      "Epoch 14/100\n",
      "227/227 - 10s - loss: 3.0032 - accuracy: 0.8771 - auc: 0.9484 - val_loss: 3.3984 - val_accuracy: 0.7782 - val_auc: 0.7859\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.79600\n",
      "Epoch 15/100\n",
      "227/227 - 10s - loss: 2.9867 - accuracy: 0.8829 - auc: 0.9536 - val_loss: 3.4078 - val_accuracy: 0.7652 - val_auc: 0.7835\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.79600\n",
      "Epoch 16/100\n",
      "227/227 - 10s - loss: 2.9792 - accuracy: 0.8878 - auc: 0.9550 - val_loss: 3.4427 - val_accuracy: 0.7652 - val_auc: 0.7713\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.79600\n",
      "Epoch 17/100\n",
      "227/227 - 10s - loss: 2.9620 - accuracy: 0.8893 - auc: 0.9602 - val_loss: 3.4464 - val_accuracy: 0.7930 - val_auc: 0.7838\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.79600\n",
      "Epoch 18/100\n",
      "227/227 - 10s - loss: 2.9519 - accuracy: 0.8988 - auc: 0.9627 - val_loss: 3.4684 - val_accuracy: 0.7874 - val_auc: 0.7733\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.79600\n",
      "Epoch 19/100\n",
      "227/227 - 10s - loss: 2.9411 - accuracy: 0.9012 - auc: 0.9655 - val_loss: 3.5172 - val_accuracy: 0.7782 - val_auc: 0.7672\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.79600\n",
      "Epoch 20/100\n",
      "227/227 - 10s - loss: 2.9269 - accuracy: 0.9066 - auc: 0.9692 - val_loss: 3.5040 - val_accuracy: 0.7893 - val_auc: 0.7726\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.79600\n",
      "Epoch 21/100\n",
      "227/227 - 10s - loss: 2.9180 - accuracy: 0.9108 - auc: 0.9709 - val_loss: 3.5846 - val_accuracy: 0.7985 - val_auc: 0.7676\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.79600\n",
      "Epoch 22/100\n",
      "227/227 - 10s - loss: 2.9057 - accuracy: 0.9150 - auc: 0.9737 - val_loss: 3.6316 - val_accuracy: 0.7948 - val_auc: 0.7534\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.79600\n",
      "Epoch 23/100\n",
      "227/227 - 10s - loss: 2.8973 - accuracy: 0.9161 - auc: 0.9754 - val_loss: 3.6032 - val_accuracy: 0.7819 - val_auc: 0.7671\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.79600\n",
      "Epoch 24/100\n",
      "227/227 - 10s - loss: 2.8866 - accuracy: 0.9200 - auc: 0.9773 - val_loss: 3.6533 - val_accuracy: 0.7745 - val_auc: 0.7585\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.79600\n",
      "Epoch 25/100\n",
      "227/227 - 10s - loss: 2.8737 - accuracy: 0.9265 - auc: 0.9801 - val_loss: 3.6545 - val_accuracy: 0.7967 - val_auc: 0.7663\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.79600\n",
      "Epoch 26/100\n",
      "227/227 - 10s - loss: 2.8696 - accuracy: 0.9274 - auc: 0.9804 - val_loss: 3.6613 - val_accuracy: 0.8059 - val_auc: 0.7614\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.79600\n",
      "Epoch 27/100\n",
      "227/227 - 10s - loss: 2.8573 - accuracy: 0.9302 - auc: 0.9830 - val_loss: 3.7412 - val_accuracy: 0.7930 - val_auc: 0.7502\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.79600\n",
      "Epoch 28/100\n",
      "227/227 - 10s - loss: 2.8502 - accuracy: 0.9325 - auc: 0.9836 - val_loss: 3.7388 - val_accuracy: 0.7856 - val_auc: 0.7557\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.79600\n",
      "Epoch 29/100\n",
      "227/227 - 10s - loss: 2.8404 - accuracy: 0.9367 - auc: 0.9854 - val_loss: 3.7703 - val_accuracy: 0.7800 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.79600\n",
      "Epoch 30/100\n",
      "227/227 - 10s - loss: 2.8400 - accuracy: 0.9365 - auc: 0.9847 - val_loss: 3.7990 - val_accuracy: 0.7893 - val_auc: 0.7558\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.79600\n",
      "Epoch 31/100\n",
      "227/227 - 10s - loss: 2.8249 - accuracy: 0.9446 - auc: 0.9875 - val_loss: 3.7384 - val_accuracy: 0.7800 - val_auc: 0.7504\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.79600\n",
      "Epoch 32/100\n",
      "227/227 - 10s - loss: 2.8219 - accuracy: 0.9419 - auc: 0.9874 - val_loss: 3.8581 - val_accuracy: 0.7930 - val_auc: 0.7393\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.79600\n",
      "Epoch 33/100\n",
      "227/227 - 9s - loss: 2.8195 - accuracy: 0.9462 - auc: 0.9874 - val_loss: 3.8805 - val_accuracy: 0.8004 - val_auc: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_auc did not improve from 0.79600\n",
      "Epoch 34/100\n",
      "227/227 - 9s - loss: 2.8117 - accuracy: 0.9461 - auc: 0.9886 - val_loss: 3.8978 - val_accuracy: 0.7930 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.79600\n",
      "Epoch 35/100\n",
      "227/227 - 9s - loss: 2.8065 - accuracy: 0.9506 - auc: 0.9893 - val_loss: 3.8522 - val_accuracy: 0.7837 - val_auc: 0.7536\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.79600\n",
      "Epoch 36/100\n",
      "227/227 - 9s - loss: 2.8007 - accuracy: 0.9482 - auc: 0.9898 - val_loss: 3.9501 - val_accuracy: 0.7985 - val_auc: 0.7486\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.79600\n",
      "Epoch 37/100\n",
      "227/227 - 9s - loss: 2.7922 - accuracy: 0.9501 - auc: 0.9909 - val_loss: 3.9608 - val_accuracy: 0.7911 - val_auc: 0.7474\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.79600\n",
      "Epoch 38/100\n",
      "227/227 - 10s - loss: 2.7915 - accuracy: 0.9533 - auc: 0.9904 - val_loss: 4.1848 - val_accuracy: 0.7745 - val_auc: 0.7094\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.79600\n",
      "Epoch 39/100\n",
      "227/227 - 10s - loss: 2.7891 - accuracy: 0.9531 - auc: 0.9900 - val_loss: 4.1986 - val_accuracy: 0.7985 - val_auc: 0.7435\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.79600\n",
      "Epoch 40/100\n",
      "227/227 - 10s - loss: 2.7807 - accuracy: 0.9559 - auc: 0.9915 - val_loss: 4.0614 - val_accuracy: 0.7893 - val_auc: 0.7388\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.79600\n",
      "Epoch 41/100\n",
      "227/227 - 10s - loss: 2.7762 - accuracy: 0.9555 - auc: 0.9920 - val_loss: 4.0684 - val_accuracy: 0.8041 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.79600\n",
      "Epoch 42/100\n",
      "227/227 - 10s - loss: 2.7659 - accuracy: 0.9612 - auc: 0.9931 - val_loss: 4.0770 - val_accuracy: 0.8022 - val_auc: 0.7448\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.79600\n",
      "Epoch 43/100\n",
      "227/227 - 10s - loss: 2.7645 - accuracy: 0.9595 - auc: 0.9930 - val_loss: 4.1224 - val_accuracy: 0.7948 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.79600\n",
      "Epoch 44/100\n",
      "227/227 - 10s - loss: 2.7632 - accuracy: 0.9621 - auc: 0.9930 - val_loss: 4.1416 - val_accuracy: 0.7985 - val_auc: 0.7455\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.79600\n",
      "Epoch 45/100\n",
      "227/227 - 10s - loss: 2.7579 - accuracy: 0.9609 - auc: 0.9934 - val_loss: 4.0690 - val_accuracy: 0.7967 - val_auc: 0.7380\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.79600\n",
      "Epoch 46/100\n",
      "227/227 - 10s - loss: 2.7494 - accuracy: 0.9638 - auc: 0.9942 - val_loss: 4.2241 - val_accuracy: 0.8041 - val_auc: 0.7347\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.79600\n",
      "Epoch 47/100\n",
      "227/227 - 10s - loss: 2.7504 - accuracy: 0.9636 - auc: 0.9940 - val_loss: 4.1222 - val_accuracy: 0.8022 - val_auc: 0.7365\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.79600\n",
      "Epoch 48/100\n",
      "227/227 - 10s - loss: 2.7443 - accuracy: 0.9652 - auc: 0.9944 - val_loss: 4.1409 - val_accuracy: 0.7930 - val_auc: 0.7353\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.79600\n",
      "Epoch 49/100\n",
      "227/227 - 10s - loss: 2.7416 - accuracy: 0.9654 - auc: 0.9943 - val_loss: 4.2129 - val_accuracy: 0.7911 - val_auc: 0.7389\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.79600\n",
      "Epoch 50/100\n",
      "227/227 - 10s - loss: 2.7335 - accuracy: 0.9672 - auc: 0.9955 - val_loss: 4.1810 - val_accuracy: 0.8059 - val_auc: 0.7479\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.79600\n",
      "Epoch 51/100\n",
      "227/227 - 10s - loss: 2.7354 - accuracy: 0.9683 - auc: 0.9946 - val_loss: 4.4480 - val_accuracy: 0.8022 - val_auc: 0.7427\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.79600\n",
      "Epoch 52/100\n",
      "227/227 - 10s - loss: 2.7372 - accuracy: 0.9671 - auc: 0.9944 - val_loss: 4.1236 - val_accuracy: 0.8004 - val_auc: 0.7569\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.79600\n",
      "Epoch 53/100\n",
      "227/227 - 10s - loss: 2.7281 - accuracy: 0.9690 - auc: 0.9954 - val_loss: 4.1905 - val_accuracy: 0.8004 - val_auc: 0.7406\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.79600\n",
      "Epoch 54/100\n",
      "227/227 - 10s - loss: 2.7244 - accuracy: 0.9692 - auc: 0.9954 - val_loss: 4.2608 - val_accuracy: 0.8096 - val_auc: 0.7526\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.79600\n",
      "Epoch 55/100\n",
      "227/227 - 10s - loss: 2.7200 - accuracy: 0.9725 - auc: 0.9958 - val_loss: 4.3818 - val_accuracy: 0.8041 - val_auc: 0.7364\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.79600\n",
      "Epoch 56/100\n",
      "227/227 - 10s - loss: 2.7197 - accuracy: 0.9717 - auc: 0.9958 - val_loss: 4.3079 - val_accuracy: 0.8041 - val_auc: 0.7403\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.79600\n",
      "Epoch 57/100\n",
      "227/227 - 10s - loss: 2.7120 - accuracy: 0.9724 - auc: 0.9961 - val_loss: 4.2239 - val_accuracy: 0.8059 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.79600\n",
      "Epoch 58/100\n",
      "227/227 - 10s - loss: 2.7117 - accuracy: 0.9711 - auc: 0.9961 - val_loss: 4.3126 - val_accuracy: 0.7967 - val_auc: 0.7442\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.79600\n",
      "Epoch 59/100\n",
      "227/227 - 10s - loss: 2.7045 - accuracy: 0.9732 - auc: 0.9968 - val_loss: 4.8095 - val_accuracy: 0.7948 - val_auc: 0.7176\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.79600\n",
      "Epoch 60/100\n",
      "227/227 - 10s - loss: 2.7177 - accuracy: 0.9721 - auc: 0.9950 - val_loss: 4.2533 - val_accuracy: 0.8004 - val_auc: 0.7516\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.79600\n",
      "Epoch 61/100\n",
      "227/227 - 10s - loss: 2.7094 - accuracy: 0.9724 - auc: 0.9960 - val_loss: 4.3200 - val_accuracy: 0.7930 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.79600\n",
      "Epoch 62/100\n",
      "227/227 - 10s - loss: 2.7009 - accuracy: 0.9758 - auc: 0.9963 - val_loss: 4.3361 - val_accuracy: 0.8004 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.79600\n",
      "Epoch 63/100\n",
      "227/227 - 10s - loss: 2.6986 - accuracy: 0.9751 - auc: 0.9965 - val_loss: 4.3841 - val_accuracy: 0.8059 - val_auc: 0.7462\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.79600\n",
      "Epoch 64/100\n",
      "227/227 - 10s - loss: 2.6965 - accuracy: 0.9755 - auc: 0.9966 - val_loss: 4.3941 - val_accuracy: 0.8022 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.79600\n",
      "Epoch 65/100\n",
      "227/227 - 10s - loss: 2.6971 - accuracy: 0.9744 - auc: 0.9966 - val_loss: 4.3623 - val_accuracy: 0.8096 - val_auc: 0.7445\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.79600\n",
      "Epoch 66/100\n",
      "227/227 - 10s - loss: 2.6907 - accuracy: 0.9764 - auc: 0.9968 - val_loss: 4.4753 - val_accuracy: 0.8059 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.79600\n",
      "Epoch 67/100\n",
      "227/227 - 10s - loss: 2.6868 - accuracy: 0.9771 - auc: 0.9970 - val_loss: 4.4553 - val_accuracy: 0.7967 - val_auc: 0.7349\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.79600\n",
      "Epoch 68/100\n",
      "227/227 - 10s - loss: 2.6895 - accuracy: 0.9748 - auc: 0.9968 - val_loss: 4.3492 - val_accuracy: 0.7893 - val_auc: 0.7457\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.79600\n",
      "Epoch 69/100\n",
      "227/227 - 10s - loss: 2.6891 - accuracy: 0.9766 - auc: 0.9966 - val_loss: 4.4200 - val_accuracy: 0.7948 - val_auc: 0.7388\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.79600\n",
      "Epoch 70/100\n",
      "227/227 - 10s - loss: 2.6799 - accuracy: 0.9768 - auc: 0.9970 - val_loss: 4.4628 - val_accuracy: 0.8004 - val_auc: 0.7464\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.79600\n",
      "Epoch 71/100\n",
      "227/227 - 10s - loss: 2.6802 - accuracy: 0.9768 - auc: 0.9972 - val_loss: 4.5920 - val_accuracy: 0.8078 - val_auc: 0.7268\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.79600\n",
      "Epoch 72/100\n",
      "227/227 - 10s - loss: 2.6794 - accuracy: 0.9766 - auc: 0.9972 - val_loss: 4.4751 - val_accuracy: 0.8041 - val_auc: 0.7370\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.79600\n",
      "Epoch 73/100\n",
      "227/227 - 10s - loss: 2.6740 - accuracy: 0.9784 - auc: 0.9974 - val_loss: 4.4431 - val_accuracy: 0.8041 - val_auc: 0.7361\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.79600\n",
      "Epoch 74/100\n",
      "227/227 - 10s - loss: 2.6719 - accuracy: 0.9777 - auc: 0.9973 - val_loss: 4.5083 - val_accuracy: 0.8041 - val_auc: 0.7390\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.79600\n",
      "Epoch 75/100\n",
      "227/227 - 10s - loss: 2.6711 - accuracy: 0.9777 - auc: 0.9974 - val_loss: 4.5057 - val_accuracy: 0.8041 - val_auc: 0.7396\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.79600\n",
      "Epoch 76/100\n",
      "227/227 - 10s - loss: 2.6715 - accuracy: 0.9790 - auc: 0.9971 - val_loss: 4.5861 - val_accuracy: 0.8004 - val_auc: 0.7443\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.79600\n",
      "Epoch 77/100\n",
      "227/227 - 10s - loss: 2.6689 - accuracy: 0.9797 - auc: 0.9972 - val_loss: 4.5170 - val_accuracy: 0.8004 - val_auc: 0.7310\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.79600\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 - 10s - loss: 2.6619 - accuracy: 0.9812 - auc: 0.9976 - val_loss: 4.4743 - val_accuracy: 0.7930 - val_auc: 0.7435\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.79600\n",
      "Epoch 79/100\n",
      "227/227 - 10s - loss: 2.6677 - accuracy: 0.9777 - auc: 0.9973 - val_loss: 4.5637 - val_accuracy: 0.7837 - val_auc: 0.7266\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.79600\n",
      "Epoch 80/100\n",
      "227/227 - 9s - loss: 2.6595 - accuracy: 0.9812 - auc: 0.9974 - val_loss: 4.5470 - val_accuracy: 0.7967 - val_auc: 0.7402\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.79600\n",
      "Epoch 81/100\n",
      "227/227 - 9s - loss: 2.6628 - accuracy: 0.9783 - auc: 0.9972 - val_loss: 4.5621 - val_accuracy: 0.8004 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.79600\n",
      "Epoch 82/100\n",
      "227/227 - 9s - loss: 2.6583 - accuracy: 0.9797 - auc: 0.9977 - val_loss: 4.5864 - val_accuracy: 0.8041 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.79600\n",
      "Epoch 83/100\n",
      "227/227 - 9s - loss: 2.6575 - accuracy: 0.9798 - auc: 0.9975 - val_loss: 4.6554 - val_accuracy: 0.8059 - val_auc: 0.7305\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.79600\n",
      "Epoch 84/100\n",
      "227/227 - 9s - loss: 2.6557 - accuracy: 0.9808 - auc: 0.9978 - val_loss: 4.4725 - val_accuracy: 0.8004 - val_auc: 0.7355\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.79600\n",
      "Epoch 85/100\n",
      "227/227 - 9s - loss: 2.6536 - accuracy: 0.9791 - auc: 0.9974 - val_loss: 4.5599 - val_accuracy: 0.7930 - val_auc: 0.7350\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.79600\n",
      "Epoch 86/100\n",
      "227/227 - 10s - loss: 2.6484 - accuracy: 0.9811 - auc: 0.9975 - val_loss: 4.5675 - val_accuracy: 0.8022 - val_auc: 0.7433\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.79600\n",
      "Epoch 87/100\n",
      "227/227 - 10s - loss: 2.6506 - accuracy: 0.9805 - auc: 0.9978 - val_loss: 4.6467 - val_accuracy: 0.8041 - val_auc: 0.7292\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.79600\n",
      "Epoch 88/100\n",
      "227/227 - 10s - loss: 2.6451 - accuracy: 0.9809 - auc: 0.9978 - val_loss: 4.6401 - val_accuracy: 0.8022 - val_auc: 0.7394\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.79600\n",
      "Epoch 89/100\n",
      "227/227 - 10s - loss: 2.6478 - accuracy: 0.9802 - auc: 0.9977 - val_loss: 4.5398 - val_accuracy: 0.8004 - val_auc: 0.7294\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.79600\n",
      "Epoch 90/100\n",
      "227/227 - 10s - loss: 2.6426 - accuracy: 0.9811 - auc: 0.9977 - val_loss: 4.6251 - val_accuracy: 0.8059 - val_auc: 0.7406\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.79600\n",
      "Epoch 91/100\n",
      "227/227 - 11s - loss: 2.6438 - accuracy: 0.9804 - auc: 0.9978 - val_loss: 4.5544 - val_accuracy: 0.8059 - val_auc: 0.7482\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.79600\n",
      "Epoch 92/100\n",
      "227/227 - 10s - loss: 2.6376 - accuracy: 0.9816 - auc: 0.9982 - val_loss: 4.6335 - val_accuracy: 0.8022 - val_auc: 0.7431\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.79600\n",
      "Epoch 93/100\n",
      "227/227 - 10s - loss: 2.6352 - accuracy: 0.9819 - auc: 0.9982 - val_loss: 4.5960 - val_accuracy: 0.8059 - val_auc: 0.7358\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.79600\n",
      "Epoch 94/100\n",
      "227/227 - 10s - loss: 2.6352 - accuracy: 0.9801 - auc: 0.9982 - val_loss: 4.6245 - val_accuracy: 0.7930 - val_auc: 0.7268\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.79600\n",
      "Epoch 95/100\n",
      "227/227 - 10s - loss: 2.6342 - accuracy: 0.9818 - auc: 0.9982 - val_loss: 4.6971 - val_accuracy: 0.8096 - val_auc: 0.7383\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.79600\n",
      "Epoch 96/100\n",
      "227/227 - 10s - loss: 2.6318 - accuracy: 0.9818 - auc: 0.9981 - val_loss: 4.7178 - val_accuracy: 0.8115 - val_auc: 0.7322\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.79600\n",
      "Epoch 97/100\n",
      "227/227 - 10s - loss: 2.6328 - accuracy: 0.9818 - auc: 0.9978 - val_loss: 4.6269 - val_accuracy: 0.8059 - val_auc: 0.7354\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.79600\n",
      "Epoch 98/100\n",
      "227/227 - 10s - loss: 2.6307 - accuracy: 0.9816 - auc: 0.9979 - val_loss: 4.6224 - val_accuracy: 0.8004 - val_auc: 0.7359\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.79600\n",
      "Epoch 99/100\n",
      "227/227 - 10s - loss: 2.6304 - accuracy: 0.9818 - auc: 0.9976 - val_loss: 4.5755 - val_accuracy: 0.8022 - val_auc: 0.7549\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.79600\n",
      "Epoch 100/100\n",
      "227/227 - 10s - loss: 2.6261 - accuracy: 0.9818 - auc: 0.9979 - val_loss: 4.6157 - val_accuracy: 0.8041 - val_auc: 0.7429\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.79600\n",
      "Epoch 1/100\n",
      "284/284 - 17s - loss: 3.3019 - accuracy: 0.6058 - auc: 0.7737 - val_loss: 3.4544 - val_accuracy: 0.6420 - val_auc: 0.7429\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.74295, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ATAD5\n",
      "Epoch 2/100\n",
      "284/284 - 13s - loss: 3.1594 - accuracy: 0.7604 - auc: 0.8899 - val_loss: 3.4724 - val_accuracy: 0.7438 - val_auc: 0.7704\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.74295 to 0.77038, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ATAD5\n",
      "Epoch 3/100\n",
      "284/284 - 13s - loss: 3.0773 - accuracy: 0.8334 - auc: 0.9311 - val_loss: 3.6100 - val_accuracy: 0.7882 - val_auc: 0.7573\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.77038\n",
      "Epoch 4/100\n",
      "284/284 - 13s - loss: 3.0094 - accuracy: 0.8764 - auc: 0.9567 - val_loss: 3.6899 - val_accuracy: 0.8424 - val_auc: 0.7753\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.77038 to 0.77528, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ATAD5\n",
      "Epoch 5/100\n",
      "284/284 - 13s - loss: 2.9707 - accuracy: 0.8957 - auc: 0.9670 - val_loss: 3.8778 - val_accuracy: 0.8276 - val_auc: 0.7618\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.77528\n",
      "Epoch 6/100\n",
      "284/284 - 13s - loss: 2.9322 - accuracy: 0.9120 - auc: 0.9740 - val_loss: 3.7574 - val_accuracy: 0.8161 - val_auc: 0.7853\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.77528 to 0.78527, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-ATAD5\n",
      "Epoch 7/100\n",
      "284/284 - 13s - loss: 2.8979 - accuracy: 0.9209 - auc: 0.9810 - val_loss: 4.1009 - val_accuracy: 0.8506 - val_auc: 0.7531\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.78527\n",
      "Epoch 8/100\n",
      "284/284 - 13s - loss: 2.8735 - accuracy: 0.9320 - auc: 0.9851 - val_loss: 4.3591 - val_accuracy: 0.8834 - val_auc: 0.7498\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78527\n",
      "Epoch 9/100\n",
      "284/284 - 13s - loss: 2.8553 - accuracy: 0.9390 - auc: 0.9873 - val_loss: 4.2991 - val_accuracy: 0.8621 - val_auc: 0.7553\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.78527\n",
      "Epoch 10/100\n",
      "284/284 - 13s - loss: 2.8345 - accuracy: 0.9445 - auc: 0.9896 - val_loss: 4.6137 - val_accuracy: 0.8867 - val_auc: 0.7397\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.78527\n",
      "Epoch 11/100\n",
      "284/284 - 13s - loss: 2.8215 - accuracy: 0.9481 - auc: 0.9910 - val_loss: 4.8865 - val_accuracy: 0.8949 - val_auc: 0.7250\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.78527\n",
      "Epoch 12/100\n",
      "284/284 - 13s - loss: 2.8161 - accuracy: 0.9518 - auc: 0.9913 - val_loss: 4.7676 - val_accuracy: 0.8785 - val_auc: 0.7434\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.78527\n",
      "Epoch 13/100\n",
      "284/284 - 13s - loss: 2.7942 - accuracy: 0.9574 - auc: 0.9933 - val_loss: 5.0979 - val_accuracy: 0.8933 - val_auc: 0.7454\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.78527\n",
      "Epoch 14/100\n",
      "284/284 - 13s - loss: 2.7878 - accuracy: 0.9630 - auc: 0.9939 - val_loss: 5.2480 - val_accuracy: 0.9080 - val_auc: 0.7366\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.78527\n",
      "Epoch 15/100\n",
      "284/284 - 13s - loss: 2.7821 - accuracy: 0.9640 - auc: 0.9937 - val_loss: 5.1755 - val_accuracy: 0.9015 - val_auc: 0.7414\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.78527\n",
      "Epoch 16/100\n",
      "284/284 - 13s - loss: 2.7684 - accuracy: 0.9703 - auc: 0.9951 - val_loss: 5.3353 - val_accuracy: 0.8998 - val_auc: 0.7361\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.78527\n",
      "Epoch 17/100\n",
      "284/284 - 13s - loss: 2.7619 - accuracy: 0.9707 - auc: 0.9956 - val_loss: 5.6072 - val_accuracy: 0.9113 - val_auc: 0.7381\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.78527\n",
      "Epoch 18/100\n",
      "284/284 - 13s - loss: 2.7536 - accuracy: 0.9750 - auc: 0.9962 - val_loss: 5.5664 - val_accuracy: 0.9015 - val_auc: 0.7439\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.78527\n",
      "Epoch 19/100\n",
      "284/284 - 13s - loss: 2.7498 - accuracy: 0.9757 - auc: 0.9960 - val_loss: 5.7058 - val_accuracy: 0.9064 - val_auc: 0.7417\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.78527\n",
      "Epoch 20/100\n",
      "284/284 - 13s - loss: 2.7433 - accuracy: 0.9763 - auc: 0.9964 - val_loss: 6.0153 - val_accuracy: 0.9146 - val_auc: 0.7364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_auc did not improve from 0.78527\n",
      "Epoch 21/100\n",
      "284/284 - 12s - loss: 2.7450 - accuracy: 0.9759 - auc: 0.9962 - val_loss: 5.8168 - val_accuracy: 0.9113 - val_auc: 0.7370\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.78527\n",
      "Epoch 22/100\n",
      "284/284 - 12s - loss: 2.7370 - accuracy: 0.9782 - auc: 0.9965 - val_loss: 5.9367 - val_accuracy: 0.9179 - val_auc: 0.7604\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.78527\n",
      "Epoch 23/100\n",
      "284/284 - 12s - loss: 2.7273 - accuracy: 0.9810 - auc: 0.9975 - val_loss: 6.0781 - val_accuracy: 0.9130 - val_auc: 0.7476\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.78527\n",
      "Epoch 24/100\n",
      "284/284 - 12s - loss: 2.7266 - accuracy: 0.9816 - auc: 0.9974 - val_loss: 6.0531 - val_accuracy: 0.9097 - val_auc: 0.7536\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.78527\n",
      "Epoch 25/100\n",
      "284/284 - 12s - loss: 2.7186 - accuracy: 0.9848 - auc: 0.9977 - val_loss: 6.2590 - val_accuracy: 0.9163 - val_auc: 0.7314\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.78527\n",
      "Epoch 26/100\n",
      "284/284 - 13s - loss: 2.7175 - accuracy: 0.9835 - auc: 0.9979 - val_loss: 6.3463 - val_accuracy: 0.9130 - val_auc: 0.7317\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.78527\n",
      "Epoch 27/100\n",
      "284/284 - 13s - loss: 2.7135 - accuracy: 0.9849 - auc: 0.9976 - val_loss: 6.4160 - val_accuracy: 0.9146 - val_auc: 0.7367\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.78527\n",
      "Epoch 28/100\n",
      "284/284 - 13s - loss: 2.7097 - accuracy: 0.9855 - auc: 0.9980 - val_loss: 6.7078 - val_accuracy: 0.9212 - val_auc: 0.7206\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.78527\n",
      "Epoch 29/100\n",
      "284/284 - 13s - loss: 2.7091 - accuracy: 0.9842 - auc: 0.9978 - val_loss: 6.6880 - val_accuracy: 0.9245 - val_auc: 0.7307\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.78527\n",
      "Epoch 30/100\n",
      "284/284 - 13s - loss: 2.7294 - accuracy: 0.9800 - auc: 0.9945 - val_loss: 6.5663 - val_accuracy: 0.9113 - val_auc: 0.7145\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.78527\n",
      "Epoch 31/100\n",
      "284/284 - 13s - loss: 2.7248 - accuracy: 0.9807 - auc: 0.9958 - val_loss: 6.3286 - val_accuracy: 0.9163 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.78527\n",
      "Epoch 32/100\n",
      "284/284 - 13s - loss: 2.6994 - accuracy: 0.9880 - auc: 0.9982 - val_loss: 6.3601 - val_accuracy: 0.9113 - val_auc: 0.7386\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.78527\n",
      "Epoch 33/100\n",
      "284/284 - 13s - loss: 2.7000 - accuracy: 0.9864 - auc: 0.9982 - val_loss: 6.3893 - val_accuracy: 0.9097 - val_auc: 0.7291\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.78527\n",
      "Epoch 34/100\n",
      "284/284 - 13s - loss: 2.6907 - accuracy: 0.9891 - auc: 0.9985 - val_loss: 6.6895 - val_accuracy: 0.9212 - val_auc: 0.7204\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.78527\n",
      "Epoch 35/100\n",
      "284/284 - 13s - loss: 2.6900 - accuracy: 0.9889 - auc: 0.9982 - val_loss: 6.7047 - val_accuracy: 0.9212 - val_auc: 0.7178\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.78527\n",
      "Epoch 36/100\n",
      "284/284 - 13s - loss: 2.6891 - accuracy: 0.9871 - auc: 0.9984 - val_loss: 6.7133 - val_accuracy: 0.9212 - val_auc: 0.7206\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.78527\n",
      "Epoch 37/100\n",
      "284/284 - 13s - loss: 2.6856 - accuracy: 0.9891 - auc: 0.9984 - val_loss: 6.6390 - val_accuracy: 0.9179 - val_auc: 0.7207\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.78527\n",
      "Epoch 38/100\n",
      "284/284 - 13s - loss: 2.6808 - accuracy: 0.9906 - auc: 0.9985 - val_loss: 6.8385 - val_accuracy: 0.9228 - val_auc: 0.7229\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.78527\n",
      "Epoch 39/100\n",
      "284/284 - 13s - loss: 2.6786 - accuracy: 0.9908 - auc: 0.9987 - val_loss: 6.6448 - val_accuracy: 0.9130 - val_auc: 0.7312\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.78527\n",
      "Epoch 40/100\n",
      "284/284 - 13s - loss: 2.6774 - accuracy: 0.9901 - auc: 0.9987 - val_loss: 6.8445 - val_accuracy: 0.9179 - val_auc: 0.7297\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.78527\n",
      "Epoch 41/100\n",
      "284/284 - 13s - loss: 2.6748 - accuracy: 0.9908 - auc: 0.9986 - val_loss: 6.9829 - val_accuracy: 0.9163 - val_auc: 0.7265\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.78527\n",
      "Epoch 42/100\n",
      "284/284 - 13s - loss: 2.6734 - accuracy: 0.9905 - auc: 0.9984 - val_loss: 6.7714 - val_accuracy: 0.9080 - val_auc: 0.7192\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.78527\n",
      "Epoch 43/100\n",
      "284/284 - 13s - loss: 2.6684 - accuracy: 0.9906 - auc: 0.9988 - val_loss: 7.1205 - val_accuracy: 0.9179 - val_auc: 0.7028\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.78527\n",
      "Epoch 44/100\n",
      "284/284 - 13s - loss: 2.6653 - accuracy: 0.9916 - auc: 0.9990 - val_loss: 7.0156 - val_accuracy: 0.9163 - val_auc: 0.7277\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.78527\n",
      "Epoch 45/100\n",
      "284/284 - 13s - loss: 2.6640 - accuracy: 0.9921 - auc: 0.9989 - val_loss: 7.0681 - val_accuracy: 0.9146 - val_auc: 0.7391\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.78527\n",
      "Epoch 46/100\n",
      "284/284 - 13s - loss: 2.6612 - accuracy: 0.9924 - auc: 0.9990 - val_loss: 6.9622 - val_accuracy: 0.9179 - val_auc: 0.7152\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.78527\n",
      "Epoch 47/100\n",
      "284/284 - 13s - loss: 2.6596 - accuracy: 0.9930 - auc: 0.9990 - val_loss: 6.7609 - val_accuracy: 0.9163 - val_auc: 0.7416\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.78527\n",
      "Epoch 48/100\n",
      "284/284 - 13s - loss: 2.6683 - accuracy: 0.9886 - auc: 0.9980 - val_loss: 6.9865 - val_accuracy: 0.9310 - val_auc: 0.7310\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.78527\n",
      "Epoch 49/100\n",
      "284/284 - 13s - loss: 2.6610 - accuracy: 0.9908 - auc: 0.9986 - val_loss: 7.0100 - val_accuracy: 0.9228 - val_auc: 0.7297\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.78527\n",
      "Epoch 50/100\n",
      "284/284 - 13s - loss: 2.6528 - accuracy: 0.9937 - auc: 0.9989 - val_loss: 7.0298 - val_accuracy: 0.9228 - val_auc: 0.7319\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.78527\n",
      "Epoch 51/100\n",
      "284/284 - 13s - loss: 2.6531 - accuracy: 0.9925 - auc: 0.9986 - val_loss: 7.3444 - val_accuracy: 0.9278 - val_auc: 0.7109\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.78527\n",
      "Epoch 52/100\n",
      "284/284 - 13s - loss: 2.6491 - accuracy: 0.9934 - auc: 0.9988 - val_loss: 7.1763 - val_accuracy: 0.9212 - val_auc: 0.7364\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.78527\n",
      "Epoch 53/100\n",
      "284/284 - 13s - loss: 2.6485 - accuracy: 0.9931 - auc: 0.9988 - val_loss: 7.1321 - val_accuracy: 0.9195 - val_auc: 0.7238\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.78527\n",
      "Epoch 54/100\n",
      "284/284 - 13s - loss: 2.6448 - accuracy: 0.9933 - auc: 0.9989 - val_loss: 7.2470 - val_accuracy: 0.9261 - val_auc: 0.7241\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.78527\n",
      "Epoch 55/100\n",
      "284/284 - 13s - loss: 2.6443 - accuracy: 0.9930 - auc: 0.9988 - val_loss: 7.1791 - val_accuracy: 0.9278 - val_auc: 0.7337\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.78527\n",
      "Epoch 56/100\n",
      "284/284 - 13s - loss: 2.6409 - accuracy: 0.9932 - auc: 0.9991 - val_loss: 7.1828 - val_accuracy: 0.9261 - val_auc: 0.7373\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.78527\n",
      "Epoch 57/100\n",
      "284/284 - 13s - loss: 2.6392 - accuracy: 0.9939 - auc: 0.9991 - val_loss: 7.2449 - val_accuracy: 0.9228 - val_auc: 0.7251\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.78527\n",
      "Epoch 58/100\n",
      "284/284 - 13s - loss: 2.6382 - accuracy: 0.9926 - auc: 0.9991 - val_loss: 7.3973 - val_accuracy: 0.9195 - val_auc: 0.7242\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.78527\n",
      "Epoch 59/100\n",
      "284/284 - 12s - loss: 2.6356 - accuracy: 0.9939 - auc: 0.9989 - val_loss: 7.1680 - val_accuracy: 0.9228 - val_auc: 0.7232\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.78527\n",
      "Epoch 60/100\n",
      "284/284 - 11s - loss: 2.6314 - accuracy: 0.9939 - auc: 0.9993 - val_loss: 7.4847 - val_accuracy: 0.9212 - val_auc: 0.7105\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.78527\n",
      "Epoch 61/100\n",
      "284/284 - 11s - loss: 2.6315 - accuracy: 0.9939 - auc: 0.9991 - val_loss: 7.4959 - val_accuracy: 0.9179 - val_auc: 0.7221\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.78527\n",
      "Epoch 62/100\n",
      "284/284 - 11s - loss: 2.6281 - accuracy: 0.9943 - auc: 0.9991 - val_loss: 7.6216 - val_accuracy: 0.9212 - val_auc: 0.7229\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.78527\n",
      "Epoch 63/100\n",
      "284/284 - 11s - loss: 2.6280 - accuracy: 0.9938 - auc: 0.9992 - val_loss: 7.3468 - val_accuracy: 0.9245 - val_auc: 0.7363\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.78527\n",
      "Epoch 64/100\n",
      "284/284 - 13s - loss: 2.6245 - accuracy: 0.9932 - auc: 0.9993 - val_loss: 7.4580 - val_accuracy: 0.9261 - val_auc: 0.7142\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.78527\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 - 13s - loss: 2.6225 - accuracy: 0.9946 - auc: 0.9992 - val_loss: 7.5676 - val_accuracy: 0.9228 - val_auc: 0.7227\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.78527\n",
      "Epoch 66/100\n",
      "284/284 - 13s - loss: 2.6224 - accuracy: 0.9944 - auc: 0.9990 - val_loss: 7.4872 - val_accuracy: 0.9245 - val_auc: 0.7123\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.78527\n",
      "Epoch 67/100\n",
      "284/284 - 13s - loss: 2.6200 - accuracy: 0.9943 - auc: 0.9990 - val_loss: 7.5128 - val_accuracy: 0.9245 - val_auc: 0.7258\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.78527\n",
      "Epoch 68/100\n",
      "284/284 - 13s - loss: 2.6179 - accuracy: 0.9941 - auc: 0.9990 - val_loss: 7.4982 - val_accuracy: 0.9212 - val_auc: 0.7253\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.78527\n",
      "Epoch 69/100\n",
      "284/284 - 13s - loss: 2.6147 - accuracy: 0.9952 - auc: 0.9992 - val_loss: 7.7623 - val_accuracy: 0.9294 - val_auc: 0.7260\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.78527\n",
      "Epoch 70/100\n",
      "284/284 - 13s - loss: 2.6114 - accuracy: 0.9952 - auc: 0.9993 - val_loss: 7.5514 - val_accuracy: 0.9278 - val_auc: 0.7155\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.78527\n",
      "Epoch 71/100\n",
      "284/284 - 13s - loss: 2.6129 - accuracy: 0.9939 - auc: 0.9990 - val_loss: 7.4975 - val_accuracy: 0.9294 - val_auc: 0.7142\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.78527\n",
      "Epoch 72/100\n",
      "284/284 - 13s - loss: 2.6101 - accuracy: 0.9947 - auc: 0.9991 - val_loss: 7.6089 - val_accuracy: 0.9278 - val_auc: 0.7273\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.78527\n",
      "Epoch 73/100\n",
      "284/284 - 13s - loss: 2.6060 - accuracy: 0.9947 - auc: 0.9994 - val_loss: 7.7923 - val_accuracy: 0.9261 - val_auc: 0.7145\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.78527\n",
      "Epoch 74/100\n",
      "284/284 - 13s - loss: 2.6060 - accuracy: 0.9946 - auc: 0.9993 - val_loss: 7.3977 - val_accuracy: 0.9245 - val_auc: 0.7145\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.78527\n",
      "Epoch 75/100\n",
      "284/284 - 13s - loss: 2.6034 - accuracy: 0.9943 - auc: 0.9994 - val_loss: 7.6932 - val_accuracy: 0.9228 - val_auc: 0.7134\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.78527\n",
      "Epoch 76/100\n",
      "284/284 - 13s - loss: 2.6074 - accuracy: 0.9923 - auc: 0.9992 - val_loss: 7.6442 - val_accuracy: 0.9278 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.78527\n",
      "Epoch 77/100\n",
      "284/284 - 13s - loss: 2.6025 - accuracy: 0.9945 - auc: 0.9990 - val_loss: 7.4139 - val_accuracy: 0.9212 - val_auc: 0.7125\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.78527\n",
      "Epoch 78/100\n",
      "284/284 - 13s - loss: 2.6004 - accuracy: 0.9942 - auc: 0.9992 - val_loss: 7.4384 - val_accuracy: 0.9212 - val_auc: 0.7207\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.78527\n",
      "Epoch 79/100\n",
      "284/284 - 13s - loss: 2.5982 - accuracy: 0.9939 - auc: 0.9992 - val_loss: 7.8176 - val_accuracy: 0.9261 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.78527\n",
      "Epoch 80/100\n",
      "284/284 - 13s - loss: 2.5941 - accuracy: 0.9953 - auc: 0.9993 - val_loss: 7.6477 - val_accuracy: 0.9245 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.78527\n",
      "Epoch 81/100\n",
      "284/284 - 13s - loss: 2.5933 - accuracy: 0.9950 - auc: 0.9993 - val_loss: 7.7026 - val_accuracy: 0.9278 - val_auc: 0.7126\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.78527\n",
      "Epoch 82/100\n",
      "284/284 - 13s - loss: 2.5911 - accuracy: 0.9946 - auc: 0.9993 - val_loss: 7.6884 - val_accuracy: 0.9245 - val_auc: 0.7133\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.78527\n",
      "Epoch 83/100\n",
      "284/284 - 13s - loss: 2.5884 - accuracy: 0.9953 - auc: 0.9994 - val_loss: 7.7407 - val_accuracy: 0.9245 - val_auc: 0.7157\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.78527\n",
      "Epoch 84/100\n",
      "284/284 - 13s - loss: 2.5859 - accuracy: 0.9953 - auc: 0.9994 - val_loss: 7.8100 - val_accuracy: 0.9261 - val_auc: 0.7164\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.78527\n",
      "Epoch 85/100\n",
      "284/284 - 13s - loss: 2.5853 - accuracy: 0.9953 - auc: 0.9993 - val_loss: 7.7599 - val_accuracy: 0.9212 - val_auc: 0.7150\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.78527\n",
      "Epoch 86/100\n",
      "284/284 - 13s - loss: 2.5839 - accuracy: 0.9952 - auc: 0.9992 - val_loss: 7.6479 - val_accuracy: 0.9245 - val_auc: 0.7261\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.78527\n",
      "Epoch 87/100\n",
      "284/284 - 13s - loss: 2.5827 - accuracy: 0.9948 - auc: 0.9992 - val_loss: 7.6626 - val_accuracy: 0.9278 - val_auc: 0.7143\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.78527\n",
      "Epoch 88/100\n",
      "284/284 - 13s - loss: 2.5815 - accuracy: 0.9944 - auc: 0.9992 - val_loss: 7.6755 - val_accuracy: 0.9261 - val_auc: 0.7152\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.78527\n",
      "Epoch 89/100\n",
      "284/284 - 13s - loss: 2.5805 - accuracy: 0.9938 - auc: 0.9992 - val_loss: 7.6716 - val_accuracy: 0.9294 - val_auc: 0.7175\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.78527\n",
      "Epoch 90/100\n",
      "284/284 - 13s - loss: 2.5772 - accuracy: 0.9953 - auc: 0.9992 - val_loss: 7.8201 - val_accuracy: 0.9228 - val_auc: 0.7145\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.78527\n",
      "Epoch 91/100\n",
      "284/284 - 13s - loss: 2.5750 - accuracy: 0.9952 - auc: 0.9993 - val_loss: 7.8639 - val_accuracy: 0.9261 - val_auc: 0.7148\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.78527\n",
      "Epoch 92/100\n",
      "284/284 - 13s - loss: 2.5720 - accuracy: 0.9955 - auc: 0.9994 - val_loss: 7.8036 - val_accuracy: 0.9245 - val_auc: 0.7162\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.78527\n",
      "Epoch 93/100\n",
      "284/284 - 13s - loss: 2.5761 - accuracy: 0.9938 - auc: 0.9989 - val_loss: 7.5585 - val_accuracy: 0.9179 - val_auc: 0.7259\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.78527\n",
      "Epoch 94/100\n",
      "284/284 - 13s - loss: 2.5689 - accuracy: 0.9950 - auc: 0.9994 - val_loss: 7.7965 - val_accuracy: 0.9212 - val_auc: 0.7152\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.78527\n",
      "Epoch 95/100\n",
      "284/284 - 13s - loss: 2.5671 - accuracy: 0.9953 - auc: 0.9994 - val_loss: 7.7767 - val_accuracy: 0.9179 - val_auc: 0.7146\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.78527\n",
      "Epoch 96/100\n",
      "284/284 - 13s - loss: 2.5644 - accuracy: 0.9956 - auc: 0.9995 - val_loss: 7.7805 - val_accuracy: 0.9179 - val_auc: 0.7160\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.78527\n",
      "Epoch 97/100\n",
      "284/284 - 12s - loss: 2.5631 - accuracy: 0.9952 - auc: 0.9994 - val_loss: 7.8088 - val_accuracy: 0.9228 - val_auc: 0.7152\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.78527\n",
      "Epoch 98/100\n",
      "284/284 - 12s - loss: 2.5624 - accuracy: 0.9946 - auc: 0.9994 - val_loss: 7.6774 - val_accuracy: 0.9261 - val_auc: 0.7188\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.78527\n",
      "Epoch 99/100\n",
      "284/284 - 11s - loss: 2.5594 - accuracy: 0.9949 - auc: 0.9994 - val_loss: 7.9375 - val_accuracy: 0.9245 - val_auc: 0.7269\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.78527\n",
      "Epoch 100/100\n",
      "284/284 - 11s - loss: 2.5573 - accuracy: 0.9958 - auc: 0.9994 - val_loss: 7.7918 - val_accuracy: 0.9228 - val_auc: 0.7149\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.78527\n",
      "Epoch 1/100\n",
      "257/257 - 15s - loss: 3.3231 - accuracy: 0.6110 - auc: 0.7460 - val_loss: 3.2280 - val_accuracy: 0.6443 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.73087, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-HSE\n",
      "Epoch 2/100\n",
      "257/257 - 12s - loss: 3.2127 - accuracy: 0.7356 - auc: 0.8503 - val_loss: 3.2187 - val_accuracy: 0.7215 - val_auc: 0.7221\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.73087\n",
      "Epoch 3/100\n",
      "257/257 - 12s - loss: 3.1618 - accuracy: 0.7980 - auc: 0.8835 - val_loss: 3.1965 - val_accuracy: 0.7701 - val_auc: 0.7578\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.73087 to 0.75782, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-HSE\n",
      "Epoch 4/100\n",
      "257/257 - 12s - loss: 3.1118 - accuracy: 0.8438 - auc: 0.9108 - val_loss: 3.1906 - val_accuracy: 0.7819 - val_auc: 0.7649\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.75782 to 0.76494, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-HSE\n",
      "Epoch 5/100\n",
      "257/257 - 12s - loss: 3.0783 - accuracy: 0.8604 - auc: 0.9248 - val_loss: 3.2202 - val_accuracy: 0.8272 - val_auc: 0.7375\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.76494\n",
      "Epoch 6/100\n",
      "257/257 - 12s - loss: 3.0510 - accuracy: 0.8716 - auc: 0.9363 - val_loss: 3.2236 - val_accuracy: 0.8188 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.76494\n",
      "Epoch 7/100\n",
      "257/257 - 12s - loss: 3.0129 - accuracy: 0.8861 - auc: 0.9504 - val_loss: 3.2150 - val_accuracy: 0.8339 - val_auc: 0.7600\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.76494\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 12s - loss: 2.9880 - accuracy: 0.8954 - auc: 0.9595 - val_loss: 3.2581 - val_accuracy: 0.8372 - val_auc: 0.7458\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.76494\n",
      "Epoch 9/100\n",
      "257/257 - 12s - loss: 2.9682 - accuracy: 0.9061 - auc: 0.9639 - val_loss: 3.2908 - val_accuracy: 0.8423 - val_auc: 0.7400\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.76494\n",
      "Epoch 10/100\n",
      "257/257 - 12s - loss: 2.9443 - accuracy: 0.9104 - auc: 0.9707 - val_loss: 3.3064 - val_accuracy: 0.8440 - val_auc: 0.7461\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.76494\n",
      "Epoch 11/100\n",
      "257/257 - 12s - loss: 2.9228 - accuracy: 0.9168 - auc: 0.9756 - val_loss: 3.3252 - val_accuracy: 0.8507 - val_auc: 0.7502\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.76494\n",
      "Epoch 12/100\n",
      "257/257 - 12s - loss: 2.9059 - accuracy: 0.9246 - auc: 0.9786 - val_loss: 3.4090 - val_accuracy: 0.8842 - val_auc: 0.7210\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.76494\n",
      "Epoch 13/100\n",
      "257/257 - 11s - loss: 2.8874 - accuracy: 0.9315 - auc: 0.9822 - val_loss: 3.4562 - val_accuracy: 0.8792 - val_auc: 0.7168\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.76494\n",
      "Epoch 14/100\n",
      "257/257 - 12s - loss: 2.8758 - accuracy: 0.9350 - auc: 0.9839 - val_loss: 3.4080 - val_accuracy: 0.8591 - val_auc: 0.7483\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.76494\n",
      "Epoch 15/100\n",
      "257/257 - 12s - loss: 2.8719 - accuracy: 0.9326 - auc: 0.9837 - val_loss: 3.4645 - val_accuracy: 0.8893 - val_auc: 0.7275\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.76494\n",
      "Epoch 16/100\n",
      "257/257 - 12s - loss: 2.8588 - accuracy: 0.9411 - auc: 0.9855 - val_loss: 3.4871 - val_accuracy: 0.8742 - val_auc: 0.7249\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.76494\n",
      "Epoch 17/100\n",
      "257/257 - 12s - loss: 2.8380 - accuracy: 0.9474 - auc: 0.9893 - val_loss: 3.5242 - val_accuracy: 0.8725 - val_auc: 0.7126\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.76494\n",
      "Epoch 18/100\n",
      "257/257 - 12s - loss: 2.8311 - accuracy: 0.9480 - auc: 0.9898 - val_loss: 3.5649 - val_accuracy: 0.8943 - val_auc: 0.7182\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.76494\n",
      "Epoch 19/100\n",
      "257/257 - 12s - loss: 2.8235 - accuracy: 0.9495 - auc: 0.9906 - val_loss: 3.5735 - val_accuracy: 0.8926 - val_auc: 0.7209\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.76494\n",
      "Epoch 20/100\n",
      "257/257 - 12s - loss: 2.8124 - accuracy: 0.9514 - auc: 0.9916 - val_loss: 3.5949 - val_accuracy: 0.8758 - val_auc: 0.7073\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.76494\n",
      "Epoch 21/100\n",
      "257/257 - 12s - loss: 2.7979 - accuracy: 0.9618 - auc: 0.9933 - val_loss: 3.6129 - val_accuracy: 0.8943 - val_auc: 0.7410\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.76494\n",
      "Epoch 22/100\n",
      "257/257 - 12s - loss: 2.7930 - accuracy: 0.9592 - auc: 0.9936 - val_loss: 3.6289 - val_accuracy: 0.8943 - val_auc: 0.7420\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.76494\n",
      "Epoch 23/100\n",
      "257/257 - 12s - loss: 2.7863 - accuracy: 0.9600 - auc: 0.9941 - val_loss: 3.7213 - val_accuracy: 0.9094 - val_auc: 0.7344\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.76494\n",
      "Epoch 24/100\n",
      "257/257 - 12s - loss: 2.7759 - accuracy: 0.9661 - auc: 0.9947 - val_loss: 3.7915 - val_accuracy: 0.8775 - val_auc: 0.6924\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.76494\n",
      "Epoch 25/100\n",
      "257/257 - 12s - loss: 2.7699 - accuracy: 0.9668 - auc: 0.9952 - val_loss: 3.7568 - val_accuracy: 0.9094 - val_auc: 0.7309\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.76494\n",
      "Epoch 26/100\n",
      "257/257 - 12s - loss: 2.7621 - accuracy: 0.9680 - auc: 0.9959 - val_loss: 3.8488 - val_accuracy: 0.8826 - val_auc: 0.6988\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.76494\n",
      "Epoch 27/100\n",
      "257/257 - 12s - loss: 2.7606 - accuracy: 0.9676 - auc: 0.9956 - val_loss: 3.9484 - val_accuracy: 0.9228 - val_auc: 0.7269\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.76494\n",
      "Epoch 28/100\n",
      "257/257 - 12s - loss: 2.7502 - accuracy: 0.9703 - auc: 0.9966 - val_loss: 3.9932 - val_accuracy: 0.9279 - val_auc: 0.7041\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.76494\n",
      "Epoch 29/100\n",
      "257/257 - 12s - loss: 2.7522 - accuracy: 0.9701 - auc: 0.9957 - val_loss: 3.9076 - val_accuracy: 0.9178 - val_auc: 0.7300\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.76494\n",
      "Epoch 30/100\n",
      "257/257 - 12s - loss: 2.7492 - accuracy: 0.9720 - auc: 0.9958 - val_loss: 3.8977 - val_accuracy: 0.8960 - val_auc: 0.7029\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.76494\n",
      "Epoch 31/100\n",
      "257/257 - 12s - loss: 2.7377 - accuracy: 0.9736 - auc: 0.9967 - val_loss: 4.0771 - val_accuracy: 0.9245 - val_auc: 0.7074\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.76494\n",
      "Epoch 32/100\n",
      "257/257 - 12s - loss: 2.7380 - accuracy: 0.9743 - auc: 0.9963 - val_loss: 4.0466 - val_accuracy: 0.9027 - val_auc: 0.7036\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.76494\n",
      "Epoch 33/100\n",
      "257/257 - 12s - loss: 2.7328 - accuracy: 0.9742 - auc: 0.9963 - val_loss: 4.0883 - val_accuracy: 0.9279 - val_auc: 0.7124\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.76494\n",
      "Epoch 34/100\n",
      "257/257 - 12s - loss: 2.7359 - accuracy: 0.9754 - auc: 0.9961 - val_loss: 4.1120 - val_accuracy: 0.9077 - val_auc: 0.6795\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.76494\n",
      "Epoch 35/100\n",
      "257/257 - 12s - loss: 2.7261 - accuracy: 0.9765 - auc: 0.9969 - val_loss: 4.1635 - val_accuracy: 0.9312 - val_auc: 0.6928\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.76494\n",
      "Epoch 36/100\n",
      "257/257 - 12s - loss: 2.7293 - accuracy: 0.9729 - auc: 0.9965 - val_loss: 4.1790 - val_accuracy: 0.9295 - val_auc: 0.6897\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.76494\n",
      "Epoch 37/100\n",
      "257/257 - 12s - loss: 2.7252 - accuracy: 0.9780 - auc: 0.9965 - val_loss: 4.1271 - val_accuracy: 0.9161 - val_auc: 0.6990\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.76494\n",
      "Epoch 38/100\n",
      "257/257 - 11s - loss: 2.7175 - accuracy: 0.9766 - auc: 0.9971 - val_loss: 4.1495 - val_accuracy: 0.9178 - val_auc: 0.6926\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.76494\n",
      "Epoch 39/100\n",
      "257/257 - 10s - loss: 2.7112 - accuracy: 0.9791 - auc: 0.9975 - val_loss: 4.2476 - val_accuracy: 0.9228 - val_auc: 0.6971\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.76494\n",
      "Epoch 40/100\n",
      "257/257 - 10s - loss: 2.7114 - accuracy: 0.9789 - auc: 0.9971 - val_loss: 4.1518 - val_accuracy: 0.9279 - val_auc: 0.7012\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.76494\n",
      "Epoch 41/100\n",
      "257/257 - 10s - loss: 2.7025 - accuracy: 0.9821 - auc: 0.9977 - val_loss: 4.1812 - val_accuracy: 0.9312 - val_auc: 0.7048\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.76494\n",
      "Epoch 42/100\n",
      "257/257 - 10s - loss: 2.7013 - accuracy: 0.9836 - auc: 0.9978 - val_loss: 4.2584 - val_accuracy: 0.9396 - val_auc: 0.7048\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.76494\n",
      "Epoch 43/100\n",
      "257/257 - 11s - loss: 2.6978 - accuracy: 0.9827 - auc: 0.9977 - val_loss: 4.2558 - val_accuracy: 0.9312 - val_auc: 0.6954\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.76494\n",
      "Epoch 44/100\n",
      "257/257 - 12s - loss: 2.6896 - accuracy: 0.9839 - auc: 0.9981 - val_loss: 4.2985 - val_accuracy: 0.9396 - val_auc: 0.7148\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.76494\n",
      "Epoch 45/100\n",
      "257/257 - 12s - loss: 2.6927 - accuracy: 0.9836 - auc: 0.9983 - val_loss: 4.2771 - val_accuracy: 0.9312 - val_auc: 0.7277\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.76494\n",
      "Epoch 46/100\n",
      "257/257 - 12s - loss: 2.6942 - accuracy: 0.9824 - auc: 0.9976 - val_loss: 4.4016 - val_accuracy: 0.9312 - val_auc: 0.6812\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.76494\n",
      "Epoch 47/100\n",
      "257/257 - 12s - loss: 2.6966 - accuracy: 0.9788 - auc: 0.9974 - val_loss: 4.4315 - val_accuracy: 0.9346 - val_auc: 0.6912\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.76494\n",
      "Epoch 48/100\n",
      "257/257 - 12s - loss: 2.6860 - accuracy: 0.9854 - auc: 0.9980 - val_loss: 4.3581 - val_accuracy: 0.9346 - val_auc: 0.7030\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.76494\n",
      "Epoch 49/100\n",
      "257/257 - 12s - loss: 2.6862 - accuracy: 0.9833 - auc: 0.9979 - val_loss: 4.3054 - val_accuracy: 0.9262 - val_auc: 0.7168\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.76494\n",
      "Epoch 50/100\n",
      "257/257 - 12s - loss: 2.6815 - accuracy: 0.9843 - auc: 0.9978 - val_loss: 4.3904 - val_accuracy: 0.9329 - val_auc: 0.6983\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.76494\n",
      "Epoch 51/100\n",
      "257/257 - 12s - loss: 2.6771 - accuracy: 0.9864 - auc: 0.9980 - val_loss: 4.3163 - val_accuracy: 0.9346 - val_auc: 0.7232\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.76494\n",
      "Epoch 52/100\n",
      "257/257 - 12s - loss: 2.6791 - accuracy: 0.9845 - auc: 0.9979 - val_loss: 4.3633 - val_accuracy: 0.9379 - val_auc: 0.6999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_auc did not improve from 0.76494\n",
      "Epoch 53/100\n",
      "257/257 - 12s - loss: 2.6759 - accuracy: 0.9853 - auc: 0.9981 - val_loss: 4.3249 - val_accuracy: 0.9396 - val_auc: 0.7036\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.76494\n",
      "Epoch 54/100\n",
      "257/257 - 12s - loss: 2.6766 - accuracy: 0.9837 - auc: 0.9976 - val_loss: 4.3822 - val_accuracy: 0.9413 - val_auc: 0.6968\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.76494\n",
      "Epoch 55/100\n",
      "257/257 - 12s - loss: 2.6702 - accuracy: 0.9861 - auc: 0.9981 - val_loss: 4.4825 - val_accuracy: 0.9446 - val_auc: 0.6994\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.76494\n",
      "Epoch 56/100\n",
      "257/257 - 12s - loss: 2.6719 - accuracy: 0.9854 - auc: 0.9979 - val_loss: 4.3460 - val_accuracy: 0.9362 - val_auc: 0.7034\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.76494\n",
      "Epoch 57/100\n",
      "257/257 - 12s - loss: 2.6652 - accuracy: 0.9864 - auc: 0.9983 - val_loss: 4.3446 - val_accuracy: 0.9329 - val_auc: 0.6903\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.76494\n",
      "Epoch 58/100\n",
      "257/257 - 12s - loss: 2.6652 - accuracy: 0.9859 - auc: 0.9983 - val_loss: 4.4222 - val_accuracy: 0.9446 - val_auc: 0.6758\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.76494\n",
      "Epoch 59/100\n",
      "257/257 - 12s - loss: 2.6633 - accuracy: 0.9865 - auc: 0.9981 - val_loss: 4.4446 - val_accuracy: 0.9413 - val_auc: 0.6769\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.76494\n",
      "Epoch 60/100\n",
      "257/257 - 12s - loss: 2.6631 - accuracy: 0.9862 - auc: 0.9981 - val_loss: 4.3886 - val_accuracy: 0.9346 - val_auc: 0.6698\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.76494\n",
      "Epoch 61/100\n",
      "257/257 - 12s - loss: 2.6581 - accuracy: 0.9867 - auc: 0.9983 - val_loss: 4.4922 - val_accuracy: 0.9396 - val_auc: 0.6790\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.76494\n",
      "Epoch 62/100\n",
      "257/257 - 12s - loss: 2.6565 - accuracy: 0.9859 - auc: 0.9982 - val_loss: 4.4750 - val_accuracy: 0.9413 - val_auc: 0.6831\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.76494\n",
      "Epoch 63/100\n",
      "257/257 - 12s - loss: 2.6539 - accuracy: 0.9869 - auc: 0.9986 - val_loss: 4.5602 - val_accuracy: 0.9329 - val_auc: 0.6587\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.76494\n",
      "Epoch 64/100\n",
      "257/257 - 12s - loss: 2.6579 - accuracy: 0.9848 - auc: 0.9981 - val_loss: 4.5440 - val_accuracy: 0.9295 - val_auc: 0.6473\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.76494\n",
      "Epoch 65/100\n",
      "257/257 - 12s - loss: 2.6525 - accuracy: 0.9858 - auc: 0.9982 - val_loss: 4.5423 - val_accuracy: 0.9379 - val_auc: 0.6849\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.76494\n",
      "Epoch 66/100\n",
      "257/257 - 12s - loss: 2.6471 - accuracy: 0.9870 - auc: 0.9986 - val_loss: 4.5461 - val_accuracy: 0.9430 - val_auc: 0.6799\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.76494\n",
      "Epoch 67/100\n",
      "257/257 - 12s - loss: 2.6490 - accuracy: 0.9867 - auc: 0.9983 - val_loss: 4.4813 - val_accuracy: 0.9379 - val_auc: 0.7092\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.76494\n",
      "Epoch 68/100\n",
      "257/257 - 12s - loss: 2.6451 - accuracy: 0.9882 - auc: 0.9984 - val_loss: 4.5937 - val_accuracy: 0.9379 - val_auc: 0.6879\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.76494\n",
      "Epoch 69/100\n",
      "257/257 - 12s - loss: 2.6422 - accuracy: 0.9886 - auc: 0.9983 - val_loss: 4.5193 - val_accuracy: 0.9379 - val_auc: 0.6855\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.76494\n",
      "Epoch 70/100\n",
      "257/257 - 12s - loss: 2.6410 - accuracy: 0.9882 - auc: 0.9984 - val_loss: 4.6125 - val_accuracy: 0.9446 - val_auc: 0.6654\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.76494\n",
      "Epoch 71/100\n",
      "257/257 - 12s - loss: 2.6402 - accuracy: 0.9877 - auc: 0.9986 - val_loss: 4.4864 - val_accuracy: 0.9379 - val_auc: 0.7139\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.76494\n",
      "Epoch 72/100\n",
      "257/257 - 12s - loss: 2.6373 - accuracy: 0.9878 - auc: 0.9986 - val_loss: 4.5586 - val_accuracy: 0.9413 - val_auc: 0.6890\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.76494\n",
      "Epoch 73/100\n",
      "257/257 - 12s - loss: 2.6347 - accuracy: 0.9873 - auc: 0.9986 - val_loss: 4.5982 - val_accuracy: 0.9446 - val_auc: 0.6991\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.76494\n",
      "Epoch 74/100\n",
      "257/257 - 12s - loss: 2.6333 - accuracy: 0.9882 - auc: 0.9987 - val_loss: 4.5112 - val_accuracy: 0.9379 - val_auc: 0.6890\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.76494\n",
      "Epoch 75/100\n",
      "257/257 - 12s - loss: 2.6328 - accuracy: 0.9878 - auc: 0.9985 - val_loss: 4.5154 - val_accuracy: 0.9379 - val_auc: 0.7141\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.76494\n",
      "Epoch 76/100\n",
      "257/257 - 12s - loss: 2.6281 - accuracy: 0.9884 - auc: 0.9988 - val_loss: 4.5189 - val_accuracy: 0.9362 - val_auc: 0.6874\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.76494\n",
      "Epoch 77/100\n",
      "257/257 - 12s - loss: 2.6278 - accuracy: 0.9884 - auc: 0.9985 - val_loss: 4.5724 - val_accuracy: 0.9396 - val_auc: 0.6876\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.76494\n",
      "Epoch 78/100\n",
      "257/257 - 12s - loss: 2.6286 - accuracy: 0.9871 - auc: 0.9984 - val_loss: 4.6935 - val_accuracy: 0.9413 - val_auc: 0.6682\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.76494\n",
      "Epoch 79/100\n",
      "257/257 - 12s - loss: 2.6280 - accuracy: 0.9876 - auc: 0.9984 - val_loss: 4.5717 - val_accuracy: 0.9362 - val_auc: 0.6632\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.76494\n",
      "Epoch 80/100\n",
      "257/257 - 10s - loss: 2.6245 - accuracy: 0.9886 - auc: 0.9983 - val_loss: 4.6004 - val_accuracy: 0.9362 - val_auc: 0.6949\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.76494\n",
      "Epoch 81/100\n",
      "257/257 - 10s - loss: 2.6218 - accuracy: 0.9880 - auc: 0.9984 - val_loss: 4.5908 - val_accuracy: 0.9413 - val_auc: 0.6911\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.76494\n",
      "Epoch 82/100\n",
      "257/257 - 10s - loss: 2.6229 - accuracy: 0.9877 - auc: 0.9985 - val_loss: 4.5642 - val_accuracy: 0.9346 - val_auc: 0.6591\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.76494\n",
      "Epoch 83/100\n",
      "257/257 - 10s - loss: 2.6207 - accuracy: 0.9881 - auc: 0.9984 - val_loss: 4.6095 - val_accuracy: 0.9396 - val_auc: 0.6680\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.76494\n",
      "Epoch 84/100\n",
      "257/257 - 10s - loss: 2.6190 - accuracy: 0.9877 - auc: 0.9983 - val_loss: 4.5899 - val_accuracy: 0.9396 - val_auc: 0.6916\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.76494\n",
      "Epoch 85/100\n",
      "257/257 - 11s - loss: 2.6143 - accuracy: 0.9894 - auc: 0.9985 - val_loss: 4.6411 - val_accuracy: 0.9430 - val_auc: 0.6946\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.76494\n",
      "Epoch 86/100\n",
      "257/257 - 12s - loss: 2.6138 - accuracy: 0.9889 - auc: 0.9987 - val_loss: 4.6740 - val_accuracy: 0.9379 - val_auc: 0.6641\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.76494\n",
      "Epoch 87/100\n",
      "257/257 - 12s - loss: 2.6126 - accuracy: 0.9882 - auc: 0.9987 - val_loss: 4.5933 - val_accuracy: 0.9430 - val_auc: 0.6443\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.76494\n",
      "Epoch 88/100\n",
      "257/257 - 12s - loss: 2.6113 - accuracy: 0.9881 - auc: 0.9985 - val_loss: 4.6431 - val_accuracy: 0.9396 - val_auc: 0.6708\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.76494\n",
      "Epoch 89/100\n",
      "257/257 - 12s - loss: 2.6084 - accuracy: 0.9875 - auc: 0.9987 - val_loss: 4.5430 - val_accuracy: 0.9379 - val_auc: 0.7003\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.76494\n",
      "Epoch 90/100\n",
      "257/257 - 12s - loss: 2.6058 - accuracy: 0.9886 - auc: 0.9986 - val_loss: 4.5218 - val_accuracy: 0.9379 - val_auc: 0.6965\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.76494\n",
      "Epoch 91/100\n",
      "257/257 - 12s - loss: 2.6055 - accuracy: 0.9884 - auc: 0.9986 - val_loss: 4.6464 - val_accuracy: 0.9413 - val_auc: 0.6677\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.76494\n",
      "Epoch 92/100\n",
      "257/257 - 12s - loss: 2.6025 - accuracy: 0.9887 - auc: 0.9987 - val_loss: 4.6293 - val_accuracy: 0.9446 - val_auc: 0.6947\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.76494\n",
      "Epoch 93/100\n",
      "257/257 - 12s - loss: 2.6001 - accuracy: 0.9897 - auc: 0.9987 - val_loss: 4.5759 - val_accuracy: 0.9430 - val_auc: 0.6949\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.76494\n",
      "Epoch 94/100\n",
      "257/257 - 12s - loss: 2.5975 - accuracy: 0.9899 - auc: 0.9988 - val_loss: 4.6653 - val_accuracy: 0.9430 - val_auc: 0.6740\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.76494\n",
      "Epoch 95/100\n",
      "257/257 - 12s - loss: 2.5998 - accuracy: 0.9889 - auc: 0.9985 - val_loss: 4.4699 - val_accuracy: 0.9329 - val_auc: 0.7130\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.76494\n",
      "Epoch 96/100\n",
      "257/257 - 12s - loss: 2.5968 - accuracy: 0.9888 - auc: 0.9987 - val_loss: 4.5990 - val_accuracy: 0.9446 - val_auc: 0.6744\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.76494\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 - 12s - loss: 2.5940 - accuracy: 0.9892 - auc: 0.9989 - val_loss: 4.5593 - val_accuracy: 0.9413 - val_auc: 0.6945\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.76494\n",
      "Epoch 98/100\n",
      "257/257 - 12s - loss: 2.5915 - accuracy: 0.9898 - auc: 0.9989 - val_loss: 4.6327 - val_accuracy: 0.9413 - val_auc: 0.6958\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.76494\n",
      "Epoch 99/100\n",
      "257/257 - 12s - loss: 2.5910 - accuracy: 0.9897 - auc: 0.9986 - val_loss: 4.6482 - val_accuracy: 0.9430 - val_auc: 0.6705\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.76494\n",
      "Epoch 100/100\n",
      "257/257 - 12s - loss: 2.5893 - accuracy: 0.9878 - auc: 0.9989 - val_loss: 4.6667 - val_accuracy: 0.9446 - val_auc: 0.6766\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.76494\n",
      "Epoch 1/100\n",
      "230/230 - 14s - loss: 3.2523 - accuracy: 0.7003 - auc: 0.8253 - val_loss: 3.1149 - val_accuracy: 0.7665 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.90295, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 2/100\n",
      "230/230 - 10s - loss: 3.1437 - accuracy: 0.7824 - auc: 0.8986 - val_loss: 3.0707 - val_accuracy: 0.7985 - val_auc: 0.9199\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.90295 to 0.91990, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 3/100\n",
      "230/230 - 11s - loss: 3.0913 - accuracy: 0.8186 - auc: 0.9225 - val_loss: 3.0502 - val_accuracy: 0.8230 - val_auc: 0.9189\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.91990\n",
      "Epoch 4/100\n",
      "230/230 - 11s - loss: 3.0524 - accuracy: 0.8484 - auc: 0.9375 - val_loss: 3.0348 - val_accuracy: 0.8362 - val_auc: 0.9265\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.91990 to 0.92651, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 5/100\n",
      "230/230 - 11s - loss: 3.0208 - accuracy: 0.8681 - auc: 0.9476 - val_loss: 3.0332 - val_accuracy: 0.8267 - val_auc: 0.9267\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.92651 to 0.92666, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 6/100\n",
      "230/230 - 11s - loss: 2.9965 - accuracy: 0.8813 - auc: 0.9550 - val_loss: 3.0147 - val_accuracy: 0.8512 - val_auc: 0.9314\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.92666 to 0.93138, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 7/100\n",
      "230/230 - 11s - loss: 2.9750 - accuracy: 0.8888 - auc: 0.9608 - val_loss: 3.0161 - val_accuracy: 0.8644 - val_auc: 0.9271\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.93138\n",
      "Epoch 8/100\n",
      "230/230 - 11s - loss: 2.9590 - accuracy: 0.8984 - auc: 0.9646 - val_loss: 3.0041 - val_accuracy: 0.8814 - val_auc: 0.9325\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.93138 to 0.93249, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 9/100\n",
      "230/230 - 11s - loss: 2.9425 - accuracy: 0.9052 - auc: 0.9691 - val_loss: 3.0110 - val_accuracy: 0.8701 - val_auc: 0.9308\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.93249\n",
      "Epoch 10/100\n",
      "230/230 - 11s - loss: 2.9306 - accuracy: 0.9078 - auc: 0.9712 - val_loss: 3.0018 - val_accuracy: 0.8832 - val_auc: 0.9337\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.93249 to 0.93371, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 11/100\n",
      "230/230 - 10s - loss: 2.9129 - accuracy: 0.9176 - auc: 0.9756 - val_loss: 3.0048 - val_accuracy: 0.8719 - val_auc: 0.9353\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.93371 to 0.93530, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 12/100\n",
      "230/230 - 11s - loss: 2.9039 - accuracy: 0.9197 - auc: 0.9771 - val_loss: 3.0098 - val_accuracy: 0.8795 - val_auc: 0.9320\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.93530\n",
      "Epoch 13/100\n",
      "230/230 - 11s - loss: 2.8905 - accuracy: 0.9233 - auc: 0.9799 - val_loss: 3.0111 - val_accuracy: 0.8795 - val_auc: 0.9327\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.93530\n",
      "Epoch 14/100\n",
      "230/230 - 11s - loss: 2.8810 - accuracy: 0.9274 - auc: 0.9812 - val_loss: 3.0115 - val_accuracy: 0.8738 - val_auc: 0.9313\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.93530\n",
      "Epoch 15/100\n",
      "230/230 - 11s - loss: 2.8712 - accuracy: 0.9277 - auc: 0.9829 - val_loss: 3.0094 - val_accuracy: 0.8757 - val_auc: 0.9358\n",
      "\n",
      "Epoch 00015: val_auc improved from 0.93530 to 0.93581, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-MMP\n",
      "Epoch 16/100\n",
      "230/230 - 11s - loss: 2.8681 - accuracy: 0.9291 - auc: 0.9831 - val_loss: 3.0086 - val_accuracy: 0.8757 - val_auc: 0.9346\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.93581\n",
      "Epoch 17/100\n",
      "230/230 - 11s - loss: 2.8516 - accuracy: 0.9390 - auc: 0.9859 - val_loss: 3.0212 - val_accuracy: 0.8776 - val_auc: 0.9342\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.93581\n",
      "Epoch 18/100\n",
      "230/230 - 11s - loss: 2.8390 - accuracy: 0.9447 - auc: 0.9881 - val_loss: 3.0326 - val_accuracy: 0.8757 - val_auc: 0.9264\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.93581\n",
      "Epoch 19/100\n",
      "230/230 - 11s - loss: 2.8349 - accuracy: 0.9457 - auc: 0.9883 - val_loss: 3.0250 - val_accuracy: 0.8757 - val_auc: 0.9308\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.93581\n",
      "Epoch 20/100\n",
      "230/230 - 10s - loss: 2.8292 - accuracy: 0.9428 - auc: 0.9889 - val_loss: 3.0312 - val_accuracy: 0.8795 - val_auc: 0.9277\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.93581\n",
      "Epoch 21/100\n",
      "230/230 - 11s - loss: 2.8181 - accuracy: 0.9508 - auc: 0.9904 - val_loss: 3.0440 - val_accuracy: 0.8795 - val_auc: 0.9262\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.93581\n",
      "Epoch 22/100\n",
      "230/230 - 10s - loss: 2.8113 - accuracy: 0.9502 - auc: 0.9912 - val_loss: 3.0365 - val_accuracy: 0.8814 - val_auc: 0.9292\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.93581\n",
      "Epoch 23/100\n",
      "230/230 - 9s - loss: 2.8085 - accuracy: 0.9492 - auc: 0.9912 - val_loss: 3.0530 - val_accuracy: 0.8832 - val_auc: 0.9268\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.93581\n",
      "Epoch 24/100\n",
      "230/230 - 9s - loss: 2.8016 - accuracy: 0.9556 - auc: 0.9918 - val_loss: 3.0426 - val_accuracy: 0.8889 - val_auc: 0.9305\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.93581\n",
      "Epoch 25/100\n",
      "230/230 - 9s - loss: 2.7945 - accuracy: 0.9578 - auc: 0.9928 - val_loss: 3.0437 - val_accuracy: 0.8814 - val_auc: 0.9267\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.93581\n",
      "Epoch 26/100\n",
      "230/230 - 9s - loss: 2.7897 - accuracy: 0.9586 - auc: 0.9930 - val_loss: 3.0626 - val_accuracy: 0.8964 - val_auc: 0.9262\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.93581\n",
      "Epoch 27/100\n",
      "230/230 - 9s - loss: 2.7852 - accuracy: 0.9592 - auc: 0.9931 - val_loss: 3.0714 - val_accuracy: 0.8814 - val_auc: 0.9246\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.93581\n",
      "Epoch 28/100\n",
      "230/230 - 10s - loss: 2.7785 - accuracy: 0.9602 - auc: 0.9938 - val_loss: 3.0925 - val_accuracy: 0.8945 - val_auc: 0.9217\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.93581\n",
      "Epoch 29/100\n",
      "230/230 - 11s - loss: 2.7725 - accuracy: 0.9635 - auc: 0.9945 - val_loss: 3.0652 - val_accuracy: 0.9040 - val_auc: 0.9294\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.93581\n",
      "Epoch 30/100\n",
      "230/230 - 10s - loss: 2.7704 - accuracy: 0.9643 - auc: 0.9943 - val_loss: 3.0885 - val_accuracy: 0.8945 - val_auc: 0.9240\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.93581\n",
      "Epoch 31/100\n",
      "230/230 - 11s - loss: 2.7642 - accuracy: 0.9681 - auc: 0.9947 - val_loss: 3.0797 - val_accuracy: 0.8945 - val_auc: 0.9271\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.93581\n",
      "Epoch 32/100\n",
      "230/230 - 11s - loss: 2.7617 - accuracy: 0.9656 - auc: 0.9948 - val_loss: 3.0950 - val_accuracy: 0.8889 - val_auc: 0.9256\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.93581\n",
      "Epoch 33/100\n",
      "230/230 - 10s - loss: 2.7584 - accuracy: 0.9683 - auc: 0.9952 - val_loss: 3.1233 - val_accuracy: 0.8927 - val_auc: 0.9206\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.93581\n",
      "Epoch 34/100\n",
      "230/230 - 10s - loss: 2.7526 - accuracy: 0.9710 - auc: 0.9954 - val_loss: 3.1097 - val_accuracy: 0.9021 - val_auc: 0.9239\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.93581\n",
      "Epoch 35/100\n",
      "230/230 - 10s - loss: 2.7480 - accuracy: 0.9724 - auc: 0.9958 - val_loss: 3.1158 - val_accuracy: 0.8964 - val_auc: 0.9221\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.93581\n",
      "Epoch 36/100\n",
      "230/230 - 11s - loss: 2.7422 - accuracy: 0.9715 - auc: 0.9963 - val_loss: 3.1043 - val_accuracy: 0.9171 - val_auc: 0.9274\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.93581\n",
      "Epoch 37/100\n",
      "230/230 - 11s - loss: 2.7411 - accuracy: 0.9721 - auc: 0.9960 - val_loss: 3.1274 - val_accuracy: 0.8945 - val_auc: 0.9228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00037: val_auc did not improve from 0.93581\n",
      "Epoch 38/100\n",
      "230/230 - 11s - loss: 2.7404 - accuracy: 0.9717 - auc: 0.9961 - val_loss: 3.1386 - val_accuracy: 0.9021 - val_auc: 0.9160\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.93581\n",
      "Epoch 39/100\n",
      "230/230 - 11s - loss: 2.7298 - accuracy: 0.9744 - auc: 0.9970 - val_loss: 3.1307 - val_accuracy: 0.9002 - val_auc: 0.9193\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.93581\n",
      "Epoch 40/100\n",
      "230/230 - 11s - loss: 2.7288 - accuracy: 0.9747 - auc: 0.9968 - val_loss: 3.1063 - val_accuracy: 0.9058 - val_auc: 0.9288\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.93581\n",
      "Epoch 41/100\n",
      "230/230 - 11s - loss: 2.7266 - accuracy: 0.9744 - auc: 0.9969 - val_loss: 3.1264 - val_accuracy: 0.9021 - val_auc: 0.9158\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.93581\n",
      "Epoch 42/100\n",
      "230/230 - 11s - loss: 2.7202 - accuracy: 0.9773 - auc: 0.9972 - val_loss: 3.1108 - val_accuracy: 0.9077 - val_auc: 0.9257\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.93581\n",
      "Epoch 43/100\n",
      "230/230 - 11s - loss: 2.7213 - accuracy: 0.9766 - auc: 0.9968 - val_loss: 3.1343 - val_accuracy: 0.9134 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.93581\n",
      "Epoch 44/100\n",
      "230/230 - 11s - loss: 2.7175 - accuracy: 0.9773 - auc: 0.9973 - val_loss: 3.1300 - val_accuracy: 0.9096 - val_auc: 0.9210\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.93581\n",
      "Epoch 45/100\n",
      "230/230 - 11s - loss: 2.7157 - accuracy: 0.9783 - auc: 0.9972 - val_loss: 3.1611 - val_accuracy: 0.9096 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.93581\n",
      "Epoch 46/100\n",
      "230/230 - 11s - loss: 2.7130 - accuracy: 0.9775 - auc: 0.9972 - val_loss: 3.1541 - val_accuracy: 0.8983 - val_auc: 0.9209\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.93581\n",
      "Epoch 47/100\n",
      "230/230 - 11s - loss: 2.7085 - accuracy: 0.9788 - auc: 0.9977 - val_loss: 3.1857 - val_accuracy: 0.9021 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.93581\n",
      "Epoch 48/100\n",
      "230/230 - 11s - loss: 2.7070 - accuracy: 0.9796 - auc: 0.9976 - val_loss: 3.1490 - val_accuracy: 0.9058 - val_auc: 0.9206\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.93581\n",
      "Epoch 49/100\n",
      "230/230 - 11s - loss: 2.7009 - accuracy: 0.9803 - auc: 0.9978 - val_loss: 3.1366 - val_accuracy: 0.9077 - val_auc: 0.9185\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.93581\n",
      "Epoch 50/100\n",
      "230/230 - 11s - loss: 2.6956 - accuracy: 0.9830 - auc: 0.9982 - val_loss: 3.1493 - val_accuracy: 0.9040 - val_auc: 0.9210\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.93581\n",
      "Epoch 51/100\n",
      "230/230 - 11s - loss: 2.6960 - accuracy: 0.9807 - auc: 0.9980 - val_loss: 3.2532 - val_accuracy: 0.8983 - val_auc: 0.8837\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.93581\n",
      "Epoch 52/100\n",
      "230/230 - 11s - loss: 2.6967 - accuracy: 0.9798 - auc: 0.9977 - val_loss: 3.1501 - val_accuracy: 0.9115 - val_auc: 0.9187\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.93581\n",
      "Epoch 53/100\n",
      "230/230 - 11s - loss: 2.6969 - accuracy: 0.9807 - auc: 0.9974 - val_loss: 3.1827 - val_accuracy: 0.9115 - val_auc: 0.9159\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.93581\n",
      "Epoch 54/100\n",
      "230/230 - 11s - loss: 2.6902 - accuracy: 0.9820 - auc: 0.9978 - val_loss: 3.1930 - val_accuracy: 0.9115 - val_auc: 0.9148\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.93581\n",
      "Epoch 55/100\n",
      "230/230 - 11s - loss: 2.6866 - accuracy: 0.9828 - auc: 0.9982 - val_loss: 3.1788 - val_accuracy: 0.9040 - val_auc: 0.9129\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.93581\n",
      "Epoch 56/100\n",
      "230/230 - 11s - loss: 2.6880 - accuracy: 0.9827 - auc: 0.9979 - val_loss: 3.1484 - val_accuracy: 0.9077 - val_auc: 0.9194\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.93581\n",
      "Epoch 57/100\n",
      "230/230 - 10s - loss: 2.6847 - accuracy: 0.9824 - auc: 0.9981 - val_loss: 3.1864 - val_accuracy: 0.9058 - val_auc: 0.9166\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.93581\n",
      "Epoch 58/100\n",
      "230/230 - 11s - loss: 2.6842 - accuracy: 0.9813 - auc: 0.9981 - val_loss: 3.1816 - val_accuracy: 0.9115 - val_auc: 0.9164\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.93581\n",
      "Epoch 59/100\n",
      "230/230 - 11s - loss: 2.6767 - accuracy: 0.9860 - auc: 0.9983 - val_loss: 3.2057 - val_accuracy: 0.9134 - val_auc: 0.9080\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.93581\n",
      "Epoch 60/100\n",
      "230/230 - 11s - loss: 2.6768 - accuracy: 0.9843 - auc: 0.9983 - val_loss: 3.1629 - val_accuracy: 0.9077 - val_auc: 0.9174\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.93581\n",
      "Epoch 61/100\n",
      "230/230 - 11s - loss: 2.6756 - accuracy: 0.9833 - auc: 0.9984 - val_loss: 3.1708 - val_accuracy: 0.9134 - val_auc: 0.9179\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.93581\n",
      "Epoch 62/100\n",
      "230/230 - 11s - loss: 2.6710 - accuracy: 0.9847 - auc: 0.9987 - val_loss: 3.2038 - val_accuracy: 0.9058 - val_auc: 0.9093\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.93581\n",
      "Epoch 63/100\n",
      "230/230 - 11s - loss: 2.6729 - accuracy: 0.9846 - auc: 0.9979 - val_loss: 3.1725 - val_accuracy: 0.9058 - val_auc: 0.9088\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.93581\n",
      "Epoch 64/100\n",
      "230/230 - 11s - loss: 2.6704 - accuracy: 0.9845 - auc: 0.9982 - val_loss: 3.2131 - val_accuracy: 0.9077 - val_auc: 0.9129\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.93581\n",
      "Epoch 65/100\n",
      "230/230 - 11s - loss: 2.6657 - accuracy: 0.9860 - auc: 0.9986 - val_loss: 3.1814 - val_accuracy: 0.9040 - val_auc: 0.9209\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.93581\n",
      "Epoch 66/100\n",
      "230/230 - 11s - loss: 2.6619 - accuracy: 0.9861 - auc: 0.9987 - val_loss: 3.2405 - val_accuracy: 0.9077 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.93581\n",
      "Epoch 67/100\n",
      "230/230 - 11s - loss: 2.6611 - accuracy: 0.9861 - auc: 0.9987 - val_loss: 3.1971 - val_accuracy: 0.9002 - val_auc: 0.9141\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.93581\n",
      "Epoch 68/100\n",
      "230/230 - 10s - loss: 2.6632 - accuracy: 0.9856 - auc: 0.9983 - val_loss: 3.2043 - val_accuracy: 0.9021 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.93581\n",
      "Epoch 69/100\n",
      "230/230 - 9s - loss: 2.6600 - accuracy: 0.9853 - auc: 0.9984 - val_loss: 3.2447 - val_accuracy: 0.9096 - val_auc: 0.8996\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.93581\n",
      "Epoch 70/100\n",
      "230/230 - 9s - loss: 2.6578 - accuracy: 0.9861 - auc: 0.9984 - val_loss: 3.2353 - val_accuracy: 0.9077 - val_auc: 0.9062\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.93581\n",
      "Epoch 71/100\n",
      "230/230 - 9s - loss: 2.6528 - accuracy: 0.9884 - auc: 0.9987 - val_loss: 3.2975 - val_accuracy: 0.9058 - val_auc: 0.8923\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.93581\n",
      "Epoch 72/100\n",
      "230/230 - 9s - loss: 2.6502 - accuracy: 0.9880 - auc: 0.9987 - val_loss: 3.2638 - val_accuracy: 0.9096 - val_auc: 0.8903\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.93581\n",
      "Epoch 73/100\n",
      "230/230 - 9s - loss: 2.6505 - accuracy: 0.9865 - auc: 0.9986 - val_loss: 3.2412 - val_accuracy: 0.9040 - val_auc: 0.9025\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.93581\n",
      "Epoch 74/100\n",
      "230/230 - 10s - loss: 2.6460 - accuracy: 0.9879 - auc: 0.9988 - val_loss: 3.2550 - val_accuracy: 0.9077 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.93581\n",
      "Epoch 75/100\n",
      "230/230 - 10s - loss: 2.6479 - accuracy: 0.9876 - auc: 0.9986 - val_loss: 3.2116 - val_accuracy: 0.9021 - val_auc: 0.9120\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.93581\n",
      "Epoch 76/100\n",
      "230/230 - 11s - loss: 2.6474 - accuracy: 0.9869 - auc: 0.9986 - val_loss: 3.2060 - val_accuracy: 0.9002 - val_auc: 0.9079\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.93581\n",
      "Epoch 77/100\n",
      "230/230 - 10s - loss: 2.6421 - accuracy: 0.9873 - auc: 0.9988 - val_loss: 3.3204 - val_accuracy: 0.9058 - val_auc: 0.8863\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.93581\n",
      "Epoch 78/100\n",
      "230/230 - 11s - loss: 2.6404 - accuracy: 0.9884 - auc: 0.9987 - val_loss: 3.2537 - val_accuracy: 0.9077 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.93581\n",
      "Epoch 79/100\n",
      "230/230 - 11s - loss: 2.6417 - accuracy: 0.9883 - auc: 0.9983 - val_loss: 3.2223 - val_accuracy: 0.9040 - val_auc: 0.9160\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.93581\n",
      "Epoch 80/100\n",
      "230/230 - 10s - loss: 2.6380 - accuracy: 0.9883 - auc: 0.9985 - val_loss: 3.2600 - val_accuracy: 0.9077 - val_auc: 0.9007\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.93581\n",
      "Epoch 81/100\n",
      "230/230 - 10s - loss: 2.6371 - accuracy: 0.9876 - auc: 0.9984 - val_loss: 3.2767 - val_accuracy: 0.9153 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.93581\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 - 10s - loss: 2.6361 - accuracy: 0.9879 - auc: 0.9985 - val_loss: 3.2892 - val_accuracy: 0.9040 - val_auc: 0.8959\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.93581\n",
      "Epoch 83/100\n",
      "230/230 - 11s - loss: 2.6323 - accuracy: 0.9890 - auc: 0.9990 - val_loss: 3.2685 - val_accuracy: 0.9096 - val_auc: 0.8945\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.93581\n",
      "Epoch 84/100\n",
      "230/230 - 11s - loss: 2.6323 - accuracy: 0.9879 - auc: 0.9989 - val_loss: 3.2608 - val_accuracy: 0.9077 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.93581\n",
      "Epoch 85/100\n",
      "230/230 - 11s - loss: 2.6279 - accuracy: 0.9880 - auc: 0.9990 - val_loss: 3.2494 - val_accuracy: 0.9021 - val_auc: 0.8946\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.93581\n",
      "Epoch 86/100\n",
      "230/230 - 10s - loss: 2.6271 - accuracy: 0.9883 - auc: 0.9991 - val_loss: 3.2574 - val_accuracy: 0.9134 - val_auc: 0.9012\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.93581\n",
      "Epoch 87/100\n",
      "230/230 - 11s - loss: 2.6272 - accuracy: 0.9883 - auc: 0.9989 - val_loss: 3.2608 - val_accuracy: 0.9077 - val_auc: 0.8950\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.93581\n",
      "Epoch 88/100\n",
      "230/230 - 11s - loss: 2.6237 - accuracy: 0.9892 - auc: 0.9990 - val_loss: 3.2966 - val_accuracy: 0.9096 - val_auc: 0.8892\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.93581\n",
      "Epoch 89/100\n",
      "230/230 - 11s - loss: 2.6207 - accuracy: 0.9899 - auc: 0.9991 - val_loss: 3.2723 - val_accuracy: 0.9058 - val_auc: 0.8994\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.93581\n",
      "Epoch 90/100\n",
      "230/230 - 11s - loss: 2.6207 - accuracy: 0.9883 - auc: 0.9991 - val_loss: 3.2123 - val_accuracy: 0.9058 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.93581\n",
      "Epoch 91/100\n",
      "230/230 - 11s - loss: 2.6196 - accuracy: 0.9884 - auc: 0.9988 - val_loss: 3.2619 - val_accuracy: 0.9021 - val_auc: 0.8974\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.93581\n",
      "Epoch 92/100\n",
      "230/230 - 11s - loss: 2.6165 - accuracy: 0.9903 - auc: 0.9989 - val_loss: 3.2639 - val_accuracy: 0.9115 - val_auc: 0.8939\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.93581\n",
      "Epoch 93/100\n",
      "230/230 - 11s - loss: 2.6166 - accuracy: 0.9897 - auc: 0.9989 - val_loss: 3.2470 - val_accuracy: 0.9058 - val_auc: 0.8999\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.93581\n",
      "Epoch 94/100\n",
      "230/230 - 11s - loss: 2.6131 - accuracy: 0.9894 - auc: 0.9989 - val_loss: 3.2594 - val_accuracy: 0.9058 - val_auc: 0.9068\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.93581\n",
      "Epoch 95/100\n",
      "230/230 - 11s - loss: 2.6095 - accuracy: 0.9907 - auc: 0.9990 - val_loss: 3.2805 - val_accuracy: 0.9096 - val_auc: 0.8878\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.93581\n",
      "Epoch 96/100\n",
      "230/230 - 11s - loss: 2.6101 - accuracy: 0.9906 - auc: 0.9990 - val_loss: 3.2767 - val_accuracy: 0.9077 - val_auc: 0.8977\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.93581\n",
      "Epoch 97/100\n",
      "230/230 - 10s - loss: 2.6122 - accuracy: 0.9887 - auc: 0.9987 - val_loss: 3.2770 - val_accuracy: 0.9096 - val_auc: 0.8976\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.93581\n",
      "Epoch 98/100\n",
      "230/230 - 11s - loss: 2.6075 - accuracy: 0.9894 - auc: 0.9991 - val_loss: 3.3110 - val_accuracy: 0.9077 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.93581\n",
      "Epoch 99/100\n",
      "230/230 - 11s - loss: 2.6076 - accuracy: 0.9898 - auc: 0.9986 - val_loss: 3.2822 - val_accuracy: 0.9115 - val_auc: 0.8938\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.93581\n",
      "Epoch 100/100\n",
      "230/230 - 11s - loss: 2.6042 - accuracy: 0.9894 - auc: 0.9990 - val_loss: 3.2835 - val_accuracy: 0.9153 - val_auc: 0.8943\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.93581\n",
      "Epoch 1/100\n",
      "271/271 - 16s - loss: 3.2789 - accuracy: 0.6521 - auc: 0.7969 - val_loss: 3.2403 - val_accuracy: 0.6584 - val_auc: 0.8267\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.82673, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 2/100\n",
      "271/271 - 13s - loss: 3.1705 - accuracy: 0.7365 - auc: 0.8773 - val_loss: 3.2148 - val_accuracy: 0.7148 - val_auc: 0.8337\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.82673 to 0.83366, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 3/100\n",
      "271/271 - 12s - loss: 3.0992 - accuracy: 0.8004 - auc: 0.9169 - val_loss: 3.2102 - val_accuracy: 0.7430 - val_auc: 0.8389\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.83366 to 0.83888, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 4/100\n",
      "271/271 - 12s - loss: 3.0575 - accuracy: 0.8288 - auc: 0.9327 - val_loss: 3.2129 - val_accuracy: 0.7579 - val_auc: 0.8390\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.83888 to 0.83903, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 5/100\n",
      "271/271 - 12s - loss: 3.0182 - accuracy: 0.8561 - auc: 0.9499 - val_loss: 3.2359 - val_accuracy: 0.7512 - val_auc: 0.8300\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.83903\n",
      "Epoch 6/100\n",
      "271/271 - 12s - loss: 2.9868 - accuracy: 0.8741 - auc: 0.9596 - val_loss: 3.2482 - val_accuracy: 0.7877 - val_auc: 0.8348\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.83903\n",
      "Epoch 7/100\n",
      "271/271 - 12s - loss: 2.9539 - accuracy: 0.8951 - auc: 0.9691 - val_loss: 3.2583 - val_accuracy: 0.7894 - val_auc: 0.8420\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.83903 to 0.84201, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 8/100\n",
      "271/271 - 12s - loss: 2.9273 - accuracy: 0.9044 - auc: 0.9748 - val_loss: 3.2973 - val_accuracy: 0.8060 - val_auc: 0.8365\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.84201\n",
      "Epoch 9/100\n",
      "271/271 - 12s - loss: 2.9050 - accuracy: 0.9147 - auc: 0.9794 - val_loss: 3.2879 - val_accuracy: 0.8126 - val_auc: 0.8441\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.84201 to 0.84412, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 10/100\n",
      "271/271 - 12s - loss: 2.8880 - accuracy: 0.9240 - auc: 0.9819 - val_loss: 3.3254 - val_accuracy: 0.7861 - val_auc: 0.8317\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.84412\n",
      "Epoch 11/100\n",
      "271/271 - 12s - loss: 2.8755 - accuracy: 0.9257 - auc: 0.9839 - val_loss: 3.3232 - val_accuracy: 0.8292 - val_auc: 0.8469\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.84412 to 0.84694, saving model to 210128_TrainingLocalitySensitivewoFW\\210129_LS_SR-p53\n",
      "Epoch 12/100\n",
      "271/271 - 11s - loss: 2.8477 - accuracy: 0.9411 - auc: 0.9888 - val_loss: 3.3864 - val_accuracy: 0.8325 - val_auc: 0.8399\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.84694\n",
      "Epoch 13/100\n",
      "271/271 - 11s - loss: 2.8349 - accuracy: 0.9455 - auc: 0.9899 - val_loss: 3.5023 - val_accuracy: 0.8673 - val_auc: 0.8333\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.84694\n",
      "Epoch 14/100\n",
      "271/271 - 11s - loss: 2.8204 - accuracy: 0.9512 - auc: 0.9914 - val_loss: 3.5095 - val_accuracy: 0.8358 - val_auc: 0.8328\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.84694\n",
      "Epoch 15/100\n",
      "271/271 - 11s - loss: 2.8075 - accuracy: 0.9558 - auc: 0.9932 - val_loss: 3.5734 - val_accuracy: 0.8590 - val_auc: 0.8339\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.84694\n",
      "Epoch 16/100\n",
      "271/271 - 11s - loss: 2.8013 - accuracy: 0.9588 - auc: 0.9933 - val_loss: 3.7501 - val_accuracy: 0.8856 - val_auc: 0.8191\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.84694\n",
      "Epoch 17/100\n",
      "271/271 - 12s - loss: 2.7946 - accuracy: 0.9601 - auc: 0.9935 - val_loss: 3.5024 - val_accuracy: 0.8375 - val_auc: 0.8451\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.84694\n",
      "Epoch 18/100\n",
      "271/271 - 12s - loss: 2.7805 - accuracy: 0.9641 - auc: 0.9952 - val_loss: 3.6096 - val_accuracy: 0.8524 - val_auc: 0.8262\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.84694\n",
      "Epoch 19/100\n",
      "271/271 - 12s - loss: 2.7714 - accuracy: 0.9688 - auc: 0.9955 - val_loss: 3.6485 - val_accuracy: 0.8773 - val_auc: 0.8419\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.84694\n",
      "Epoch 20/100\n",
      "271/271 - 12s - loss: 2.7642 - accuracy: 0.9692 - auc: 0.9960 - val_loss: 3.6681 - val_accuracy: 0.8574 - val_auc: 0.8357\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.84694\n",
      "Epoch 21/100\n",
      "271/271 - 12s - loss: 2.7710 - accuracy: 0.9703 - auc: 0.9942 - val_loss: 3.6026 - val_accuracy: 0.8541 - val_auc: 0.8454\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.84694\n",
      "Epoch 22/100\n",
      "271/271 - 12s - loss: 2.7528 - accuracy: 0.9752 - auc: 0.9962 - val_loss: 3.7786 - val_accuracy: 0.8740 - val_auc: 0.8213\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.84694\n",
      "Epoch 23/100\n",
      "271/271 - 12s - loss: 2.7450 - accuracy: 0.9758 - auc: 0.9970 - val_loss: 3.8328 - val_accuracy: 0.8872 - val_auc: 0.8245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_auc did not improve from 0.84694\n",
      "Epoch 24/100\n",
      "271/271 - 12s - loss: 2.7383 - accuracy: 0.9794 - auc: 0.9975 - val_loss: 3.8623 - val_accuracy: 0.8789 - val_auc: 0.8218\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.84694\n",
      "Epoch 25/100\n",
      "271/271 - 12s - loss: 2.7350 - accuracy: 0.9788 - auc: 0.9976 - val_loss: 3.8827 - val_accuracy: 0.8806 - val_auc: 0.8194\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.84694\n",
      "Epoch 26/100\n",
      "271/271 - 12s - loss: 2.7305 - accuracy: 0.9809 - auc: 0.9976 - val_loss: 4.0497 - val_accuracy: 0.8922 - val_auc: 0.8200\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.84694\n",
      "Epoch 27/100\n",
      "271/271 - 12s - loss: 2.7277 - accuracy: 0.9806 - auc: 0.9977 - val_loss: 3.9599 - val_accuracy: 0.8839 - val_auc: 0.8087\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.84694\n",
      "Epoch 28/100\n",
      "271/271 - 13s - loss: 2.7210 - accuracy: 0.9832 - auc: 0.9981 - val_loss: 4.0121 - val_accuracy: 0.8839 - val_auc: 0.8163\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.84694\n",
      "Epoch 29/100\n",
      "271/271 - 12s - loss: 2.7190 - accuracy: 0.9809 - auc: 0.9979 - val_loss: 3.9780 - val_accuracy: 0.8889 - val_auc: 0.8124\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.84694\n",
      "Epoch 30/100\n",
      "271/271 - 12s - loss: 2.7170 - accuracy: 0.9830 - auc: 0.9978 - val_loss: 4.0559 - val_accuracy: 0.8839 - val_auc: 0.8010\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.84694\n",
      "Epoch 31/100\n",
      "271/271 - 12s - loss: 2.7113 - accuracy: 0.9843 - auc: 0.9981 - val_loss: 3.9139 - val_accuracy: 0.8657 - val_auc: 0.8223\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.84694\n",
      "Epoch 32/100\n",
      "271/271 - 12s - loss: 2.7103 - accuracy: 0.9832 - auc: 0.9983 - val_loss: 4.0658 - val_accuracy: 0.8823 - val_auc: 0.8044\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.84694\n",
      "Epoch 33/100\n",
      "271/271 - 12s - loss: 2.7038 - accuracy: 0.9865 - auc: 0.9986 - val_loss: 4.0027 - val_accuracy: 0.8491 - val_auc: 0.8097\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.84694\n",
      "Epoch 34/100\n",
      "271/271 - 12s - loss: 2.7063 - accuracy: 0.9840 - auc: 0.9982 - val_loss: 4.1575 - val_accuracy: 0.8789 - val_auc: 0.7996\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.84694\n",
      "Epoch 35/100\n",
      "271/271 - 12s - loss: 2.7028 - accuracy: 0.9850 - auc: 0.9984 - val_loss: 3.9753 - val_accuracy: 0.8823 - val_auc: 0.8175\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.84694\n",
      "Epoch 36/100\n",
      "271/271 - 12s - loss: 2.6941 - accuracy: 0.9881 - auc: 0.9986 - val_loss: 4.2713 - val_accuracy: 0.8972 - val_auc: 0.8107\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.84694\n",
      "Epoch 37/100\n",
      "271/271 - 12s - loss: 2.6914 - accuracy: 0.9887 - auc: 0.9986 - val_loss: 4.0783 - val_accuracy: 0.8872 - val_auc: 0.8112\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.84694\n",
      "Epoch 38/100\n",
      "271/271 - 12s - loss: 2.6898 - accuracy: 0.9888 - auc: 0.9986 - val_loss: 4.1033 - val_accuracy: 0.8872 - val_auc: 0.8126\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.84694\n",
      "Epoch 39/100\n",
      "271/271 - 12s - loss: 2.6903 - accuracy: 0.9880 - auc: 0.9984 - val_loss: 4.1382 - val_accuracy: 0.8756 - val_auc: 0.8052\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.84694\n",
      "Epoch 40/100\n",
      "271/271 - 12s - loss: 2.6853 - accuracy: 0.9899 - auc: 0.9985 - val_loss: 4.2412 - val_accuracy: 0.8988 - val_auc: 0.8157\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.84694\n",
      "Epoch 41/100\n",
      "271/271 - 12s - loss: 2.6806 - accuracy: 0.9898 - auc: 0.9985 - val_loss: 4.2432 - val_accuracy: 0.8939 - val_auc: 0.8110\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.84694\n",
      "Epoch 42/100\n",
      "271/271 - 12s - loss: 2.6780 - accuracy: 0.9912 - auc: 0.9987 - val_loss: 4.2471 - val_accuracy: 0.8955 - val_auc: 0.8155\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.84694\n",
      "Epoch 43/100\n",
      "271/271 - 12s - loss: 2.6783 - accuracy: 0.9904 - auc: 0.9987 - val_loss: 4.3248 - val_accuracy: 0.8972 - val_auc: 0.8133\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.84694\n",
      "Epoch 44/100\n",
      "271/271 - 12s - loss: 2.6736 - accuracy: 0.9904 - auc: 0.9989 - val_loss: 4.4001 - val_accuracy: 0.8972 - val_auc: 0.7917\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.84694\n",
      "Epoch 45/100\n",
      "271/271 - 12s - loss: 2.6718 - accuracy: 0.9917 - auc: 0.9987 - val_loss: 4.3698 - val_accuracy: 0.8889 - val_auc: 0.7989\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.84694\n",
      "Epoch 46/100\n",
      "271/271 - 12s - loss: 2.6708 - accuracy: 0.9911 - auc: 0.9988 - val_loss: 4.3543 - val_accuracy: 0.9005 - val_auc: 0.8188\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.84694\n",
      "Epoch 47/100\n",
      "271/271 - 12s - loss: 2.6657 - accuracy: 0.9917 - auc: 0.9990 - val_loss: 4.5003 - val_accuracy: 0.8955 - val_auc: 0.8054\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.84694\n",
      "Epoch 48/100\n",
      "271/271 - 12s - loss: 2.6648 - accuracy: 0.9911 - auc: 0.9991 - val_loss: 4.5083 - val_accuracy: 0.8955 - val_auc: 0.8062\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.84694\n",
      "Epoch 49/100\n",
      "271/271 - 12s - loss: 2.6636 - accuracy: 0.9909 - auc: 0.9988 - val_loss: 4.4065 - val_accuracy: 0.8972 - val_auc: 0.8050\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.84694\n",
      "Epoch 50/100\n",
      "271/271 - 12s - loss: 2.6603 - accuracy: 0.9916 - auc: 0.9989 - val_loss: 4.4631 - val_accuracy: 0.8972 - val_auc: 0.8144\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.84694\n",
      "Epoch 51/100\n",
      "271/271 - 12s - loss: 2.6585 - accuracy: 0.9919 - auc: 0.9986 - val_loss: 4.3927 - val_accuracy: 0.8922 - val_auc: 0.8030\n",
      "\n",
      "Epoch 00051: val_auc did not improve from 0.84694\n",
      "Epoch 52/100\n",
      "271/271 - 11s - loss: 2.6609 - accuracy: 0.9896 - auc: 0.9989 - val_loss: 4.6246 - val_accuracy: 0.9022 - val_auc: 0.7878\n",
      "\n",
      "Epoch 00052: val_auc did not improve from 0.84694\n",
      "Epoch 53/100\n",
      "271/271 - 11s - loss: 2.6550 - accuracy: 0.9910 - auc: 0.9992 - val_loss: 4.4143 - val_accuracy: 0.8872 - val_auc: 0.7936\n",
      "\n",
      "Epoch 00053: val_auc did not improve from 0.84694\n",
      "Epoch 54/100\n",
      "271/271 - 11s - loss: 2.6529 - accuracy: 0.9928 - auc: 0.9991 - val_loss: 4.6063 - val_accuracy: 0.8988 - val_auc: 0.8069\n",
      "\n",
      "Epoch 00054: val_auc did not improve from 0.84694\n",
      "Epoch 55/100\n",
      "271/271 - 11s - loss: 2.6519 - accuracy: 0.9917 - auc: 0.9992 - val_loss: 4.5582 - val_accuracy: 0.8972 - val_auc: 0.7849\n",
      "\n",
      "Epoch 00055: val_auc did not improve from 0.84694\n",
      "Epoch 56/100\n",
      "271/271 - 11s - loss: 2.6505 - accuracy: 0.9916 - auc: 0.9990 - val_loss: 4.4330 - val_accuracy: 0.9005 - val_auc: 0.8097\n",
      "\n",
      "Epoch 00056: val_auc did not improve from 0.84694\n",
      "Epoch 57/100\n",
      "271/271 - 12s - loss: 2.6478 - accuracy: 0.9917 - auc: 0.9989 - val_loss: 4.5490 - val_accuracy: 0.8905 - val_auc: 0.7943\n",
      "\n",
      "Epoch 00057: val_auc did not improve from 0.84694\n",
      "Epoch 58/100\n",
      "271/271 - 12s - loss: 2.6418 - accuracy: 0.9938 - auc: 0.9993 - val_loss: 4.7017 - val_accuracy: 0.9055 - val_auc: 0.7898\n",
      "\n",
      "Epoch 00058: val_auc did not improve from 0.84694\n",
      "Epoch 59/100\n",
      "271/271 - 12s - loss: 2.6412 - accuracy: 0.9934 - auc: 0.9993 - val_loss: 4.6163 - val_accuracy: 0.9005 - val_auc: 0.7858\n",
      "\n",
      "Epoch 00059: val_auc did not improve from 0.84694\n",
      "Epoch 60/100\n",
      "271/271 - 12s - loss: 2.6401 - accuracy: 0.9935 - auc: 0.9990 - val_loss: 4.6222 - val_accuracy: 0.9038 - val_auc: 0.7932\n",
      "\n",
      "Epoch 00060: val_auc did not improve from 0.84694\n",
      "Epoch 61/100\n",
      "271/271 - 12s - loss: 2.6372 - accuracy: 0.9939 - auc: 0.9991 - val_loss: 4.6208 - val_accuracy: 0.9038 - val_auc: 0.7916\n",
      "\n",
      "Epoch 00061: val_auc did not improve from 0.84694\n",
      "Epoch 62/100\n",
      "271/271 - 12s - loss: 2.6331 - accuracy: 0.9947 - auc: 0.9995 - val_loss: 4.6063 - val_accuracy: 0.9038 - val_auc: 0.7768\n",
      "\n",
      "Epoch 00062: val_auc did not improve from 0.84694\n",
      "Epoch 63/100\n",
      "271/271 - 12s - loss: 2.6341 - accuracy: 0.9938 - auc: 0.9991 - val_loss: 4.5697 - val_accuracy: 0.8988 - val_auc: 0.7818\n",
      "\n",
      "Epoch 00063: val_auc did not improve from 0.84694\n",
      "Epoch 64/100\n",
      "271/271 - 12s - loss: 2.6323 - accuracy: 0.9936 - auc: 0.9993 - val_loss: 4.6669 - val_accuracy: 0.8955 - val_auc: 0.7876\n",
      "\n",
      "Epoch 00064: val_auc did not improve from 0.84694\n",
      "Epoch 65/100\n",
      "271/271 - 12s - loss: 2.6277 - accuracy: 0.9950 - auc: 0.9991 - val_loss: 4.5678 - val_accuracy: 0.8955 - val_auc: 0.7891\n",
      "\n",
      "Epoch 00065: val_auc did not improve from 0.84694\n",
      "Epoch 66/100\n",
      "271/271 - 12s - loss: 2.6305 - accuracy: 0.9934 - auc: 0.9991 - val_loss: 4.7183 - val_accuracy: 0.8988 - val_auc: 0.7903\n",
      "\n",
      "Epoch 00066: val_auc did not improve from 0.84694\n",
      "Epoch 67/100\n",
      "271/271 - 12s - loss: 2.6281 - accuracy: 0.9943 - auc: 0.9988 - val_loss: 4.4932 - val_accuracy: 0.8905 - val_auc: 0.8011\n",
      "\n",
      "Epoch 00067: val_auc did not improve from 0.84694\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 - 12s - loss: 2.6249 - accuracy: 0.9935 - auc: 0.9991 - val_loss: 4.7310 - val_accuracy: 0.8988 - val_auc: 0.7777\n",
      "\n",
      "Epoch 00068: val_auc did not improve from 0.84694\n",
      "Epoch 69/100\n",
      "271/271 - 12s - loss: 2.6236 - accuracy: 0.9932 - auc: 0.9994 - val_loss: 4.5554 - val_accuracy: 0.8939 - val_auc: 0.7943\n",
      "\n",
      "Epoch 00069: val_auc did not improve from 0.84694\n",
      "Epoch 70/100\n",
      "271/271 - 12s - loss: 2.6200 - accuracy: 0.9947 - auc: 0.9991 - val_loss: 4.5934 - val_accuracy: 0.8955 - val_auc: 0.7772\n",
      "\n",
      "Epoch 00070: val_auc did not improve from 0.84694\n",
      "Epoch 71/100\n",
      "271/271 - 12s - loss: 2.6183 - accuracy: 0.9947 - auc: 0.9991 - val_loss: 4.8203 - val_accuracy: 0.9038 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00071: val_auc did not improve from 0.84694\n",
      "Epoch 72/100\n",
      "271/271 - 12s - loss: 2.6168 - accuracy: 0.9942 - auc: 0.9994 - val_loss: 4.8153 - val_accuracy: 0.9055 - val_auc: 0.7881\n",
      "\n",
      "Epoch 00072: val_auc did not improve from 0.84694\n",
      "Epoch 73/100\n",
      "271/271 - 12s - loss: 2.6166 - accuracy: 0.9941 - auc: 0.9990 - val_loss: 4.7012 - val_accuracy: 0.8939 - val_auc: 0.7864\n",
      "\n",
      "Epoch 00073: val_auc did not improve from 0.84694\n",
      "Epoch 74/100\n",
      "271/271 - 12s - loss: 2.6129 - accuracy: 0.9946 - auc: 0.9993 - val_loss: 4.7705 - val_accuracy: 0.8972 - val_auc: 0.7556\n",
      "\n",
      "Epoch 00074: val_auc did not improve from 0.84694\n",
      "Epoch 75/100\n",
      "271/271 - 12s - loss: 2.6126 - accuracy: 0.9943 - auc: 0.9993 - val_loss: 4.3559 - val_accuracy: 0.7745 - val_auc: 0.7862\n",
      "\n",
      "Epoch 00075: val_auc did not improve from 0.84694\n",
      "Epoch 76/100\n",
      "271/271 - 12s - loss: 2.6550 - accuracy: 0.9811 - auc: 0.9951 - val_loss: 4.5158 - val_accuracy: 0.8922 - val_auc: 0.7908\n",
      "\n",
      "Epoch 00076: val_auc did not improve from 0.84694\n",
      "Epoch 77/100\n",
      "271/271 - 12s - loss: 2.6163 - accuracy: 0.9931 - auc: 0.9984 - val_loss: 4.6034 - val_accuracy: 0.9022 - val_auc: 0.7970\n",
      "\n",
      "Epoch 00077: val_auc did not improve from 0.84694\n",
      "Epoch 78/100\n",
      "271/271 - 12s - loss: 2.6109 - accuracy: 0.9933 - auc: 0.9988 - val_loss: 4.5412 - val_accuracy: 0.8988 - val_auc: 0.7953\n",
      "\n",
      "Epoch 00078: val_auc did not improve from 0.84694\n",
      "Epoch 79/100\n",
      "271/271 - 12s - loss: 2.6069 - accuracy: 0.9946 - auc: 0.9990 - val_loss: 4.7226 - val_accuracy: 0.9071 - val_auc: 0.7657\n",
      "\n",
      "Epoch 00079: val_auc did not improve from 0.84694\n",
      "Epoch 80/100\n",
      "271/271 - 12s - loss: 2.6070 - accuracy: 0.9933 - auc: 0.9991 - val_loss: 4.6670 - val_accuracy: 0.9055 - val_auc: 0.7718\n",
      "\n",
      "Epoch 00080: val_auc did not improve from 0.84694\n",
      "Epoch 81/100\n",
      "271/271 - 12s - loss: 2.6037 - accuracy: 0.9938 - auc: 0.9993 - val_loss: 4.6317 - val_accuracy: 0.9022 - val_auc: 0.7749\n",
      "\n",
      "Epoch 00081: val_auc did not improve from 0.84694\n",
      "Epoch 82/100\n",
      "271/271 - 12s - loss: 2.6012 - accuracy: 0.9941 - auc: 0.9994 - val_loss: 4.5172 - val_accuracy: 0.8955 - val_auc: 0.7903\n",
      "\n",
      "Epoch 00082: val_auc did not improve from 0.84694\n",
      "Epoch 83/100\n",
      "271/271 - 12s - loss: 2.5986 - accuracy: 0.9951 - auc: 0.9991 - val_loss: 4.6202 - val_accuracy: 0.9038 - val_auc: 0.7808\n",
      "\n",
      "Epoch 00083: val_auc did not improve from 0.84694\n",
      "Epoch 84/100\n",
      "271/271 - 12s - loss: 2.5976 - accuracy: 0.9949 - auc: 0.9991 - val_loss: 4.9099 - val_accuracy: 0.9154 - val_auc: 0.7607\n",
      "\n",
      "Epoch 00084: val_auc did not improve from 0.84694\n",
      "Epoch 85/100\n",
      "271/271 - 12s - loss: 2.6005 - accuracy: 0.9932 - auc: 0.9993 - val_loss: 4.4150 - val_accuracy: 0.8856 - val_auc: 0.7776\n",
      "\n",
      "Epoch 00085: val_auc did not improve from 0.84694\n",
      "Epoch 86/100\n",
      "271/271 - 12s - loss: 2.5946 - accuracy: 0.9942 - auc: 0.9990 - val_loss: 4.9856 - val_accuracy: 0.9088 - val_auc: 0.7508\n",
      "\n",
      "Epoch 00086: val_auc did not improve from 0.84694\n",
      "Epoch 87/100\n",
      "271/271 - 12s - loss: 2.5898 - accuracy: 0.9949 - auc: 0.9994 - val_loss: 4.8794 - val_accuracy: 0.9138 - val_auc: 0.7794\n",
      "\n",
      "Epoch 00087: val_auc did not improve from 0.84694\n",
      "Epoch 88/100\n",
      "271/271 - 12s - loss: 2.5891 - accuracy: 0.9946 - auc: 0.9993 - val_loss: 4.7726 - val_accuracy: 0.9088 - val_auc: 0.7785\n",
      "\n",
      "Epoch 00088: val_auc did not improve from 0.84694\n",
      "Epoch 89/100\n",
      "271/271 - 12s - loss: 2.5867 - accuracy: 0.9951 - auc: 0.9993 - val_loss: 4.7368 - val_accuracy: 0.9104 - val_auc: 0.7747\n",
      "\n",
      "Epoch 00089: val_auc did not improve from 0.84694\n",
      "Epoch 90/100\n",
      "271/271 - 12s - loss: 2.5843 - accuracy: 0.9953 - auc: 0.9994 - val_loss: 4.8090 - val_accuracy: 0.9038 - val_auc: 0.7797\n",
      "\n",
      "Epoch 00090: val_auc did not improve from 0.84694\n",
      "Epoch 91/100\n",
      "271/271 - 12s - loss: 2.5839 - accuracy: 0.9946 - auc: 0.9992 - val_loss: 4.7665 - val_accuracy: 0.8988 - val_auc: 0.7772\n",
      "\n",
      "Epoch 00091: val_auc did not improve from 0.84694\n",
      "Epoch 92/100\n",
      "271/271 - 11s - loss: 2.5815 - accuracy: 0.9944 - auc: 0.9993 - val_loss: 5.0862 - val_accuracy: 0.9121 - val_auc: 0.7354\n",
      "\n",
      "Epoch 00092: val_auc did not improve from 0.84694\n",
      "Epoch 93/100\n",
      "271/271 - 11s - loss: 2.5823 - accuracy: 0.9946 - auc: 0.9994 - val_loss: 4.7462 - val_accuracy: 0.9055 - val_auc: 0.7717\n",
      "\n",
      "Epoch 00093: val_auc did not improve from 0.84694\n",
      "Epoch 94/100\n",
      "271/271 - 11s - loss: 2.5781 - accuracy: 0.9951 - auc: 0.9993 - val_loss: 4.7108 - val_accuracy: 0.9088 - val_auc: 0.7803\n",
      "\n",
      "Epoch 00094: val_auc did not improve from 0.84694\n",
      "Epoch 95/100\n",
      "271/271 - 11s - loss: 2.5754 - accuracy: 0.9951 - auc: 0.9994 - val_loss: 4.7431 - val_accuracy: 0.9038 - val_auc: 0.7906\n",
      "\n",
      "Epoch 00095: val_auc did not improve from 0.84694\n",
      "Epoch 96/100\n",
      "271/271 - 12s - loss: 2.5727 - accuracy: 0.9953 - auc: 0.9997 - val_loss: 4.8949 - val_accuracy: 0.9104 - val_auc: 0.7710\n",
      "\n",
      "Epoch 00096: val_auc did not improve from 0.84694\n",
      "Epoch 97/100\n",
      "271/271 - 12s - loss: 2.5716 - accuracy: 0.9958 - auc: 0.9994 - val_loss: 4.8085 - val_accuracy: 0.9121 - val_auc: 0.7742\n",
      "\n",
      "Epoch 00097: val_auc did not improve from 0.84694\n",
      "Epoch 98/100\n",
      "271/271 - 12s - loss: 2.5700 - accuracy: 0.9949 - auc: 0.9996 - val_loss: 4.8353 - val_accuracy: 0.9055 - val_auc: 0.7738\n",
      "\n",
      "Epoch 00098: val_auc did not improve from 0.84694\n",
      "Epoch 99/100\n",
      "271/271 - 12s - loss: 2.5693 - accuracy: 0.9957 - auc: 0.9995 - val_loss: 4.8527 - val_accuracy: 0.9088 - val_auc: 0.7512\n",
      "\n",
      "Epoch 00099: val_auc did not improve from 0.84694\n",
      "Epoch 100/100\n",
      "271/271 - 12s - loss: 2.5685 - accuracy: 0.9949 - auc: 0.9993 - val_loss: 4.7867 - val_accuracy: 0.9055 - val_auc: 0.7917\n",
      "\n",
      "Epoch 00100: val_auc did not improve from 0.84694\n"
     ]
    }
   ],
   "source": [
    "# Repeat above for all labels\n",
    "n_epoch = 100\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewoFW\",\n",
    "                                       time.localtime()))\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "\n",
    "tmp_file = os.path.join(save_folder,\n",
    "\"{}_LS_tmpfile.csv\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     ))\n",
    "\n",
    "with open(tmp_file, 'w') as tmpfile:\n",
    "    tmpfile.write(\",\".join([\"Label\", \"Best_AUC\\n\"]))\n",
    "\n",
    "    \n",
    "for label in y_train.columns:\n",
    "    # Load data\n",
    "    train_ind=~np.isnan(y_train[label])\n",
    "    test_ind=~np.isnan(y_test[label])\n",
    "    train_targets=y_train[label][train_ind]\n",
    "    test_targets=y_test[label][test_ind]\n",
    "\n",
    "    # train_tensor=np.hstack([train_data, train_Fweights\n",
    "    #                        ])[train_ind]\n",
    "    # test_tensor=np.hstack([test_data, test_Fweights\n",
    "    #                       ])[test_ind]\n",
    "\n",
    "    train_tensor=X_train_scaled[train_ind]\n",
    "    test_tensor=X_test_scaled[test_ind]\n",
    "    \n",
    "    # train_Fweights\n",
    "    # test_Fweights\n",
    "\n",
    "    weights_dicts = get_weights_dicts(np.expand_dims(train_targets, 1))\n",
    "\n",
    "    # Set save folders\n",
    "    checkpoint_path = os.path.join(save_folder, \"{}_LS_{}\".format(time.strftime(\"%y%m%d\", time.localtime()),\n",
    "                     label)\n",
    "                                  )\n",
    "    try:\n",
    "        os.mkdir(checkpoint_path)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    LS_model_=initialize_LSmodel(weights_dicts = weights_dicts)\n",
    "\n",
    "\n",
    "    cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 monitor = 'val_auc',\n",
    "                                                 mode = 'max',\n",
    "                                                 save_best_only = True,\n",
    "                                                 save_weights_only = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "    csv_filename=os.path.join(checkpoint_path, \"training_log.csv\")\n",
    "    csvlogger_callback=tf.keras.callbacks.CSVLogger(\n",
    "        filename = csv_filename, append = True)\n",
    "\n",
    "    LS_model_.fit(train_tensor,\n",
    "                    train_targets,\n",
    "                    epochs=n_epoch, \n",
    "                    batch_size=n_batch, \n",
    "                    validation_data=(test_tensor, test_targets),\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[csvlogger_callback,\n",
    "                               cp_callback\n",
    "                              ])\n",
    "    \n",
    "    with open(tmp_file, 'a') as tmpfile:\n",
    "        tmpfile.write(\",\".join([label, str(cp_callback.best)+\"/n\"]))\n",
    "    \n",
    "    del LS_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions=[LS_model_.layers[1].attention_layers[i](train_tensor[:2]) \n",
    "            for i in range(n_attention)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n",
       "array([[6.44123197e-01, 1.00000000e+00, 1.00000000e+00, 2.25430576e-05,\n",
       "        8.67243727e-07, 2.02709962e-05, 6.97454019e-03, 2.99754349e-04,\n",
       "        3.12414329e-07, 2.31972504e-02, 4.19366241e-01, 7.46119804e-06,\n",
       "        1.45811441e-06, 5.55445695e-05, 1.31393713e-03, 2.03859597e-03,\n",
       "        4.51146298e-06, 9.99993205e-01, 1.00000000e+00, 2.88781479e-07],\n",
       "       [6.25995040e-01, 1.00000000e+00, 1.00000000e+00, 5.70607190e-05,\n",
       "        2.25496115e-06, 5.72950230e-05, 1.04652429e-02, 5.36933891e-04,\n",
       "        1.15586545e-06, 2.92520169e-02, 4.23738629e-01, 8.87763417e-06,\n",
       "        4.43622775e-06, 1.47782514e-04, 2.31930753e-03, 3.53392260e-03,\n",
       "        1.23563905e-05, 9.99974847e-01, 9.99999762e-01, 9.02504041e-07]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "concat_layer=Concatenate()\n",
    "concat_layer(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 18900), dtype=float32, numpy=\n",
       "array([[2.34226629e-01, 1.17113315e-01, 1.28824636e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.50371296e-08],\n",
       "       [1.70725927e-01, 1.70725927e-01, 1.25199005e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.50676777e-08]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=train_tensor[:2]\n",
    "x=tf.einsum('ai, ak -> aik', concat_layer(attentions), inputs)\n",
    "x=tf.reshape(x, (2,18900))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=tf.math.dd(tf.tensordot(x, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.034681212"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(LS_model_.layers[1].w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.keras.initializers.GlorotNormal()\n",
    "out=init(shape=(18900, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022216508"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022216508"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.min(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.976px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
