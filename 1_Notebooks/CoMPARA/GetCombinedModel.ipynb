{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results for combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from CoMPARA_experiment_helper import load_data, get_model, data_scaling, file_updater \n",
    "from CoMPARA_experiment_helper import get_model_setup_params, get_model_compile_params#, setup_callback_paths\n",
    "# from AOTexperiment_helper import cont_model_eval, get_cont_model_score\n",
    "from CoMPARA_experiment_helper import get_model_predictions\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "\n",
    "data_dict = load_data()\n",
    "train_features = data_dict['train_features']\n",
    "test_features = data_dict['test_features']\n",
    "train_targets = data_dict['train_targets']\n",
    "test_targets = data_dict['test_targets']\n",
    "train_Fweights = data_dict['Fweights_train']\n",
    "test_Fweights = data_dict['Fweights_test']\n",
    "labels = data_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get scaled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = None\n",
    "binary_labels = [0, 2, 4]\n",
    "train_features_scaled, test_features_scaled, train_targets_scaled, test_targets_scaled, feature_scaler, target_scaler = data_scaling(\n",
    "    feature_scaler,\n",
    "    target_scaler,\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_targets,\n",
    "    test_targets\n",
    ")\n",
    "n_feat = train_features_scaled.shape[1]\n",
    "\n",
    "def get_valid_ind(y):\n",
    "    ind = np.where(~np.isnan(y.astype(np.float32)))[0]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update this for each model_type\n",
    "# model_type = \"dense\"\n",
    "# super_folder = os.path.join(\"CoMPARA_singlelabelmodels\",\n",
    "#                             \"final_210429_dense_lr0_005\")\n",
    "\n",
    "# model_type = \"LS\"\n",
    "# super_folder = os.path.join(\"CoMPARA_singlelabelmodels\",\n",
    "#                             \"final_210429_LS_lr0_005\")\n",
    "\n",
    "# model_type = \"LSwFW\"\n",
    "# super_folder = os.path.join(\"CoMPARA_singlelabelmodels\",\n",
    "#                             \"final_210520_LSwFW_lr0_001\")\n",
    "\n",
    "# model_type = \"LSwFW_ones\"\n",
    "# super_folder = os.path.join(\"CoMPARA_singlelabelmodels\",\n",
    "#                             \"final_210520_LSwFW_lr0_001\")\n",
    "\n",
    "# f = os.walk(super_folder)\n",
    "# folder_names = next(f)[1]\n",
    "\n",
    "\n",
    "\n",
    "model_type = \"xgboost\"\n",
    "super_folder = \"CoMPARA_singlelabelmodels\"\n",
    "folder_names = [\n",
    "    \"210528_xgboost_AgonistClass\", \n",
    "    \"210528_xgboost_AntagonistClass\",\n",
    "    \"210528_xgboost_BindingClass\"\n",
    "]\n",
    "output_prefix = \"_\".join([model_type, \"CoMPARA\"])\n",
    "column_headers = labels[binary_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for each model_type\n",
    "train_predicts = []\n",
    "test_predicts = []\n",
    "for idx, label_idx in enumerate(binary_labels):\n",
    "    valid_train_ind = get_valid_ind(train_targets_scaled.values[:, label_idx])\n",
    "    valid_test_ind = get_valid_ind(test_targets_scaled.values[:, label_idx])\n",
    "    \n",
    "    endpoint=\"binary\"\n",
    "    n_endpoints=None\n",
    "#     n_endpoints = None\n",
    "#     if label_idx < 2:\n",
    "#         endpoint = \"binary\"\n",
    "#     elif label_idx == 2:\n",
    "#         endpoint = \"regression\"\n",
    "#     else:\n",
    "#         endpoint = \"multiclass\"\n",
    "#         n_endpoints = len(np.unique(\n",
    "#             train_targets_scaled[valid_train_ind, label_idx]))\n",
    "\n",
    "    checkpoint_path = os.path.join(super_folder,\n",
    "                                   folder_names[idx],\n",
    "                                   \"model_checkpoint\"\n",
    "                                   )\n",
    "    X_train = train_features_scaled\n",
    "    X_test = test_features_scaled\n",
    "    if model_type==\"xgboost\":\n",
    "        import xgboost as xgb\n",
    "        checkpoint_path = os.path.join(super_folder, \n",
    "                                       folder_names[idx]\n",
    "                                      )\n",
    "    elif model_type==\"LSwFW\":\n",
    "        X_train = np.hstack([train_features_scaled,train_Fweights])\n",
    "        X_test = np.hstack([test_features_scaled, test_Fweights])\n",
    "    elif model_type ==\"LSwFW_ones\":\n",
    "        X_train = np.hstack([train_features_scaled, \n",
    "                             np.ones_like(train_features_scaled)])\n",
    "        X_test = np.hstack([test_features_scaled,\n",
    "                            np.ones_like(test_features_scaled)\n",
    "                           ])\n",
    "    #Get predictions for all datapoints\n",
    "    a, b = get_model_predictions(\n",
    "        model_type,\n",
    "        checkpoint_path,\n",
    "        endpoint=endpoint,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        n_feat=n_feat,\n",
    "        target_scaler=target_scaler,\n",
    "        n_endpoints=n_endpoints\n",
    "    )\n",
    "    if a.ndim==1:\n",
    "        a = a.reshape(-1,1)\n",
    "        b = b.reshape(-1,1)\n",
    "    train_predicts.append(a)\n",
    "    test_predicts.append(b)\n",
    "\n",
    "train_predicts = pd.DataFrame(np.hstack(train_predicts),\n",
    "                              columns=column_headers)\n",
    "test_predicts = pd.DataFrame(np.hstack(test_predicts),\n",
    "                             columns=column_headers)\n",
    "train_predicts.to_csv(\"_\".join([output_prefix,\n",
    "                                \"train_predict\"\n",
    "                                ]), index=False)\n",
    "test_predicts.to_csv(\"_\".join([output_prefix,\n",
    "                               \"test_predict\"\n",
    "                               ]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get combined predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AgonistClass', 'Potency_Class_Agonist', 'AntagonistClass',\n",
       "       'Potency_Class_Antagonist', 'BindingClass', 'Potency_Class_Binding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_names = [\n",
    "#     \"210517_dense_AOT_wFP_very_toxic_\",\n",
    "#     \"210517_LS_AOT_wFP_very_toxic_\",\n",
    "#     \"210517_LSwFW_AOT_wFP_very_toxic_\",\n",
    "#     \"210517_LSwFW_ones_AOT_wFP_very_toxic_\"\n",
    "# ]\n",
    "\n",
    "label = \"BindingClass\"\n",
    "label_idx = 4\n",
    "\n",
    "folder_names = [\n",
    "    os.path.join(\"final_210429_dense_lr0_005\",\n",
    "        f\"210429_Dense_lr0_005_CoMPARA_binary_{label}\"),\n",
    "    os.path.join(\"final_210429_LS_lr0_005\",\n",
    "                 f\"210429_LS_lr0_005_CoMPARA_binary_{label}\"),\n",
    "    os.path.join(\"final_210520_LSwFW_lr0_001\",\n",
    "        f\"210520_LSwFW_lr0_001_CoMPARA_binary_{label}\"),\n",
    "    os.path.join(\"final_210520_LSwFW_ones_lr0_001\",\n",
    "        f\"210520_LSwFW_ones_lr0_001_CoMPARA_binary_{label}\")\n",
    "]\n",
    "\n",
    "# folder_names = [\n",
    "#     \"210515_dense_AOT_regression_LD50_mgkg\",\n",
    "#     \"210515_LS_AOT_regression_LD50_mgkg\",\n",
    "#     \"210516_LSwFW_AOT_regression_LD50_mgkg\",\n",
    "#     \"210516_LSwFW_ones_AOT_regression_LD50_mgkg\"\n",
    "# ]\n",
    "\n",
    "model_types = [\"dense\", \"LS\", \"LSwFW\", \"LSwFW_ones\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dense layer with 1200 hidden unites\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Get predictions for each model_type\n",
    "train_predicts = []\n",
    "test_predicts = []\n",
    "for idx, model_type in enumerate(model_types):\n",
    "    valid_train_ind = get_valid_ind(\n",
    "        train_targets_scaled.values[:, label_idx])\n",
    "    valid_test_ind = get_valid_ind(\n",
    "        test_targets_scaled.values[:, label_idx])\n",
    "    endpoint = \"binary\"\n",
    "    n_endpoints = None\n",
    "\n",
    "    checkpoint_path = os.path.join(\n",
    "        \"CoMPARA_singlelabelmodels\",\n",
    "        folder_names[idx],\n",
    "        \"model_checkpoint\"\n",
    "    )\n",
    "    if model_type == \"LSwFW\":\n",
    "        X_train = np.hstack([train_features_scaled[valid_train_ind],\n",
    "                             train_Fweights[valid_train_ind]\n",
    "                             ])\n",
    "        X_test = np.hstack([test_features_scaled[valid_test_ind],\n",
    "                            test_Fweights[valid_test_ind]\n",
    "                            ])\n",
    "    elif model_type == \"LSwFW_ones\":\n",
    "        X_train = np.hstack([\n",
    "            train_features_scaled[valid_train_ind],\n",
    "            np.ones_like(train_Fweights[valid_train_ind])\n",
    "        ])\n",
    "        X_test = np.hstack([\n",
    "            test_features_scaled[valid_test_ind],\n",
    "            np.ones_like(test_Fweights[valid_test_ind])\n",
    "        ])\n",
    "    else:\n",
    "        X_train = train_features_scaled[valid_train_ind]\n",
    "        X_test = test_features_scaled[valid_test_ind]\n",
    "    a, b = get_model_predictions(\n",
    "        model_type,\n",
    "        checkpoint_path,\n",
    "        endpoint=endpoint,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        n_feat=n_feat,\n",
    "        target_scaler=target_scaler,\n",
    "        n_endpoints=n_endpoints\n",
    "    )\n",
    "#     if endpoint ==\"multiclass\":\n",
    "#         a = np.expand_dims(np.argmax(a, axis=1)+1, axis=1)\n",
    "#         b = np.expand_dims(np.argmax(b, axis=1)+1, axis=1)\n",
    "    train_predicts.append(a)\n",
    "    test_predicts.append(b)\n",
    "\n",
    "train_predicts = pd.DataFrame(np.hstack(train_predicts),\n",
    "                              )  # columns=model_types)\n",
    "test_predicts = pd.DataFrame(np.hstack(test_predicts),\n",
    "                             )  # columns=model_types)\n",
    "# train_predicts.to_csv(\"_\".join([output_prefix,\n",
    "#                                 \"train_predict\"\n",
    "#                                 ]), index=False)\n",
    "# test_predicts.to_csv(\"_\".join([output_prefix,\n",
    "#                                \"test_predict\"\n",
    "#                                ]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoMPARA_experiment_helper import get_cm, get_sn_sp, get_qual_model_score\n",
    "def get_model_eval(y_train, y_test, train_predict, test_predict, num_classes=2):\n",
    "    if num_classes>2:\n",
    "        sn_train_list, sp_train_list = [],[]\n",
    "        sn_test_list, sp_test_list=[],[]\n",
    "        for i in range(num_classes):\n",
    "            if len(np.unique(y_train[:, i]))<2:\n",
    "                continue\n",
    "            cm = get_cm(y_train[:,i], train_predict[:,i], )\n",
    "            sn_train, sp_train = get_sn_sp(cm)\n",
    "            cm = get_cm(y_test[:,i], test_predict[:,i], )\n",
    "            sn_test, sp_test = get_sn_sp(cm)\n",
    "            sn_train_list.append(sn_train)\n",
    "            sp_train_list.append(sp_train)\n",
    "            sn_test_list.append(sn_test)\n",
    "            sp_test_list.append(sp_test)\n",
    "        sn_train = np.mean(sn_train_list)\n",
    "        sp_train = np.mean(sp_train_list)\n",
    "        sn_test = np.mean(sn_test_list)\n",
    "        sp_test = np.mean(sp_test_list)\n",
    "    else:\n",
    "        cm = get_cm(y_train, train_predict, num_classes=num_classes)\n",
    "        sn_train, sp_train = get_sn_sp(cm)\n",
    "        cm = get_cm(y_test, test_predict)\n",
    "        sn_test, sp_test = get_sn_sp(cm)\n",
    "    model_score = get_qual_model_score(sn_train, sp_train, sn_test, sp_test)\n",
    "    return model_score, (sn_train, sp_train, sn_test, sp_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8107716141643768, (0.9595959595959596, 0.950136612021858, 0.577433628318584, 0.9067055393586005))\n"
     ]
    }
   ],
   "source": [
    "model_ind=[0,1]\n",
    "\n",
    "y_train = train_targets_scaled.values[valid_train_ind, label_idx]\n",
    "y_test = test_targets_scaled.values[valid_test_ind, label_idx]\n",
    "combined_train_predict = np.mean(\n",
    "    train_predicts.values[:,model_ind], axis=1)\n",
    "combined_test_predict = np.mean(test_predicts.values[:,model_ind],\n",
    "                       axis=1)\n",
    "if endpoint==\"binary\":\n",
    "    r=get_model_eval(y_train.astype(int), y_test.astype(int), \n",
    "               train_predict=combined_train_predict>0.5,\n",
    "               test_predict=combined_test_predict>0.5,\n",
    "              )\n",
    "    print(r)\n",
    "elif endpoint==\"multiclass\":\n",
    "    combined_train_predict = [train_predicts.values[:, \n",
    "            i*n_endpoints:(i+1)*n_endpoints]\n",
    "                             for i in model_ind]\n",
    "    combined_train_predict = to_categorical(np.argmax(\n",
    "        np.mean(combined_train_predict, axis=0),\n",
    "        axis=1\n",
    "    ), num_classes=n_endpoints)\n",
    "    combined_test_predict = [test_predicts.values[:, \n",
    "            i*n_endpoints:(i+1)*n_endpoints] \n",
    "                             for i in model_ind]\n",
    "    combined_test_predict = to_categorical(np.argmax(\n",
    "        np.mean(combined_test_predict, axis=0), \n",
    "        axis=1\n",
    "    ), num_classes=n_endpoints)\n",
    "    y_train = to_categorical(y_train.astype(int)-1)\n",
    "    y_test = to_categorical(y_test.astype(int)-1)\n",
    "    r=get_model_eval(y_train, y_test, \n",
    "                     train_predict=combined_train_predict,\n",
    "                     test_predict=combined_test_predict,\n",
    "                     num_classes=n_endpoints\n",
    "                    )    \n",
    "    print(r)\n",
    "else:\n",
    "    y_train = np.log10(y_train.astype(np.float32))\n",
    "    y_test = y_test.astype(np.float32)\n",
    "    ind = np.where(y_test>10000.)[0]\n",
    "    y_test[ind]=10000.\n",
    "    y_test = np.log10(y_test)\n",
    "    \n",
    "    from sklearn.metrics import r2_score, mean_squared_error\n",
    "    r2_train = r2_score(y_train, combined_train_predict)\n",
    "    r2_test = r2_score(y_test, combined_test_predict)\n",
    "    model_score = (0.3*r2_train) + (0.45*r2_test) +(0.25*(1-np.abs(r2_train-r2_test)))\n",
    "    print(model_score, r2_train, r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RF/XGBoost \"Stacking\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def tune_xgbc(params, X_train, y_train, X_test, y_test, regression=False, \n",
    "\tobjective = \"reg:logistic\", eval_metric='logloss'):\n",
    "# Implementation learned on a lesson of Mario Filho (Kagle Grandmaster) for parametes optmization.\n",
    "# Link to the video: https://www.youtube.com/watch?v=WhnkeasZNHI\n",
    "\n",
    "\t\"\"\"Function to be passed as scikit-optimize minimizer/maximizer input\n",
    "\n",
    "\tParameters:\n",
    "\tTuples with information about the range that the optimizer should use for that parameter, \n",
    "\tas well as the behaviour that it should follow in that range.\n",
    "\n",
    "\tReturns:\n",
    "\tfloat: the metric that should be minimized. If the objective is maximization, then the negative \n",
    "\tof the desired metric must be returned. In this case, the negative AUC average generated by CV is returned.\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "\t#Hyperparameters to be optimized\n",
    "\tprint(params)\n",
    "\tlearning_rate = params[0] \n",
    "\tn_estimators = params[1] \n",
    "\tmax_depth = params[2]\n",
    "\tmin_child_weight = params[3]\n",
    "\tgamma = params[4]\n",
    "\tsubsample = params[5]\n",
    "\tcolsample_bytree = params[6]\n",
    "\n",
    "\n",
    "\t#Model to be optimized\n",
    "\tif regression:\n",
    "\t\tsample_weight = None  \t\n",
    "\t\n",
    "\t\tmdl = xgb.XGBRegressor(learning_rate = learning_rate, \n",
    "\t\t\t\t\t\t\tn_estimators = n_estimators, \n",
    "\t\t\t\t\t\t\tmax_depth = max_depth, \n",
    "\t\t\t\t\t\t\tmin_child_weight = min_child_weight, \n",
    "\t\t\t\t\t\t\tgamma = gamma, \n",
    "\t\t\t\t\t\t\tsubsample = subsample, \n",
    "\t\t\t\t\t\t\tcolsample_bytree = colsample_bytree, \n",
    "\t\t\t\t\t\t\tobjective=objective,\n",
    "\t\t\t\t\t\t\tuse_label_encoder=False,\n",
    "\t\t\t\t\t\t\tseed = 42\n",
    "\t\t\t\t\t\t\t)\n",
    "\telse:\n",
    "\t\tsample_weight = compute_sample_weight(\"balanced\", y_train)    \t\n",
    "\t\tmdl = xgb.XGBClassifier(learning_rate = learning_rate, \n",
    "\t\t\t\t\t\t\tn_estimators = n_estimators, \n",
    "\t\t\t\t\t\t\tmax_depth = max_depth, \n",
    "\t\t\t\t\t\t\tmin_child_weight = min_child_weight, \n",
    "\t\t\t\t\t\t\tgamma = gamma, \n",
    "\t\t\t\t\t\t\tsubsample = subsample, \n",
    "\t\t\t\t\t\t\tcolsample_bytree = colsample_bytree, \n",
    "\t\t\t\t\t\t\tobjective=objective,\n",
    "\t\t\t\t\t\t\tuse_label_encoder=False,\n",
    "\t\t\t\t\t\t\teval_metric=eval_metric,\n",
    "\t\t\t\t\t\t\tseed = 42)\n",
    "\n",
    "\n",
    "\n",
    "\t# #Cross-Validation in order to avoid overfitting\n",
    "\t# auc = cross_val_score(mdl, X_train_selected, y_train, cv = 10, scoring = 'roc_auc')\n",
    "\n",
    "\tmdl.fit(X_train, y_train, sample_weight = sample_weight)\n",
    "\tif regression:\n",
    "\t\ttest_predict = mdl.predict(X_test)\n",
    "\t\tres = mean_squared_error(y_test, test_predict, squared=False)\n",
    "\telse:\n",
    "\t\ttest_predict = mdl.predict_proba(X_test)\n",
    "\t\ty_test=y_test.astype(int)\n",
    "\t\tif test_predict.shape[1]==2:\n",
    "\t\t\ttest_predict=test_predict[:, 1]\n",
    "\t\tres = roc_auc_score(y_test, test_predict, multi_class = 'ovr')\n",
    "\n",
    "\tprint(res.mean())\n",
    "\t# as the function is minimization (forest_minimize), we need to use the negative of the desired metric (AUC)\n",
    "\treturn -res.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoMPARA_experiment_helper import load_data, get_model, data_scaling, file_updater \n",
    "\n",
    "data_dict = load_data()\n",
    "train_features = data_dict['train_features']\n",
    "test_features = data_dict['test_features']\n",
    "train_targets = data_dict['train_targets']\n",
    "test_targets = data_dict['test_targets']\n",
    "train_Fweights = data_dict['Fweights_train']\n",
    "test_Fweights = data_dict['Fweights_test']\n",
    "labels = data_dict['labels']\n",
    "\n",
    "#Get scaled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = None\n",
    "binary_labels = [0, 2, 4]\n",
    "train_features_scaled, test_features_scaled, train_targets_scaled, test_targets_scaled, feature_scaler, target_scaler = data_scaling(\n",
    "    feature_scaler,\n",
    "    target_scaler,\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_targets,\n",
    "    test_targets\n",
    ")\n",
    "n_feat = train_features_scaled.shape[1]\n",
    "\n",
    "def get_valid_ind(y):\n",
    "    ind = np.where(~np.isnan(y.astype(np.float32)))[0]\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "label_idx = binary_labels[2]\n",
    "\n",
    "valid_train_ind = get_valid_ind(\n",
    "    train_targets.values[:, label_idx])\n",
    "valid_test_ind = get_valid_ind(\n",
    "    test_targets.values[:,label_idx])\n",
    "y_train = train_targets.values[valid_train_ind, label_idx].astype(int)\n",
    "y_test = test_targets.values[valid_test_ind, label_idx].astype(int)\n",
    "X_train = train_features_scaled[valid_train_ind]\n",
    "X_test = test_features_scaled[valid_test_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.03918194347141743, 1394, 8, 3.9932924209851834, 0.07800932022121827, 0.5779972601681014, 0.5290418060840998]\n",
      "0.8388461389612736\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 10.0760\n",
      "Function value obtained: -0.8388\n",
      "Current minimum: -0.8388\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.05399484409787437, 1223, 8, 4.540362888980228, 0.010292247147901225, 0.9849549260809973, 0.916221320400211]\n",
      "0.8383085218916897\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 12.8790\n",
      "Function value obtained: -0.8383\n",
      "Current minimum: -0.8388\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.0026587543983272693, 1315, 5, 4.087407548138583, 0.3058265802441405, 0.5035331526098588, 0.5115312125207079]\n",
      "0.8385552387832503\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 13.1573\n",
      "Function value obtained: -0.8386\n",
      "Current minimum: -0.8388\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.011208547084229371, 610, 10, 1.2333283160680772, 0.4868777594207297, 0.6163856702151521, 0.5453032172664104]\n",
      "0.8438611032276374\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 9.5667\n",
      "Function value obtained: -0.8439\n",
      "Current minimum: -0.8439\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.017249321573179006, 1999, 7, 5.916154429033941, 0.23338144662399002, 0.9299702033681604, 0.8401537692938899]\n",
      "0.8397036817255348\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 24.4243\n",
      "Function value obtained: -0.8397\n",
      "Current minimum: -0.8439\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.007961566078062952, 1397, 4, 5.711008778424264, 0.2816441089227697, 0.692708251269958, 0.5079831261101071]\n",
      "0.8426136510229882\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 12.5549\n",
      "Function value obtained: -0.8426\n",
      "Current minimum: -0.8439\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.002895927274708839, 191, 7, 4.049983288913105, 0.4165974558680823, 0.5866823267538861, 0.6955303037866205]\n",
      "0.8467581722954669\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 3.1407\n",
      "Function value obtained: -0.8468\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.0023145798905204883, 1511, 2, 3.1257793724562237, 0.10397083143409444, 0.7838501639099957, 0.5156566462277793]\n",
      "0.8227585851028147\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 9.6097\n",
      "Function value obtained: -0.8228\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.04836927180682224, 1679, 2, 2.9757511800090723, 0.4633294328968972, 0.8636359979282104, 0.6632703844029177]\n",
      "0.8320699708454811\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 11.7412\n",
      "Function value obtained: -0.8321\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.013832094546570485, 1375, 9, 5.805860121746746, 0.4222669243390758, 0.8736600550686905, 0.7698460661945399]\n",
      "0.8434295905467117\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 18.9838\n",
      "Function value obtained: -0.8434\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.014910847596941088, 316, 9, 2.481367528520412, 0.08263346953150126, 0.507818203370597, 0.7117007403531849]\n",
      "0.8384936401867954\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 5.2237\n",
      "Function value obtained: -0.8385\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.006162586615353729, 747, 8, 1.0703991135754223, 0.0994212020444026, 0.8556709763743251, 0.8950877702656029]\n",
      "0.8425081916458113\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 19.7130\n",
      "Function value obtained: -0.8425\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.016289957436723502, 1613, 7, 4.255385127509722, 0.4574798377718905, 0.9250192888948998, 0.7247253370691018]\n",
      "0.8428252147888233\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 20.0632\n",
      "Function value obtained: -0.8428\n",
      "Current minimum: -0.8468\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.0015517445651473882, 602, 7, 4.344206263318037, 0.3329611783087484, 0.7956488938538636, 0.6373608964950321]\n",
      "0.8483919863773575\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 10.4454\n",
      "Function value obtained: -0.8484\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.013258269776216493, 1862, 5, 5.858560476945519, 0.42445691213304204, 0.8608647605824367, 0.6179924598744779]\n",
      "0.8406457209938337\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 18.9558\n",
      "Function value obtained: -0.8406\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.003251895982771604, 894, 9, 4.553314448428937, 0.05544541040591568, 0.7196682509328851, 0.6008596011676981]\n",
      "0.8369307773678373\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 14.4458\n",
      "Function value obtained: -0.8369\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.061876706758809547, 1364, 4, 3.8163778598819187, 0.3477580432130638, 0.5696657272029378, 0.8022086896389087]\n",
      "0.836159988647798\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 10.6469\n",
      "Function value obtained: -0.8362\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.012013849374287178, 640, 4, 5.714267852789906, 0.29943273324426806, 0.8473924665198523, 0.940233919507629]\n",
      "0.8403512732526639\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 9.8152\n",
      "Function value obtained: -0.8404\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.01772997389934229, 1697, 9, 1.5274712991513533, 0.22826728524145518, 0.6092202186084168, 0.7082549739351831]\n",
      "0.8426207461492814\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 20.5682\n",
      "Function value obtained: -0.8426\n",
      "Current minimum: -0.8484\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.05841986080198009, 1763, 10, 1.6104397735033669, 0.17814891903848748, 0.9534142207728771, 0.6360661246923177]\n",
      "0.8512593849170516\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 17.0184\n",
      "Function value obtained: -0.8513\n",
      "Current minimum: -0.8513\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.0013742289135193493, 423, 5, 1.288116908420809, 0.3569050986720037, 0.7764504128473618, 0.5013835500547941]\n",
      "0.8509062411310921\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.4492\n",
      "Function value obtained: -0.8509\n",
      "Current minimum: -0.8513\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.0011665357917163477, 544, 4, 2.415644424936197, 0.42421307719945534, 0.8012801607949451, 0.5464480758675369]\n",
      "0.847795673262984\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.3430\n",
      "Function value obtained: -0.8478\n",
      "Current minimum: -0.8513\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.0016700665600093338, 1099, 1, 1.321320233089879, 0.39890448218492963, 0.8884987688057875, 0.5186518809381448]\n",
      "0.7904073892515286\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.9221\n",
      "Function value obtained: -0.7904\n",
      "Current minimum: -0.8513\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.0014241735774323712, 481, 3, 2.4826881335953654, 0.4034840797423385, 0.6724059520250179, 0.5189086133341406]\n",
      "0.8367830697386414\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.1600\n",
      "Function value obtained: -0.8368\n",
      "Current minimum: -0.8513\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.001659163613857964, 1351, 6, 1.0757439444327053, 0.33679493335389304, 0.94130930192512, 0.5403868749895289]\n",
      "0.8461699218246086\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.2519\n",
      "Function value obtained: -0.8462\n",
      "Current minimum: -0.8513\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from skopt import forest_minimize\n",
    "import dill as pickle\n",
    "# from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "# sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "# for _train_ind, _val_ind in sss.split(list(range(len(y_train))), y_train):\n",
    "#     break\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # learning rate\n",
    "        (100, 2000), # n_estimators\n",
    "        (1, 10), # max_depth \n",
    "        (1, 6.), # min_child_weight \n",
    "        (0, 0.5), # gamma \n",
    "        (0.5, 1.), # subsample \n",
    "        (0.5, 1.)] # colsample_bytree \n",
    "func = partial(tune_xgbc, \n",
    "               X_train = X_train,\n",
    "               y_train = y_train, \n",
    "               X_test = X_test,\n",
    "               y_test = y_test, \n",
    "               objective = \"binary:logistic\",\n",
    "               regression = False,\n",
    "               eval_metric=\"logloss\"\n",
    "              )\n",
    "result = forest_minimize(func, space, random_state=42, n_random_starts=20, n_calls=25, verbose=1)\n",
    "\n",
    "with open(f\"xgboost_{labels[label_idx]}_params.ob\", 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"xgboost_{labels[label_idx]}_params.ob\", 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "params = params['x']\n",
    "learning_rate = params[0] \n",
    "n_estimators = params[1] \n",
    "max_depth = params[2]\n",
    "min_child_weight = params[3]\n",
    "gamma = params[4]\n",
    "subsample = params[5]\n",
    "colsample_bytree = params[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cavio\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:444: UserWarning: n_estimators is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.')\n",
      "c:\\users\\cavio\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:444: UserWarning: max_depth is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(\"balanced\", y_train)\n",
    "model = xgb.XGBClassifier(\n",
    "                          learning_rate=learning_rate,\n",
    "                          n_estimators=n_estimators,\n",
    "                          max_depth=max_depth,\n",
    "                          min_child_weight=min_child_weight,\n",
    "                          gamma=gamma,\n",
    "                          subsample=subsample,\n",
    "                          colsample_bytree=colsample_bytree,\n",
    "                          use_label_encoder=False,\n",
    "                          objective=\"binary:logistic\",\n",
    "                          eval_metric=\"logloss\",\n",
    "                          random_state=42)\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          sample_weight=sample_weights\n",
    "          )\n",
    "model.save_model(os.path.join(\"CoMPARA_singlelabelmodels\", \n",
    "                              \"_\".join([time.strftime(\"%y%m%d\", time.localtime()), \n",
    "                                                                     \"xgboost\", labels[label_idx] \n",
    "                                       ] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7139177416858019, (1.0, 1.0, 0.3185840707964602, 0.9892128279883382))\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(\n",
    "    train_features_scaled[valid_train_ind])\n",
    "test_predict = model.predict(\n",
    "    test_features_scaled[valid_test_ind])\n",
    "r=get_model_eval(\n",
    "    y_train,\n",
    "    y_test, \n",
    "    train_predict=train_predict>0.5,\n",
    "    test_predict=test_predict>0.5,\n",
    "    num_classes=2\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
