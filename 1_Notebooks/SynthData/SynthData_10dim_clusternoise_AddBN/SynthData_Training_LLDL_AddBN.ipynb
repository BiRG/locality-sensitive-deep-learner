{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally-Linear Deep Learner on Synthetic Data\n",
    "Uses attention_model (v3). Additions:  \n",
    "    - Batch Normalization to the hidden layer after concat.    \n",
    "    - Similarity batching (to be implemented)  \n",
    "    - Softmax layer/Activity Regularizer (?) for Concat layer  \n",
    "Synth data: (10-dimension with cluster-specific noise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TMPDIR=/tmp/temp\n"
     ]
    }
   ],
   "source": [
    "%env TMPDIR=/tmp/temp \n",
    "#For joblib multi-threading\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "code_folder=os.path.join(os.getcwd(), \"..\", \"..\", \"0_code\")\n",
    "sys.path.append(code_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"SynthData_10dim_clusternoise.csv\",\n",
    "               index_col=0\n",
    "              )\n",
    "Fweights_df=pd.read_csv(\"Fweights.csv\")\n",
    "Fweights_test_df=pd.read_csv(\"Fweights_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>cluster_labels</th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.578484</td>\n",
       "      <td>-1.959433</td>\n",
       "      <td>-0.637669</td>\n",
       "      <td>1.834927</td>\n",
       "      <td>-0.795933</td>\n",
       "      <td>-0.989418</td>\n",
       "      <td>-0.975603</td>\n",
       "      <td>0.837159</td>\n",
       "      <td>-0.806057</td>\n",
       "      <td>-1.151965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300661</td>\n",
       "      <td>1.084462</td>\n",
       "      <td>1.453934</td>\n",
       "      <td>1.188252</td>\n",
       "      <td>-1.842271</td>\n",
       "      <td>0.979053</td>\n",
       "      <td>-0.662538</td>\n",
       "      <td>1.058707</td>\n",
       "      <td>-0.204496</td>\n",
       "      <td>0.741998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.473968</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>-0.504463</td>\n",
       "      <td>0.676847</td>\n",
       "      <td>-1.335443</td>\n",
       "      <td>-0.068589</td>\n",
       "      <td>0.397734</td>\n",
       "      <td>-1.835240</td>\n",
       "      <td>-0.494869</td>\n",
       "      <td>-0.483825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386544</td>\n",
       "      <td>0.385803</td>\n",
       "      <td>0.315255</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>0.041539</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>-1.616635</td>\n",
       "      <td>-0.335498</td>\n",
       "      <td>1.192081</td>\n",
       "      <td>0.282956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.994573</td>\n",
       "      <td>1.794217</td>\n",
       "      <td>-0.156877</td>\n",
       "      <td>1.806804</td>\n",
       "      <td>-0.165868</td>\n",
       "      <td>-0.320657</td>\n",
       "      <td>1.014013</td>\n",
       "      <td>1.703030</td>\n",
       "      <td>-1.216164</td>\n",
       "      <td>1.149043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  cluster_labels  Class  feat_000  feat_001  feat_002  feat_003  \\\n",
       "0  Training               1      1 -1.578484 -1.959433 -0.637669  1.834927   \n",
       "1  Training               3      1 -0.300661  1.084462  1.453934  1.188252   \n",
       "2  Training               0      1  1.473968 -0.632456 -0.504463  0.676847   \n",
       "3  Training               4      0  1.386544  0.385803  0.315255  1.005859   \n",
       "4  Training               3      0 -0.994573  1.794217 -0.156877  1.806804   \n",
       "\n",
       "   feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \n",
       "0 -0.795933 -0.989418 -0.975603  0.837159 -0.806057 -1.151965  \n",
       "1 -1.842271  0.979053 -0.662538  1.058707 -0.204496  0.741998  \n",
       "2 -1.335443 -0.068589  0.397734 -1.835240 -0.494869 -0.483825  \n",
       "3  0.041539  0.130468 -1.616635 -0.335498  1.192081  0.282956  \n",
       "4 -0.165868 -0.320657  1.014013  1.703030 -1.216164  1.149043  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fweights_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'cluster_labels', 'Class', 'feat_000', 'feat_001', 'feat_002',\n",
       "       'feat_003', 'feat_004', 'feat_005', 'feat_006', 'feat_007', 'feat_008',\n",
       "       'feat_009'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df[df['Type']==\"Training\"].iloc[:, 3:]\n",
    "X_test=df[df['Type']==\"Testing\"].iloc[:,3:]\n",
    "y_train=df[df['Type']==\"Training\"].iloc[:,2]\n",
    "y_test=df[df['Type']==\"Testing\"].iloc[:,2]\n",
    "Fweights_train=Fweights_df.values\n",
    "Fweights_test=Fweights_test_df.values\n",
    "\n",
    "cluster_labels_train=df[df['Type']=='Training']['cluster_labels']\n",
    "cluster_labels_test=df[df['Type']=='Testing']['cluster_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=X_train.values\n",
    "train_targets=np.expand_dims(y_train, axis=1).astype(np.float32)\n",
    "test_data=X_test.values\n",
    "test_targets=np.expand_dims(y_test, axis=1).astype(np.float32)\n",
    "train_Fweights=Fweights_train\n",
    "test_Fweights=Fweights_test\n",
    "\n",
    "train_tensor=np.hstack([train_data, train_Fweights])\n",
    "test_tensor=np.hstack([test_data, test_Fweights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LLDL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 6th Jan 2021 (Edited Line 71 to Line 72. Reduce_mean instead of mean, to preserve the required rank)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "epsilon=K.epsilon\n",
    "\n",
    "def get_weights_dicts(Y):\n",
    "    weights_dicts=[]\n",
    "    for j in range(Y.shape[1]):\n",
    "        weight_zero, weight_one = _get_label_weights(Y[:,j])\n",
    "        d={'weight_zero':weight_zero,\n",
    "           'weight_one':weight_one\n",
    "          }\n",
    "        weights_dicts.append(d)\n",
    "    return weights_dicts\n",
    "def _get_label_weights(y):\n",
    "    #Get label weights for majority and minority class using the following:\n",
    "        #major_weight=n/(n_major*2)\n",
    "        #minor_weight=n*(n_major/n_minor)/(n_major*2)\n",
    "        #NaN weights are set to zero\n",
    "    y1=y[~np.isnan(y)]\n",
    "    n=len(y1)\n",
    "    n_zero=np.count_nonzero(np.isclose(y1,0))\n",
    "    n_one=np.count_nonzero(np.isclose(y1,1))\n",
    "    if n_zero>n_one:\n",
    "        weight_zero=n/(n_zero*2)\n",
    "        weight_one=n*(n_zero/n_one)/(n_zero*2)\n",
    "    else:\n",
    "        weight_zero=n*(n_one/n_zero)/(n_one*2)\n",
    "        weight_one=n/(n_one*2)\n",
    "    return weight_zero, weight_one    \n",
    "\n",
    "class BinaryCrossEntropyIgnoreNaN(tf.keras.losses.Loss):\n",
    "    def __init__(self, weights_dicts=None, axis=0, **kwargs):\n",
    "        super(BinaryCrossEntropyIgnoreNaN, self).__init__(**kwargs)\n",
    "        self.weights_dicts=weights_dicts\n",
    "        self.axis=axis        \n",
    "\n",
    "    def __call__(self, target, output, sample_weight=None):\n",
    "        #Binary cross entropy that ignores Nan and replaces with mini-batch Nan with 0\n",
    "        #modified from tf.python.keras.backend.binary_crossentropy\n",
    "        \n",
    "        ##NEED TO TEST THIS CODE MORE THOROUGHLY\n",
    "        target=tf.convert_to_tensor(target)\n",
    "        output=tf.convert_to_tensor(output)\n",
    "        if len(target.shape)==1:\n",
    "            target=tf.expand_dims(target, 1)\n",
    "            output=tf.expand_dims(output, 1)\n",
    "        epsilon_ = tf.constant(epsilon(), dtype=output.dtype.base_dtype)\n",
    "        output=tf.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "\n",
    "        #Compute cross entropy from probabilities\n",
    "        bce=target * tf.math.log(output+epsilon_)\n",
    "        bce+=(1-target)* tf.math.log(1-output+epsilon_)\n",
    "\n",
    "        bce=tf.where(tf.math.is_nan(-bce), epsilon(), -bce)\n",
    "        if self.weights_dicts is not None:\n",
    "            sample_weight=tf.cast(tf.where(target==0.,1.,0.)*[self.weights_dicts[i]['weight_zero'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            sample_weight+=tf.cast(tf.where(target==1., 1., 0.)*[self.weights_dicts[i]['weight_one'] for i in range(len(self.weights_dicts))], dtype=target.dtype)\n",
    "            bce=tf.multiply(sample_weight, bce)\n",
    "#         return tf.keras.backend.mean(bce, axis=self.axis)  \n",
    "        return tf.math.reduce_mean(bce)\n",
    "\n",
    "    def call(self, target, output, sample_weight=None):\n",
    "        return self(target, output, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = train_data.shape[1]\n",
    "n_attention = 10 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=40\n",
    "n_attention_out=1\n",
    "n_concat_hidden=128\n",
    "n_hidden1 =64\n",
    "n_hidden2 = 64\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=8\n",
    "\n",
    "label=\"SynthData\"\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewFW\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"LocalitySensitivewFW_{}\".format(label),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"selu\"\n",
    "attention_hidden_activation=\"selu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"selu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attention_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-11a37aafa2a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'attention_model' is not defined"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(attention_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "input_layer=Input(shape=(n_feat*2, ))\n",
    "\n",
    "attentions_layer=attention_model.ConcatAttentionswFeatWeights(\n",
    "    n_attention=n_attention,\n",
    "    n_attention_hidden=n_attention_hidden,\n",
    "    n_attention_out=n_attention_out,\n",
    "    n_feat=n_feat,\n",
    "    n_hidden=n_concat_hidden,\n",
    "    activation=concat_activation, \n",
    "    kernel_initializer=kernel_initializer,\n",
    "    kernel_regularizer=l2(1E-5),\n",
    "    bias_regularizer=l2(1E-5),\n",
    "    attention_initializer=kernel_initializer,\n",
    "    attention_hidden_activation=attention_hidden_activation,\n",
    "    attention_output_activation=attention_output_activation,\n",
    "    batch_norm_kwargs={\"trainable\":False, \"renorm\":False},\n",
    ")(input_layer)\n",
    "##Removed dropout for attentions_layer because of Batch normalization\n",
    "# dropout0=Dropout(0.1)(attentions_layer)\n",
    "dense_layer1=Dense(n_hidden1, \n",
    "                   activation=hidden_activation, \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5),\n",
    "                  )(attentions_layer)\n",
    "# dropout1=Dropout(0.1)(dense_layer1)\n",
    "dense_layer2=Dense(n_hidden2,\n",
    "                   activation=hidden_activation,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5)\n",
    "                  )(dense_layer1)\n",
    "# dropout2=Dropout(0.1)(dense_layer2)\n",
    "output_layer=Dense(1, activation=\"sigmoid\")(dense_layer2)\n",
    "\n",
    "LSwFW_model=Model(inputs=input_layer, \n",
    "                  outputs=output_layer\n",
    "                 )\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "# loss_fn=tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "LSwFW_model.compile(loss=loss_fn,\n",
    "    #loss=BinaryCrossentropy(from_logits=False, \n",
    "#                                             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "#                                            ), \n",
    "              optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy',]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "concat_attentionsw_feat_weig (None, 128)               18350     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,831\n",
      "Trainable params: 30,319\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSwFW_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "113/113 - 13s - loss: 0.6201 - accuracy: 0.6822 - val_loss: 0.6268 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 2/2000\n",
      "113/113 - 7s - loss: 0.4969 - accuracy: 0.7578 - val_loss: 0.6136 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69000 to 0.70000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 3/2000\n",
      "113/113 - 7s - loss: 0.4227 - accuracy: 0.8133 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70000 to 0.75000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 4/2000\n",
      "113/113 - 7s - loss: 0.4063 - accuracy: 0.8211 - val_loss: 0.5325 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75000 to 0.76000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 5/2000\n",
      "113/113 - 7s - loss: 0.3561 - accuracy: 0.8500 - val_loss: 0.5408 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76000\n",
      "Epoch 6/2000\n",
      "113/113 - 7s - loss: 0.3911 - accuracy: 0.8211 - val_loss: 0.6033 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76000\n",
      "Epoch 7/2000\n",
      "113/113 - 7s - loss: 0.3542 - accuracy: 0.8522 - val_loss: 0.4672 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.76000 to 0.83000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 8/2000\n",
      "113/113 - 7s - loss: 0.3207 - accuracy: 0.8656 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83000\n",
      "Epoch 9/2000\n",
      "113/113 - 7s - loss: 0.3058 - accuracy: 0.8867 - val_loss: 0.4476 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83000\n",
      "Epoch 10/2000\n",
      "113/113 - 7s - loss: 0.2822 - accuracy: 0.8889 - val_loss: 0.4834 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83000\n",
      "Epoch 11/2000\n",
      "113/113 - 7s - loss: 0.2726 - accuracy: 0.8800 - val_loss: 0.4903 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83000\n",
      "Epoch 12/2000\n",
      "113/113 - 7s - loss: 0.2658 - accuracy: 0.8878 - val_loss: 0.6458 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83000\n",
      "Epoch 13/2000\n",
      "113/113 - 7s - loss: 0.2400 - accuracy: 0.9033 - val_loss: 0.4541 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83000 to 0.85000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 14/2000\n",
      "113/113 - 7s - loss: 0.2476 - accuracy: 0.9000 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.85000\n",
      "Epoch 15/2000\n",
      "113/113 - 7s - loss: 0.2194 - accuracy: 0.9100 - val_loss: 0.4705 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85000\n",
      "Epoch 16/2000\n",
      "113/113 - 7s - loss: 0.2136 - accuracy: 0.9189 - val_loss: 0.4580 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85000\n",
      "Epoch 17/2000\n",
      "113/113 - 7s - loss: 0.2265 - accuracy: 0.9056 - val_loss: 0.4794 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85000\n",
      "Epoch 18/2000\n",
      "113/113 - 7s - loss: 0.2121 - accuracy: 0.9122 - val_loss: 0.5401 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85000\n",
      "Epoch 19/2000\n",
      "113/113 - 7s - loss: 0.1736 - accuracy: 0.9400 - val_loss: 0.6244 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85000\n",
      "Epoch 20/2000\n",
      "113/113 - 7s - loss: 0.1804 - accuracy: 0.9289 - val_loss: 0.4811 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85000\n",
      "Epoch 21/2000\n",
      "113/113 - 7s - loss: 0.2032 - accuracy: 0.9111 - val_loss: 0.4763 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85000\n",
      "Epoch 22/2000\n",
      "113/113 - 7s - loss: 0.1739 - accuracy: 0.9289 - val_loss: 0.5312 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85000\n",
      "Epoch 23/2000\n",
      "113/113 - 7s - loss: 0.1879 - accuracy: 0.9300 - val_loss: 0.4817 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85000 to 0.87000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 24/2000\n",
      "113/113 - 7s - loss: 0.1660 - accuracy: 0.9344 - val_loss: 0.5318 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.87000\n",
      "Epoch 25/2000\n",
      "113/113 - 7s - loss: 0.1497 - accuracy: 0.9300 - val_loss: 0.5511 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.87000\n",
      "Epoch 26/2000\n",
      "113/113 - 7s - loss: 0.1334 - accuracy: 0.9511 - val_loss: 0.4596 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.87000\n",
      "Epoch 27/2000\n",
      "113/113 - 7s - loss: 0.1419 - accuracy: 0.9411 - val_loss: 0.5823 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.87000\n",
      "Epoch 28/2000\n",
      "113/113 - 7s - loss: 0.1874 - accuracy: 0.9289 - val_loss: 0.9231 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.87000\n",
      "Epoch 29/2000\n",
      "113/113 - 7s - loss: 0.2011 - accuracy: 0.9244 - val_loss: 0.4517 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.87000\n",
      "Epoch 30/2000\n",
      "113/113 - 7s - loss: 0.1337 - accuracy: 0.9478 - val_loss: 0.4857 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.87000\n",
      "Epoch 31/2000\n",
      "113/113 - 7s - loss: 0.1175 - accuracy: 0.9589 - val_loss: 0.5109 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.87000\n",
      "Epoch 32/2000\n",
      "113/113 - 7s - loss: 0.1073 - accuracy: 0.9600 - val_loss: 0.5639 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.87000\n",
      "Epoch 33/2000\n",
      "113/113 - 7s - loss: 0.1069 - accuracy: 0.9611 - val_loss: 0.4881 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.87000 to 0.88000, saving model to 210219_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_SynthData\n",
      "Epoch 34/2000\n",
      "113/113 - 7s - loss: 0.0981 - accuracy: 0.9633 - val_loss: 0.5205 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.88000\n",
      "Epoch 35/2000\n",
      "113/113 - 7s - loss: 0.0970 - accuracy: 0.9667 - val_loss: 0.6013 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.88000\n",
      "Epoch 36/2000\n",
      "113/113 - 7s - loss: 0.0971 - accuracy: 0.9700 - val_loss: 0.5514 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.88000\n",
      "Epoch 37/2000\n",
      "113/113 - 7s - loss: 0.1999 - accuracy: 0.9400 - val_loss: 0.6943 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.88000\n",
      "Epoch 38/2000\n",
      "113/113 - 7s - loss: 0.1206 - accuracy: 0.9567 - val_loss: 0.5115 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.88000\n",
      "Epoch 39/2000\n",
      "113/113 - 7s - loss: 0.1413 - accuracy: 0.9478 - val_loss: 0.6928 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.88000\n",
      "Epoch 40/2000\n",
      "113/113 - 7s - loss: 0.1174 - accuracy: 0.9544 - val_loss: 0.6415 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.88000\n",
      "Epoch 41/2000\n",
      "113/113 - 7s - loss: 0.0946 - accuracy: 0.9611 - val_loss: 0.5720 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.88000\n",
      "Epoch 42/2000\n",
      "113/113 - 7s - loss: 0.1106 - accuracy: 0.9567 - val_loss: 0.5822 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.88000\n",
      "Epoch 43/2000\n",
      "113/113 - 7s - loss: 0.0801 - accuracy: 0.9711 - val_loss: 0.5217 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.88000\n",
      "Epoch 44/2000\n",
      "113/113 - 7s - loss: 0.0891 - accuracy: 0.9700 - val_loss: 0.6317 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.88000\n",
      "Epoch 45/2000\n",
      "113/113 - 7s - loss: 0.0728 - accuracy: 0.9778 - val_loss: 0.6215 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.88000\n",
      "Epoch 46/2000\n",
      "113/113 - 7s - loss: 0.0573 - accuracy: 0.9822 - val_loss: 0.6505 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.88000\n",
      "Epoch 47/2000\n",
      "113/113 - 7s - loss: 0.0433 - accuracy: 0.9900 - val_loss: 0.6082 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.88000\n",
      "Epoch 48/2000\n",
      "113/113 - 7s - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.6541 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.88000\n",
      "Epoch 49/2000\n",
      "113/113 - 7s - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.7249 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.88000\n",
      "Epoch 50/2000\n",
      "113/113 - 7s - loss: 0.0698 - accuracy: 0.9800 - val_loss: 0.6615 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.88000\n",
      "Epoch 51/2000\n",
      "113/113 - 7s - loss: 0.0771 - accuracy: 0.9778 - val_loss: 0.7816 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.88000\n",
      "Epoch 52/2000\n",
      "113/113 - 7s - loss: 0.0620 - accuracy: 0.9822 - val_loss: 0.7541 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.88000\n",
      "Epoch 53/2000\n",
      "113/113 - 7s - loss: 0.0695 - accuracy: 0.9800 - val_loss: 0.8306 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.88000\n",
      "Epoch 54/2000\n",
      "113/113 - 7s - loss: 0.1824 - accuracy: 0.9456 - val_loss: 0.6632 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.88000\n",
      "Epoch 55/2000\n",
      "113/113 - 7s - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.7319 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.88000\n",
      "Epoch 56/2000\n",
      "113/113 - 7s - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.8074 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.88000\n",
      "Epoch 57/2000\n",
      "113/113 - 7s - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.9959 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.88000\n",
      "Epoch 58/2000\n",
      "113/113 - 7s - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.7092 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.88000\n",
      "Epoch 59/2000\n",
      "113/113 - 7s - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.6657 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.88000\n",
      "Epoch 60/2000\n",
      "113/113 - 7s - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.7473 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.88000\n",
      "Epoch 61/2000\n",
      "113/113 - 7s - loss: 0.0389 - accuracy: 0.9900 - val_loss: 0.8388 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.88000\n",
      "Epoch 62/2000\n",
      "113/113 - 7s - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.8539 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.88000\n",
      "Epoch 63/2000\n",
      "113/113 - 7s - loss: 0.0741 - accuracy: 0.9800 - val_loss: 0.8898 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.88000\n",
      "Epoch 64/2000\n",
      "113/113 - 7s - loss: 0.0415 - accuracy: 0.9889 - val_loss: 0.7873 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.88000\n",
      "Epoch 65/2000\n",
      "113/113 - 7s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.88000\n",
      "Epoch 66/2000\n",
      "113/113 - 7s - loss: 0.0510 - accuracy: 0.9900 - val_loss: 0.8238 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.88000\n",
      "Epoch 67/2000\n",
      "113/113 - 7s - loss: 0.0376 - accuracy: 0.9889 - val_loss: 1.0731 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.88000\n",
      "Epoch 68/2000\n",
      "113/113 - 7s - loss: 0.0872 - accuracy: 0.9756 - val_loss: 0.6956 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.88000\n",
      "Epoch 69/2000\n",
      "113/113 - 7s - loss: 0.2704 - accuracy: 0.9433 - val_loss: 0.8637 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.88000\n",
      "Epoch 70/2000\n",
      "113/113 - 7s - loss: 0.1031 - accuracy: 0.9678 - val_loss: 0.9255 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.88000\n",
      "Epoch 71/2000\n",
      "113/113 - 7s - loss: 0.0250 - accuracy: 0.9956 - val_loss: 0.9409 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.88000\n",
      "Epoch 72/2000\n",
      "113/113 - 7s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.88000\n",
      "Epoch 73/2000\n",
      "113/113 - 7s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.88000\n",
      "Epoch 74/2000\n",
      "113/113 - 7s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.88000\n",
      "Epoch 75/2000\n",
      "113/113 - 7s - loss: 0.0193 - accuracy: 0.9967 - val_loss: 0.8387 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.88000\n",
      "Epoch 76/2000\n",
      "113/113 - 7s - loss: 0.0304 - accuracy: 0.9944 - val_loss: 0.9141 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.88000\n",
      "Epoch 77/2000\n",
      "113/113 - 7s - loss: 0.0316 - accuracy: 0.9944 - val_loss: 0.9224 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.88000\n",
      "Epoch 78/2000\n",
      "113/113 - 7s - loss: 0.0263 - accuracy: 0.9956 - val_loss: 0.9507 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.88000\n",
      "Epoch 79/2000\n",
      "113/113 - 7s - loss: 0.0434 - accuracy: 0.9900 - val_loss: 0.8378 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.88000\n",
      "Epoch 80/2000\n",
      "113/113 - 7s - loss: 0.0345 - accuracy: 0.9922 - val_loss: 1.0143 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.88000\n",
      "Epoch 81/2000\n",
      "113/113 - 7s - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.8434 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.88000\n",
      "Epoch 82/2000\n",
      "113/113 - 7s - loss: 0.0525 - accuracy: 0.9911 - val_loss: 1.1039 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.88000\n",
      "Epoch 83/2000\n",
      "113/113 - 7s - loss: 0.0246 - accuracy: 0.9956 - val_loss: 0.9138 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.88000\n",
      "Epoch 84/2000\n",
      "113/113 - 7s - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.9407 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.88000\n",
      "Epoch 85/2000\n",
      "113/113 - 7s - loss: 0.0352 - accuracy: 0.9900 - val_loss: 1.0304 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.88000\n",
      "Epoch 86/2000\n",
      "113/113 - 7s - loss: 0.0566 - accuracy: 0.9878 - val_loss: 0.9053 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.88000\n",
      "Epoch 87/2000\n",
      "113/113 - 7s - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.9507 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.88000\n",
      "Epoch 88/2000\n",
      "113/113 - 7s - loss: 0.0183 - accuracy: 0.9978 - val_loss: 0.9422 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.88000\n",
      "Epoch 89/2000\n",
      "113/113 - 7s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.88000\n",
      "Epoch 90/2000\n",
      "113/113 - 7s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.88000\n",
      "Epoch 91/2000\n",
      "113/113 - 7s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9159 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.88000\n",
      "Epoch 92/2000\n",
      "113/113 - 7s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.88000\n",
      "Epoch 93/2000\n",
      "113/113 - 7s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.88000\n",
      "Epoch 94/2000\n",
      "113/113 - 7s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.88000\n",
      "Epoch 95/2000\n",
      "113/113 - 7s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.88000\n",
      "Epoch 96/2000\n",
      "113/113 - 7s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.88000\n",
      "Epoch 97/2000\n",
      "113/113 - 7s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.88000\n",
      "Epoch 98/2000\n",
      "113/113 - 7s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.88000\n",
      "Epoch 99/2000\n",
      "113/113 - 7s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.88000\n",
      "Epoch 100/2000\n",
      "113/113 - 7s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.88000\n",
      "Epoch 101/2000\n",
      "113/113 - 7s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0057 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.88000\n",
      "Epoch 102/2000\n",
      "113/113 - 7s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9956 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.88000\n",
      "Epoch 103/2000\n",
      "113/113 - 7s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.88000\n",
      "Epoch 104/2000\n",
      "113/113 - 7s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.88000\n",
      "Epoch 105/2000\n",
      "113/113 - 7s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0055 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.88000\n",
      "Epoch 106/2000\n",
      "113/113 - 7s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0492 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.88000\n",
      "Epoch 107/2000\n",
      "113/113 - 7s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.88000\n",
      "Epoch 108/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.88000\n",
      "Epoch 109/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.88000\n",
      "Epoch 110/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.88000\n",
      "Epoch 111/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.88000\n",
      "Epoch 112/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0882 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.88000\n",
      "Epoch 113/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.88000\n",
      "Epoch 114/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.88000\n",
      "Epoch 115/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.88000\n",
      "Epoch 116/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1214 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.88000\n",
      "Epoch 117/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.88000\n",
      "Epoch 118/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1175 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.88000\n",
      "Epoch 119/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.88000\n",
      "Epoch 120/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.88000\n",
      "Epoch 121/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.88000\n",
      "Epoch 122/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1551 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.88000\n",
      "Epoch 123/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.88000\n",
      "Epoch 124/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.88000\n",
      "Epoch 125/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1532 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.88000\n",
      "Epoch 126/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.88000\n",
      "Epoch 127/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1334 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.88000\n",
      "Epoch 128/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.88000\n",
      "Epoch 129/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.88000\n",
      "Epoch 130/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2022 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.88000\n",
      "Epoch 131/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.88000\n",
      "Epoch 132/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1934 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.88000\n",
      "Epoch 133/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1966 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.88000\n",
      "Epoch 134/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2166 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.88000\n",
      "Epoch 135/2000\n",
      "113/113 - 7s - loss: 0.5235 - accuracy: 0.9367 - val_loss: 1.6125 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.88000\n",
      "Epoch 136/2000\n",
      "113/113 - 7s - loss: 0.6380 - accuracy: 0.8778 - val_loss: 1.3473 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.88000\n",
      "Epoch 137/2000\n",
      "113/113 - 7s - loss: 0.1264 - accuracy: 0.9500 - val_loss: 0.9628 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.88000\n",
      "Epoch 138/2000\n",
      "113/113 - 7s - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.8634 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.88000\n",
      "Epoch 139/2000\n",
      "113/113 - 7s - loss: 0.0476 - accuracy: 0.9878 - val_loss: 0.9147 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.88000\n",
      "Epoch 140/2000\n",
      "113/113 - 7s - loss: 0.0226 - accuracy: 0.9967 - val_loss: 0.9258 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.88000\n",
      "Epoch 141/2000\n",
      "113/113 - 7s - loss: 0.0208 - accuracy: 0.9967 - val_loss: 0.8088 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.88000\n",
      "Epoch 142/2000\n",
      "113/113 - 7s - loss: 0.0143 - accuracy: 0.9978 - val_loss: 0.8675 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.88000\n",
      "Epoch 143/2000\n",
      "113/113 - 7s - loss: 0.0272 - accuracy: 0.9944 - val_loss: 0.8801 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.88000\n",
      "Epoch 144/2000\n",
      "113/113 - 7s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.88000\n",
      "Epoch 145/2000\n",
      "113/113 - 7s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.88000\n",
      "Epoch 146/2000\n",
      "113/113 - 7s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8904 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.88000\n",
      "Epoch 147/2000\n",
      "113/113 - 7s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.88000\n",
      "Epoch 148/2000\n",
      "113/113 - 7s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.88000\n",
      "Epoch 149/2000\n",
      "113/113 - 7s - loss: 0.0285 - accuracy: 0.9933 - val_loss: 1.0068 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.88000\n",
      "Epoch 150/2000\n",
      "113/113 - 7s - loss: 0.0283 - accuracy: 0.9933 - val_loss: 1.0598 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.88000\n",
      "Epoch 151/2000\n",
      "113/113 - 7s - loss: 0.0554 - accuracy: 0.9878 - val_loss: 1.0082 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.88000\n",
      "Epoch 152/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0637 - accuracy: 0.9811 - val_loss: 1.0922 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.88000\n",
      "Epoch 153/2000\n",
      "113/113 - 7s - loss: 0.0666 - accuracy: 0.9733 - val_loss: 1.1733 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.88000\n",
      "Epoch 154/2000\n",
      "113/113 - 7s - loss: 0.0521 - accuracy: 0.9867 - val_loss: 0.9124 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.88000\n",
      "Epoch 155/2000\n",
      "113/113 - 7s - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.8708 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.88000\n",
      "Epoch 156/2000\n",
      "113/113 - 7s - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.8627 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.88000\n",
      "Epoch 157/2000\n",
      "113/113 - 7s - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.9040 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.88000\n",
      "Epoch 158/2000\n",
      "113/113 - 7s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.88000\n",
      "Epoch 159/2000\n",
      "113/113 - 7s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.88000\n",
      "Epoch 160/2000\n",
      "113/113 - 7s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.88000\n",
      "Epoch 161/2000\n",
      "113/113 - 7s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9188 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.88000\n",
      "Epoch 162/2000\n",
      "113/113 - 7s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.88000\n",
      "Epoch 163/2000\n",
      "113/113 - 7s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.88000\n",
      "Epoch 164/2000\n",
      "113/113 - 7s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.88000\n",
      "Epoch 165/2000\n",
      "113/113 - 7s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.88000\n",
      "Epoch 166/2000\n",
      "113/113 - 7s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.88000\n",
      "Epoch 167/2000\n",
      "113/113 - 7s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.88000\n",
      "Epoch 168/2000\n",
      "113/113 - 7s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.88000\n",
      "Epoch 169/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.88000\n",
      "Epoch 170/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.88000\n",
      "Epoch 171/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.88000\n",
      "Epoch 172/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9866 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.88000\n",
      "Epoch 173/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.88000\n",
      "Epoch 174/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.88000\n",
      "Epoch 175/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.88000\n",
      "Epoch 176/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.88000\n",
      "Epoch 177/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.88000\n",
      "Epoch 178/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.88000\n",
      "Epoch 179/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0114 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.88000\n",
      "Epoch 180/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.88000\n",
      "Epoch 181/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.88000\n",
      "Epoch 182/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.88000\n",
      "Epoch 183/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.88000\n",
      "Epoch 184/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.88000\n",
      "Epoch 185/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.88000\n",
      "Epoch 186/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.88000\n",
      "Epoch 187/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0566 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.88000\n",
      "Epoch 188/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.88000\n",
      "Epoch 189/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.88000\n",
      "Epoch 190/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.88000\n",
      "Epoch 191/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0739 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.88000\n",
      "Epoch 192/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.88000\n",
      "Epoch 193/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.88000\n",
      "Epoch 194/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0876 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.88000\n",
      "Epoch 195/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1046 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.88000\n",
      "Epoch 196/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.88000\n",
      "Epoch 197/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1109 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.88000\n",
      "Epoch 198/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0973 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.88000\n",
      "Epoch 199/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0862 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.88000\n",
      "Epoch 200/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.88000\n",
      "Epoch 201/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1323 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.88000\n",
      "Epoch 202/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.88000\n",
      "Epoch 203/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1116 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.88000\n",
      "Epoch 204/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.88000\n",
      "Epoch 205/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.88000\n",
      "Epoch 206/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.88000\n",
      "Epoch 207/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.88000\n",
      "Epoch 208/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1608 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.88000\n",
      "Epoch 209/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.88000\n",
      "Epoch 210/2000\n",
      "113/113 - 7s - loss: 1.2155 - accuracy: 0.8900 - val_loss: 2.6843 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.88000\n",
      "Epoch 211/2000\n",
      "113/113 - 7s - loss: 0.9070 - accuracy: 0.8611 - val_loss: 0.9710 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.88000\n",
      "Epoch 212/2000\n",
      "113/113 - 7s - loss: 0.1700 - accuracy: 0.9444 - val_loss: 0.7903 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.88000\n",
      "Epoch 213/2000\n",
      "113/113 - 7s - loss: 0.0751 - accuracy: 0.9822 - val_loss: 0.7526 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.88000\n",
      "Epoch 214/2000\n",
      "113/113 - 7s - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.8332 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.88000\n",
      "Epoch 215/2000\n",
      "113/113 - 7s - loss: 0.0247 - accuracy: 0.9967 - val_loss: 0.8929 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.88000\n",
      "Epoch 216/2000\n",
      "113/113 - 7s - loss: 0.0186 - accuracy: 0.9989 - val_loss: 0.8424 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.88000\n",
      "Epoch 217/2000\n",
      "113/113 - 7s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.88000\n",
      "Epoch 218/2000\n",
      "113/113 - 7s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.88000\n",
      "Epoch 219/2000\n",
      "113/113 - 7s - loss: 0.0182 - accuracy: 0.9967 - val_loss: 0.9890 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.88000\n",
      "Epoch 220/2000\n",
      "113/113 - 7s - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.8907 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.88000\n",
      "Epoch 221/2000\n",
      "113/113 - 7s - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.8324 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.88000\n",
      "Epoch 222/2000\n",
      "113/113 - 7s - loss: 0.0184 - accuracy: 0.9978 - val_loss: 0.8700 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.88000\n",
      "Epoch 223/2000\n",
      "113/113 - 7s - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.8678 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.88000\n",
      "Epoch 224/2000\n",
      "113/113 - 7s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.88000\n",
      "Epoch 225/2000\n",
      "113/113 - 7s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9194 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.88000\n",
      "Epoch 226/2000\n",
      "113/113 - 7s - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.9549 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.88000\n",
      "Epoch 227/2000\n",
      "113/113 - 7s - loss: 0.0081 - accuracy: 0.9989 - val_loss: 1.0217 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.88000\n",
      "Epoch 228/2000\n",
      "113/113 - 7s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.88000\n",
      "Epoch 229/2000\n",
      "113/113 - 7s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.88000\n",
      "Epoch 230/2000\n",
      "113/113 - 7s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9656 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.88000\n",
      "Epoch 231/2000\n",
      "113/113 - 7s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.88000\n",
      "Epoch 232/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.88000\n",
      "Epoch 233/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.88000\n",
      "Epoch 234/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.88000\n",
      "Epoch 235/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0296 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.88000\n",
      "Epoch 236/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.88000\n",
      "Epoch 237/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.88000\n",
      "Epoch 238/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.88000\n",
      "Epoch 239/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.88000\n",
      "Epoch 240/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0779 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.88000\n",
      "Epoch 241/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.88000\n",
      "Epoch 242/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.88000\n",
      "Epoch 243/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.88000\n",
      "Epoch 244/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.88000\n",
      "Epoch 245/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.88000\n",
      "Epoch 246/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1345 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.88000\n",
      "Epoch 247/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1342 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.88000\n",
      "Epoch 248/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.88000\n",
      "Epoch 249/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1547 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.88000\n",
      "Epoch 250/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1544 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.88000\n",
      "Epoch 251/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.88000\n",
      "Epoch 252/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.88000\n",
      "Epoch 253/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1758 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.88000\n",
      "Epoch 254/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1863 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.88000\n",
      "Epoch 255/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.88000\n",
      "Epoch 256/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.88000\n",
      "Epoch 257/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.88000\n",
      "Epoch 258/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2211 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.88000\n",
      "Epoch 259/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.88000\n",
      "Epoch 260/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.88000\n",
      "Epoch 261/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.88000\n",
      "Epoch 262/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.88000\n",
      "Epoch 263/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2477 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.88000\n",
      "Epoch 264/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.88000\n",
      "Epoch 265/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2579 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.88000\n",
      "Epoch 266/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.88000\n",
      "Epoch 267/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2899 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.88000\n",
      "Epoch 268/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.88000\n",
      "Epoch 269/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.88000\n",
      "Epoch 270/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3119 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.88000\n",
      "Epoch 271/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.88000\n",
      "Epoch 272/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3149 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.88000\n",
      "Epoch 273/2000\n",
      "113/113 - 7s - loss: 0.3635 - accuracy: 0.9400 - val_loss: 1.9562 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.88000\n",
      "Epoch 274/2000\n",
      "113/113 - 7s - loss: 0.3300 - accuracy: 0.9256 - val_loss: 1.1186 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.88000\n",
      "Epoch 275/2000\n",
      "113/113 - 7s - loss: 0.0781 - accuracy: 0.9778 - val_loss: 1.0289 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.88000\n",
      "Epoch 276/2000\n",
      "113/113 - 7s - loss: 0.0670 - accuracy: 0.9844 - val_loss: 1.1787 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.88000\n",
      "Epoch 277/2000\n",
      "113/113 - 7s - loss: 0.0162 - accuracy: 0.9989 - val_loss: 1.2008 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.88000\n",
      "Epoch 278/2000\n",
      "113/113 - 7s - loss: 0.0294 - accuracy: 0.9933 - val_loss: 1.0735 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.88000\n",
      "Epoch 279/2000\n",
      "113/113 - 7s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0912 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.88000\n",
      "Epoch 280/2000\n",
      "113/113 - 7s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.88000\n",
      "Epoch 281/2000\n",
      "113/113 - 7s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0984 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.88000\n",
      "Epoch 282/2000\n",
      "113/113 - 7s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.88000\n",
      "Epoch 283/2000\n",
      "113/113 - 7s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.88000\n",
      "Epoch 284/2000\n",
      "113/113 - 7s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1352 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.88000\n",
      "Epoch 285/2000\n",
      "113/113 - 7s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1425 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.88000\n",
      "Epoch 286/2000\n",
      "113/113 - 7s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1407 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.88000\n",
      "Epoch 287/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.88000\n",
      "Epoch 288/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.88000\n",
      "Epoch 289/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.88000\n",
      "Epoch 290/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.88000\n",
      "Epoch 291/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1825 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.88000\n",
      "Epoch 292/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.88000\n",
      "Epoch 293/2000\n",
      "113/113 - 7s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.88000\n",
      "Epoch 294/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2005 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.88000\n",
      "Epoch 295/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2070 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.88000\n",
      "Epoch 296/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.88000\n",
      "Epoch 297/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.88000\n",
      "Epoch 298/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.88000\n",
      "Epoch 299/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2273 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.88000\n",
      "Epoch 300/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.88000\n",
      "Epoch 301/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.88000\n",
      "Epoch 302/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.88000\n",
      "Epoch 303/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2493 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.88000\n",
      "Epoch 304/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.88000\n",
      "Epoch 305/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.88000\n",
      "Epoch 306/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.88000\n",
      "Epoch 307/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.88000\n",
      "Epoch 308/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.88000\n",
      "Epoch 309/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2947 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.88000\n",
      "Epoch 310/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.88000\n",
      "Epoch 311/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3047 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.88000\n",
      "Epoch 312/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.88000\n",
      "Epoch 313/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3181 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.88000\n",
      "Epoch 314/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.88000\n",
      "Epoch 315/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.88000\n",
      "Epoch 316/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.88000\n",
      "Epoch 317/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.88000\n",
      "Epoch 318/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.88000\n",
      "Epoch 319/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.88000\n",
      "Epoch 320/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3643 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.88000\n",
      "Epoch 321/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3697 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.88000\n",
      "Epoch 322/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3703 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.88000\n",
      "Epoch 323/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3742 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.88000\n",
      "Epoch 324/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3880 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.88000\n",
      "Epoch 325/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3813 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.88000\n",
      "Epoch 326/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.88000\n",
      "Epoch 327/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3913 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.88000\n",
      "Epoch 328/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3963 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.88000\n",
      "Epoch 329/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3778 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.88000\n",
      "Epoch 330/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4007 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.88000\n",
      "Epoch 331/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3969 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.88000\n",
      "Epoch 332/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.88000\n",
      "Epoch 333/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4017 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.88000\n",
      "Epoch 334/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3878 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.88000\n",
      "Epoch 335/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.88000\n",
      "Epoch 336/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4104 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.88000\n",
      "Epoch 337/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4011 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.88000\n",
      "Epoch 338/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.88000\n",
      "Epoch 339/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4259 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.88000\n",
      "Epoch 340/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4853 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.88000\n",
      "Epoch 341/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4117 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.88000\n",
      "Epoch 342/2000\n",
      "113/113 - 7s - loss: 0.0417 - accuracy: 0.9967 - val_loss: 2.3866 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.88000\n",
      "Epoch 343/2000\n",
      "113/113 - 7s - loss: 0.7392 - accuracy: 0.8756 - val_loss: 0.9999 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.88000\n",
      "Epoch 344/2000\n",
      "113/113 - 7s - loss: 0.1630 - accuracy: 0.9578 - val_loss: 1.0215 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.88000\n",
      "Epoch 345/2000\n",
      "113/113 - 7s - loss: 0.0924 - accuracy: 0.9667 - val_loss: 1.1643 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.88000\n",
      "Epoch 346/2000\n",
      "113/113 - 7s - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.9365 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.88000\n",
      "Epoch 347/2000\n",
      "113/113 - 7s - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.0497 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.88000\n",
      "Epoch 348/2000\n",
      "113/113 - 7s - loss: 0.0117 - accuracy: 0.9978 - val_loss: 1.0644 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.88000\n",
      "Epoch 349/2000\n",
      "113/113 - 7s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.88000\n",
      "Epoch 350/2000\n",
      "113/113 - 7s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.88000\n",
      "Epoch 351/2000\n",
      "113/113 - 7s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.88000\n",
      "Epoch 352/2000\n",
      "113/113 - 7s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.88000\n",
      "Epoch 353/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1288 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.88000\n",
      "Epoch 354/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.88000\n",
      "Epoch 355/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1448 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.88000\n",
      "Epoch 356/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.88000\n",
      "Epoch 357/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1661 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.88000\n",
      "Epoch 358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.88000\n",
      "Epoch 359/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.88000\n",
      "Epoch 360/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.88000\n",
      "Epoch 361/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.88000\n",
      "Epoch 362/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2070 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.88000\n",
      "Epoch 363/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2259 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.88000\n",
      "Epoch 364/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2299 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.88000\n",
      "Epoch 365/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2415 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.88000\n",
      "Epoch 366/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.88000\n",
      "Epoch 367/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.88000\n",
      "Epoch 368/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.88000\n",
      "Epoch 369/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2778 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.88000\n",
      "Epoch 370/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.88000\n",
      "Epoch 371/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2951 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.88000\n",
      "Epoch 372/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2947 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.88000\n",
      "Epoch 373/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3075 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.88000\n",
      "Epoch 374/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3173 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.88000\n",
      "Epoch 375/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.88000\n",
      "Epoch 376/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3332 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.88000\n",
      "Epoch 377/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3404 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.88000\n",
      "Epoch 378/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3475 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.88000\n",
      "Epoch 379/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3583 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.88000\n",
      "Epoch 380/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3678 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.88000\n",
      "Epoch 381/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3716 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.88000\n",
      "Epoch 382/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3792 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.88000\n",
      "Epoch 383/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.88000\n",
      "Epoch 384/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3968 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.88000\n",
      "Epoch 385/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3998 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.88000\n",
      "Epoch 386/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.88000\n",
      "Epoch 387/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.88000\n",
      "Epoch 388/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.88000\n",
      "Epoch 389/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4306 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.88000\n",
      "Epoch 390/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4443 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.88000\n",
      "Epoch 391/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.88000\n",
      "Epoch 392/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.88000\n",
      "Epoch 393/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.88000\n",
      "Epoch 394/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4496 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.88000\n",
      "Epoch 395/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.88000\n",
      "Epoch 396/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4664 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.88000\n",
      "Epoch 397/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4819 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.88000\n",
      "Epoch 398/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4727 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.88000\n",
      "Epoch 399/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4896 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.88000\n",
      "Epoch 400/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4801 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.88000\n",
      "Epoch 401/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.88000\n",
      "Epoch 402/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4973 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.88000\n",
      "Epoch 403/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4888 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.88000\n",
      "Epoch 404/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5084 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.88000\n",
      "Epoch 405/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5120 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.88000\n",
      "Epoch 406/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.88000\n",
      "Epoch 407/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.88000\n",
      "Epoch 408/2000\n",
      "113/113 - 7s - loss: 0.5916 - accuracy: 0.9000 - val_loss: 1.2915 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.88000\n",
      "Epoch 409/2000\n",
      "113/113 - 7s - loss: 0.1709 - accuracy: 0.9467 - val_loss: 1.3205 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.88000\n",
      "Epoch 410/2000\n",
      "113/113 - 7s - loss: 0.0725 - accuracy: 0.9767 - val_loss: 1.1660 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.88000\n",
      "Epoch 411/2000\n",
      "113/113 - 7s - loss: 0.0443 - accuracy: 0.9878 - val_loss: 1.0747 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.88000\n",
      "Epoch 412/2000\n",
      "113/113 - 7s - loss: 0.0305 - accuracy: 0.9911 - val_loss: 1.1443 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.88000\n",
      "Epoch 413/2000\n",
      "113/113 - 7s - loss: 0.0173 - accuracy: 0.9978 - val_loss: 1.0562 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.88000\n",
      "Epoch 414/2000\n",
      "113/113 - 7s - loss: 0.0289 - accuracy: 0.9933 - val_loss: 1.0915 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.88000\n",
      "Epoch 415/2000\n",
      "113/113 - 7s - loss: 0.0258 - accuracy: 0.9922 - val_loss: 1.0967 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.88000\n",
      "Epoch 416/2000\n",
      "113/113 - 7s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.88000\n",
      "Epoch 417/2000\n",
      "113/113 - 7s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.88000\n",
      "Epoch 418/2000\n",
      "113/113 - 7s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1411 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.88000\n",
      "Epoch 419/2000\n",
      "113/113 - 7s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.88000\n",
      "Epoch 420/2000\n",
      "113/113 - 7s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.88000\n",
      "Epoch 421/2000\n",
      "113/113 - 7s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1761 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.88000\n",
      "Epoch 422/2000\n",
      "113/113 - 7s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.88000\n",
      "Epoch 423/2000\n",
      "113/113 - 7s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.88000\n",
      "Epoch 424/2000\n",
      "113/113 - 7s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.88000\n",
      "Epoch 425/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2328 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.88000\n",
      "Epoch 426/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2428 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.88000\n",
      "Epoch 427/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.2449 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.88000\n",
      "Epoch 428/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2625 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.88000\n",
      "Epoch 429/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.88000\n",
      "Epoch 430/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.88000\n",
      "Epoch 431/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2925 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.88000\n",
      "Epoch 432/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.88000\n",
      "Epoch 433/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.88000\n",
      "Epoch 434/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3277 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.88000\n",
      "Epoch 435/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.88000\n",
      "Epoch 436/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3393 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.88000\n",
      "Epoch 437/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.88000\n",
      "Epoch 438/2000\n",
      "113/113 - 8s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3613 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.88000\n",
      "Epoch 439/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.88000\n",
      "Epoch 440/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3700 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.88000\n",
      "Epoch 441/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.88000\n",
      "Epoch 442/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3880 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.88000\n",
      "Epoch 443/2000\n",
      "113/113 - 7s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3904 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.88000\n",
      "Epoch 444/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.88000\n",
      "Epoch 445/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.88000\n",
      "Epoch 446/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.88000\n",
      "Epoch 447/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.88000\n",
      "Epoch 448/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4171 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.88000\n",
      "Epoch 449/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.88000\n",
      "Epoch 450/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4231 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.88000\n",
      "Epoch 451/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4344 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.88000\n",
      "Epoch 452/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4405 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.88000\n",
      "Epoch 453/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4367 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.88000\n",
      "Epoch 454/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.88000\n",
      "Epoch 455/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4483 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.88000\n",
      "Epoch 456/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.88000\n",
      "Epoch 457/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4618 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.88000\n",
      "Epoch 458/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4567 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.88000\n",
      "Epoch 459/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4682 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.88000\n",
      "Epoch 460/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4707 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.88000\n",
      "Epoch 461/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4733 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.88000\n",
      "Epoch 462/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4790 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.88000\n",
      "Epoch 463/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.88000\n",
      "Epoch 464/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4910 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.88000\n",
      "Epoch 465/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4901 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.88000\n",
      "Epoch 466/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4980 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.88000\n",
      "Epoch 467/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.88000\n",
      "Epoch 468/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.88000\n",
      "Epoch 469/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5228 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.88000\n",
      "Epoch 470/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4969 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.88000\n",
      "Epoch 471/2000\n",
      "113/113 - 7s - loss: 0.0335 - accuracy: 0.9967 - val_loss: 2.1398 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.88000\n",
      "Epoch 472/2000\n",
      "113/113 - 7s - loss: 0.6104 - accuracy: 0.8956 - val_loss: 1.4892 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.88000\n",
      "Epoch 473/2000\n",
      "113/113 - 6s - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.9730 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.88000\n",
      "Epoch 474/2000\n",
      "113/113 - 6s - loss: 0.0614 - accuracy: 0.9822 - val_loss: 1.0471 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.88000\n",
      "Epoch 475/2000\n",
      "113/113 - 7s - loss: 0.0391 - accuracy: 0.9844 - val_loss: 1.0843 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.88000\n",
      "Epoch 476/2000\n",
      "113/113 - 6s - loss: 0.0184 - accuracy: 0.9967 - val_loss: 1.0695 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.88000\n",
      "Epoch 477/2000\n",
      "113/113 - 7s - loss: 0.0156 - accuracy: 0.9967 - val_loss: 1.1367 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.88000\n",
      "Epoch 478/2000\n",
      "113/113 - 7s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.88000\n",
      "Epoch 479/2000\n",
      "113/113 - 6s - loss: 0.0085 - accuracy: 0.9989 - val_loss: 1.0831 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.88000\n",
      "Epoch 480/2000\n",
      "113/113 - 6s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.88000\n",
      "Epoch 481/2000\n",
      "113/113 - 6s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1081 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.88000\n",
      "Epoch 482/2000\n",
      "113/113 - 6s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1224 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.88000\n",
      "Epoch 483/2000\n",
      "113/113 - 6s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.88000\n",
      "Epoch 484/2000\n",
      "113/113 - 6s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.88000\n",
      "Epoch 485/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1587 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.88000\n",
      "Epoch 486/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.88000\n",
      "Epoch 487/2000\n",
      "113/113 - 6s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1826 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.88000\n",
      "Epoch 488/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1940 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.88000\n",
      "Epoch 489/2000\n",
      "113/113 - 6s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.88000\n",
      "Epoch 490/2000\n",
      "113/113 - 6s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.88000\n",
      "Epoch 491/2000\n",
      "113/113 - 6s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.88000\n",
      "Epoch 492/2000\n",
      "113/113 - 6s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2380 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.88000\n",
      "Epoch 493/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2445 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.88000\n",
      "Epoch 494/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.88000\n",
      "Epoch 495/2000\n",
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.88000\n",
      "Epoch 496/2000\n",
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.88000\n",
      "Epoch 497/2000\n",
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.88000\n",
      "Epoch 498/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2844 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.88000\n",
      "Epoch 499/2000\n",
      "113/113 - 6s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.88000\n",
      "Epoch 500/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2967 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.88000\n",
      "Epoch 501/2000\n",
      "113/113 - 6s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00501: val_accuracy did not improve from 0.88000\n",
      "Epoch 502/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00502: val_accuracy did not improve from 0.88000\n",
      "Epoch 503/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3144 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00503: val_accuracy did not improve from 0.88000\n",
      "Epoch 504/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00504: val_accuracy did not improve from 0.88000\n",
      "Epoch 505/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3296 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00505: val_accuracy did not improve from 0.88000\n",
      "Epoch 506/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3407 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00506: val_accuracy did not improve from 0.88000\n",
      "Epoch 507/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3463 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00507: val_accuracy did not improve from 0.88000\n",
      "Epoch 508/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3472 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00508: val_accuracy did not improve from 0.88000\n",
      "Epoch 509/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00509: val_accuracy did not improve from 0.88000\n",
      "Epoch 510/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3616 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00510: val_accuracy did not improve from 0.88000\n",
      "Epoch 511/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00511: val_accuracy did not improve from 0.88000\n",
      "Epoch 512/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00512: val_accuracy did not improve from 0.88000\n",
      "Epoch 513/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00513: val_accuracy did not improve from 0.88000\n",
      "Epoch 514/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00514: val_accuracy did not improve from 0.88000\n",
      "Epoch 515/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00515: val_accuracy did not improve from 0.88000\n",
      "Epoch 516/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4029 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00516: val_accuracy did not improve from 0.88000\n",
      "Epoch 517/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3954 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00517: val_accuracy did not improve from 0.88000\n",
      "Epoch 518/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00518: val_accuracy did not improve from 0.88000\n",
      "Epoch 519/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00519: val_accuracy did not improve from 0.88000\n",
      "Epoch 520/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00520: val_accuracy did not improve from 0.88000\n",
      "Epoch 521/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00521: val_accuracy did not improve from 0.88000\n",
      "Epoch 522/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4227 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00522: val_accuracy did not improve from 0.88000\n",
      "Epoch 523/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4255 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00523: val_accuracy did not improve from 0.88000\n",
      "Epoch 524/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00524: val_accuracy did not improve from 0.88000\n",
      "Epoch 525/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4243 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00525: val_accuracy did not improve from 0.88000\n",
      "Epoch 526/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4304 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00526: val_accuracy did not improve from 0.88000\n",
      "Epoch 527/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4320 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00527: val_accuracy did not improve from 0.88000\n",
      "Epoch 528/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00528: val_accuracy did not improve from 0.88000\n",
      "Epoch 529/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00529: val_accuracy did not improve from 0.88000\n",
      "Epoch 530/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00530: val_accuracy did not improve from 0.88000\n",
      "Epoch 531/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.4485 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00531: val_accuracy did not improve from 0.88000\n",
      "Epoch 532/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4344 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00532: val_accuracy did not improve from 0.88000\n",
      "Epoch 533/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4307 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00533: val_accuracy did not improve from 0.88000\n",
      "Epoch 534/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4437 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00534: val_accuracy did not improve from 0.88000\n",
      "Epoch 535/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4550 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00535: val_accuracy did not improve from 0.88000\n",
      "Epoch 536/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00536: val_accuracy did not improve from 0.88000\n",
      "Epoch 537/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4506 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00537: val_accuracy did not improve from 0.88000\n",
      "Epoch 538/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4275 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00538: val_accuracy did not improve from 0.88000\n",
      "Epoch 539/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00539: val_accuracy did not improve from 0.88000\n",
      "Epoch 540/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4456 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00540: val_accuracy did not improve from 0.88000\n",
      "Epoch 541/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00541: val_accuracy did not improve from 0.88000\n",
      "Epoch 542/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00542: val_accuracy did not improve from 0.88000\n",
      "Epoch 543/2000\n",
      "113/113 - 7s - loss: 0.7525 - accuracy: 0.8933 - val_loss: 1.4450 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00543: val_accuracy did not improve from 0.88000\n",
      "Epoch 544/2000\n",
      "113/113 - 7s - loss: 0.1427 - accuracy: 0.9578 - val_loss: 1.0014 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00544: val_accuracy did not improve from 0.88000\n",
      "Epoch 545/2000\n",
      "113/113 - 6s - loss: 0.0424 - accuracy: 0.9833 - val_loss: 0.8967 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00545: val_accuracy did not improve from 0.88000\n",
      "Epoch 546/2000\n",
      "113/113 - 7s - loss: 0.0245 - accuracy: 0.9956 - val_loss: 1.1350 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00546: val_accuracy did not improve from 0.88000\n",
      "Epoch 547/2000\n",
      "113/113 - 7s - loss: 0.0262 - accuracy: 0.9967 - val_loss: 1.0498 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00547: val_accuracy did not improve from 0.88000\n",
      "Epoch 548/2000\n",
      "113/113 - 7s - loss: 0.0204 - accuracy: 0.9956 - val_loss: 1.0907 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00548: val_accuracy did not improve from 0.88000\n",
      "Epoch 549/2000\n",
      "113/113 - 7s - loss: 0.0178 - accuracy: 0.9944 - val_loss: 1.0581 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00549: val_accuracy did not improve from 0.88000\n",
      "Epoch 550/2000\n",
      "113/113 - 7s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00550: val_accuracy did not improve from 0.88000\n",
      "Epoch 551/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00551: val_accuracy did not improve from 0.88000\n",
      "Epoch 552/2000\n",
      "113/113 - 6s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00552: val_accuracy did not improve from 0.88000\n",
      "Epoch 553/2000\n",
      "113/113 - 6s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0144 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00553: val_accuracy did not improve from 0.88000\n",
      "Epoch 554/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00554: val_accuracy did not improve from 0.88000\n",
      "Epoch 555/2000\n",
      "113/113 - 6s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00555: val_accuracy did not improve from 0.88000\n",
      "Epoch 556/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00556: val_accuracy did not improve from 0.88000\n",
      "Epoch 557/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0435 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00557: val_accuracy did not improve from 0.88000\n",
      "Epoch 558/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00558: val_accuracy did not improve from 0.88000\n",
      "Epoch 559/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00559: val_accuracy did not improve from 0.88000\n",
      "Epoch 560/2000\n",
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00560: val_accuracy did not improve from 0.88000\n",
      "Epoch 561/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00561: val_accuracy did not improve from 0.88000\n",
      "Epoch 562/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0830 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00562: val_accuracy did not improve from 0.88000\n",
      "Epoch 563/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00563: val_accuracy did not improve from 0.88000\n",
      "Epoch 564/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1027 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00564: val_accuracy did not improve from 0.88000\n",
      "Epoch 565/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00565: val_accuracy did not improve from 0.88000\n",
      "Epoch 566/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1212 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00566: val_accuracy did not improve from 0.88000\n",
      "Epoch 567/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00567: val_accuracy did not improve from 0.88000\n",
      "Epoch 568/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1315 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00568: val_accuracy did not improve from 0.88000\n",
      "Epoch 569/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00569: val_accuracy did not improve from 0.88000\n",
      "Epoch 570/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1472 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00570: val_accuracy did not improve from 0.88000\n",
      "Epoch 571/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1471 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00571: val_accuracy did not improve from 0.88000\n",
      "Epoch 572/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1638 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00572: val_accuracy did not improve from 0.88000\n",
      "Epoch 573/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1701 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00573: val_accuracy did not improve from 0.88000\n",
      "Epoch 574/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00574: val_accuracy did not improve from 0.88000\n",
      "Epoch 575/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00575: val_accuracy did not improve from 0.88000\n",
      "Epoch 576/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00576: val_accuracy did not improve from 0.88000\n",
      "Epoch 577/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00577: val_accuracy did not improve from 0.88000\n",
      "Epoch 578/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1941 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00578: val_accuracy did not improve from 0.88000\n",
      "Epoch 579/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2006 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00579: val_accuracy did not improve from 0.88000\n",
      "Epoch 580/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2059 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00580: val_accuracy did not improve from 0.88000\n",
      "Epoch 581/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00581: val_accuracy did not improve from 0.88000\n",
      "Epoch 582/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00582: val_accuracy did not improve from 0.88000\n",
      "Epoch 583/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00583: val_accuracy did not improve from 0.88000\n",
      "Epoch 584/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00584: val_accuracy did not improve from 0.88000\n",
      "Epoch 585/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00585: val_accuracy did not improve from 0.88000\n",
      "Epoch 586/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00586: val_accuracy did not improve from 0.88000\n",
      "Epoch 587/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00587: val_accuracy did not improve from 0.88000\n",
      "Epoch 588/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00588: val_accuracy did not improve from 0.88000\n",
      "Epoch 589/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2487 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00589: val_accuracy did not improve from 0.88000\n",
      "Epoch 590/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2549 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00590: val_accuracy did not improve from 0.88000\n",
      "Epoch 591/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2556 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00591: val_accuracy did not improve from 0.88000\n",
      "Epoch 592/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2556 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00592: val_accuracy did not improve from 0.88000\n",
      "Epoch 593/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00593: val_accuracy did not improve from 0.88000\n",
      "Epoch 594/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00594: val_accuracy did not improve from 0.88000\n",
      "Epoch 595/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2766 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00595: val_accuracy did not improve from 0.88000\n",
      "Epoch 596/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2714 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00596: val_accuracy did not improve from 0.88000\n",
      "Epoch 597/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00597: val_accuracy did not improve from 0.88000\n",
      "Epoch 598/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00598: val_accuracy did not improve from 0.88000\n",
      "Epoch 599/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2891 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00599: val_accuracy did not improve from 0.88000\n",
      "Epoch 600/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00600: val_accuracy did not improve from 0.88000\n",
      "Epoch 601/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00601: val_accuracy did not improve from 0.88000\n",
      "Epoch 602/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2838 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00602: val_accuracy did not improve from 0.88000\n",
      "Epoch 603/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3046 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00603: val_accuracy did not improve from 0.88000\n",
      "Epoch 604/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00604: val_accuracy did not improve from 0.88000\n",
      "Epoch 605/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00605: val_accuracy did not improve from 0.88000\n",
      "Epoch 606/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00606: val_accuracy did not improve from 0.88000\n",
      "Epoch 607/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00607: val_accuracy did not improve from 0.88000\n",
      "Epoch 608/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00608: val_accuracy did not improve from 0.88000\n",
      "Epoch 609/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00609: val_accuracy did not improve from 0.88000\n",
      "Epoch 610/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00610: val_accuracy did not improve from 0.88000\n",
      "Epoch 611/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00611: val_accuracy did not improve from 0.88000\n",
      "Epoch 612/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00612: val_accuracy did not improve from 0.88000\n",
      "Epoch 613/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3554 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00613: val_accuracy did not improve from 0.88000\n",
      "Epoch 614/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00614: val_accuracy did not improve from 0.88000\n",
      "Epoch 615/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4436 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00615: val_accuracy did not improve from 0.88000\n",
      "Epoch 616/2000\n",
      "113/113 - 6s - loss: 0.1825 - accuracy: 0.9722 - val_loss: 2.4496 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00616: val_accuracy did not improve from 0.88000\n",
      "Epoch 617/2000\n",
      "113/113 - 7s - loss: 0.5377 - accuracy: 0.9089 - val_loss: 0.7801 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00617: val_accuracy did not improve from 0.88000\n",
      "Epoch 618/2000\n",
      "113/113 - 7s - loss: 0.1360 - accuracy: 0.9544 - val_loss: 0.7668 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00618: val_accuracy did not improve from 0.88000\n",
      "Epoch 619/2000\n",
      "113/113 - 7s - loss: 0.0610 - accuracy: 0.9778 - val_loss: 0.8570 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00619: val_accuracy did not improve from 0.88000\n",
      "Epoch 620/2000\n",
      "113/113 - 7s - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.7740 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00620: val_accuracy did not improve from 0.88000\n",
      "Epoch 621/2000\n",
      "113/113 - 7s - loss: 0.0274 - accuracy: 0.9933 - val_loss: 0.8119 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00621: val_accuracy did not improve from 0.88000\n",
      "Epoch 622/2000\n",
      "113/113 - 7s - loss: 0.0247 - accuracy: 0.9956 - val_loss: 0.8297 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00622: val_accuracy did not improve from 0.88000\n",
      "Epoch 623/2000\n",
      "113/113 - 7s - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.8762 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00623: val_accuracy did not improve from 0.88000\n",
      "Epoch 624/2000\n",
      "113/113 - 6s - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.9208 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00624: val_accuracy did not improve from 0.88000\n",
      "Epoch 625/2000\n",
      "113/113 - 7s - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.9585 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00625: val_accuracy did not improve from 0.88000\n",
      "Epoch 626/2000\n",
      "113/113 - 7s - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.8988 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00626: val_accuracy did not improve from 0.88000\n",
      "Epoch 627/2000\n",
      "113/113 - 6s - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.9132 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00627: val_accuracy did not improve from 0.88000\n",
      "Epoch 628/2000\n",
      "113/113 - 6s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00628: val_accuracy did not improve from 0.88000\n",
      "Epoch 629/2000\n",
      "113/113 - 7s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9571 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00629: val_accuracy did not improve from 0.88000\n",
      "Epoch 630/2000\n",
      "113/113 - 7s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00630: val_accuracy did not improve from 0.88000\n",
      "Epoch 631/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00631: val_accuracy did not improve from 0.88000\n",
      "Epoch 632/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00632: val_accuracy did not improve from 0.88000\n",
      "Epoch 633/2000\n",
      "113/113 - 6s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0019 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00633: val_accuracy did not improve from 0.88000\n",
      "Epoch 634/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00634: val_accuracy did not improve from 0.88000\n",
      "Epoch 635/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00635: val_accuracy did not improve from 0.88000\n",
      "Epoch 636/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0414 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00636: val_accuracy did not improve from 0.88000\n",
      "Epoch 637/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00637: val_accuracy did not improve from 0.88000\n",
      "Epoch 638/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00638: val_accuracy did not improve from 0.88000\n",
      "Epoch 639/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0565 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00639: val_accuracy did not improve from 0.88000\n",
      "Epoch 640/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0764 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00640: val_accuracy did not improve from 0.88000\n",
      "Epoch 641/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00641: val_accuracy did not improve from 0.88000\n",
      "Epoch 642/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00642: val_accuracy did not improve from 0.88000\n",
      "Epoch 643/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00643: val_accuracy did not improve from 0.88000\n",
      "Epoch 644/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00644: val_accuracy did not improve from 0.88000\n",
      "Epoch 645/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1133 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00645: val_accuracy did not improve from 0.88000\n",
      "Epoch 646/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1217 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00646: val_accuracy did not improve from 0.88000\n",
      "Epoch 647/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00647: val_accuracy did not improve from 0.88000\n",
      "Epoch 648/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00648: val_accuracy did not improve from 0.88000\n",
      "Epoch 649/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00649: val_accuracy did not improve from 0.88000\n",
      "Epoch 650/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00650: val_accuracy did not improve from 0.88000\n",
      "Epoch 651/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1549 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00651: val_accuracy did not improve from 0.88000\n",
      "Epoch 652/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1575 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00652: val_accuracy did not improve from 0.88000\n",
      "Epoch 653/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00653: val_accuracy did not improve from 0.88000\n",
      "Epoch 654/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00654: val_accuracy did not improve from 0.88000\n",
      "Epoch 655/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1898 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00655: val_accuracy did not improve from 0.88000\n",
      "Epoch 656/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1925 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00656: val_accuracy did not improve from 0.88000\n",
      "Epoch 657/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1893 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00657: val_accuracy did not improve from 0.88000\n",
      "Epoch 658/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00658: val_accuracy did not improve from 0.88000\n",
      "Epoch 659/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1927 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00659: val_accuracy did not improve from 0.88000\n",
      "Epoch 660/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2139 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00660: val_accuracy did not improve from 0.88000\n",
      "Epoch 661/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00661: val_accuracy did not improve from 0.88000\n",
      "Epoch 662/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2157 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00662: val_accuracy did not improve from 0.88000\n",
      "Epoch 663/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2249 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00663: val_accuracy did not improve from 0.88000\n",
      "Epoch 664/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00664: val_accuracy did not improve from 0.88000\n",
      "Epoch 665/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00665: val_accuracy did not improve from 0.88000\n",
      "Epoch 666/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2314 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00666: val_accuracy did not improve from 0.88000\n",
      "Epoch 667/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2420 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00667: val_accuracy did not improve from 0.88000\n",
      "Epoch 668/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00668: val_accuracy did not improve from 0.88000\n",
      "Epoch 669/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2417 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00669: val_accuracy did not improve from 0.88000\n",
      "Epoch 670/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2538 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00670: val_accuracy did not improve from 0.88000\n",
      "Epoch 671/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00671: val_accuracy did not improve from 0.88000\n",
      "Epoch 672/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00672: val_accuracy did not improve from 0.88000\n",
      "Epoch 673/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2559 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00673: val_accuracy did not improve from 0.88000\n",
      "Epoch 674/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00674: val_accuracy did not improve from 0.88000\n",
      "Epoch 675/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00675: val_accuracy did not improve from 0.88000\n",
      "Epoch 676/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2745 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00676: val_accuracy did not improve from 0.88000\n",
      "Epoch 677/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00677: val_accuracy did not improve from 0.88000\n",
      "Epoch 678/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00678: val_accuracy did not improve from 0.88000\n",
      "Epoch 679/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00679: val_accuracy did not improve from 0.88000\n",
      "Epoch 680/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00680: val_accuracy did not improve from 0.88000\n",
      "Epoch 681/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3062 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00681: val_accuracy did not improve from 0.88000\n",
      "Epoch 682/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00682: val_accuracy did not improve from 0.88000\n",
      "Epoch 683/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00683: val_accuracy did not improve from 0.88000\n",
      "Epoch 684/2000\n",
      "113/113 - 7s - loss: 0.2825 - accuracy: 0.9544 - val_loss: 2.5368 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00684: val_accuracy did not improve from 0.88000\n",
      "Epoch 685/2000\n",
      "113/113 - 7s - loss: 0.3234 - accuracy: 0.9200 - val_loss: 1.3027 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00685: val_accuracy did not improve from 0.88000\n",
      "Epoch 686/2000\n",
      "113/113 - 6s - loss: 0.0963 - accuracy: 0.9722 - val_loss: 1.0217 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00686: val_accuracy did not improve from 0.88000\n",
      "Epoch 687/2000\n",
      "113/113 - 6s - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.9891 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00687: val_accuracy did not improve from 0.88000\n",
      "Epoch 688/2000\n",
      "113/113 - 7s - loss: 0.0229 - accuracy: 0.9911 - val_loss: 1.0069 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00688: val_accuracy did not improve from 0.88000\n",
      "Epoch 689/2000\n",
      "113/113 - 6s - loss: 0.0098 - accuracy: 0.9989 - val_loss: 1.0144 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00689: val_accuracy did not improve from 0.88000\n",
      "Epoch 690/2000\n",
      "113/113 - 6s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00690: val_accuracy did not improve from 0.88000\n",
      "Epoch 691/2000\n",
      "113/113 - 7s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00691: val_accuracy did not improve from 0.88000\n",
      "Epoch 692/2000\n",
      "113/113 - 6s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0057 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00692: val_accuracy did not improve from 0.88000\n",
      "Epoch 693/2000\n",
      "113/113 - 7s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0161 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00693: val_accuracy did not improve from 0.88000\n",
      "Epoch 694/2000\n",
      "113/113 - 7s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0298 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00694: val_accuracy did not improve from 0.88000\n",
      "Epoch 695/2000\n",
      "113/113 - 6s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00695: val_accuracy did not improve from 0.88000\n",
      "Epoch 696/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00696: val_accuracy did not improve from 0.88000\n",
      "Epoch 697/2000\n",
      "113/113 - 7s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00697: val_accuracy did not improve from 0.88000\n",
      "Epoch 698/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00698: val_accuracy did not improve from 0.88000\n",
      "Epoch 699/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00699: val_accuracy did not improve from 0.88000\n",
      "Epoch 700/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00700: val_accuracy did not improve from 0.88000\n",
      "Epoch 701/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00701: val_accuracy did not improve from 0.88000\n",
      "Epoch 702/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00702: val_accuracy did not improve from 0.88000\n",
      "Epoch 703/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00703: val_accuracy did not improve from 0.88000\n",
      "Epoch 704/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1107 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00704: val_accuracy did not improve from 0.88000\n",
      "Epoch 705/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1153 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00705: val_accuracy did not improve from 0.88000\n",
      "Epoch 706/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1255 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00706: val_accuracy did not improve from 0.88000\n",
      "Epoch 707/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00707: val_accuracy did not improve from 0.88000\n",
      "Epoch 708/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1315 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00708: val_accuracy did not improve from 0.88000\n",
      "Epoch 709/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00709: val_accuracy did not improve from 0.88000\n",
      "Epoch 710/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1393 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00710: val_accuracy did not improve from 0.88000\n",
      "Epoch 711/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1463 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00711: val_accuracy did not improve from 0.88000\n",
      "Epoch 712/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1516 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00712: val_accuracy did not improve from 0.88000\n",
      "Epoch 713/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00713: val_accuracy did not improve from 0.88000\n",
      "Epoch 714/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1611 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00714: val_accuracy did not improve from 0.88000\n",
      "Epoch 715/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00715: val_accuracy did not improve from 0.88000\n",
      "Epoch 716/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00716: val_accuracy did not improve from 0.88000\n",
      "Epoch 717/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00717: val_accuracy did not improve from 0.88000\n",
      "Epoch 718/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00718: val_accuracy did not improve from 0.88000\n",
      "Epoch 719/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00719: val_accuracy did not improve from 0.88000\n",
      "Epoch 720/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2014 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00720: val_accuracy did not improve from 0.88000\n",
      "Epoch 721/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00721: val_accuracy did not improve from 0.88000\n",
      "Epoch 722/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00722: val_accuracy did not improve from 0.88000\n",
      "Epoch 723/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00723: val_accuracy did not improve from 0.88000\n",
      "Epoch 724/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2219 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00724: val_accuracy did not improve from 0.88000\n",
      "Epoch 725/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00725: val_accuracy did not improve from 0.88000\n",
      "Epoch 726/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2328 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00726: val_accuracy did not improve from 0.88000\n",
      "Epoch 727/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00727: val_accuracy did not improve from 0.88000\n",
      "Epoch 728/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00728: val_accuracy did not improve from 0.88000\n",
      "Epoch 729/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2499 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00729: val_accuracy did not improve from 0.88000\n",
      "Epoch 730/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2557 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00730: val_accuracy did not improve from 0.88000\n",
      "Epoch 731/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2622 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00731: val_accuracy did not improve from 0.88000\n",
      "Epoch 732/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00732: val_accuracy did not improve from 0.88000\n",
      "Epoch 733/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00733: val_accuracy did not improve from 0.88000\n",
      "Epoch 734/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00734: val_accuracy did not improve from 0.88000\n",
      "Epoch 735/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00735: val_accuracy did not improve from 0.88000\n",
      "Epoch 736/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2881 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00736: val_accuracy did not improve from 0.88000\n",
      "Epoch 737/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2914 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00737: val_accuracy did not improve from 0.88000\n",
      "Epoch 738/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00738: val_accuracy did not improve from 0.88000\n",
      "Epoch 739/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00739: val_accuracy did not improve from 0.88000\n",
      "Epoch 740/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00740: val_accuracy did not improve from 0.88000\n",
      "Epoch 741/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3226 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00741: val_accuracy did not improve from 0.88000\n",
      "Epoch 742/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3236 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00742: val_accuracy did not improve from 0.88000\n",
      "Epoch 743/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00743: val_accuracy did not improve from 0.88000\n",
      "Epoch 744/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00744: val_accuracy did not improve from 0.88000\n",
      "Epoch 745/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00745: val_accuracy did not improve from 0.88000\n",
      "Epoch 746/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3356 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00746: val_accuracy did not improve from 0.88000\n",
      "Epoch 747/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00747: val_accuracy did not improve from 0.88000\n",
      "Epoch 748/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00748: val_accuracy did not improve from 0.88000\n",
      "Epoch 749/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00749: val_accuracy did not improve from 0.88000\n",
      "Epoch 750/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00750: val_accuracy did not improve from 0.88000\n",
      "Epoch 751/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3684 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00751: val_accuracy did not improve from 0.88000\n",
      "Epoch 752/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00752: val_accuracy did not improve from 0.88000\n",
      "Epoch 753/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3639 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00753: val_accuracy did not improve from 0.88000\n",
      "Epoch 754/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00754: val_accuracy did not improve from 0.88000\n",
      "Epoch 755/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5341 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00755: val_accuracy did not improve from 0.88000\n",
      "Epoch 756/2000\n",
      "113/113 - 7s - loss: 0.7376 - accuracy: 0.8856 - val_loss: 1.5819 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00756: val_accuracy did not improve from 0.88000\n",
      "Epoch 757/2000\n",
      "113/113 - 6s - loss: 0.1958 - accuracy: 0.9411 - val_loss: 0.8432 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00757: val_accuracy did not improve from 0.88000\n",
      "Epoch 758/2000\n",
      "113/113 - 7s - loss: 0.0694 - accuracy: 0.9778 - val_loss: 0.7603 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00758: val_accuracy did not improve from 0.88000\n",
      "Epoch 759/2000\n",
      "113/113 - 7s - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.8581 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00759: val_accuracy did not improve from 0.88000\n",
      "Epoch 760/2000\n",
      "113/113 - 7s - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.8186 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00760: val_accuracy did not improve from 0.88000\n",
      "Epoch 761/2000\n",
      "113/113 - 7s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00761: val_accuracy did not improve from 0.88000\n",
      "Epoch 762/2000\n",
      "113/113 - 6s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00762: val_accuracy did not improve from 0.88000\n",
      "Epoch 763/2000\n",
      "113/113 - 7s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00763: val_accuracy did not improve from 0.88000\n",
      "Epoch 764/2000\n",
      "113/113 - 7s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00764: val_accuracy did not improve from 0.88000\n",
      "Epoch 765/2000\n",
      "113/113 - 6s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00765: val_accuracy did not improve from 0.88000\n",
      "Epoch 766/2000\n",
      "113/113 - 6s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00766: val_accuracy did not improve from 0.88000\n",
      "Epoch 767/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00767: val_accuracy did not improve from 0.88000\n",
      "Epoch 768/2000\n",
      "113/113 - 6s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0343 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00768: val_accuracy did not improve from 0.88000\n",
      "Epoch 769/2000\n",
      "113/113 - 7s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00769: val_accuracy did not improve from 0.88000\n",
      "Epoch 770/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00770: val_accuracy did not improve from 0.88000\n",
      "Epoch 771/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00771: val_accuracy did not improve from 0.88000\n",
      "Epoch 772/2000\n",
      "113/113 - 6s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00772: val_accuracy did not improve from 0.88000\n",
      "Epoch 773/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00773: val_accuracy did not improve from 0.88000\n",
      "Epoch 774/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00774: val_accuracy did not improve from 0.88000\n",
      "Epoch 775/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1384 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00775: val_accuracy did not improve from 0.88000\n",
      "Epoch 776/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00776: val_accuracy did not improve from 0.88000\n",
      "Epoch 777/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00777: val_accuracy did not improve from 0.88000\n",
      "Epoch 778/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1689 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00778: val_accuracy did not improve from 0.88000\n",
      "Epoch 779/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1834 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00779: val_accuracy did not improve from 0.88000\n",
      "Epoch 780/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00780: val_accuracy did not improve from 0.88000\n",
      "Epoch 781/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2031 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00781: val_accuracy did not improve from 0.88000\n",
      "Epoch 782/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00782: val_accuracy did not improve from 0.88000\n",
      "Epoch 783/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2265 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00783: val_accuracy did not improve from 0.88000\n",
      "Epoch 784/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2330 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00784: val_accuracy did not improve from 0.88000\n",
      "Epoch 785/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00785: val_accuracy did not improve from 0.88000\n",
      "Epoch 786/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00786: val_accuracy did not improve from 0.88000\n",
      "Epoch 787/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2658 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00787: val_accuracy did not improve from 0.88000\n",
      "Epoch 788/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2732 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00788: val_accuracy did not improve from 0.88000\n",
      "Epoch 789/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2778 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00789: val_accuracy did not improve from 0.88000\n",
      "Epoch 790/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00790: val_accuracy did not improve from 0.88000\n",
      "Epoch 791/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00791: val_accuracy did not improve from 0.88000\n",
      "Epoch 792/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00792: val_accuracy did not improve from 0.88000\n",
      "Epoch 793/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00793: val_accuracy did not improve from 0.88000\n",
      "Epoch 794/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3169 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00794: val_accuracy did not improve from 0.88000\n",
      "Epoch 795/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00795: val_accuracy did not improve from 0.88000\n",
      "Epoch 796/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00796: val_accuracy did not improve from 0.88000\n",
      "Epoch 797/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00797: val_accuracy did not improve from 0.88000\n",
      "Epoch 798/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00798: val_accuracy did not improve from 0.88000\n",
      "Epoch 799/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3445 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00799: val_accuracy did not improve from 0.88000\n",
      "Epoch 800/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00800: val_accuracy did not improve from 0.88000\n",
      "Epoch 801/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3556 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00801: val_accuracy did not improve from 0.88000\n",
      "Epoch 802/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3619 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00802: val_accuracy did not improve from 0.88000\n",
      "Epoch 803/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3637 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00803: val_accuracy did not improve from 0.88000\n",
      "Epoch 804/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3632 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00804: val_accuracy did not improve from 0.88000\n",
      "Epoch 805/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3651 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00805: val_accuracy did not improve from 0.88000\n",
      "Epoch 806/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3706 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00806: val_accuracy did not improve from 0.88000\n",
      "Epoch 807/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00807: val_accuracy did not improve from 0.88000\n",
      "Epoch 808/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3785 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00808: val_accuracy did not improve from 0.88000\n",
      "Epoch 809/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3839 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00809: val_accuracy did not improve from 0.88000\n",
      "Epoch 810/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3771 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00810: val_accuracy did not improve from 0.88000\n",
      "Epoch 811/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00811: val_accuracy did not improve from 0.88000\n",
      "Epoch 812/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3922 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00812: val_accuracy did not improve from 0.88000\n",
      "Epoch 813/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3982 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00813: val_accuracy did not improve from 0.88000\n",
      "Epoch 814/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4049 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00814: val_accuracy did not improve from 0.88000\n",
      "Epoch 815/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3882 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00815: val_accuracy did not improve from 0.88000\n",
      "Epoch 816/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4006 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00816: val_accuracy did not improve from 0.88000\n",
      "Epoch 817/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00817: val_accuracy did not improve from 0.88000\n",
      "Epoch 818/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3983 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00818: val_accuracy did not improve from 0.88000\n",
      "Epoch 819/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3920 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00819: val_accuracy did not improve from 0.88000\n",
      "Epoch 820/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00820: val_accuracy did not improve from 0.88000\n",
      "Epoch 821/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00821: val_accuracy did not improve from 0.88000\n",
      "Epoch 822/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00822: val_accuracy did not improve from 0.88000\n",
      "Epoch 823/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00823: val_accuracy did not improve from 0.88000\n",
      "Epoch 824/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3918 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00824: val_accuracy did not improve from 0.88000\n",
      "Epoch 825/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3939 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00825: val_accuracy did not improve from 0.88000\n",
      "Epoch 826/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3902 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00826: val_accuracy did not improve from 0.88000\n",
      "Epoch 827/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3937 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00827: val_accuracy did not improve from 0.88000\n",
      "Epoch 828/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00828: val_accuracy did not improve from 0.88000\n",
      "Epoch 829/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00829: val_accuracy did not improve from 0.88000\n",
      "Epoch 830/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3690 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00830: val_accuracy did not improve from 0.88000\n",
      "Epoch 831/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4117 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00831: val_accuracy did not improve from 0.88000\n",
      "Epoch 832/2000\n",
      "113/113 - 7s - loss: 0.2395 - accuracy: 0.9767 - val_loss: 3.8113 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00832: val_accuracy did not improve from 0.88000\n",
      "Epoch 833/2000\n",
      "113/113 - 7s - loss: 0.9175 - accuracy: 0.8578 - val_loss: 1.0717 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00833: val_accuracy did not improve from 0.88000\n",
      "Epoch 834/2000\n",
      "113/113 - 7s - loss: 0.1307 - accuracy: 0.9578 - val_loss: 0.9462 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00834: val_accuracy did not improve from 0.88000\n",
      "Epoch 835/2000\n",
      "113/113 - 7s - loss: 0.0956 - accuracy: 0.9678 - val_loss: 0.9649 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00835: val_accuracy did not improve from 0.88000\n",
      "Epoch 836/2000\n",
      "113/113 - 6s - loss: 0.0380 - accuracy: 0.9867 - val_loss: 0.9976 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00836: val_accuracy did not improve from 0.88000\n",
      "Epoch 837/2000\n",
      "113/113 - 7s - loss: 0.0192 - accuracy: 0.9944 - val_loss: 1.0296 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00837: val_accuracy did not improve from 0.88000\n",
      "Epoch 838/2000\n",
      "113/113 - 6s - loss: 0.0129 - accuracy: 0.9956 - val_loss: 1.0532 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00838: val_accuracy did not improve from 0.88000\n",
      "Epoch 839/2000\n",
      "113/113 - 6s - loss: 0.0086 - accuracy: 0.9989 - val_loss: 1.0534 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00839: val_accuracy did not improve from 0.88000\n",
      "Epoch 840/2000\n",
      "113/113 - 6s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00840: val_accuracy did not improve from 0.88000\n",
      "Epoch 841/2000\n",
      "113/113 - 6s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00841: val_accuracy did not improve from 0.88000\n",
      "Epoch 842/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1151 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00842: val_accuracy did not improve from 0.88000\n",
      "Epoch 843/2000\n",
      "113/113 - 7s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1302 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00843: val_accuracy did not improve from 0.88000\n",
      "Epoch 844/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00844: val_accuracy did not improve from 0.88000\n",
      "Epoch 845/2000\n",
      "113/113 - 6s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00845: val_accuracy did not improve from 0.88000\n",
      "Epoch 846/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1513 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00846: val_accuracy did not improve from 0.88000\n",
      "Epoch 847/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00847: val_accuracy did not improve from 0.88000\n",
      "Epoch 848/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00848: val_accuracy did not improve from 0.88000\n",
      "Epoch 849/2000\n",
      "113/113 - 7s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00849: val_accuracy did not improve from 0.88000\n",
      "Epoch 850/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1829 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00850: val_accuracy did not improve from 0.88000\n",
      "Epoch 851/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1890 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00851: val_accuracy did not improve from 0.88000\n",
      "Epoch 852/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1957 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00852: val_accuracy did not improve from 0.88000\n",
      "Epoch 853/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1982 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00853: val_accuracy did not improve from 0.88000\n",
      "Epoch 854/2000\n",
      "113/113 - 7s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2079 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00854: val_accuracy did not improve from 0.88000\n",
      "Epoch 855/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00855: val_accuracy did not improve from 0.88000\n",
      "Epoch 856/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00856: val_accuracy did not improve from 0.88000\n",
      "Epoch 857/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2289 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00857: val_accuracy did not improve from 0.88000\n",
      "Epoch 858/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00858: val_accuracy did not improve from 0.88000\n",
      "Epoch 859/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00859: val_accuracy did not improve from 0.88000\n",
      "Epoch 860/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00860: val_accuracy did not improve from 0.88000\n",
      "Epoch 861/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2519 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00861: val_accuracy did not improve from 0.88000\n",
      "Epoch 862/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00862: val_accuracy did not improve from 0.88000\n",
      "Epoch 863/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2610 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00863: val_accuracy did not improve from 0.88000\n",
      "Epoch 864/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2697 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00864: val_accuracy did not improve from 0.88000\n",
      "Epoch 865/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00865: val_accuracy did not improve from 0.88000\n",
      "Epoch 866/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00866: val_accuracy did not improve from 0.88000\n",
      "Epoch 867/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2858 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00867: val_accuracy did not improve from 0.88000\n",
      "Epoch 868/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00868: val_accuracy did not improve from 0.88000\n",
      "Epoch 869/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2962 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00869: val_accuracy did not improve from 0.88000\n",
      "Epoch 870/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3027 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00870: val_accuracy did not improve from 0.88000\n",
      "Epoch 871/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3035 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00871: val_accuracy did not improve from 0.88000\n",
      "Epoch 872/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00872: val_accuracy did not improve from 0.88000\n",
      "Epoch 873/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3213 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00873: val_accuracy did not improve from 0.88000\n",
      "Epoch 874/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00874: val_accuracy did not improve from 0.88000\n",
      "Epoch 875/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3272 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00875: val_accuracy did not improve from 0.88000\n",
      "Epoch 876/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3468 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00876: val_accuracy did not improve from 0.88000\n",
      "Epoch 877/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00877: val_accuracy did not improve from 0.88000\n",
      "Epoch 878/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00878: val_accuracy did not improve from 0.88000\n",
      "Epoch 879/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3574 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00879: val_accuracy did not improve from 0.88000\n",
      "Epoch 880/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3640 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00880: val_accuracy did not improve from 0.88000\n",
      "Epoch 881/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3738 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00881: val_accuracy did not improve from 0.88000\n",
      "Epoch 882/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3723 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00882: val_accuracy did not improve from 0.88000\n",
      "Epoch 883/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3803 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00883: val_accuracy did not improve from 0.88000\n",
      "Epoch 884/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3763 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00884: val_accuracy did not improve from 0.88000\n",
      "Epoch 885/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00885: val_accuracy did not improve from 0.88000\n",
      "Epoch 886/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3929 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00886: val_accuracy did not improve from 0.88000\n",
      "Epoch 887/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3938 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00887: val_accuracy did not improve from 0.88000\n",
      "Epoch 888/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4091 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00888: val_accuracy did not improve from 0.88000\n",
      "Epoch 889/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4047 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00889: val_accuracy did not improve from 0.88000\n",
      "Epoch 890/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4106 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00890: val_accuracy did not improve from 0.88000\n",
      "Epoch 891/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00891: val_accuracy did not improve from 0.88000\n",
      "Epoch 892/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4257 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00892: val_accuracy did not improve from 0.88000\n",
      "Epoch 893/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4383 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00893: val_accuracy did not improve from 0.88000\n",
      "Epoch 894/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4288 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00894: val_accuracy did not improve from 0.88000\n",
      "Epoch 895/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00895: val_accuracy did not improve from 0.88000\n",
      "Epoch 896/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4652 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00896: val_accuracy did not improve from 0.88000\n",
      "Epoch 897/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00897: val_accuracy did not improve from 0.88000\n",
      "Epoch 898/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4567 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00898: val_accuracy did not improve from 0.88000\n",
      "Epoch 899/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4721 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00899: val_accuracy did not improve from 0.88000\n",
      "Epoch 900/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4513 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00900: val_accuracy did not improve from 0.88000\n",
      "Epoch 901/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4609 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00901: val_accuracy did not improve from 0.88000\n",
      "Epoch 902/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00902: val_accuracy did not improve from 0.88000\n",
      "Epoch 903/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4659 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00903: val_accuracy did not improve from 0.88000\n",
      "Epoch 904/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4545 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00904: val_accuracy did not improve from 0.88000\n",
      "Epoch 905/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4948 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00905: val_accuracy did not improve from 0.88000\n",
      "Epoch 906/2000\n",
      "113/113 - 6s - loss: 0.6162 - accuracy: 0.9200 - val_loss: 1.2637 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00906: val_accuracy did not improve from 0.88000\n",
      "Epoch 907/2000\n",
      "113/113 - 7s - loss: 0.1240 - accuracy: 0.9589 - val_loss: 1.0645 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00907: val_accuracy did not improve from 0.88000\n",
      "Epoch 908/2000\n",
      "113/113 - 7s - loss: 0.0354 - accuracy: 0.9844 - val_loss: 1.0281 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00908: val_accuracy did not improve from 0.88000\n",
      "Epoch 909/2000\n",
      "113/113 - 6s - loss: 0.0187 - accuracy: 0.9944 - val_loss: 1.0024 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00909: val_accuracy did not improve from 0.88000\n",
      "Epoch 910/2000\n",
      "113/113 - 6s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00910: val_accuracy did not improve from 0.88000\n",
      "Epoch 911/2000\n",
      "113/113 - 6s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00911: val_accuracy did not improve from 0.88000\n",
      "Epoch 912/2000\n",
      "113/113 - 7s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0767 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00912: val_accuracy did not improve from 0.88000\n",
      "Epoch 913/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00913: val_accuracy did not improve from 0.88000\n",
      "Epoch 914/2000\n",
      "113/113 - 6s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0988 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00914: val_accuracy did not improve from 0.88000\n",
      "Epoch 915/2000\n",
      "113/113 - 7s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00915: val_accuracy did not improve from 0.88000\n",
      "Epoch 916/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00916: val_accuracy did not improve from 0.88000\n",
      "Epoch 917/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.1242 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00917: val_accuracy did not improve from 0.88000\n",
      "Epoch 918/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00918: val_accuracy did not improve from 0.88000\n",
      "Epoch 919/2000\n",
      "113/113 - 7s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00919: val_accuracy did not improve from 0.88000\n",
      "Epoch 920/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1587 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00920: val_accuracy did not improve from 0.88000\n",
      "Epoch 921/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00921: val_accuracy did not improve from 0.88000\n",
      "Epoch 922/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00922: val_accuracy did not improve from 0.88000\n",
      "Epoch 923/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1920 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00923: val_accuracy did not improve from 0.88000\n",
      "Epoch 924/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00924: val_accuracy did not improve from 0.88000\n",
      "Epoch 925/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00925: val_accuracy did not improve from 0.88000\n",
      "Epoch 926/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00926: val_accuracy did not improve from 0.88000\n",
      "Epoch 927/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2340 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00927: val_accuracy did not improve from 0.88000\n",
      "Epoch 928/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2450 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00928: val_accuracy did not improve from 0.88000\n",
      "Epoch 929/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00929: val_accuracy did not improve from 0.88000\n",
      "Epoch 930/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00930: val_accuracy did not improve from 0.88000\n",
      "Epoch 931/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2688 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00931: val_accuracy did not improve from 0.88000\n",
      "Epoch 932/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2783 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00932: val_accuracy did not improve from 0.88000\n",
      "Epoch 933/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00933: val_accuracy did not improve from 0.88000\n",
      "Epoch 934/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00934: val_accuracy did not improve from 0.88000\n",
      "Epoch 935/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00935: val_accuracy did not improve from 0.88000\n",
      "Epoch 936/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3133 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00936: val_accuracy did not improve from 0.88000\n",
      "Epoch 937/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00937: val_accuracy did not improve from 0.88000\n",
      "Epoch 938/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00938: val_accuracy did not improve from 0.88000\n",
      "Epoch 939/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3322 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00939: val_accuracy did not improve from 0.88000\n",
      "Epoch 940/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00940: val_accuracy did not improve from 0.88000\n",
      "Epoch 941/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00941: val_accuracy did not improve from 0.88000\n",
      "Epoch 942/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3549 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00942: val_accuracy did not improve from 0.88000\n",
      "Epoch 943/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3621 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00943: val_accuracy did not improve from 0.88000\n",
      "Epoch 944/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3686 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00944: val_accuracy did not improve from 0.88000\n",
      "Epoch 945/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3699 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00945: val_accuracy did not improve from 0.88000\n",
      "Epoch 946/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00946: val_accuracy did not improve from 0.88000\n",
      "Epoch 947/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3933 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00947: val_accuracy did not improve from 0.88000\n",
      "Epoch 948/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4005 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00948: val_accuracy did not improve from 0.88000\n",
      "Epoch 949/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00949: val_accuracy did not improve from 0.88000\n",
      "Epoch 950/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00950: val_accuracy did not improve from 0.88000\n",
      "Epoch 951/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00951: val_accuracy did not improve from 0.88000\n",
      "Epoch 952/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4219 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00952: val_accuracy did not improve from 0.88000\n",
      "Epoch 953/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4262 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00953: val_accuracy did not improve from 0.88000\n",
      "Epoch 954/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00954: val_accuracy did not improve from 0.88000\n",
      "Epoch 955/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4512 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00955: val_accuracy did not improve from 0.88000\n",
      "Epoch 956/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4584 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00956: val_accuracy did not improve from 0.88000\n",
      "Epoch 957/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00957: val_accuracy did not improve from 0.88000\n",
      "Epoch 958/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00958: val_accuracy did not improve from 0.88000\n",
      "Epoch 959/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4748 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00959: val_accuracy did not improve from 0.88000\n",
      "Epoch 960/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4789 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00960: val_accuracy did not improve from 0.88000\n",
      "Epoch 961/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4895 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00961: val_accuracy did not improve from 0.88000\n",
      "Epoch 962/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4916 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00962: val_accuracy did not improve from 0.88000\n",
      "Epoch 963/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00963: val_accuracy did not improve from 0.88000\n",
      "Epoch 964/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00964: val_accuracy did not improve from 0.88000\n",
      "Epoch 965/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00965: val_accuracy did not improve from 0.88000\n",
      "Epoch 966/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5207 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00966: val_accuracy did not improve from 0.88000\n",
      "Epoch 967/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5173 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00967: val_accuracy did not improve from 0.88000\n",
      "Epoch 968/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5185 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00968: val_accuracy did not improve from 0.88000\n",
      "Epoch 969/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5198 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00969: val_accuracy did not improve from 0.88000\n",
      "Epoch 970/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00970: val_accuracy did not improve from 0.88000\n",
      "Epoch 971/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5340 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00971: val_accuracy did not improve from 0.88000\n",
      "Epoch 972/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5466 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00972: val_accuracy did not improve from 0.88000\n",
      "Epoch 973/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5485 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00973: val_accuracy did not improve from 0.88000\n",
      "Epoch 974/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5485 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00974: val_accuracy did not improve from 0.88000\n",
      "Epoch 975/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00975: val_accuracy did not improve from 0.88000\n",
      "Epoch 976/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00976: val_accuracy did not improve from 0.88000\n",
      "Epoch 977/2000\n",
      "113/113 - 7s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00977: val_accuracy did not improve from 0.88000\n",
      "Epoch 978/2000\n",
      "113/113 - 7s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00978: val_accuracy did not improve from 0.88000\n",
      "Epoch 979/2000\n",
      "113/113 - 7s - loss: 0.4039 - accuracy: 0.9300 - val_loss: 1.1272 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00979: val_accuracy did not improve from 0.88000\n",
      "Epoch 980/2000\n",
      "113/113 - 7s - loss: 0.1863 - accuracy: 0.9467 - val_loss: 0.6604 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00980: val_accuracy did not improve from 0.88000\n",
      "Epoch 981/2000\n",
      "113/113 - 6s - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.8438 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00981: val_accuracy did not improve from 0.88000\n",
      "Epoch 982/2000\n",
      "113/113 - 7s - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.9108 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00982: val_accuracy did not improve from 0.88000\n",
      "Epoch 983/2000\n",
      "113/113 - 7s - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.8646 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00983: val_accuracy did not improve from 0.88000\n",
      "Epoch 984/2000\n",
      "113/113 - 7s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00984: val_accuracy did not improve from 0.88000\n",
      "Epoch 985/2000\n",
      "113/113 - 7s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00985: val_accuracy did not improve from 0.88000\n",
      "Epoch 986/2000\n",
      "113/113 - 6s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9103 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00986: val_accuracy did not improve from 0.88000\n",
      "Epoch 987/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00987: val_accuracy did not improve from 0.88000\n",
      "Epoch 988/2000\n",
      "113/113 - 6s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00988: val_accuracy did not improve from 0.88000\n",
      "Epoch 989/2000\n",
      "113/113 - 7s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00989: val_accuracy did not improve from 0.88000\n",
      "Epoch 990/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00990: val_accuracy did not improve from 0.88000\n",
      "Epoch 991/2000\n",
      "113/113 - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00991: val_accuracy did not improve from 0.88000\n",
      "Epoch 992/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00992: val_accuracy did not improve from 0.88000\n",
      "Epoch 993/2000\n",
      "113/113 - 6s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00993: val_accuracy did not improve from 0.88000\n",
      "Epoch 994/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00994: val_accuracy did not improve from 0.88000\n",
      "Epoch 995/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00995: val_accuracy did not improve from 0.88000\n",
      "Epoch 996/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00996: val_accuracy did not improve from 0.88000\n",
      "Epoch 997/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00997: val_accuracy did not improve from 0.88000\n",
      "Epoch 998/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00998: val_accuracy did not improve from 0.88000\n",
      "Epoch 999/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9980 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00999: val_accuracy did not improve from 0.88000\n",
      "Epoch 1000/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01000: val_accuracy did not improve from 0.88000\n",
      "Epoch 1001/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01001: val_accuracy did not improve from 0.88000\n",
      "Epoch 1002/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01002: val_accuracy did not improve from 0.88000\n",
      "Epoch 1003/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01003: val_accuracy did not improve from 0.88000\n",
      "Epoch 1004/2000\n",
      "113/113 - 7s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01004: val_accuracy did not improve from 0.88000\n",
      "Epoch 1005/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0360 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01005: val_accuracy did not improve from 0.88000\n",
      "Epoch 1006/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01006: val_accuracy did not improve from 0.88000\n",
      "Epoch 1007/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01007: val_accuracy did not improve from 0.88000\n",
      "Epoch 1008/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0557 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01008: val_accuracy did not improve from 0.88000\n",
      "Epoch 1009/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0621 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01009: val_accuracy did not improve from 0.88000\n",
      "Epoch 1010/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01010: val_accuracy did not improve from 0.88000\n",
      "Epoch 1011/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0753 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01011: val_accuracy did not improve from 0.88000\n",
      "Epoch 1012/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0745 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01012: val_accuracy did not improve from 0.88000\n",
      "Epoch 1013/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01013: val_accuracy did not improve from 0.88000\n",
      "Epoch 1014/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01014: val_accuracy did not improve from 0.88000\n",
      "Epoch 1015/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01015: val_accuracy did not improve from 0.88000\n",
      "Epoch 1016/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0931 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01016: val_accuracy did not improve from 0.88000\n",
      "Epoch 1017/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01017: val_accuracy did not improve from 0.88000\n",
      "Epoch 1018/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01018: val_accuracy did not improve from 0.88000\n",
      "Epoch 1019/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01019: val_accuracy did not improve from 0.88000\n",
      "Epoch 1020/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01020: val_accuracy did not improve from 0.88000\n",
      "Epoch 1021/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01021: val_accuracy did not improve from 0.88000\n",
      "Epoch 1022/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01022: val_accuracy did not improve from 0.88000\n",
      "Epoch 1023/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01023: val_accuracy did not improve from 0.88000\n",
      "Epoch 1024/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01024: val_accuracy did not improve from 0.88000\n",
      "Epoch 1025/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01025: val_accuracy did not improve from 0.88000\n",
      "Epoch 1026/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01026: val_accuracy did not improve from 0.88000\n",
      "Epoch 1027/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01027: val_accuracy did not improve from 0.88000\n",
      "Epoch 1028/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01028: val_accuracy did not improve from 0.88000\n",
      "Epoch 1029/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1354 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01029: val_accuracy did not improve from 0.88000\n",
      "Epoch 1030/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01030: val_accuracy did not improve from 0.88000\n",
      "Epoch 1031/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01031: val_accuracy did not improve from 0.88000\n",
      "Epoch 1032/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1392 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01032: val_accuracy did not improve from 0.88000\n",
      "Epoch 1033/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01033: val_accuracy did not improve from 0.88000\n",
      "Epoch 1034/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1405 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01034: val_accuracy did not improve from 0.88000\n",
      "Epoch 1035/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1515 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01035: val_accuracy did not improve from 0.88000\n",
      "Epoch 1036/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01036: val_accuracy did not improve from 0.88000\n",
      "Epoch 1037/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1517 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01037: val_accuracy did not improve from 0.88000\n",
      "Epoch 1038/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01038: val_accuracy did not improve from 0.88000\n",
      "Epoch 1039/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01039: val_accuracy did not improve from 0.88000\n",
      "Epoch 1040/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01040: val_accuracy did not improve from 0.88000\n",
      "Epoch 1041/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01041: val_accuracy did not improve from 0.88000\n",
      "Epoch 1042/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01042: val_accuracy did not improve from 0.88000\n",
      "Epoch 1043/2000\n",
      "113/113 - 7s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01043: val_accuracy did not improve from 0.88000\n",
      "Epoch 1044/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01044: val_accuracy did not improve from 0.88000\n",
      "Epoch 1045/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01045: val_accuracy did not improve from 0.88000\n",
      "Epoch 1046/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01046: val_accuracy did not improve from 0.88000\n",
      "Epoch 1047/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01047: val_accuracy did not improve from 0.88000\n",
      "Epoch 1048/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2086 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01048: val_accuracy did not improve from 0.88000\n",
      "Epoch 1049/2000\n",
      "113/113 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01049: val_accuracy did not improve from 0.88000\n",
      "Epoch 1050/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01050: val_accuracy did not improve from 0.88000\n",
      "Epoch 1051/2000\n",
      "113/113 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01051: val_accuracy did not improve from 0.88000\n",
      "Epoch 1052/2000\n",
      "113/113 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2385 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01052: val_accuracy did not improve from 0.88000\n",
      "Epoch 1053/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2114 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01053: val_accuracy did not improve from 0.88000\n",
      "Epoch 1054/2000\n",
      "113/113 - 6s - loss: 0.4944 - accuracy: 0.9289 - val_loss: 1.5783 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01054: val_accuracy did not improve from 0.88000\n",
      "Epoch 1055/2000\n",
      "113/113 - 6s - loss: 0.2511 - accuracy: 0.9400 - val_loss: 1.2484 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01055: val_accuracy did not improve from 0.88000\n",
      "Epoch 1056/2000\n",
      "113/113 - 6s - loss: 0.0579 - accuracy: 0.9789 - val_loss: 1.2253 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01056: val_accuracy did not improve from 0.88000\n",
      "Epoch 1057/2000\n",
      "113/113 - 6s - loss: 0.0224 - accuracy: 0.9956 - val_loss: 1.2439 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01057: val_accuracy did not improve from 0.88000\n",
      "Epoch 1058/2000\n",
      "113/113 - 6s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01058: val_accuracy did not improve from 0.88000\n",
      "Epoch 1059/2000\n",
      "113/113 - 7s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01059: val_accuracy did not improve from 0.88000\n",
      "Epoch 1060/2000\n",
      "113/113 - 6s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01060: val_accuracy did not improve from 0.88000\n",
      "Epoch 1061/2000\n",
      "113/113 - 6s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01061: val_accuracy did not improve from 0.88000\n",
      "Epoch 1062/2000\n",
      "113/113 - 6s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01062: val_accuracy did not improve from 0.88000\n",
      "Epoch 1063/2000\n",
      "113/113 - 6s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01063: val_accuracy did not improve from 0.88000\n",
      "Epoch 1064/2000\n",
      "113/113 - 7s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01064: val_accuracy did not improve from 0.88000\n",
      "Epoch 1065/2000\n",
      "113/113 - 7s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01065: val_accuracy did not improve from 0.88000\n",
      "Epoch 1066/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01066: val_accuracy did not improve from 0.88000\n",
      "Epoch 1067/2000\n",
      "113/113 - 6s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01067: val_accuracy did not improve from 0.88000\n",
      "Epoch 1068/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2493 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01068: val_accuracy did not improve from 0.88000\n",
      "Epoch 1069/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2555 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01069: val_accuracy did not improve from 0.88000\n",
      "Epoch 1070/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01070: val_accuracy did not improve from 0.88000\n",
      "Epoch 1071/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01071: val_accuracy did not improve from 0.88000\n",
      "Epoch 1072/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01072: val_accuracy did not improve from 0.88000\n",
      "Epoch 1073/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2679 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01073: val_accuracy did not improve from 0.88000\n",
      "Epoch 1074/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2814 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01074: val_accuracy did not improve from 0.88000\n",
      "Epoch 1075/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2797 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01075: val_accuracy did not improve from 0.88000\n",
      "Epoch 1076/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2917 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01076: val_accuracy did not improve from 0.88000\n",
      "Epoch 1077/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01077: val_accuracy did not improve from 0.88000\n",
      "Epoch 1078/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01078: val_accuracy did not improve from 0.88000\n",
      "Epoch 1079/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3047 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01079: val_accuracy did not improve from 0.88000\n",
      "Epoch 1080/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01080: val_accuracy did not improve from 0.88000\n",
      "Epoch 1081/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3222 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01081: val_accuracy did not improve from 0.88000\n",
      "Epoch 1082/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01082: val_accuracy did not improve from 0.88000\n",
      "Epoch 1083/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01083: val_accuracy did not improve from 0.88000\n",
      "Epoch 1084/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3308 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01084: val_accuracy did not improve from 0.88000\n",
      "Epoch 1085/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3327 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01085: val_accuracy did not improve from 0.88000\n",
      "Epoch 1086/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3379 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01086: val_accuracy did not improve from 0.88000\n",
      "Epoch 1087/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01087: val_accuracy did not improve from 0.88000\n",
      "Epoch 1088/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01088: val_accuracy did not improve from 0.88000\n",
      "Epoch 1089/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01089: val_accuracy did not improve from 0.88000\n",
      "Epoch 1090/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3689 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01090: val_accuracy did not improve from 0.88000\n",
      "Epoch 1091/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3745 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01091: val_accuracy did not improve from 0.88000\n",
      "Epoch 1092/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3727 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01092: val_accuracy did not improve from 0.88000\n",
      "Epoch 1093/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3714 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01093: val_accuracy did not improve from 0.88000\n",
      "Epoch 1094/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3844 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01094: val_accuracy did not improve from 0.88000\n",
      "Epoch 1095/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3818 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01095: val_accuracy did not improve from 0.88000\n",
      "Epoch 1096/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3869 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01096: val_accuracy did not improve from 0.88000\n",
      "Epoch 1097/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01097: val_accuracy did not improve from 0.88000\n",
      "Epoch 1098/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3968 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01098: val_accuracy did not improve from 0.88000\n",
      "Epoch 1099/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3972 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01099: val_accuracy did not improve from 0.88000\n",
      "Epoch 1100/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4131 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01100: val_accuracy did not improve from 0.88000\n",
      "Epoch 1101/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4084 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01101: val_accuracy did not improve from 0.88000\n",
      "Epoch 1102/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01102: val_accuracy did not improve from 0.88000\n",
      "Epoch 1103/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4249 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01103: val_accuracy did not improve from 0.88000\n",
      "Epoch 1104/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01104: val_accuracy did not improve from 0.88000\n",
      "Epoch 1105/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4348 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01105: val_accuracy did not improve from 0.88000\n",
      "Epoch 1106/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01106: val_accuracy did not improve from 0.88000\n",
      "Epoch 1107/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4369 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01107: val_accuracy did not improve from 0.88000\n",
      "Epoch 1108/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01108: val_accuracy did not improve from 0.88000\n",
      "Epoch 1109/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4341 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01109: val_accuracy did not improve from 0.88000\n",
      "Epoch 1110/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4370 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01110: val_accuracy did not improve from 0.88000\n",
      "Epoch 1111/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4483 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01111: val_accuracy did not improve from 0.88000\n",
      "Epoch 1112/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4513 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01112: val_accuracy did not improve from 0.88000\n",
      "Epoch 1113/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4521 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01113: val_accuracy did not improve from 0.88000\n",
      "Epoch 1114/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4547 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01114: val_accuracy did not improve from 0.88000\n",
      "Epoch 1115/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01115: val_accuracy did not improve from 0.88000\n",
      "Epoch 1116/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4559 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01116: val_accuracy did not improve from 0.88000\n",
      "Epoch 1117/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01117: val_accuracy did not improve from 0.88000\n",
      "Epoch 1118/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4521 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01118: val_accuracy did not improve from 0.88000\n",
      "Epoch 1119/2000\n",
      "113/113 - 7s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01119: val_accuracy did not improve from 0.88000\n",
      "Epoch 1120/2000\n",
      "113/113 - 7s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4927 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01120: val_accuracy did not improve from 0.88000\n",
      "Epoch 1121/2000\n",
      "113/113 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01121: val_accuracy did not improve from 0.88000\n",
      "Epoch 1122/2000\n",
      "113/113 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4855 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01122: val_accuracy did not improve from 0.88000\n",
      "Epoch 1123/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4505 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01123: val_accuracy did not improve from 0.88000\n",
      "Epoch 1124/2000\n",
      "113/113 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4947 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01124: val_accuracy did not improve from 0.88000\n",
      "Epoch 1125/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4675 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01125: val_accuracy did not improve from 0.88000\n",
      "Epoch 1126/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01126: val_accuracy did not improve from 0.88000\n",
      "Epoch 1127/2000\n",
      "113/113 - 7s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5047 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01127: val_accuracy did not improve from 0.88000\n",
      "Epoch 1128/2000\n",
      "113/113 - 7s - loss: 0.3387 - accuracy: 0.9589 - val_loss: 1.8642 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01128: val_accuracy did not improve from 0.88000\n",
      "Epoch 1129/2000\n",
      "113/113 - 7s - loss: 0.3387 - accuracy: 0.9278 - val_loss: 1.1502 - val_accuracy: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01129: val_accuracy did not improve from 0.88000\n",
      "Epoch 1130/2000\n",
      "113/113 - 6s - loss: 0.0635 - accuracy: 0.9789 - val_loss: 0.9270 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01130: val_accuracy did not improve from 0.88000\n",
      "Epoch 1131/2000\n",
      "113/113 - 6s - loss: 0.0311 - accuracy: 0.9922 - val_loss: 1.0535 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01131: val_accuracy did not improve from 0.88000\n",
      "Epoch 1132/2000\n",
      "113/113 - 7s - loss: 0.0341 - accuracy: 0.9944 - val_loss: 1.0061 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01132: val_accuracy did not improve from 0.88000\n",
      "Epoch 1133/2000\n",
      "113/113 - 7s - loss: 0.0080 - accuracy: 0.9989 - val_loss: 1.0777 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01133: val_accuracy did not improve from 0.88000\n",
      "Epoch 1134/2000\n",
      "113/113 - 7s - loss: 0.0135 - accuracy: 0.9978 - val_loss: 1.0335 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01134: val_accuracy did not improve from 0.88000\n",
      "Epoch 1135/2000\n",
      "113/113 - 6s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01135: val_accuracy did not improve from 0.88000\n",
      "Epoch 1136/2000\n",
      "113/113 - 6s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0823 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01136: val_accuracy did not improve from 0.88000\n",
      "Epoch 1137/2000\n",
      "113/113 - 7s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01137: val_accuracy did not improve from 0.88000\n",
      "Epoch 1138/2000\n",
      "113/113 - 6s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01138: val_accuracy did not improve from 0.88000\n",
      "Epoch 1139/2000\n",
      "113/113 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01139: val_accuracy did not improve from 0.88000\n",
      "Epoch 1140/2000\n",
      "113/113 - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01140: val_accuracy did not improve from 0.88000\n",
      "Epoch 1141/2000\n",
      "113/113 - 6s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1595 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01141: val_accuracy did not improve from 0.88000\n",
      "Epoch 1142/2000\n",
      "113/113 - 7s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1737 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01142: val_accuracy did not improve from 0.88000\n",
      "Epoch 1143/2000\n",
      "113/113 - 7s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01143: val_accuracy did not improve from 0.88000\n",
      "Epoch 1144/2000\n",
      "113/113 - 7s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1989 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01144: val_accuracy did not improve from 0.88000\n",
      "Epoch 1145/2000\n",
      "113/113 - 6s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01145: val_accuracy did not improve from 0.88000\n",
      "Epoch 1146/2000\n",
      "113/113 - 6s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2174 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01146: val_accuracy did not improve from 0.88000\n",
      "Epoch 1147/2000\n",
      "113/113 - 7s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2305 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01147: val_accuracy did not improve from 0.88000\n",
      "Epoch 1148/2000\n",
      "113/113 - 7s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2365 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01148: val_accuracy did not improve from 0.88000\n",
      "Epoch 1149/2000\n",
      "113/113 - 6s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01149: val_accuracy did not improve from 0.88000\n",
      "Epoch 1150/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01150: val_accuracy did not improve from 0.88000\n",
      "Epoch 1151/2000\n",
      "113/113 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01151: val_accuracy did not improve from 0.88000\n",
      "Epoch 1152/2000\n",
      "113/113 - 7s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2752 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01152: val_accuracy did not improve from 0.88000\n",
      "Epoch 1153/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01153: val_accuracy did not improve from 0.88000\n",
      "Epoch 1154/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2913 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01154: val_accuracy did not improve from 0.88000\n",
      "Epoch 1155/2000\n",
      "113/113 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01155: val_accuracy did not improve from 0.88000\n",
      "Epoch 1156/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3076 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01156: val_accuracy did not improve from 0.88000\n",
      "Epoch 1157/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3162 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01157: val_accuracy did not improve from 0.88000\n",
      "Epoch 1158/2000\n",
      "113/113 - 7s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01158: val_accuracy did not improve from 0.88000\n",
      "Epoch 1159/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01159: val_accuracy did not improve from 0.88000\n",
      "Epoch 1160/2000\n",
      "113/113 - 6s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01160: val_accuracy did not improve from 0.88000\n",
      "Epoch 1161/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01161: val_accuracy did not improve from 0.88000\n",
      "Epoch 1162/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01162: val_accuracy did not improve from 0.88000\n",
      "Epoch 1163/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3657 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01163: val_accuracy did not improve from 0.88000\n",
      "Epoch 1164/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01164: val_accuracy did not improve from 0.88000\n",
      "Epoch 1165/2000\n",
      "113/113 - 7s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01165: val_accuracy did not improve from 0.88000\n",
      "Epoch 1166/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01166: val_accuracy did not improve from 0.88000\n",
      "Epoch 1167/2000\n",
      "113/113 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01167: val_accuracy did not improve from 0.88000\n",
      "Epoch 1168/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4021 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01168: val_accuracy did not improve from 0.88000\n",
      "Epoch 1169/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4081 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01169: val_accuracy did not improve from 0.88000\n",
      "Epoch 1170/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4236 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01170: val_accuracy did not improve from 0.88000\n",
      "Epoch 1171/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4213 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01171: val_accuracy did not improve from 0.88000\n",
      "Epoch 1172/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4309 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01172: val_accuracy did not improve from 0.88000\n",
      "Epoch 1173/2000\n",
      "113/113 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4368 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01173: val_accuracy did not improve from 0.88000\n",
      "Epoch 1174/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01174: val_accuracy did not improve from 0.88000\n",
      "Epoch 1175/2000\n",
      "113/113 - 7s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4546 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01175: val_accuracy did not improve from 0.88000\n",
      "Epoch 1176/2000\n",
      "113/113 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4617 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01176: val_accuracy did not improve from 0.88000\n",
      "Epoch 1177/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4746 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01177: val_accuracy did not improve from 0.88000\n",
      "Epoch 1178/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01178: val_accuracy did not improve from 0.88000\n",
      "Epoch 1179/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01179: val_accuracy did not improve from 0.88000\n",
      "Epoch 1180/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4829 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01180: val_accuracy did not improve from 0.88000\n",
      "Epoch 1181/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4855 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01181: val_accuracy did not improve from 0.88000\n",
      "Epoch 1182/2000\n",
      "113/113 - 7s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01182: val_accuracy did not improve from 0.88000\n",
      "Epoch 1183/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01183: val_accuracy did not improve from 0.88000\n",
      "Epoch 1184/2000\n",
      "113/113 - 7s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5020 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01184: val_accuracy did not improve from 0.88000\n",
      "Epoch 1185/2000\n",
      "113/113 - 6s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01185: val_accuracy did not improve from 0.88000\n",
      "Epoch 1186/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5147 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01186: val_accuracy did not improve from 0.88000\n",
      "Epoch 1187/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5152 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01187: val_accuracy did not improve from 0.88000\n",
      "Epoch 1188/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5270 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01188: val_accuracy did not improve from 0.88000\n",
      "Epoch 1189/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5396 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01189: val_accuracy did not improve from 0.88000\n",
      "Epoch 1190/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5381 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01190: val_accuracy did not improve from 0.88000\n",
      "Epoch 1191/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5455 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01191: val_accuracy did not improve from 0.88000\n",
      "Epoch 1192/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5384 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01192: val_accuracy did not improve from 0.88000\n",
      "Epoch 1193/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5537 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01193: val_accuracy did not improve from 0.88000\n",
      "Epoch 1194/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5571 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01194: val_accuracy did not improve from 0.88000\n",
      "Epoch 1195/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01195: val_accuracy did not improve from 0.88000\n",
      "Epoch 1196/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01196: val_accuracy did not improve from 0.88000\n",
      "Epoch 1197/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01197: val_accuracy did not improve from 0.88000\n",
      "Epoch 1198/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5434 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01198: val_accuracy did not improve from 0.88000\n",
      "Epoch 1199/2000\n",
      "113/113 - 4s - loss: 0.0133 - accuracy: 0.9989 - val_loss: 1.8224 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01199: val_accuracy did not improve from 0.88000\n",
      "Epoch 1200/2000\n",
      "113/113 - 4s - loss: 0.5548 - accuracy: 0.9033 - val_loss: 0.9696 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01200: val_accuracy did not improve from 0.88000\n",
      "Epoch 1201/2000\n",
      "113/113 - 4s - loss: 0.2182 - accuracy: 0.9433 - val_loss: 0.7808 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01201: val_accuracy did not improve from 0.88000\n",
      "Epoch 1202/2000\n",
      "113/113 - 4s - loss: 0.0624 - accuracy: 0.9800 - val_loss: 0.8979 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01202: val_accuracy did not improve from 0.88000\n",
      "Epoch 1203/2000\n",
      "113/113 - 4s - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.9672 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01203: val_accuracy did not improve from 0.88000\n",
      "Epoch 1204/2000\n",
      "113/113 - 4s - loss: 0.0130 - accuracy: 0.9978 - val_loss: 1.0315 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01204: val_accuracy did not improve from 0.88000\n",
      "Epoch 1205/2000\n",
      "113/113 - 4s - loss: 0.0126 - accuracy: 0.9967 - val_loss: 1.0568 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01205: val_accuracy did not improve from 0.88000\n",
      "Epoch 1206/2000\n",
      "113/113 - 4s - loss: 0.0113 - accuracy: 0.9989 - val_loss: 1.0482 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01206: val_accuracy did not improve from 0.88000\n",
      "Epoch 1207/2000\n",
      "113/113 - 4s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0541 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01207: val_accuracy did not improve from 0.88000\n",
      "Epoch 1208/2000\n",
      "113/113 - 4s - loss: 0.0056 - accuracy: 0.9989 - val_loss: 1.0998 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01208: val_accuracy did not improve from 0.88000\n",
      "Epoch 1209/2000\n",
      "113/113 - 4s - loss: 0.0052 - accuracy: 0.9989 - val_loss: 1.0635 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01209: val_accuracy did not improve from 0.88000\n",
      "Epoch 1210/2000\n",
      "113/113 - 4s - loss: 0.0055 - accuracy: 0.9989 - val_loss: 1.1189 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01210: val_accuracy did not improve from 0.88000\n",
      "Epoch 1211/2000\n",
      "113/113 - 4s - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.1657 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01211: val_accuracy did not improve from 0.88000\n",
      "Epoch 1212/2000\n",
      "113/113 - 4s - loss: 0.0055 - accuracy: 0.9978 - val_loss: 1.1451 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01212: val_accuracy did not improve from 0.88000\n",
      "Epoch 1213/2000\n",
      "113/113 - 4s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01213: val_accuracy did not improve from 0.88000\n",
      "Epoch 1214/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01214: val_accuracy did not improve from 0.88000\n",
      "Epoch 1215/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1437 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01215: val_accuracy did not improve from 0.88000\n",
      "Epoch 1216/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01216: val_accuracy did not improve from 0.88000\n",
      "Epoch 1217/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01217: val_accuracy did not improve from 0.88000\n",
      "Epoch 1218/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01218: val_accuracy did not improve from 0.88000\n",
      "Epoch 1219/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1905 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01219: val_accuracy did not improve from 0.88000\n",
      "Epoch 1220/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01220: val_accuracy did not improve from 0.88000\n",
      "Epoch 1221/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01221: val_accuracy did not improve from 0.88000\n",
      "Epoch 1222/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01222: val_accuracy did not improve from 0.88000\n",
      "Epoch 1223/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01223: val_accuracy did not improve from 0.88000\n",
      "Epoch 1224/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01224: val_accuracy did not improve from 0.88000\n",
      "Epoch 1225/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01225: val_accuracy did not improve from 0.88000\n",
      "Epoch 1226/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01226: val_accuracy did not improve from 0.88000\n",
      "Epoch 1227/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2645 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01227: val_accuracy did not improve from 0.88000\n",
      "Epoch 1228/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01228: val_accuracy did not improve from 0.88000\n",
      "Epoch 1229/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01229: val_accuracy did not improve from 0.88000\n",
      "Epoch 1230/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01230: val_accuracy did not improve from 0.88000\n",
      "Epoch 1231/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2976 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01231: val_accuracy did not improve from 0.88000\n",
      "Epoch 1232/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01232: val_accuracy did not improve from 0.88000\n",
      "Epoch 1233/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01233: val_accuracy did not improve from 0.88000\n",
      "Epoch 1234/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3234 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01234: val_accuracy did not improve from 0.88000\n",
      "Epoch 1235/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01235: val_accuracy did not improve from 0.88000\n",
      "Epoch 1236/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01236: val_accuracy did not improve from 0.88000\n",
      "Epoch 1237/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01237: val_accuracy did not improve from 0.88000\n",
      "Epoch 1238/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01238: val_accuracy did not improve from 0.88000\n",
      "Epoch 1239/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01239: val_accuracy did not improve from 0.88000\n",
      "Epoch 1240/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3609 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01240: val_accuracy did not improve from 0.88000\n",
      "Epoch 1241/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3672 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01241: val_accuracy did not improve from 0.88000\n",
      "Epoch 1242/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01242: val_accuracy did not improve from 0.88000\n",
      "Epoch 1243/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01243: val_accuracy did not improve from 0.88000\n",
      "Epoch 1244/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3906 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01244: val_accuracy did not improve from 0.88000\n",
      "Epoch 1245/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01245: val_accuracy did not improve from 0.88000\n",
      "Epoch 1246/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01246: val_accuracy did not improve from 0.88000\n",
      "Epoch 1247/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01247: val_accuracy did not improve from 0.88000\n",
      "Epoch 1248/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01248: val_accuracy did not improve from 0.88000\n",
      "Epoch 1249/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4220 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01249: val_accuracy did not improve from 0.88000\n",
      "Epoch 1250/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4333 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01250: val_accuracy did not improve from 0.88000\n",
      "Epoch 1251/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4434 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01251: val_accuracy did not improve from 0.88000\n",
      "Epoch 1252/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4394 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01252: val_accuracy did not improve from 0.88000\n",
      "Epoch 1253/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4549 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01253: val_accuracy did not improve from 0.88000\n",
      "Epoch 1254/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01254: val_accuracy did not improve from 0.88000\n",
      "Epoch 1255/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4682 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01255: val_accuracy did not improve from 0.88000\n",
      "Epoch 1256/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01256: val_accuracy did not improve from 0.88000\n",
      "Epoch 1257/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01257: val_accuracy did not improve from 0.88000\n",
      "Epoch 1258/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01258: val_accuracy did not improve from 0.88000\n",
      "Epoch 1259/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4948 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01259: val_accuracy did not improve from 0.88000\n",
      "Epoch 1260/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4891 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01260: val_accuracy did not improve from 0.88000\n",
      "Epoch 1261/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5090 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01261: val_accuracy did not improve from 0.88000\n",
      "Epoch 1262/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01262: val_accuracy did not improve from 0.88000\n",
      "Epoch 1263/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01263: val_accuracy did not improve from 0.88000\n",
      "Epoch 1264/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01264: val_accuracy did not improve from 0.88000\n",
      "Epoch 1265/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01265: val_accuracy did not improve from 0.88000\n",
      "Epoch 1266/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5242 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01266: val_accuracy did not improve from 0.88000\n",
      "Epoch 1267/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5156 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01267: val_accuracy did not improve from 0.88000\n",
      "Epoch 1268/2000\n",
      "113/113 - 4s - loss: 0.1340 - accuracy: 0.9833 - val_loss: 2.2730 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 01268: val_accuracy did not improve from 0.88000\n",
      "Epoch 1269/2000\n",
      "113/113 - 4s - loss: 0.3608 - accuracy: 0.9211 - val_loss: 0.9336 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01269: val_accuracy did not improve from 0.88000\n",
      "Epoch 1270/2000\n",
      "113/113 - 4s - loss: 0.1375 - accuracy: 0.9611 - val_loss: 0.8797 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01270: val_accuracy did not improve from 0.88000\n",
      "Epoch 1271/2000\n",
      "113/113 - 4s - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.9677 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01271: val_accuracy did not improve from 0.88000\n",
      "Epoch 1272/2000\n",
      "113/113 - 4s - loss: 0.0335 - accuracy: 0.9944 - val_loss: 1.0157 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 01272: val_accuracy did not improve from 0.88000\n",
      "Epoch 1273/2000\n",
      "113/113 - 4s - loss: 0.0268 - accuracy: 0.9967 - val_loss: 1.0963 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01273: val_accuracy did not improve from 0.88000\n",
      "Epoch 1274/2000\n",
      "113/113 - 4s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01274: val_accuracy did not improve from 0.88000\n",
      "Epoch 1275/2000\n",
      "113/113 - 4s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1353 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01275: val_accuracy did not improve from 0.88000\n",
      "Epoch 1276/2000\n",
      "113/113 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01276: val_accuracy did not improve from 0.88000\n",
      "Epoch 1277/2000\n",
      "113/113 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01277: val_accuracy did not improve from 0.88000\n",
      "Epoch 1278/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01278: val_accuracy did not improve from 0.88000\n",
      "Epoch 1279/2000\n",
      "113/113 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1825 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01279: val_accuracy did not improve from 0.88000\n",
      "Epoch 1280/2000\n",
      "113/113 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01280: val_accuracy did not improve from 0.88000\n",
      "Epoch 1281/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2164 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01281: val_accuracy did not improve from 0.88000\n",
      "Epoch 1282/2000\n",
      "113/113 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2225 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01282: val_accuracy did not improve from 0.88000\n",
      "Epoch 1283/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2323 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01283: val_accuracy did not improve from 0.88000\n",
      "Epoch 1284/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01284: val_accuracy did not improve from 0.88000\n",
      "Epoch 1285/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2464 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01285: val_accuracy did not improve from 0.88000\n",
      "Epoch 1286/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01286: val_accuracy did not improve from 0.88000\n",
      "Epoch 1287/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01287: val_accuracy did not improve from 0.88000\n",
      "Epoch 1288/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2752 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01288: val_accuracy did not improve from 0.88000\n",
      "Epoch 1289/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2829 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01289: val_accuracy did not improve from 0.88000\n",
      "Epoch 1290/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01290: val_accuracy did not improve from 0.88000\n",
      "Epoch 1291/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01291: val_accuracy did not improve from 0.88000\n",
      "Epoch 1292/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3034 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01292: val_accuracy did not improve from 0.88000\n",
      "Epoch 1293/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3119 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01293: val_accuracy did not improve from 0.88000\n",
      "Epoch 1294/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01294: val_accuracy did not improve from 0.88000\n",
      "Epoch 1295/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3265 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01295: val_accuracy did not improve from 0.88000\n",
      "Epoch 1296/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3322 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01296: val_accuracy did not improve from 0.88000\n",
      "Epoch 1297/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01297: val_accuracy did not improve from 0.88000\n",
      "Epoch 1298/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01298: val_accuracy did not improve from 0.88000\n",
      "Epoch 1299/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01299: val_accuracy did not improve from 0.88000\n",
      "Epoch 1300/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01300: val_accuracy did not improve from 0.88000\n",
      "Epoch 1301/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3633 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01301: val_accuracy did not improve from 0.88000\n",
      "Epoch 1302/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3661 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01302: val_accuracy did not improve from 0.88000\n",
      "Epoch 1303/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3717 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01303: val_accuracy did not improve from 0.88000\n",
      "Epoch 1304/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3782 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01304: val_accuracy did not improve from 0.88000\n",
      "Epoch 1305/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3864 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01305: val_accuracy did not improve from 0.88000\n",
      "Epoch 1306/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3964 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01306: val_accuracy did not improve from 0.88000\n",
      "Epoch 1307/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01307: val_accuracy did not improve from 0.88000\n",
      "Epoch 1308/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4038 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01308: val_accuracy did not improve from 0.88000\n",
      "Epoch 1309/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4113 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01309: val_accuracy did not improve from 0.88000\n",
      "Epoch 1310/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4112 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01310: val_accuracy did not improve from 0.88000\n",
      "Epoch 1311/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4202 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01311: val_accuracy did not improve from 0.88000\n",
      "Epoch 1312/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4243 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01312: val_accuracy did not improve from 0.88000\n",
      "Epoch 1313/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4322 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01313: val_accuracy did not improve from 0.88000\n",
      "Epoch 1314/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4404 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01314: val_accuracy did not improve from 0.88000\n",
      "Epoch 1315/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4398 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01315: val_accuracy did not improve from 0.88000\n",
      "Epoch 1316/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01316: val_accuracy did not improve from 0.88000\n",
      "Epoch 1317/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4453 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01317: val_accuracy did not improve from 0.88000\n",
      "Epoch 1318/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4583 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01318: val_accuracy did not improve from 0.88000\n",
      "Epoch 1319/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4590 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01319: val_accuracy did not improve from 0.88000\n",
      "Epoch 1320/2000\n",
      "113/113 - 5s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01320: val_accuracy did not improve from 0.88000\n",
      "Epoch 1321/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01321: val_accuracy did not improve from 0.88000\n",
      "Epoch 1322/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01322: val_accuracy did not improve from 0.88000\n",
      "Epoch 1323/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01323: val_accuracy did not improve from 0.88000\n",
      "Epoch 1324/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4983 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01324: val_accuracy did not improve from 0.88000\n",
      "Epoch 1325/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5011 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01325: val_accuracy did not improve from 0.88000\n",
      "Epoch 1326/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5106 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01326: val_accuracy did not improve from 0.88000\n",
      "Epoch 1327/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01327: val_accuracy did not improve from 0.88000\n",
      "Epoch 1328/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5089 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01328: val_accuracy did not improve from 0.88000\n",
      "Epoch 1329/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5025 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01329: val_accuracy did not improve from 0.88000\n",
      "Epoch 1330/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5116 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01330: val_accuracy did not improve from 0.88000\n",
      "Epoch 1331/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5306 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01331: val_accuracy did not improve from 0.88000\n",
      "Epoch 1332/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5234 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01332: val_accuracy did not improve from 0.88000\n",
      "Epoch 1333/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5127 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01333: val_accuracy did not improve from 0.88000\n",
      "Epoch 1334/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4942 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01334: val_accuracy did not improve from 0.88000\n",
      "Epoch 1335/2000\n",
      "113/113 - 4s - loss: 0.0327 - accuracy: 0.9944 - val_loss: 1.8683 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01335: val_accuracy did not improve from 0.88000\n",
      "Epoch 1336/2000\n",
      "113/113 - 4s - loss: 0.3602 - accuracy: 0.9322 - val_loss: 1.3326 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01336: val_accuracy did not improve from 0.88000\n",
      "Epoch 1337/2000\n",
      "113/113 - 4s - loss: 0.1035 - accuracy: 0.9667 - val_loss: 1.0135 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01337: val_accuracy did not improve from 0.88000\n",
      "Epoch 1338/2000\n",
      "113/113 - 4s - loss: 0.0406 - accuracy: 0.9911 - val_loss: 1.0521 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01338: val_accuracy did not improve from 0.88000\n",
      "Epoch 1339/2000\n",
      "113/113 - 4s - loss: 0.0163 - accuracy: 0.9978 - val_loss: 0.9825 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01339: val_accuracy did not improve from 0.88000\n",
      "Epoch 1340/2000\n",
      "113/113 - 4s - loss: 0.0231 - accuracy: 0.9956 - val_loss: 1.0754 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01340: val_accuracy did not improve from 0.88000\n",
      "Epoch 1341/2000\n",
      "113/113 - 4s - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.0422 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01341: val_accuracy did not improve from 0.88000\n",
      "Epoch 1342/2000\n",
      "113/113 - 4s - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.0190 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01342: val_accuracy did not improve from 0.88000\n",
      "Epoch 1343/2000\n",
      "113/113 - 4s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01343: val_accuracy did not improve from 0.88000\n",
      "Epoch 1344/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0439 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01344: val_accuracy did not improve from 0.88000\n",
      "Epoch 1345/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01345: val_accuracy did not improve from 0.88000\n",
      "Epoch 1346/2000\n",
      "113/113 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0607 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01346: val_accuracy did not improve from 0.88000\n",
      "Epoch 1347/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01347: val_accuracy did not improve from 0.88000\n",
      "Epoch 1348/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0867 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01348: val_accuracy did not improve from 0.88000\n",
      "Epoch 1349/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01349: val_accuracy did not improve from 0.88000\n",
      "Epoch 1350/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01350: val_accuracy did not improve from 0.88000\n",
      "Epoch 1351/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01351: val_accuracy did not improve from 0.88000\n",
      "Epoch 1352/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01352: val_accuracy did not improve from 0.88000\n",
      "Epoch 1353/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01353: val_accuracy did not improve from 0.88000\n",
      "Epoch 1354/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1379 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01354: val_accuracy did not improve from 0.88000\n",
      "Epoch 1355/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01355: val_accuracy did not improve from 0.88000\n",
      "Epoch 1356/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1519 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01356: val_accuracy did not improve from 0.88000\n",
      "Epoch 1357/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01357: val_accuracy did not improve from 0.88000\n",
      "Epoch 1358/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1687 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01358: val_accuracy did not improve from 0.88000\n",
      "Epoch 1359/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01359: val_accuracy did not improve from 0.88000\n",
      "Epoch 1360/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01360: val_accuracy did not improve from 0.88000\n",
      "Epoch 1361/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01361: val_accuracy did not improve from 0.88000\n",
      "Epoch 1362/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01362: val_accuracy did not improve from 0.88000\n",
      "Epoch 1363/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2062 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01363: val_accuracy did not improve from 0.88000\n",
      "Epoch 1364/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01364: val_accuracy did not improve from 0.88000\n",
      "Epoch 1365/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2199 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01365: val_accuracy did not improve from 0.88000\n",
      "Epoch 1366/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2260 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01366: val_accuracy did not improve from 0.88000\n",
      "Epoch 1367/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01367: val_accuracy did not improve from 0.88000\n",
      "Epoch 1368/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01368: val_accuracy did not improve from 0.88000\n",
      "Epoch 1369/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01369: val_accuracy did not improve from 0.88000\n",
      "Epoch 1370/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2529 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01370: val_accuracy did not improve from 0.88000\n",
      "Epoch 1371/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2583 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01371: val_accuracy did not improve from 0.88000\n",
      "Epoch 1372/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2647 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01372: val_accuracy did not improve from 0.88000\n",
      "Epoch 1373/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01373: val_accuracy did not improve from 0.88000\n",
      "Epoch 1374/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01374: val_accuracy did not improve from 0.88000\n",
      "Epoch 1375/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01375: val_accuracy did not improve from 0.88000\n",
      "Epoch 1376/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01376: val_accuracy did not improve from 0.88000\n",
      "Epoch 1377/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2936 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01377: val_accuracy did not improve from 0.88000\n",
      "Epoch 1378/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2990 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01378: val_accuracy did not improve from 0.88000\n",
      "Epoch 1379/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3057 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01379: val_accuracy did not improve from 0.88000\n",
      "Epoch 1380/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01380: val_accuracy did not improve from 0.88000\n",
      "Epoch 1381/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01381: val_accuracy did not improve from 0.88000\n",
      "Epoch 1382/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01382: val_accuracy did not improve from 0.88000\n",
      "Epoch 1383/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3278 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01383: val_accuracy did not improve from 0.88000\n",
      "Epoch 1384/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3348 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01384: val_accuracy did not improve from 0.88000\n",
      "Epoch 1385/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3378 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01385: val_accuracy did not improve from 0.88000\n",
      "Epoch 1386/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01386: val_accuracy did not improve from 0.88000\n",
      "Epoch 1387/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01387: val_accuracy did not improve from 0.88000\n",
      "Epoch 1388/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01388: val_accuracy did not improve from 0.88000\n",
      "Epoch 1389/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3580 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01389: val_accuracy did not improve from 0.88000\n",
      "Epoch 1390/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01390: val_accuracy did not improve from 0.88000\n",
      "Epoch 1391/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3706 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01391: val_accuracy did not improve from 0.88000\n",
      "Epoch 1392/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01392: val_accuracy did not improve from 0.88000\n",
      "Epoch 1393/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01393: val_accuracy did not improve from 0.88000\n",
      "Epoch 1394/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3811 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01394: val_accuracy did not improve from 0.88000\n",
      "Epoch 1395/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3801 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01395: val_accuracy did not improve from 0.88000\n",
      "Epoch 1396/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3947 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01396: val_accuracy did not improve from 0.88000\n",
      "Epoch 1397/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3939 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01397: val_accuracy did not improve from 0.88000\n",
      "Epoch 1398/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01398: val_accuracy did not improve from 0.88000\n",
      "Epoch 1399/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01399: val_accuracy did not improve from 0.88000\n",
      "Epoch 1400/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01400: val_accuracy did not improve from 0.88000\n",
      "Epoch 1401/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4130 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01401: val_accuracy did not improve from 0.88000\n",
      "Epoch 1402/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4082 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01402: val_accuracy did not improve from 0.88000\n",
      "Epoch 1403/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01403: val_accuracy did not improve from 0.88000\n",
      "Epoch 1404/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4123 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01404: val_accuracy did not improve from 0.88000\n",
      "Epoch 1405/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01405: val_accuracy did not improve from 0.88000\n",
      "Epoch 1406/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4213 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01406: val_accuracy did not improve from 0.88000\n",
      "Epoch 1407/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4233 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01407: val_accuracy did not improve from 0.88000\n",
      "Epoch 1408/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4340 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01408: val_accuracy did not improve from 0.88000\n",
      "Epoch 1409/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01409: val_accuracy did not improve from 0.88000\n",
      "Epoch 1410/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01410: val_accuracy did not improve from 0.88000\n",
      "Epoch 1411/2000\n",
      "113/113 - 4s - loss: 0.5069 - accuracy: 0.9344 - val_loss: 2.0969 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 01411: val_accuracy did not improve from 0.88000\n",
      "Epoch 1412/2000\n",
      "113/113 - 4s - loss: 0.2570 - accuracy: 0.9222 - val_loss: 1.0346 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 01412: val_accuracy did not improve from 0.88000\n",
      "Epoch 1413/2000\n",
      "113/113 - 4s - loss: 0.0583 - accuracy: 0.9800 - val_loss: 1.0450 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01413: val_accuracy did not improve from 0.88000\n",
      "Epoch 1414/2000\n",
      "113/113 - 4s - loss: 0.0268 - accuracy: 0.9922 - val_loss: 1.0849 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01414: val_accuracy did not improve from 0.88000\n",
      "Epoch 1415/2000\n",
      "113/113 - 4s - loss: 0.0204 - accuracy: 0.9956 - val_loss: 0.9649 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01415: val_accuracy did not improve from 0.88000\n",
      "Epoch 1416/2000\n",
      "113/113 - 4s - loss: 0.0178 - accuracy: 0.9956 - val_loss: 0.9955 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01416: val_accuracy did not improve from 0.88000\n",
      "Epoch 1417/2000\n",
      "113/113 - 4s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01417: val_accuracy did not improve from 0.88000\n",
      "Epoch 1418/2000\n",
      "113/113 - 4s - loss: 0.0085 - accuracy: 0.9978 - val_loss: 1.0327 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01418: val_accuracy did not improve from 0.88000\n",
      "Epoch 1419/2000\n",
      "113/113 - 4s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01419: val_accuracy did not improve from 0.88000\n",
      "Epoch 1420/2000\n",
      "113/113 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0505 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01420: val_accuracy did not improve from 0.88000\n",
      "Epoch 1421/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01421: val_accuracy did not improve from 0.88000\n",
      "Epoch 1422/2000\n",
      "113/113 - 4s - loss: 0.0049 - accuracy: 0.9989 - val_loss: 1.0727 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01422: val_accuracy did not improve from 0.88000\n",
      "Epoch 1423/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0791 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01423: val_accuracy did not improve from 0.88000\n",
      "Epoch 1424/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01424: val_accuracy did not improve from 0.88000\n",
      "Epoch 1425/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01425: val_accuracy did not improve from 0.88000\n",
      "Epoch 1426/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01426: val_accuracy did not improve from 0.88000\n",
      "Epoch 1427/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01427: val_accuracy did not improve from 0.88000\n",
      "Epoch 1428/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01428: val_accuracy did not improve from 0.88000\n",
      "Epoch 1429/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01429: val_accuracy did not improve from 0.88000\n",
      "Epoch 1430/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01430: val_accuracy did not improve from 0.88000\n",
      "Epoch 1431/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1314 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01431: val_accuracy did not improve from 0.88000\n",
      "Epoch 1432/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01432: val_accuracy did not improve from 0.88000\n",
      "Epoch 1433/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01433: val_accuracy did not improve from 0.88000\n",
      "Epoch 1434/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1516 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01434: val_accuracy did not improve from 0.88000\n",
      "Epoch 1435/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1564 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01435: val_accuracy did not improve from 0.88000\n",
      "Epoch 1436/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01436: val_accuracy did not improve from 0.88000\n",
      "Epoch 1437/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01437: val_accuracy did not improve from 0.88000\n",
      "Epoch 1438/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01438: val_accuracy did not improve from 0.88000\n",
      "Epoch 1439/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01439: val_accuracy did not improve from 0.88000\n",
      "Epoch 1440/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1904 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01440: val_accuracy did not improve from 0.88000\n",
      "Epoch 1441/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01441: val_accuracy did not improve from 0.88000\n",
      "Epoch 1442/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2065 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01442: val_accuracy did not improve from 0.88000\n",
      "Epoch 1443/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01443: val_accuracy did not improve from 0.88000\n",
      "Epoch 1444/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01444: val_accuracy did not improve from 0.88000\n",
      "Epoch 1445/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01445: val_accuracy did not improve from 0.88000\n",
      "Epoch 1446/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2286 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01446: val_accuracy did not improve from 0.88000\n",
      "Epoch 1447/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2353 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01447: val_accuracy did not improve from 0.88000\n",
      "Epoch 1448/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01448: val_accuracy did not improve from 0.88000\n",
      "Epoch 1449/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01449: val_accuracy did not improve from 0.88000\n",
      "Epoch 1450/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01450: val_accuracy did not improve from 0.88000\n",
      "Epoch 1451/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01451: val_accuracy did not improve from 0.88000\n",
      "Epoch 1452/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01452: val_accuracy did not improve from 0.88000\n",
      "Epoch 1453/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2679 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01453: val_accuracy did not improve from 0.88000\n",
      "Epoch 1454/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01454: val_accuracy did not improve from 0.88000\n",
      "Epoch 1455/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2785 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01455: val_accuracy did not improve from 0.88000\n",
      "Epoch 1456/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2842 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01456: val_accuracy did not improve from 0.88000\n",
      "Epoch 1457/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01457: val_accuracy did not improve from 0.88000\n",
      "Epoch 1458/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2964 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01458: val_accuracy did not improve from 0.88000\n",
      "Epoch 1459/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2990 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01459: val_accuracy did not improve from 0.88000\n",
      "Epoch 1460/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3026 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01460: val_accuracy did not improve from 0.88000\n",
      "Epoch 1461/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01461: val_accuracy did not improve from 0.88000\n",
      "Epoch 1462/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01462: val_accuracy did not improve from 0.88000\n",
      "Epoch 1463/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01463: val_accuracy did not improve from 0.88000\n",
      "Epoch 1464/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01464: val_accuracy did not improve from 0.88000\n",
      "Epoch 1465/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01465: val_accuracy did not improve from 0.88000\n",
      "Epoch 1466/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3226 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01466: val_accuracy did not improve from 0.88000\n",
      "Epoch 1467/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3349 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01467: val_accuracy did not improve from 0.88000\n",
      "Epoch 1468/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3338 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01468: val_accuracy did not improve from 0.88000\n",
      "Epoch 1469/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01469: val_accuracy did not improve from 0.88000\n",
      "Epoch 1470/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3333 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01470: val_accuracy did not improve from 0.88000\n",
      "Epoch 1471/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01471: val_accuracy did not improve from 0.88000\n",
      "Epoch 1472/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01472: val_accuracy did not improve from 0.88000\n",
      "Epoch 1473/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3524 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01473: val_accuracy did not improve from 0.88000\n",
      "Epoch 1474/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3566 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01474: val_accuracy did not improve from 0.88000\n",
      "Epoch 1475/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01475: val_accuracy did not improve from 0.88000\n",
      "Epoch 1476/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01476: val_accuracy did not improve from 0.88000\n",
      "Epoch 1477/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3700 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01477: val_accuracy did not improve from 0.88000\n",
      "Epoch 1478/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01478: val_accuracy did not improve from 0.88000\n",
      "Epoch 1479/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3822 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01479: val_accuracy did not improve from 0.88000\n",
      "Epoch 1480/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3830 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01480: val_accuracy did not improve from 0.88000\n",
      "Epoch 1481/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01481: val_accuracy did not improve from 0.88000\n",
      "Epoch 1482/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3897 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01482: val_accuracy did not improve from 0.88000\n",
      "Epoch 1483/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3804 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01483: val_accuracy did not improve from 0.88000\n",
      "Epoch 1484/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3977 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01484: val_accuracy did not improve from 0.88000\n",
      "Epoch 1485/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3806 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01485: val_accuracy did not improve from 0.88000\n",
      "Epoch 1486/2000\n",
      "113/113 - 4s - loss: 0.5931 - accuracy: 0.9200 - val_loss: 1.9233 - val_accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01486: val_accuracy did not improve from 0.88000\n",
      "Epoch 1487/2000\n",
      "113/113 - 4s - loss: 0.2784 - accuracy: 0.9467 - val_loss: 1.1024 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01487: val_accuracy did not improve from 0.88000\n",
      "Epoch 1488/2000\n",
      "113/113 - 4s - loss: 0.0339 - accuracy: 0.9911 - val_loss: 0.9761 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01488: val_accuracy did not improve from 0.88000\n",
      "Epoch 1489/2000\n",
      "113/113 - 4s - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.9606 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01489: val_accuracy did not improve from 0.88000\n",
      "Epoch 1490/2000\n",
      "113/113 - 4s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0398 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01490: val_accuracy did not improve from 0.88000\n",
      "Epoch 1491/2000\n",
      "113/113 - 4s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01491: val_accuracy did not improve from 0.88000\n",
      "Epoch 1492/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01492: val_accuracy did not improve from 0.88000\n",
      "Epoch 1493/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01493: val_accuracy did not improve from 0.88000\n",
      "Epoch 1494/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0572 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01494: val_accuracy did not improve from 0.88000\n",
      "Epoch 1495/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01495: val_accuracy did not improve from 0.88000\n",
      "Epoch 1496/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01496: val_accuracy did not improve from 0.88000\n",
      "Epoch 1497/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01497: val_accuracy did not improve from 0.88000\n",
      "Epoch 1498/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01498: val_accuracy did not improve from 0.88000\n",
      "Epoch 1499/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01499: val_accuracy did not improve from 0.88000\n",
      "Epoch 1500/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1144 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01500: val_accuracy did not improve from 0.88000\n",
      "Epoch 1501/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01501: val_accuracy did not improve from 0.88000\n",
      "Epoch 1502/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1248 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01502: val_accuracy did not improve from 0.88000\n",
      "Epoch 1503/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1342 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01503: val_accuracy did not improve from 0.88000\n",
      "Epoch 1504/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1413 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01504: val_accuracy did not improve from 0.88000\n",
      "Epoch 1505/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01505: val_accuracy did not improve from 0.88000\n",
      "Epoch 1506/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1605 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01506: val_accuracy did not improve from 0.88000\n",
      "Epoch 1507/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01507: val_accuracy did not improve from 0.88000\n",
      "Epoch 1508/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01508: val_accuracy did not improve from 0.88000\n",
      "Epoch 1509/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1796 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01509: val_accuracy did not improve from 0.88000\n",
      "Epoch 1510/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01510: val_accuracy did not improve from 0.88000\n",
      "Epoch 1511/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1913 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01511: val_accuracy did not improve from 0.88000\n",
      "Epoch 1512/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01512: val_accuracy did not improve from 0.88000\n",
      "Epoch 1513/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01513: val_accuracy did not improve from 0.88000\n",
      "Epoch 1514/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01514: val_accuracy did not improve from 0.88000\n",
      "Epoch 1515/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01515: val_accuracy did not improve from 0.88000\n",
      "Epoch 1516/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01516: val_accuracy did not improve from 0.88000\n",
      "Epoch 1517/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2352 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01517: val_accuracy did not improve from 0.88000\n",
      "Epoch 1518/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01518: val_accuracy did not improve from 0.88000\n",
      "Epoch 1519/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01519: val_accuracy did not improve from 0.88000\n",
      "Epoch 1520/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01520: val_accuracy did not improve from 0.88000\n",
      "Epoch 1521/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01521: val_accuracy did not improve from 0.88000\n",
      "Epoch 1522/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01522: val_accuracy did not improve from 0.88000\n",
      "Epoch 1523/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2720 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01523: val_accuracy did not improve from 0.88000\n",
      "Epoch 1524/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01524: val_accuracy did not improve from 0.88000\n",
      "Epoch 1525/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01525: val_accuracy did not improve from 0.88000\n",
      "Epoch 1526/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2895 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01526: val_accuracy did not improve from 0.88000\n",
      "Epoch 1527/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2964 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01527: val_accuracy did not improve from 0.88000\n",
      "Epoch 1528/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2995 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01528: val_accuracy did not improve from 0.88000\n",
      "Epoch 1529/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3053 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01529: val_accuracy did not improve from 0.88000\n",
      "Epoch 1530/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3159 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01530: val_accuracy did not improve from 0.88000\n",
      "Epoch 1531/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3157 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01531: val_accuracy did not improve from 0.88000\n",
      "Epoch 1532/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01532: val_accuracy did not improve from 0.88000\n",
      "Epoch 1533/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3345 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01533: val_accuracy did not improve from 0.88000\n",
      "Epoch 1534/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3381 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01534: val_accuracy did not improve from 0.88000\n",
      "Epoch 1535/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01535: val_accuracy did not improve from 0.88000\n",
      "Epoch 1536/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01536: val_accuracy did not improve from 0.88000\n",
      "Epoch 1537/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01537: val_accuracy did not improve from 0.88000\n",
      "Epoch 1538/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3605 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01538: val_accuracy did not improve from 0.88000\n",
      "Epoch 1539/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3590 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01539: val_accuracy did not improve from 0.88000\n",
      "Epoch 1540/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3627 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01540: val_accuracy did not improve from 0.88000\n",
      "Epoch 1541/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3643 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01541: val_accuracy did not improve from 0.88000\n",
      "Epoch 1542/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3695 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01542: val_accuracy did not improve from 0.88000\n",
      "Epoch 1543/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01543: val_accuracy did not improve from 0.88000\n",
      "Epoch 1544/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01544: val_accuracy did not improve from 0.88000\n",
      "Epoch 1545/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3820 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01545: val_accuracy did not improve from 0.88000\n",
      "Epoch 1546/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01546: val_accuracy did not improve from 0.88000\n",
      "Epoch 1547/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3922 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01547: val_accuracy did not improve from 0.88000\n",
      "Epoch 1548/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01548: val_accuracy did not improve from 0.88000\n",
      "Epoch 1549/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01549: val_accuracy did not improve from 0.88000\n",
      "Epoch 1550/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4187 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01550: val_accuracy did not improve from 0.88000\n",
      "Epoch 1551/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4154 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01551: val_accuracy did not improve from 0.88000\n",
      "Epoch 1552/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4083 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01552: val_accuracy did not improve from 0.88000\n",
      "Epoch 1553/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4073 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01553: val_accuracy did not improve from 0.88000\n",
      "Epoch 1554/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4269 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01554: val_accuracy did not improve from 0.88000\n",
      "Epoch 1555/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01555: val_accuracy did not improve from 0.88000\n",
      "Epoch 1556/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01556: val_accuracy did not improve from 0.88000\n",
      "Epoch 1557/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4156 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01557: val_accuracy did not improve from 0.88000\n",
      "Epoch 1558/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01558: val_accuracy did not improve from 0.88000\n",
      "Epoch 1559/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3882 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01559: val_accuracy did not improve from 0.88000\n",
      "Epoch 1560/2000\n",
      "113/113 - 4s - loss: 0.2783 - accuracy: 0.9433 - val_loss: 0.7395 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01560: val_accuracy did not improve from 0.88000\n",
      "Epoch 1561/2000\n",
      "113/113 - 4s - loss: 0.1035 - accuracy: 0.9678 - val_loss: 0.8538 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01561: val_accuracy did not improve from 0.88000\n",
      "Epoch 1562/2000\n",
      "113/113 - 4s - loss: 0.0350 - accuracy: 0.9900 - val_loss: 0.8845 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01562: val_accuracy did not improve from 0.88000\n",
      "Epoch 1563/2000\n",
      "113/113 - 4s - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.8907 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01563: val_accuracy did not improve from 0.88000\n",
      "Epoch 1564/2000\n",
      "113/113 - 4s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9249 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01564: val_accuracy did not improve from 0.88000\n",
      "Epoch 1565/2000\n",
      "113/113 - 4s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01565: val_accuracy did not improve from 0.88000\n",
      "Epoch 1566/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01566: val_accuracy did not improve from 0.88000\n",
      "Epoch 1567/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01567: val_accuracy did not improve from 0.88000\n",
      "Epoch 1568/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01568: val_accuracy did not improve from 0.88000\n",
      "Epoch 1569/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9659 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01569: val_accuracy did not improve from 0.88000\n",
      "Epoch 1570/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9786 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01570: val_accuracy did not improve from 0.88000\n",
      "Epoch 1571/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01571: val_accuracy did not improve from 0.88000\n",
      "Epoch 1572/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01572: val_accuracy did not improve from 0.88000\n",
      "Epoch 1573/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01573: val_accuracy did not improve from 0.88000\n",
      "Epoch 1574/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01574: val_accuracy did not improve from 0.88000\n",
      "Epoch 1575/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0203 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01575: val_accuracy did not improve from 0.88000\n",
      "Epoch 1576/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0351 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01576: val_accuracy did not improve from 0.88000\n",
      "Epoch 1577/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01577: val_accuracy did not improve from 0.88000\n",
      "Epoch 1578/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01578: val_accuracy did not improve from 0.88000\n",
      "Epoch 1579/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01579: val_accuracy did not improve from 0.88000\n",
      "Epoch 1580/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01580: val_accuracy did not improve from 0.88000\n",
      "Epoch 1581/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01581: val_accuracy did not improve from 0.88000\n",
      "Epoch 1582/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01582: val_accuracy did not improve from 0.88000\n",
      "Epoch 1583/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0836 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01583: val_accuracy did not improve from 0.88000\n",
      "Epoch 1584/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01584: val_accuracy did not improve from 0.88000\n",
      "Epoch 1585/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0925 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01585: val_accuracy did not improve from 0.88000\n",
      "Epoch 1586/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0935 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01586: val_accuracy did not improve from 0.88000\n",
      "Epoch 1587/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01587: val_accuracy did not improve from 0.88000\n",
      "Epoch 1588/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1110 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01588: val_accuracy did not improve from 0.88000\n",
      "Epoch 1589/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1164 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01589: val_accuracy did not improve from 0.88000\n",
      "Epoch 1590/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1176 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01590: val_accuracy did not improve from 0.88000\n",
      "Epoch 1591/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1265 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01591: val_accuracy did not improve from 0.88000\n",
      "Epoch 1592/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1322 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01592: val_accuracy did not improve from 0.88000\n",
      "Epoch 1593/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01593: val_accuracy did not improve from 0.88000\n",
      "Epoch 1594/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01594: val_accuracy did not improve from 0.88000\n",
      "Epoch 1595/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01595: val_accuracy did not improve from 0.88000\n",
      "Epoch 1596/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01596: val_accuracy did not improve from 0.88000\n",
      "Epoch 1597/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1633 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01597: val_accuracy did not improve from 0.88000\n",
      "Epoch 1598/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01598: val_accuracy did not improve from 0.88000\n",
      "Epoch 1599/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01599: val_accuracy did not improve from 0.88000\n",
      "Epoch 1600/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1791 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01600: val_accuracy did not improve from 0.88000\n",
      "Epoch 1601/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01601: val_accuracy did not improve from 0.88000\n",
      "Epoch 1602/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01602: val_accuracy did not improve from 0.88000\n",
      "Epoch 1603/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01603: val_accuracy did not improve from 0.88000\n",
      "Epoch 1604/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01604: val_accuracy did not improve from 0.88000\n",
      "Epoch 1605/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01605: val_accuracy did not improve from 0.88000\n",
      "Epoch 1606/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2173 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01606: val_accuracy did not improve from 0.88000\n",
      "Epoch 1607/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01607: val_accuracy did not improve from 0.88000\n",
      "Epoch 1608/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2274 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01608: val_accuracy did not improve from 0.88000\n",
      "Epoch 1609/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01609: val_accuracy did not improve from 0.88000\n",
      "Epoch 1610/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01610: val_accuracy did not improve from 0.88000\n",
      "Epoch 1611/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01611: val_accuracy did not improve from 0.88000\n",
      "Epoch 1612/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2472 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01612: val_accuracy did not improve from 0.88000\n",
      "Epoch 1613/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01613: val_accuracy did not improve from 0.88000\n",
      "Epoch 1614/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2613 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01614: val_accuracy did not improve from 0.88000\n",
      "Epoch 1615/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01615: val_accuracy did not improve from 0.88000\n",
      "Epoch 1616/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01616: val_accuracy did not improve from 0.88000\n",
      "Epoch 1617/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01617: val_accuracy did not improve from 0.88000\n",
      "Epoch 1618/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01618: val_accuracy did not improve from 0.88000\n",
      "Epoch 1619/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2865 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01619: val_accuracy did not improve from 0.88000\n",
      "Epoch 1620/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2900 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01620: val_accuracy did not improve from 0.88000\n",
      "Epoch 1621/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2935 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01621: val_accuracy did not improve from 0.88000\n",
      "Epoch 1622/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2995 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01622: val_accuracy did not improve from 0.88000\n",
      "Epoch 1623/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01623: val_accuracy did not improve from 0.88000\n",
      "Epoch 1624/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3170 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01624: val_accuracy did not improve from 0.88000\n",
      "Epoch 1625/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01625: val_accuracy did not improve from 0.88000\n",
      "Epoch 1626/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01626: val_accuracy did not improve from 0.88000\n",
      "Epoch 1627/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3328 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01627: val_accuracy did not improve from 0.88000\n",
      "Epoch 1628/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01628: val_accuracy did not improve from 0.88000\n",
      "Epoch 1629/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01629: val_accuracy did not improve from 0.88000\n",
      "Epoch 1630/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01630: val_accuracy did not improve from 0.88000\n",
      "Epoch 1631/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01631: val_accuracy did not improve from 0.88000\n",
      "Epoch 1632/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01632: val_accuracy did not improve from 0.88000\n",
      "Epoch 1633/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3728 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01633: val_accuracy did not improve from 0.88000\n",
      "Epoch 1634/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3472 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01634: val_accuracy did not improve from 0.88000\n",
      "Epoch 1635/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01635: val_accuracy did not improve from 0.88000\n",
      "Epoch 1636/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6363 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01636: val_accuracy did not improve from 0.88000\n",
      "Epoch 1637/2000\n",
      "113/113 - 4s - loss: 0.2215 - accuracy: 0.9500 - val_loss: 1.4496 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01637: val_accuracy did not improve from 0.88000\n",
      "Epoch 1638/2000\n",
      "113/113 - 4s - loss: 0.1715 - accuracy: 0.9667 - val_loss: 1.1705 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01638: val_accuracy did not improve from 0.88000\n",
      "Epoch 1639/2000\n",
      "113/113 - 4s - loss: 0.0323 - accuracy: 0.9889 - val_loss: 1.0497 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01639: val_accuracy did not improve from 0.88000\n",
      "Epoch 1640/2000\n",
      "113/113 - 4s - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.9240 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01640: val_accuracy did not improve from 0.88000\n",
      "Epoch 1641/2000\n",
      "113/113 - 4s - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.0180 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01641: val_accuracy did not improve from 0.88000\n",
      "Epoch 1642/2000\n",
      "113/113 - 4s - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.9870 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01642: val_accuracy did not improve from 0.88000\n",
      "Epoch 1643/2000\n",
      "113/113 - 4s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0541 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01643: val_accuracy did not improve from 0.88000\n",
      "Epoch 1644/2000\n",
      "113/113 - 4s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01644: val_accuracy did not improve from 0.88000\n",
      "Epoch 1645/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01645: val_accuracy did not improve from 0.88000\n",
      "Epoch 1646/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01646: val_accuracy did not improve from 0.88000\n",
      "Epoch 1647/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01647: val_accuracy did not improve from 0.88000\n",
      "Epoch 1648/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01648: val_accuracy did not improve from 0.88000\n",
      "Epoch 1649/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01649: val_accuracy did not improve from 0.88000\n",
      "Epoch 1650/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01650: val_accuracy did not improve from 0.88000\n",
      "Epoch 1651/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01651: val_accuracy did not improve from 0.88000\n",
      "Epoch 1652/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01652: val_accuracy did not improve from 0.88000\n",
      "Epoch 1653/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1652 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01653: val_accuracy did not improve from 0.88000\n",
      "Epoch 1654/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01654: val_accuracy did not improve from 0.88000\n",
      "Epoch 1655/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01655: val_accuracy did not improve from 0.88000\n",
      "Epoch 1656/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01656: val_accuracy did not improve from 0.88000\n",
      "Epoch 1657/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1984 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01657: val_accuracy did not improve from 0.88000\n",
      "Epoch 1658/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2025 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01658: val_accuracy did not improve from 0.88000\n",
      "Epoch 1659/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01659: val_accuracy did not improve from 0.88000\n",
      "Epoch 1660/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01660: val_accuracy did not improve from 0.88000\n",
      "Epoch 1661/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2285 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01661: val_accuracy did not improve from 0.88000\n",
      "Epoch 1662/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2329 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01662: val_accuracy did not improve from 0.88000\n",
      "Epoch 1663/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01663: val_accuracy did not improve from 0.88000\n",
      "Epoch 1664/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01664: val_accuracy did not improve from 0.88000\n",
      "Epoch 1665/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01665: val_accuracy did not improve from 0.88000\n",
      "Epoch 1666/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01666: val_accuracy did not improve from 0.88000\n",
      "Epoch 1667/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2611 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01667: val_accuracy did not improve from 0.88000\n",
      "Epoch 1668/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2640 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01668: val_accuracy did not improve from 0.88000\n",
      "Epoch 1669/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2754 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01669: val_accuracy did not improve from 0.88000\n",
      "Epoch 1670/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2791 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01670: val_accuracy did not improve from 0.88000\n",
      "Epoch 1671/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01671: val_accuracy did not improve from 0.88000\n",
      "Epoch 1672/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01672: val_accuracy did not improve from 0.88000\n",
      "Epoch 1673/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2955 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01673: val_accuracy did not improve from 0.88000\n",
      "Epoch 1674/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01674: val_accuracy did not improve from 0.88000\n",
      "Epoch 1675/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3039 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01675: val_accuracy did not improve from 0.88000\n",
      "Epoch 1676/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3040 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01676: val_accuracy did not improve from 0.88000\n",
      "Epoch 1677/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01677: val_accuracy did not improve from 0.88000\n",
      "Epoch 1678/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3150 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01678: val_accuracy did not improve from 0.88000\n",
      "Epoch 1679/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3263 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01679: val_accuracy did not improve from 0.88000\n",
      "Epoch 1680/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01680: val_accuracy did not improve from 0.88000\n",
      "Epoch 1681/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3324 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01681: val_accuracy did not improve from 0.88000\n",
      "Epoch 1682/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01682: val_accuracy did not improve from 0.88000\n",
      "Epoch 1683/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01683: val_accuracy did not improve from 0.88000\n",
      "Epoch 1684/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01684: val_accuracy did not improve from 0.88000\n",
      "Epoch 1685/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01685: val_accuracy did not improve from 0.88000\n",
      "Epoch 1686/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01686: val_accuracy did not improve from 0.88000\n",
      "Epoch 1687/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3545 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01687: val_accuracy did not improve from 0.88000\n",
      "Epoch 1688/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01688: val_accuracy did not improve from 0.88000\n",
      "Epoch 1689/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01689: val_accuracy did not improve from 0.88000\n",
      "Epoch 1690/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3782 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01690: val_accuracy did not improve from 0.88000\n",
      "Epoch 1691/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3787 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01691: val_accuracy did not improve from 0.88000\n",
      "Epoch 1692/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01692: val_accuracy did not improve from 0.88000\n",
      "Epoch 1693/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3816 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01693: val_accuracy did not improve from 0.88000\n",
      "Epoch 1694/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01694: val_accuracy did not improve from 0.88000\n",
      "Epoch 1695/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01695: val_accuracy did not improve from 0.88000\n",
      "Epoch 1696/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4034 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01696: val_accuracy did not improve from 0.88000\n",
      "Epoch 1697/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01697: val_accuracy did not improve from 0.88000\n",
      "Epoch 1698/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4005 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01698: val_accuracy did not improve from 0.88000\n",
      "Epoch 1699/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4010 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01699: val_accuracy did not improve from 0.88000\n",
      "Epoch 1700/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01700: val_accuracy did not improve from 0.88000\n",
      "Epoch 1701/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01701: val_accuracy did not improve from 0.88000\n",
      "Epoch 1702/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4224 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01702: val_accuracy did not improve from 0.88000\n",
      "Epoch 1703/2000\n",
      "113/113 - 4s - loss: 0.0349 - accuracy: 0.9956 - val_loss: 1.4695 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01703: val_accuracy did not improve from 0.88000\n",
      "Epoch 1704/2000\n",
      "113/113 - 4s - loss: 0.3220 - accuracy: 0.9322 - val_loss: 1.3305 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01704: val_accuracy did not improve from 0.88000\n",
      "Epoch 1705/2000\n",
      "113/113 - 4s - loss: 0.0702 - accuracy: 0.9722 - val_loss: 1.4055 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01705: val_accuracy did not improve from 0.88000\n",
      "Epoch 1706/2000\n",
      "113/113 - 4s - loss: 0.0622 - accuracy: 0.9844 - val_loss: 0.9251 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01706: val_accuracy did not improve from 0.88000\n",
      "Epoch 1707/2000\n",
      "113/113 - 4s - loss: 0.0105 - accuracy: 0.9978 - val_loss: 1.0411 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01707: val_accuracy did not improve from 0.88000\n",
      "Epoch 1708/2000\n",
      "113/113 - 4s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01708: val_accuracy did not improve from 0.88000\n",
      "Epoch 1709/2000\n",
      "113/113 - 4s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01709: val_accuracy did not improve from 0.88000\n",
      "Epoch 1710/2000\n",
      "113/113 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0487 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01710: val_accuracy did not improve from 0.88000\n",
      "Epoch 1711/2000\n",
      "113/113 - 4s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01711: val_accuracy did not improve from 0.88000\n",
      "Epoch 1712/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01712: val_accuracy did not improve from 0.88000\n",
      "Epoch 1713/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01713: val_accuracy did not improve from 0.88000\n",
      "Epoch 1714/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01714: val_accuracy did not improve from 0.88000\n",
      "Epoch 1715/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01715: val_accuracy did not improve from 0.88000\n",
      "Epoch 1716/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01716: val_accuracy did not improve from 0.88000\n",
      "Epoch 1717/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01717: val_accuracy did not improve from 0.88000\n",
      "Epoch 1718/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0746 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01718: val_accuracy did not improve from 0.88000\n",
      "Epoch 1719/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01719: val_accuracy did not improve from 0.88000\n",
      "Epoch 1720/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01720: val_accuracy did not improve from 0.88000\n",
      "Epoch 1721/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0857 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01721: val_accuracy did not improve from 0.88000\n",
      "Epoch 1722/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01722: val_accuracy did not improve from 0.88000\n",
      "Epoch 1723/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01723: val_accuracy did not improve from 0.88000\n",
      "Epoch 1724/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01724: val_accuracy did not improve from 0.88000\n",
      "Epoch 1725/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01725: val_accuracy did not improve from 0.88000\n",
      "Epoch 1726/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01726: val_accuracy did not improve from 0.88000\n",
      "Epoch 1727/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01727: val_accuracy did not improve from 0.88000\n",
      "Epoch 1728/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01728: val_accuracy did not improve from 0.88000\n",
      "Epoch 1729/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01729: val_accuracy did not improve from 0.88000\n",
      "Epoch 1730/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01730: val_accuracy did not improve from 0.88000\n",
      "Epoch 1731/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01731: val_accuracy did not improve from 0.88000\n",
      "Epoch 1732/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01732: val_accuracy did not improve from 0.88000\n",
      "Epoch 1733/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1241 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01733: val_accuracy did not improve from 0.88000\n",
      "Epoch 1734/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01734: val_accuracy did not improve from 0.88000\n",
      "Epoch 1735/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01735: val_accuracy did not improve from 0.88000\n",
      "Epoch 1736/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01736: val_accuracy did not improve from 0.88000\n",
      "Epoch 1737/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01737: val_accuracy did not improve from 0.88000\n",
      "Epoch 1738/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1419 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01738: val_accuracy did not improve from 0.88000\n",
      "Epoch 1739/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1472 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01739: val_accuracy did not improve from 0.88000\n",
      "Epoch 1740/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01740: val_accuracy did not improve from 0.88000\n",
      "Epoch 1741/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01741: val_accuracy did not improve from 0.88000\n",
      "Epoch 1742/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1593 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01742: val_accuracy did not improve from 0.88000\n",
      "Epoch 1743/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01743: val_accuracy did not improve from 0.88000\n",
      "Epoch 1744/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1680 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01744: val_accuracy did not improve from 0.88000\n",
      "Epoch 1745/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01745: val_accuracy did not improve from 0.88000\n",
      "Epoch 1746/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1764 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01746: val_accuracy did not improve from 0.88000\n",
      "Epoch 1747/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1789 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01747: val_accuracy did not improve from 0.88000\n",
      "Epoch 1748/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01748: val_accuracy did not improve from 0.88000\n",
      "Epoch 1749/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01749: val_accuracy did not improve from 0.88000\n",
      "Epoch 1750/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1978 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01750: val_accuracy did not improve from 0.88000\n",
      "Epoch 1751/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2030 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01751: val_accuracy did not improve from 0.88000\n",
      "Epoch 1752/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2102 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01752: val_accuracy did not improve from 0.88000\n",
      "Epoch 1753/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01753: val_accuracy did not improve from 0.88000\n",
      "Epoch 1754/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2199 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01754: val_accuracy did not improve from 0.88000\n",
      "Epoch 1755/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01755: val_accuracy did not improve from 0.88000\n",
      "Epoch 1756/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01756: val_accuracy did not improve from 0.88000\n",
      "Epoch 1757/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2356 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01757: val_accuracy did not improve from 0.88000\n",
      "Epoch 1758/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2434 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01758: val_accuracy did not improve from 0.88000\n",
      "Epoch 1759/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2495 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01759: val_accuracy did not improve from 0.88000\n",
      "Epoch 1760/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01760: val_accuracy did not improve from 0.88000\n",
      "Epoch 1761/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2654 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01761: val_accuracy did not improve from 0.88000\n",
      "Epoch 1762/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01762: val_accuracy did not improve from 0.88000\n",
      "Epoch 1763/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2717 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01763: val_accuracy did not improve from 0.88000\n",
      "Epoch 1764/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2829 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01764: val_accuracy did not improve from 0.88000\n",
      "Epoch 1765/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2937 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01765: val_accuracy did not improve from 0.88000\n",
      "Epoch 1766/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2940 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01766: val_accuracy did not improve from 0.88000\n",
      "Epoch 1767/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3003 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01767: val_accuracy did not improve from 0.88000\n",
      "Epoch 1768/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01768: val_accuracy did not improve from 0.88000\n",
      "Epoch 1769/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3232 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01769: val_accuracy did not improve from 0.88000\n",
      "Epoch 1770/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3158 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01770: val_accuracy did not improve from 0.88000\n",
      "Epoch 1771/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01771: val_accuracy did not improve from 0.88000\n",
      "Epoch 1772/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01772: val_accuracy did not improve from 0.88000\n",
      "Epoch 1773/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3332 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01773: val_accuracy did not improve from 0.88000\n",
      "Epoch 1774/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3479 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01774: val_accuracy did not improve from 0.88000\n",
      "Epoch 1775/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3528 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01775: val_accuracy did not improve from 0.88000\n",
      "Epoch 1776/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3605 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01776: val_accuracy did not improve from 0.88000\n",
      "Epoch 1777/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01777: val_accuracy did not improve from 0.88000\n",
      "Epoch 1778/2000\n",
      "113/113 - 4s - loss: 0.0982 - accuracy: 0.9767 - val_loss: 1.7553 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01778: val_accuracy did not improve from 0.88000\n",
      "Epoch 1779/2000\n",
      "113/113 - 4s - loss: 0.3533 - accuracy: 0.9022 - val_loss: 1.0026 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01779: val_accuracy did not improve from 0.88000\n",
      "Epoch 1780/2000\n",
      "113/113 - 4s - loss: 0.0575 - accuracy: 0.9867 - val_loss: 1.0619 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01780: val_accuracy did not improve from 0.88000\n",
      "Epoch 1781/2000\n",
      "113/113 - 4s - loss: 0.0340 - accuracy: 0.9867 - val_loss: 1.2036 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01781: val_accuracy did not improve from 0.88000\n",
      "Epoch 1782/2000\n",
      "113/113 - 4s - loss: 0.0303 - accuracy: 0.9911 - val_loss: 1.2126 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01782: val_accuracy did not improve from 0.88000\n",
      "Epoch 1783/2000\n",
      "113/113 - 4s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 1.2139 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01783: val_accuracy did not improve from 0.88000\n",
      "Epoch 1784/2000\n",
      "113/113 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2374 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01784: val_accuracy did not improve from 0.88000\n",
      "Epoch 1785/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2503 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01785: val_accuracy did not improve from 0.88000\n",
      "Epoch 1786/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01786: val_accuracy did not improve from 0.88000\n",
      "Epoch 1787/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01787: val_accuracy did not improve from 0.88000\n",
      "Epoch 1788/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01788: val_accuracy did not improve from 0.88000\n",
      "Epoch 1789/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01789: val_accuracy did not improve from 0.88000\n",
      "Epoch 1790/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2900 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01790: val_accuracy did not improve from 0.88000\n",
      "Epoch 1791/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2952 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 01791: val_accuracy did not improve from 0.88000\n",
      "Epoch 1792/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3003 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01792: val_accuracy did not improve from 0.88000\n",
      "Epoch 1793/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3040 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01793: val_accuracy did not improve from 0.88000\n",
      "Epoch 1794/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01794: val_accuracy did not improve from 0.88000\n",
      "Epoch 1795/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01795: val_accuracy did not improve from 0.88000\n",
      "Epoch 1796/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3157 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01796: val_accuracy did not improve from 0.88000\n",
      "Epoch 1797/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01797: val_accuracy did not improve from 0.88000\n",
      "Epoch 1798/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01798: val_accuracy did not improve from 0.88000\n",
      "Epoch 1799/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3279 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01799: val_accuracy did not improve from 0.88000\n",
      "Epoch 1800/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01800: val_accuracy did not improve from 0.88000\n",
      "Epoch 1801/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01801: val_accuracy did not improve from 0.88000\n",
      "Epoch 1802/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01802: val_accuracy did not improve from 0.88000\n",
      "Epoch 1803/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01803: val_accuracy did not improve from 0.88000\n",
      "Epoch 1804/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01804: val_accuracy did not improve from 0.88000\n",
      "Epoch 1805/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01805: val_accuracy did not improve from 0.88000\n",
      "Epoch 1806/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01806: val_accuracy did not improve from 0.88000\n",
      "Epoch 1807/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01807: val_accuracy did not improve from 0.88000\n",
      "Epoch 1808/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3585 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01808: val_accuracy did not improve from 0.88000\n",
      "Epoch 1809/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3607 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01809: val_accuracy did not improve from 0.88000\n",
      "Epoch 1810/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3627 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01810: val_accuracy did not improve from 0.88000\n",
      "Epoch 1811/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3650 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01811: val_accuracy did not improve from 0.88000\n",
      "Epoch 1812/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3671 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01812: val_accuracy did not improve from 0.88000\n",
      "Epoch 1813/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01813: val_accuracy did not improve from 0.88000\n",
      "Epoch 1814/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01814: val_accuracy did not improve from 0.88000\n",
      "Epoch 1815/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3757 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01815: val_accuracy did not improve from 0.88000\n",
      "Epoch 1816/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01816: val_accuracy did not improve from 0.88000\n",
      "Epoch 1817/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3771 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01817: val_accuracy did not improve from 0.88000\n",
      "Epoch 1818/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01818: val_accuracy did not improve from 0.88000\n",
      "Epoch 1819/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01819: val_accuracy did not improve from 0.88000\n",
      "Epoch 1820/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3818 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01820: val_accuracy did not improve from 0.88000\n",
      "Epoch 1821/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3839 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01821: val_accuracy did not improve from 0.88000\n",
      "Epoch 1822/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01822: val_accuracy did not improve from 0.88000\n",
      "Epoch 1823/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01823: val_accuracy did not improve from 0.88000\n",
      "Epoch 1824/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01824: val_accuracy did not improve from 0.88000\n",
      "Epoch 1825/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3912 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01825: val_accuracy did not improve from 0.88000\n",
      "Epoch 1826/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01826: val_accuracy did not improve from 0.88000\n",
      "Epoch 1827/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01827: val_accuracy did not improve from 0.88000\n",
      "Epoch 1828/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3972 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01828: val_accuracy did not improve from 0.88000\n",
      "Epoch 1829/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01829: val_accuracy did not improve from 0.88000\n",
      "Epoch 1830/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3980 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01830: val_accuracy did not improve from 0.88000\n",
      "Epoch 1831/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3997 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01831: val_accuracy did not improve from 0.88000\n",
      "Epoch 1832/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4008 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01832: val_accuracy did not improve from 0.88000\n",
      "Epoch 1833/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01833: val_accuracy did not improve from 0.88000\n",
      "Epoch 1834/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01834: val_accuracy did not improve from 0.88000\n",
      "Epoch 1835/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01835: val_accuracy did not improve from 0.88000\n",
      "Epoch 1836/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4005 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01836: val_accuracy did not improve from 0.88000\n",
      "Epoch 1837/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01837: val_accuracy did not improve from 0.88000\n",
      "Epoch 1838/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01838: val_accuracy did not improve from 0.88000\n",
      "Epoch 1839/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4065 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01839: val_accuracy did not improve from 0.88000\n",
      "Epoch 1840/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4078 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01840: val_accuracy did not improve from 0.88000\n",
      "Epoch 1841/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4084 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01841: val_accuracy did not improve from 0.88000\n",
      "Epoch 1842/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01842: val_accuracy did not improve from 0.88000\n",
      "Epoch 1843/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3986 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01843: val_accuracy did not improve from 0.88000\n",
      "Epoch 1844/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01844: val_accuracy did not improve from 0.88000\n",
      "Epoch 1845/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01845: val_accuracy did not improve from 0.88000\n",
      "Epoch 1846/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01846: val_accuracy did not improve from 0.88000\n",
      "Epoch 1847/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3948 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01847: val_accuracy did not improve from 0.88000\n",
      "Epoch 1848/2000\n",
      "113/113 - 5s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01848: val_accuracy did not improve from 0.88000\n",
      "Epoch 1849/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01849: val_accuracy did not improve from 0.88000\n",
      "Epoch 1850/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3925 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01850: val_accuracy did not improve from 0.88000\n",
      "Epoch 1851/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3948 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01851: val_accuracy did not improve from 0.88000\n",
      "Epoch 1852/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 01852: val_accuracy did not improve from 0.88000\n",
      "Epoch 1853/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01853: val_accuracy did not improve from 0.88000\n",
      "Epoch 1854/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3971 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01854: val_accuracy did not improve from 0.88000\n",
      "Epoch 1855/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3881 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01855: val_accuracy did not improve from 0.88000\n",
      "Epoch 1856/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01856: val_accuracy did not improve from 0.88000\n",
      "Epoch 1857/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4071 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01857: val_accuracy did not improve from 0.88000\n",
      "Epoch 1858/2000\n",
      "113/113 - 4s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3787 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01858: val_accuracy did not improve from 0.88000\n",
      "Epoch 1859/2000\n",
      "113/113 - 4s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01859: val_accuracy did not improve from 0.88000\n",
      "Epoch 1860/2000\n",
      "113/113 - 4s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3880 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 01860: val_accuracy did not improve from 0.88000\n",
      "Epoch 1861/2000\n",
      "113/113 - 4s - loss: 0.1955 - accuracy: 0.9733 - val_loss: 2.3728 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 01861: val_accuracy did not improve from 0.88000\n",
      "Epoch 1862/2000\n",
      "113/113 - 4s - loss: 0.3292 - accuracy: 0.9289 - val_loss: 1.2410 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 01862: val_accuracy did not improve from 0.88000\n",
      "Epoch 1863/2000\n",
      "113/113 - 4s - loss: 0.0763 - accuracy: 0.9789 - val_loss: 1.0489 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01863: val_accuracy did not improve from 0.88000\n",
      "Epoch 1864/2000\n",
      "113/113 - 4s - loss: 0.0177 - accuracy: 0.9922 - val_loss: 1.0594 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01864: val_accuracy did not improve from 0.88000\n",
      "Epoch 1865/2000\n",
      "113/113 - 4s - loss: 0.0097 - accuracy: 0.9989 - val_loss: 1.0433 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01865: val_accuracy did not improve from 0.88000\n",
      "Epoch 1866/2000\n",
      "113/113 - 4s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01866: val_accuracy did not improve from 0.88000\n",
      "Epoch 1867/2000\n",
      "113/113 - 4s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01867: val_accuracy did not improve from 0.88000\n",
      "Epoch 1868/2000\n",
      "113/113 - 4s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1135 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01868: val_accuracy did not improve from 0.88000\n",
      "Epoch 1869/2000\n",
      "113/113 - 4s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1082 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01869: val_accuracy did not improve from 0.88000\n",
      "Epoch 1870/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01870: val_accuracy did not improve from 0.88000\n",
      "Epoch 1871/2000\n",
      "113/113 - 4s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01871: val_accuracy did not improve from 0.88000\n",
      "Epoch 1872/2000\n",
      "113/113 - 4s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01872: val_accuracy did not improve from 0.88000\n",
      "Epoch 1873/2000\n",
      "113/113 - 4s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01873: val_accuracy did not improve from 0.88000\n",
      "Epoch 1874/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1785 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01874: val_accuracy did not improve from 0.88000\n",
      "Epoch 1875/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1868 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01875: val_accuracy did not improve from 0.88000\n",
      "Epoch 1876/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01876: val_accuracy did not improve from 0.88000\n",
      "Epoch 1877/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01877: val_accuracy did not improve from 0.88000\n",
      "Epoch 1878/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2113 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01878: val_accuracy did not improve from 0.88000\n",
      "Epoch 1879/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01879: val_accuracy did not improve from 0.88000\n",
      "Epoch 1880/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2427 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01880: val_accuracy did not improve from 0.88000\n",
      "Epoch 1881/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01881: val_accuracy did not improve from 0.88000\n",
      "Epoch 1882/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2572 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01882: val_accuracy did not improve from 0.88000\n",
      "Epoch 1883/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2613 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01883: val_accuracy did not improve from 0.88000\n",
      "Epoch 1884/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2669 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01884: val_accuracy did not improve from 0.88000\n",
      "Epoch 1885/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2745 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01885: val_accuracy did not improve from 0.88000\n",
      "Epoch 1886/2000\n",
      "113/113 - 5s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2784 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01886: val_accuracy did not improve from 0.88000\n",
      "Epoch 1887/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2775 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01887: val_accuracy did not improve from 0.88000\n",
      "Epoch 1888/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2926 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01888: val_accuracy did not improve from 0.88000\n",
      "Epoch 1889/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2933 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01889: val_accuracy did not improve from 0.88000\n",
      "Epoch 1890/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01890: val_accuracy did not improve from 0.88000\n",
      "Epoch 1891/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01891: val_accuracy did not improve from 0.88000\n",
      "Epoch 1892/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3079 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01892: val_accuracy did not improve from 0.88000\n",
      "Epoch 1893/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01893: val_accuracy did not improve from 0.88000\n",
      "Epoch 1894/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01894: val_accuracy did not improve from 0.88000\n",
      "Epoch 1895/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3305 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01895: val_accuracy did not improve from 0.88000\n",
      "Epoch 1896/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01896: val_accuracy did not improve from 0.88000\n",
      "Epoch 1897/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01897: val_accuracy did not improve from 0.88000\n",
      "Epoch 1898/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3434 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01898: val_accuracy did not improve from 0.88000\n",
      "Epoch 1899/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01899: val_accuracy did not improve from 0.88000\n",
      "Epoch 1900/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01900: val_accuracy did not improve from 0.88000\n",
      "Epoch 1901/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01901: val_accuracy did not improve from 0.88000\n",
      "Epoch 1902/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3588 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01902: val_accuracy did not improve from 0.88000\n",
      "Epoch 1903/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01903: val_accuracy did not improve from 0.88000\n",
      "Epoch 1904/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3740 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01904: val_accuracy did not improve from 0.88000\n",
      "Epoch 1905/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3722 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01905: val_accuracy did not improve from 0.88000\n",
      "Epoch 1906/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01906: val_accuracy did not improve from 0.88000\n",
      "Epoch 1907/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3843 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01907: val_accuracy did not improve from 0.88000\n",
      "Epoch 1908/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01908: val_accuracy did not improve from 0.88000\n",
      "Epoch 1909/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01909: val_accuracy did not improve from 0.88000\n",
      "Epoch 1910/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3924 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01910: val_accuracy did not improve from 0.88000\n",
      "Epoch 1911/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3912 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01911: val_accuracy did not improve from 0.88000\n",
      "Epoch 1912/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3977 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01912: val_accuracy did not improve from 0.88000\n",
      "Epoch 1913/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01913: val_accuracy did not improve from 0.88000\n",
      "Epoch 1914/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01914: val_accuracy did not improve from 0.88000\n",
      "Epoch 1915/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4101 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01915: val_accuracy did not improve from 0.88000\n",
      "Epoch 1916/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01916: val_accuracy did not improve from 0.88000\n",
      "Epoch 1917/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4157 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01917: val_accuracy did not improve from 0.88000\n",
      "Epoch 1918/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4178 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01918: val_accuracy did not improve from 0.88000\n",
      "Epoch 1919/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01919: val_accuracy did not improve from 0.88000\n",
      "Epoch 1920/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4233 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01920: val_accuracy did not improve from 0.88000\n",
      "Epoch 1921/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01921: val_accuracy did not improve from 0.88000\n",
      "Epoch 1922/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4346 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01922: val_accuracy did not improve from 0.88000\n",
      "Epoch 1923/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4394 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01923: val_accuracy did not improve from 0.88000\n",
      "Epoch 1924/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4494 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01924: val_accuracy did not improve from 0.88000\n",
      "Epoch 1925/2000\n",
      "113/113 - 4s - loss: 0.2588 - accuracy: 0.9589 - val_loss: 1.0212 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01925: val_accuracy did not improve from 0.88000\n",
      "Epoch 1926/2000\n",
      "113/113 - 4s - loss: 0.1504 - accuracy: 0.9522 - val_loss: 0.7924 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01926: val_accuracy did not improve from 0.88000\n",
      "Epoch 1927/2000\n",
      "113/113 - 4s - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.7747 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 01927: val_accuracy did not improve from 0.88000\n",
      "Epoch 1928/2000\n",
      "113/113 - 4s - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.8131 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01928: val_accuracy did not improve from 0.88000\n",
      "Epoch 1929/2000\n",
      "113/113 - 4s - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.8874 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 01929: val_accuracy did not improve from 0.88000\n",
      "Epoch 1930/2000\n",
      "113/113 - 4s - loss: 0.0204 - accuracy: 0.9978 - val_loss: 0.8194 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01930: val_accuracy did not improve from 0.88000\n",
      "Epoch 1931/2000\n",
      "113/113 - 4s - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.8348 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01931: val_accuracy did not improve from 0.88000\n",
      "Epoch 1932/2000\n",
      "113/113 - 4s - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.8462 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01932: val_accuracy did not improve from 0.88000\n",
      "Epoch 1933/2000\n",
      "113/113 - 4s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01933: val_accuracy did not improve from 0.88000\n",
      "Epoch 1934/2000\n",
      "113/113 - 4s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01934: val_accuracy did not improve from 0.88000\n",
      "Epoch 1935/2000\n",
      "113/113 - 4s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01935: val_accuracy did not improve from 0.88000\n",
      "Epoch 1936/2000\n",
      "113/113 - 4s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01936: val_accuracy did not improve from 0.88000\n",
      "Epoch 1937/2000\n",
      "113/113 - 4s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01937: val_accuracy did not improve from 0.88000\n",
      "Epoch 1938/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9440 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01938: val_accuracy did not improve from 0.88000\n",
      "Epoch 1939/2000\n",
      "113/113 - 4s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01939: val_accuracy did not improve from 0.88000\n",
      "Epoch 1940/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01940: val_accuracy did not improve from 0.88000\n",
      "Epoch 1941/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01941: val_accuracy did not improve from 0.88000\n",
      "Epoch 1942/2000\n",
      "113/113 - 4s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01942: val_accuracy did not improve from 0.88000\n",
      "Epoch 1943/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9977 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01943: val_accuracy did not improve from 0.88000\n",
      "Epoch 1944/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01944: val_accuracy did not improve from 0.88000\n",
      "Epoch 1945/2000\n",
      "113/113 - 4s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01945: val_accuracy did not improve from 0.88000\n",
      "Epoch 1946/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01946: val_accuracy did not improve from 0.88000\n",
      "Epoch 1947/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01947: val_accuracy did not improve from 0.88000\n",
      "Epoch 1948/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01948: val_accuracy did not improve from 0.88000\n",
      "Epoch 1949/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01949: val_accuracy did not improve from 0.88000\n",
      "Epoch 1950/2000\n",
      "113/113 - 4s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0496 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01950: val_accuracy did not improve from 0.88000\n",
      "Epoch 1951/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01951: val_accuracy did not improve from 0.88000\n",
      "Epoch 1952/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01952: val_accuracy did not improve from 0.88000\n",
      "Epoch 1953/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01953: val_accuracy did not improve from 0.88000\n",
      "Epoch 1954/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01954: val_accuracy did not improve from 0.88000\n",
      "Epoch 1955/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01955: val_accuracy did not improve from 0.88000\n",
      "Epoch 1956/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01956: val_accuracy did not improve from 0.88000\n",
      "Epoch 1957/2000\n",
      "113/113 - 4s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01957: val_accuracy did not improve from 0.88000\n",
      "Epoch 1958/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01958: val_accuracy did not improve from 0.88000\n",
      "Epoch 1959/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1006 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01959: val_accuracy did not improve from 0.88000\n",
      "Epoch 1960/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01960: val_accuracy did not improve from 0.88000\n",
      "Epoch 1961/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01961: val_accuracy did not improve from 0.88000\n",
      "Epoch 1962/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01962: val_accuracy did not improve from 0.88000\n",
      "Epoch 1963/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01963: val_accuracy did not improve from 0.88000\n",
      "Epoch 1964/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01964: val_accuracy did not improve from 0.88000\n",
      "Epoch 1965/2000\n",
      "113/113 - 4s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1341 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01965: val_accuracy did not improve from 0.88000\n",
      "Epoch 1966/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01966: val_accuracy did not improve from 0.88000\n",
      "Epoch 1967/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01967: val_accuracy did not improve from 0.88000\n",
      "Epoch 1968/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01968: val_accuracy did not improve from 0.88000\n",
      "Epoch 1969/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01969: val_accuracy did not improve from 0.88000\n",
      "Epoch 1970/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01970: val_accuracy did not improve from 0.88000\n",
      "Epoch 1971/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01971: val_accuracy did not improve from 0.88000\n",
      "Epoch 1972/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1695 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01972: val_accuracy did not improve from 0.88000\n",
      "Epoch 1973/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01973: val_accuracy did not improve from 0.88000\n",
      "Epoch 1974/2000\n",
      "113/113 - 4s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01974: val_accuracy did not improve from 0.88000\n",
      "Epoch 1975/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1867 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01975: val_accuracy did not improve from 0.88000\n",
      "Epoch 1976/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01976: val_accuracy did not improve from 0.88000\n",
      "Epoch 1977/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01977: val_accuracy did not improve from 0.88000\n",
      "Epoch 1978/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01978: val_accuracy did not improve from 0.88000\n",
      "Epoch 1979/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1979 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01979: val_accuracy did not improve from 0.88000\n",
      "Epoch 1980/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 01980: val_accuracy did not improve from 0.88000\n",
      "Epoch 1981/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2178 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01981: val_accuracy did not improve from 0.88000\n",
      "Epoch 1982/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01982: val_accuracy did not improve from 0.88000\n",
      "Epoch 1983/2000\n",
      "113/113 - 4s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01983: val_accuracy did not improve from 0.88000\n",
      "Epoch 1984/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01984: val_accuracy did not improve from 0.88000\n",
      "Epoch 1985/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01985: val_accuracy did not improve from 0.88000\n",
      "Epoch 1986/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01986: val_accuracy did not improve from 0.88000\n",
      "Epoch 1987/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2450 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01987: val_accuracy did not improve from 0.88000\n",
      "Epoch 1988/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01988: val_accuracy did not improve from 0.88000\n",
      "Epoch 1989/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01989: val_accuracy did not improve from 0.88000\n",
      "Epoch 1990/2000\n",
      "113/113 - 4s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01990: val_accuracy did not improve from 0.88000\n",
      "Epoch 1991/2000\n",
      "113/113 - 4s - loss: 0.1687 - accuracy: 0.9744 - val_loss: 1.1573 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 01991: val_accuracy did not improve from 0.88000\n",
      "Epoch 1992/2000\n",
      "113/113 - 4s - loss: 0.1323 - accuracy: 0.9667 - val_loss: 0.8360 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01992: val_accuracy did not improve from 0.88000\n",
      "Epoch 1993/2000\n",
      "113/113 - 4s - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.7661 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01993: val_accuracy did not improve from 0.88000\n",
      "Epoch 1994/2000\n",
      "113/113 - 4s - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.8688 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01994: val_accuracy did not improve from 0.88000\n",
      "Epoch 1995/2000\n",
      "113/113 - 4s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8961 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 01995: val_accuracy did not improve from 0.88000\n",
      "Epoch 1996/2000\n",
      "113/113 - 4s - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.9081 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01996: val_accuracy did not improve from 0.88000\n",
      "Epoch 1997/2000\n",
      "113/113 - 4s - loss: 0.0099 - accuracy: 0.9956 - val_loss: 0.8753 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 01997: val_accuracy did not improve from 0.88000\n",
      "Epoch 1998/2000\n",
      "113/113 - 4s - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.8492 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01998: val_accuracy did not improve from 0.88000\n",
      "Epoch 1999/2000\n",
      "113/113 - 4s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 01999: val_accuracy did not improve from 0.88000\n",
      "Epoch 2000/2000\n",
      "113/113 - 4s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 02000: val_accuracy did not improve from 0.88000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162dd868610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "# LSwFW_model.fit(train_tensor, \n",
    "#                 train_targets, \n",
    "#                 epochs=1,\n",
    "#                 batch_size=n_batch,\n",
    "#                 shuffle=True,\n",
    "#                 verbose=2, \n",
    "#                )\n",
    "# #Set feat weights\n",
    "# # Fweights=cosa_mdl.Fweight\n",
    "# sampled_Fweights=train_Fweights[np.random.choice(range(len(train_Fweights)), n_attention)]\n",
    "# for i in range(n_attention):\n",
    "#     weights=LSwFW_model.layers[1].attention_layers[i].get_weights()\n",
    "#     weights[0]=np.reshape(sampled_Fweights[i], (1,n_feat))\n",
    "#     LSwFW_model.layers[1].attention_layers[i].set_weights(weights)\n",
    "\n",
    "\n",
    "n_epoch=2000\n",
    "\n",
    "\n",
    "LSwFW_model.fit(train_tensor, \n",
    "                train_targets, \n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_tensor, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x25b0a911ac0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSwFW_model.load_weights(os.path.join(\"210210_TrainingLocalitySensitivewFW\",\n",
    "                                      \"LocalitySensitivewFW_label\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attentions=[LSwFW_model.layers[1].attention_layers[i](train_tensor).numpy() for i in range(10)]\n",
    "# attentions=np.reshape(attentions, (900,10))\n",
    "\n",
    "attentions=LSwFW_model.layers[1](train_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "dr=TSNE()\n",
    "embed_attentions=dr.fit_transform(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1635d4343d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "scatter=ax.scatter(embed_attentions[:,0], embed_attentions[:,1],\n",
    "                   c=cluster_labels_train,\n",
    "                   s=3\n",
    "                  )\n",
    "\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1635fa32460>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD8CAYAAADQSqd1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABZr0lEQVR4nO3ddXwU19rA8d+ZlbgQw90pFPdSoEhbqFCFurtQ19v2rd26Oy33llujlLpAvaW4uzshgbgnKzPP+8cuISkQQtlks+F8+5lPd2dnZs8Jmydnz5zzHCUiaJqmabXLCHYBNE3TjkU6+GqapgWBDr6apmlBoIOvpmlaEOjgq2maFgQ6+GqapgWBDr6apmkBoJSaqJRarZRao5S67XDH6+CraZp2lJRSXYFrgH5Ad+A0pVS7qs7RwVfTNO3odQYWiEiJiHiBP4GzqzrBXivFqqakpCRp1apVsIuhaVoIWLJkSZaIJB/NNU4eHiXZOWb13m+law1QVmHXJBGZ5H+8GnhSKZUIlAJjgMVVXa9OBd9WrVqxeHGV5dU0TQNAKbXjaK+RnWOy8McW1TrW1nhTmYj0OdhrIrJOKfUM8BNQDCwHqozquttB07RjlgBWNf877LVEJotIbxE5EcgFNlZ1fJ1q+WqaptUmQfBI9bodDkcplSIiGUqpFvj6ewdUdbwOvpqmHdOq06qtps/9fb4e4CYRyavqYB18NU07ZgmCGaC0uiIy5EiO18FX07RjmkVwcprr4Ktp2jFLADNIwVePdtC0QyjIKcTt8gS7GFoNs5BqbYGmW76adhDzvl3MY+c+j2EzsDvtDBs/iNvfuT7YxdICTABPkJZS0y1fTTuIdfM3YpoW7jIPJQWl/PDurxTlF3Pv6Me5uPWN7Fi7CwDTa2JZAbtbrtUyQTCruQWabvlqml9JYSn3nfw4RXkl3DPlJqY99zWm5fuli2kQzUdPfs7KWWsxvSbv3P0B6+ZvxFXiJjI2gkkrniehUYMg10A7YgJmkNYQ1sFX0/zWL9jEluXbsSxh3tf7p7kbNoPC3CKmv/AtcUmxAGxYtJmi3GIAyooUW1fu1ME3BPlmuAWH7nbQNL/jBnek+7CutO/ZmpOvGEZETASGzeC8e84gLCqMpCYJFGQVkJ9VQGFOISjfeY3aNKTnSV2DWnbtn1KY1dwCTbd8jyEipeCaA85eKCMh2MWpc8Iiwvj3Dw8AsHHJFlwlLsQS5ny+AMtrkpuRj81uwxLB8u5vLzmcdlI3pfPGrf+h84AObF62je7DunD+XWcGqypaNfluuAU+sFaHDr71kIgbKXwOsKFi7kKKXoOST8BIAnMrGA1RKX8Gu5h1WruerTnx3IH89sls0rbsRSmF6fXlAEhsmkD27hwAbHaDLgM78Mr1k1j11zqW/boKgEUzl9Hn5B606dYyaHXQDs83zjc4wVd3O9RDknc3lEyBkg+QonegeBJIni/wYoG1B6vgccQqCXZR6yzDMJj41jU0ap2CzW5wySPnlr+WvTsHw2YQlxRDw5YpfPPmj6z6a12l88US7hz2SHnA1uouS1S1tkDTwbceEDGx8v+FlXM1lncXuGb4X/FA8Zv40oqGgfMEyv/JSz6F0i+CU+AQEREdwZSNr9Hm+JZ8+PjnHD+0Cygw7AYT7hvH1N2TKCsuO/BE/+9pUW4xK2etrd1Ca0dkX8s3GH2+OviGMKvsd6ycq5HSL6D0a3DPhbKfwd7df4QNX4IlwNEb1eBdSPgUiAMUOLoFp+B11OrZ6/j02a945Kxn+f7dXwBQSrFt1U68bi+FuUU4nA6UUmSn5WJ32Hns63vp0KftQa+nDMWGhZtrswraERIUJka1tkDTfb6hLO8uoBDMdLC3ADMTFTYEoq5AMseCtQVfM0zAsxjJfwDKvgDnUFT8yygjMsgVqBsyU7O5/cSH2Lsjk31j6ed+vYiBp/cmoVEDTP/NNYfDznO/PsKaOesZc81IADr2bcdNr17JbSf8C/GPCUZ8w9P6j+nJ2OtGBaNK2hGoiS6F6tDBN0SJewm+1UoA50DwLAUVjbjmQuk3YO1rcUUDRYAF7iWAgHsWqLCglLsuWvLzSnLS83yB1/+3CgVhkb6f0bl3nsbPU/7kwgfP4bhBHTluUMdK5y+asQwqTFFVhuL4E7vw0Gd34nA6aq0e2pETFG6xBeW9dfANVd5tgP8X294cSj8FXFD0FFSaCrmvT1KBvTO4dwIGlP0IEWNqs8R11qAz+/DrR7Ow222cf984dqzeRdfBHYmK9X0zuPqpi7n6qYsPef7Y60axcfEWMlOz2bZ6J3aHjcsfn6ADbwjwTbIITJeCUup24Gr/ZVcBV4jIQW4K+OjgG6oizgArC1QD32PXHHDP8b/orXCgF4gFCsH9I+D07ba3AkBEUCo4X7vqitiEGJ775ZHy5z2HHdmEiaQmCTz5/QPkZebz9CWvkdi4AZ36tQt0MbUaEoibaUqppsCtQBcRKVVKTQMmAO8f6hwdfEOUUk5U9PWIlYcUv4uKugyJfRzKPgdHHyj+GNwzQCVB1NVQ9CzYWkHYSRA+DGytsDKGgpWBxL+NET402FUKefHJcTw981/BLoZ2BEQUpgTsZpodiFBKeYBIIO1wB2shyCr5FAoeA1sTMFORYgOiroXi9/B1XPrHl0qWvyvCAVIMJZOh7Bsk/l2w0n3HFDyK2Keg7M2DVJvaU5BTyKPnPI8jzMEjn99FRFR4sIukBZkVgJaviOxWSj0P7ARKgZ9E5KeqztFDzUJV6ReAB8zdgA1ULBS/BbgAE4xEfP+8+z5YHrD2+h4ajaDo7f3XstKRrNMQc08tViA4Fny3lPULNrHyzzXls9G0Y5fvhpu9WhuQpJRaXGG7dt91lFINgDOB1kATIEopdegbBejgG7JUzH3g6OVr7Tr7QsQ4fDfgHBB5HVg5gA0cY4EIfF9ynODoD1aRr0uinAl4EO9mxFO/A1KvUceT2LQBHreX5698k8zUbEyvyeZl245o1YrpL37D9b3u5rL2NzP5gY8xTT2TLRTtu+FWnQ3IEpE+FbZJFS41EtgmIpki4gG+AAZV9d662yFEKWdPiH0UybnEN3XYsw4V+ygY0YAgJf6/q9Y6fN+CFNjagWcJghdV/nd3X9DwQu4NCAriX0KFj6jtKtUIV6mLpy95DVeJi4lvXcOauRvYuz0LBApzipg1fR4bFm5m9pcL6dS/PS/+8ehhr7n8j9W8c9cH5c+nPvMlETHhXHj/2TVZFa2GmIEZ57sTGKCUisT3CzcCWFzVCTr4hjDJvdUXeAHCTkBF+n75LbMAnP3B1hzChkPBg2BlgrkJS3w5+QsdI4i3GeD6ueIVAQWSX8s1CSyP28O9o58gbVM6F9x/FgtnLMMyLS7rcKsv18K+kXgKGrdO4fepczA9XvZsz+Dlhz5n46pU7nvhAlq0Tal0XRHhf/83jQ8fn37Aex7jA0ZC1r4Zbkd9HZEFSqnpwFJ8Q4yWAZOqOkcH31Bm7fI/sGPEP79/2FjxG/5hZwoVczMk/YBkn4GYWWzygKGgVEUQby2ocLFwiLwUbA0hfFzt1yWAdm/aw7r5G/F6vPzy8V8kNU2gOL+E/MwCAGwOG8nNEjjjxlMYeEZfSovKeO++j+g4oCO/fLkU07T4espf7JizCnepm0c+v5vExg1YNHM5nzx1YD6Mfqf25Py7dfrIUGUFaLSDiDwCPHLYA/10n2+9oLBKv0f2dsHKudLXvYACIw5UFMqIRiX9ikpZTJvwJrR1CMc5i1BxT/lmx4WfC+FnQ8n7UPQ8WBnBrtBRadG5KcMvGAzA+vmbaNAwjtcX/Lu8dSqW8Mjnd3PenWfgcXl47oo3yNqdw9zP59GqdQKxETa2zlrJit/XsG7+Jj57/muK8opp0DAOZfP9yjjDfRMoDJvBTa9cic0WnFlS2tHxJdYJTm4HHXxDmXMgYAfHQN+UYkxwz0FFnolKmoFK+gnln0Ysxe9ARlccVhYGNmxSjAo7ESNhCkb8v1HOLoABYoEUBbNWR80wDC57dDxhEb66r5m7gbQtezH8gdOwG6Rv8Y38sDlsxCREA76k6Dt+X0bRhm24i8t8wVrBN2/8yJVdbqN1txbc9d4N2B02LMui25DO3PL6VTRp2ygo9dSOnqDwiK1aW6DpbocQZXn3gPsv3xPPLIi4yJcyMmwkSjl9iXYqKvvR/8DwjZQI/9vU4ohzUCiwJaPsoTc7a/aXC3juijcYPK4fLY9rzn8e+BjL9CXEad21Be5SD3anA6W8nH7dKAaN6wuAzWbj/Q2vsmtDGlENIrm++92gFEPPH8Rp149m6a+rmP35fIpyi/F6THas243Xn6P35tev0snSQ5wIgZxkcUR08A1RyohCsOPr2zdQYQNQ4YfublKx/+db0SLyAlT4CMS7EytjHBixqISpKCMGIs+rreIHlIjw6qTfyO/Sip8+n8+QorLy5dyd4Q4mvnUNXQZ25MFPbsMZ7qD3qO7l5+Zl5vPJU1/y/aRfCIt0ct8Ht1KQXcgP7/1C1u4cHv3yHjr2aUun/u0JjwzDVezCGeYApXSLt15QAZlk8U/o4BuilBEDyX8i3u0oe1OUrUnVxzu7oxLe27/DPRusbLCykLxbIf5V3zVDUNqePLJsdiQuivi+Heh/Wm+SmiZQkF1Il4Ed6DKwI0opBp7e54BzX7vpPf76YgFiCabXJHVTOr1GdGPLih1YXotFP67gkofOZcbkX/n1w1lc+OA5tOzSjPa92xAeqTPDhTpBt3y1f0DZklG25MMeJ1Y+qGiUqtBvFX4qlHwB3tXgXuibMRd1WQ2WtuY0TImjW5emrF2TSt7yrbw8ew3fFH7oa6EehiPcUZ6H1+v28sGj01g3fyOWv2sha3c2manZvHrje1hiERkbyTXPVDlxSQsxNXEzrTr0Dbd6zir+BMnoj2SfjVTKOdsAlTCZXLMJbssBzt6Vzisr82BZ8vfL1UkfPvoZ6174kjZpGRgFvnXpzk68gnULNh3ynFnT5/HTlD8O6LP1uL0s+G4JSikcYQ5adm5GbGI0CY3jMZSi6wmdarQuWu0Sqrd+W00kXNct3/rOPQ8Q8G7At6SQs/yln/Zs49HVg0gKi+XzRp2wFf8PvGv4ZfHZPPXSLNq2TmbSK5dhGHV7BsGiGUsRgb07MrHbbXjcXkyvi4fPfJo+o3tw139uxGb3tfq3rtrBE+NfInXDbhxhTu549zpOu34UhdnFFOQUsuy3VQjQeUAHbn71Str1bI1SiimbfLPkouKigltZLaB8S8cHJwwedctXKdVcKfW7UmqtUmqNUmqif3+CUupnpdQm//8bHH1xtSOlYu+DiLMh7hXfKIgKVuXtQgSyXAUUubZD4RNQ+iVW4euICFu2ZVJ2BPkOgmFTXhZ7L29Fs5M7ct//bqHivZO8jAJ+nzqbjUu2Ar4RETf2uZdd63f77nJ7TRq2SuHm167i9nevozi/BARiE6J59ueHaN+rTXmuY7vDrgNvvVS9xTNrYgHNQIR8L3CniCxVSsUAS5RSPwOXA7+KyNNKqfuA+4B7A/B+2hFQtia+yRR/I95tXJUwBdyd6JZyLnFh+2/Yjey/koUbzqdf79ZERjgPOLcueXX5XBZHFqLOj+UitwuP21vpdcsSNizaTHxKLLs2+NKrKqVo0bkpd7x3A536tePGPveybdVOLn98PL1GHs+w8YPKxwhr9ZsQuBluR+qog6+IpAPp/seFSql1QFN86dWG+Q+bAvyBDr51hpR8RBwruaPRWlTyDSgjEsvWGsxtGJETePje04NdxGo5s00Xft65mf6NmpO/NrfyCkr4ZrO9fecUpj79JVM2vYZS0KxDE044qz/gS7yzbdVORIRtK3fywMe31X4ltKCqiVZtdQS0s0Mp1QroCSwAGvoDM8AeoOEhzrkWuBagRYsWBztEqwEq/HSk7Hvfum6Gb7yqkfzjYc6qe0a2aMf6S+8AIL3dXj595itKi8ooK3aVH6OUIiImgrCIMCbce1al88Miwrjvw1tZPHM5lz02vlbLrgWfiArdlu8+Sqlo4HPgNhEpqLgumIiIUuqgt879OTEnAfTp0yc0bq/XA8rZHZUyDwARN2KVoYzQ7tNs3KYh09LfY83c9Twy7llcpW4mvn0tDVLi6NCn7SHPGz5+MMPHD67Fkmp1he+GWwivXqyUcuALvB+JyL60T3uVUo1FJF0p1RgI7Wwt9ZSY2UjWqSClkPAhytn98CfVYXu2Z3DvqMcBuPu/NzH0/CrzWWvHvICu4XZEAjHaQQGTgXUi8mKFl74B9o3avwz4+mjfSwssERMp+84XeBHE9TNS8ilVrHZd53k9vnzFKHCX1e2RGlrw+W64he4438HAJcAqpdRy/74HgKeBaUqpq4AdwPkBeC8tAMQ1Gyl6E4wUcP0KiC+tZPEUX+DybkLFhuYqvM3aN+bZnx8md28eg8f1w2OauLwm0WF1e9SGFjzBmuEWiNEOs+GQtwvrx1o09YCIheReB55VoGy+lS3Y19flhNg7wfU9SBmY2YhVGLK5Ho4b1BGAYrebU9+cQnZxCe9MGMcJbXUGMq2yfTPcjpZSqiPwaYVdbYCHReTlQ52jpxcfA8SzBsmb6EtBKTnAvuXSTcCCxI9QnqUQdT2oxuCagWQMxip8PYilPnpZRSXklpQiCMtS04JdHK2OOoIFNA9JRDaISA8R6QH0BkqAL6s6R08vrufEykfy7gBzG6hIsLWBsCFQPAkwwdYavLuQ/DvxtYSdgAWUQfGrWFFXYhiRQa3DP9UyIZ57R53IpswsLu3XM9jF0eogEfBYAW+DjgC2iMiOqg7SLd96zCqZjmQMADMbMCBsBEbSFyB2wOHr5415FPLvxDdR0QPhoypcwYCMnlg51yKe9UGpw9G6uG8PhhVG8MKEV9i2emewi6PVMb5uB6NaG5CklFpcYbv2EJedAHxyuPfWLd/6zL0I3/3cIkj6DXAi4oaSSYALyn6Gss/9xxgQcSkq9n5ESsE1E4j0nev+A8n+E4l/DSN8dPDq8w9sXr6Nf1/4Mgjsycth0p/PBLtIWh1zBDPcskTkwKTQFShfApUzgPsPdzHd8q3HVMwdEHEuxL0IrrmQdQKSMRxw+4/Ip9J83LAhvkQy4acBBhjxYOy7SSXgmlWbxf/HRASv5cvH+/5DU/EcF44o2NbDdZgztWNNDQw1OxVYKiJ7D3egDr71mLI1xIh7AiNiDJR9A1ggmeDoDsSAsS8RuwKcKMlEvLugdBpggpUOCR+C/XgwmqGirjvgPUzLYu2OPZS6gzumVsSXQCc3M5+rF7zNCT89zC/pqxh16VDoFU3B1+0YevWJBz23xOuqlOtYO5YcUbdDdVxANbocQHc7HDsiTgPPIsBAxT0P5k4k9wYgDCIvR9lbIGGjIPNEEC/YOkDkhRj2hpA0vdKlvKZFTmEJyZGbeHzKdGauTKZN42Q+fuCioFQNYNrz3zDl/6YhQ2LJvq0BCpiVsZbHzhvPH+cNwmuZ2A0bIsJ3u5eS7ylhQstBTNsxj1c2zKBPQhve6HdV0MqvBU+g1nBTSkUBo4ADWykHoYPvMUDMTFDREP8WytbIF2jxsG94tooYg3J0psy9BYe4UBio8JEYURcecC23x8uIe96huMzNNcO3kZbjwDRNMvKCu9x8TloupaOjKL4sDrsy6JPYluva7795aDd8Y5rnZ23i6TVfYShFvDOKOZkbfEPRcrcHqeRaMPlGOwQmt4OIFAOJ1T1eB99jgOSMB3MvOAeWL6Kp7G0h5Q8QC2VLAmBp5gOYHoMEexzHRd8EgFX8EZR8CM5+qLBBrNvdjeIyNyD8tiGJNyZ8xfdrx3Fi3+Cu/3b5ExNI/cLLn+E7UMrg/7qdR0JYdKVjijxl3L7kfSxACby87ntMMemX2JZzWwwITsG1oArUJIt/QgffY4FVBHjAPQ+RUpSKAEAZCQCIZyNi5RJtSyHdvQmn0R5friSg6DmQEijdipR+QafG02jS2EFGTgkxfdOwmn/LFe2bBqli+0VEhfP4xVcyK2M9TSMbHBB4AXYUZ2L5HwtQ4C0FIM9dwrCGx9VeYbU6RS8dr9Wc8DFQ6pv5WJCVRUxiUwzDdwNBSr9D8u8BvHQjilaN3iA63DeaRsQEwvBN1gGw4TCyefvOUXy0/Wl6RnpJstedFR8MZTCsYZdDvt45rin9EtuyMHtLpf1RtjDclhenoX8djjX7RjsEgx7tUE+JVYyVPR4rY6RvuFnEeViml/Rlp/Hw6U/uP85Mh/L2YDExRU9hSDFW4RuIazZIPqAgbBQ4ekLeNTQpe5C7U3YzMmIZRv5tQajdP2Mog9f7XkX/xHaV9i/L287XuxYHqVRasAV4tEO16eBbX3lWgmc1WDsh5wJfwhwltOlSyq4Na8sPU1GXQfQ9oJIBA6QAKfg3FL8GedeB80zflOToW8GzDDAR92rStuT7lpZXgZl6XOQp48tdC9lZnBWQ61Xl0ePP54Wel1Ta1zIqqcbfV6t7RBReMaq1BZr+nlWLtm3cw8I/1jNyXC8SU2Jr9s2cvXx5G8xNvufhp1BWkMGiXw1uf/eO8sOUcqKir0QizoCyHyBsqC/H777WsPsrQEHxO2A0BGsbqVvDmTi2KX1HCg989kpAivuvFVOZl7URmzL4Y9T/HXEXgIjgsjyE26pOHSkiXDTnVYq8LrrFtSC1JJuzm/ejX1K7Ks/T6i99w62e+eHTBezenkVGeh7L521hxJk9+fqDuQB88NrPhEc4ufa+sYw+u8rZiv+YUmGQ9AVS9A4Yiaiw4US3OInhVxzieFsSRF0KgEReDyWfIdZeytw2wh1upPQHDOWbNeZxQ2mRQUzDk8tv3lWX28xnTtp4vFYRA5t8iEVDJm36hZ3FmQjgFYuVuTvok3joZX/+TkS4Yt6brC3YTeuoZN7odzVJYYdOh+myvAhCs6gEJg+8/ojKr9Uvwezz1cG3Biyfv4U3H/8GQbBM38ypH6fv71M0vRbFhWV8/NZvNRZ8wd+qjbnliM+bt3Ar/35hDN17RVESvoUnz5mBw27DUBYgtOlcwg+7VqLs+YhcglLhh73mPgXu9bjMTBAhp3QhX6fH8PmuBSgg3hFJmMfB759toM0FKSTExSAi/PbxbEoKSxlzzQhstgPHZK7P3cva/N0IsK04k+93L+WyNkMP8TNR/HfgjazM3cHIRt2O+Gej1T/6hls9sWd3Lg9d+19M08KyhKgYX2AyjMr/wA6njYtvHlnj5XGZWczefR6zUs8ms2Rutc756be1FBXDnNnFNEg8hWWpPRHbcRD9YPkxSgHmbvBurXZZnvrkN06/dwEb1p5FcuQQGkedQre4FigUCWExTOlxMyVvGKxP+ZJHt1zLouy/WPPHh7x07eu8c+cU/pw276DXvfTraeD1TRlRAoOSO1RZjpZRSZzerDcRdr26xbFu3zjfUF1GSKvgqds+xuvxfT3v0rMlHbo24+sP5tJ3WCdWLNhCXnYRLdqm8PY3t1Fxheeasn7LxxTY1iEK5qVdzzc/jOepSyeSHH/gONh9Lr9oMDm5xQzq35YJZ7VEMpeBWOCOx/f3ev9oWSGs2qMkv1uwFpfHZNGK1kwc41umaFij4/gh4X4i7U4wITE5iqiWvtlyK/P+4uSIz4A2iEBKi4PfFEtaZ+LaJLj7wrWDR9E+pnE1S6RpwRvnq1u+Adak1f4AkZGWy+yfVvPmNxO5+eEzOeXcPpx31Ylc/8DpvPfcDPbuzq3x8mTMW0aE4ft4iaXILSxl0cZdVZ7TumUSrz13IRec2x+MBHxtSgHPFoi5F5wj8I3/taPUoT9CpphkufaWJ6255/zhdG3VkAv7dObZy19n6a+rAIhzRLCzZBN5ZiYfvHUtTdedhnN1D05NOZcmrZ38d+4WJi8/l66DOx30fV668jzid4fRcVYi5/TSqxVr1ScCXsuo1hZouuUbYGFhdpTy/aNm7SnA4bSzeXUq/3rpJ7IzCgD45sN5uF0eNq1K5dkPDpWPOTBaHXcpDQoXsqvIwdQ142kS15ETu7WpdMyKLWmkZRcwuk8HbEblD5lSTsTRGzxLwdkFI+oKJPJycM8BIx5lb33I935i2b/IYSf94odxUZtrOHPQcZw56DgmDn6QtfM2MvfrRXyVO4VFOX8xbddkRISRRbfw07R0vF7F3X/+yQeTfiYpsQBlb3bI9+nUqRlfLPy/o/kxaccwfcMthBUXlfHaI18SHRtBkxYH5tXYtCaN3KzC8ufRcRHkZ1u07dKkxsvWvs9wYA1JQM+DNAo/WDuHV99chN2wkV9cyoThBy63oxImg3cz2H19qUopCDsBgLz8ErKyi2jXJqXSOTkFJewtS8UebrF8zxouqhDve47oxroFm+jiX+jSbblwl3kQsXjrqU+xjIYA7N6TiyVR2O01PCxPO2bp3A4h7vrTXiJrbwGGzcDptGGzGzRpmUh+Tgn5OcX88tUSuvVrw7YN6QwaeRxX3nkKRQVlNGrWIKjlfunbP/hg5lKwfDfQoiMOPlVYKSc4Dpy2W1Lq5uJr3sXlNrnl2pM4Y0wPAHbm5LFhTyY561qT2HULDZ3NK513+WMTOHviWGISfP3Og5JG8Np1/6Nks4cCtxtHR4PkFBtX3Lmc9NJvaB5zVkDrrWkViQ6+oam4sIysvb7uBBHBGe5ASqFr7zaERzr4csocSopcREQ4+XTuQ+XnxcQFd1HKN7+ZywczlgEK7Ba3XjaAsb07V/t8EWHO/E2UlHowDMXeTN/PoMTt4cx3P8SyhJNHFONyWOxm6QHnxybuH4ebmZZPx8QTWZWxlaT2zcnaW8TePV7c9qWszFpM0+jTMPYl+tG0ANOJdUJUVEw4rTs2YsfmDK65ZwwnntKNzevS6DWoPTec+Qpi+W42zf99HW//+1uuvPMUnGHBDyQL1u8guV0WTbvuZUDsWC7uU/2UiiIm8+ZM47lXd2MYirNO68mlEwb6XkPKb7DFu3rjjnTRJ2HIIa9lek2uO+1FXGVeDEPx9J2n8/Z//8Tb+i/sDos8bxTqEB/TzUXr+GnPVwxPOZXOsT2qX/l66uXb32J5gz+JDYvnudteISys5pMeiQhS+CS4F6PinkM52tf4ewaSSOD6fJVS8cB7QFd88zeuFJGDj49EB9+AePOriZWe9/NPHT71/L68/+KPRMSEU1JQxoxpC2nXpSkjx/UKRjEreeSS0bySOhPsbrLD5wJH8NW+9DPCPP8BazhKhXHyiK6E+f+gRDmdfH71RWzKyGJkp3bYjQMTsu+zZn0aM39ehdvtG5pnd9jo1KExb7xwMU+uWcqUOSexfVEL8kfO48YzDuywnrrzXTJd6aSV7uCJbm8D8MuHf/LefR9zzu1jOe/OM6pfp3pg7u4/aDheIZLH7GV/MmJA5cVOV65Jxen/GQeMle3L94yFlLyPGfMAhe6NxIV1w1ChEF4UZuBGMrwCzBSRc/0LaVb59VYPNatB7jIvlgidujcnPNKBMhTtauEmW3W0aZzI8MajcCgngxJPOrKTVTQ9O+/l5ft+5q3nxxxws61tUgKndOmA3aj64/XAo1/wzYwVJPdpwfnXDuO9mXfhcPp+YW/v+BhFG7vg9diY/tfKg57fM97XWu8e3w+ALNde3nn0fbLTcvjkqS+PrE71QL+OA3xDsMts9Ozau9Jri5Zu565/TePWez5h45bDru1YLcWenWzO/wyvwzckUUWczdy0i5iffiWrsh4uP85rlbC94BNyS1ewKfdtVmc9jtcqqeLKtUtEVWurilIqDjgRmOy7prhFJK+qc0LhT1PImvbeH5hei4W/r+fzxY9gt9vqRJfDPuOaXcy4Zhcf8Xkq4jSwNaNzUgLK3uIfv3/Hdg1ZvHwHPQe05YobRlV6LdIezf3nj+bNb+ZyyajeBz1/bJPzObXxuaSV7uS9rS+wt2w3UVcWU/KaYtydJ2OJhVHFOOT65q7Hb8cUE5fHJLekDIAysxSFwjStfaO1sUyryuscinjWgusviDgHZUti0Z4bKfFuZzNhdGhwE22dvSn2bEfwkl70E5klc4l1dqbAvRa3lQeYgMLAgcKJx8ohMbwfzWLOrpUJRwetE0fU7ZCklKqYe3SSiEzyP24NZAL/VUp1B5YAE/1LCx2Uqkurtvbp00cWL64feVWLPTt4+ZV7mPt+K+ITYvjwzweD9gGrqyxLyMopIjkxuto/G1NMsl0ZJIU1xBKTM99/k6RWq4hvUIxN+fI+hBuRFJuFRNqiObvpJfROOOGYCcJey2LU6/8hs6iYiaO6sMHxIYaycW+nZ9i6Jp+4yG20a9sYcq8HoyEq8cNqJ0ey9vb2rWriHIJq8A4zt/fyrwXokxIxnHz3Gl/uDqqKK8q/WYBBo8jRtIydQEJ4T5Sq/npqSqklInJUyVGi2jeWLq8eItvU3ywe89Qh308p1QeYDwwWkQVKqVeAAhF56GDHg2751pis0nn0OmcjHYbu4sSOL+nAexCGoUhJOnT2sYOZtOVZNhWtoXeDwfSKG8Lm3SZmeDxx8cV0jevNGU0v5OUNjwBQYhbx8c5JzEj/nHxvLr3iB3Jhy+vr9b+Fy+slo7AYEWFT/hZIAlPK+C31Oka2bEScZxbkxoGVA1YeeDaCs3v1Lm5rCN6dYG8BCDYjHK9lsm+6eUbp74TbmhLn7Eq+2zd70aYiMKWU8lmSAAh2FYtX8gFhT8lM9pTMJMyWwonNvsZhHNln4mgFaLRDKpAqIgv8z6cD91V1wrHRHAiCxlGnkBjRnw4th5IcE/wbbPWBJRZbitZjismukm20imlDvx55FOU34PykB2gc3pxpuybTOroDqvwXSsj2ZOAVD4ty/6LIWxDUOhyp3zdu5dcNWw57XOruHBYt3U6kw8HjpzfkpOPWMq5THkOShtI6LJ1ItZHFBXOwxCLPW4Zl7wHhp4Kj+mvXqYTpkPAJK8oK+Wv3WfRIfp6UiCE4MOjt9HC8w4PLTPUHXoMoR1sMtT95kUEYDZy9satoTCmhUeSpONT+SUkeK49Sz+4j+fEcNfHfcKvOVuV1RPYAu5RSHf27RgBrqzhFt3xritMWT79Gb9fKe82asZKlczZx8S0jSWoYVyvvGQxppTuwxDcyosCTx3Pr7+fVkx+mgTORAk8eD69+Cqn0dVehlCLGFkehN58wI5yMsjRiHKHxM1qwfRe3ffE9AG+efwaD27Q86HH5BaVcdfMUBOH6K4bSsPdXjIlZTZ5nLh1iribS9OCxwAMs8jYj35tJotGAvknP8eveb9hVso2zm11GrCO+yvIoI5JSFc+e4h8RvGSVzqVHyrNk59xDovdXRCx2m5BtKQzloHHkaLLL5lPg3kCDsB7EhnWmRcx4/kwdi2Cyp2QmFbsnkiNOIMbZ8dAFqCEB7Hm9BfjIP9JhK1Blf4Zu+Ya4/OwinrlrKj9+sZiJ573B6sXbgl2kGtMwvCn2P5JIvQXy1haT78lhfcEKAKLtscTY4/92hmCKSZuoTtiVnTKrlG/Tp9Z6uf+pSKcDxDeWNtJ56Bu1IvvHVrs9Jk2iTy9/bVvhZFpEj993JIVmEYJFmbmXHHcm36dPY3neAv7I+KFaZYqwNyElcigR9qY0iz4duxFFSvy9GEYy2JpRRiLJ4SfSN+VddhZMI9e1DFNKcNriaRQ1ihWZ99Is+kyi7K0OuHZGyV94rLzq/ngCJhCjHXzXkeUi0kdEjheRcSJSZeYs3fINYd99Mp83Hv8au92G5THJySzk3sve5atlj5UP2apPHIaT1Q9m4Cnz4nTH0OWj1hwf3xdTvJSZpXSL78OcrJ8BsOG7cWNisjp/CQ2cSRR4cxmcWPM5lAOlW5NGTLvyAiwxSYhZQ6G7lBjngSt8xMdF8sYLF7E7PY8hA9uzIe+P/a85e7Ol4B3/M6Ft3NUoQ9E48mQctngSnQ3Jdu+lY0z1EssrZaN3w8pLRyl7C1TKX6zJ+j+KremUlM2mW9L/4a4Qe5pHn8+GnJfIdS0j17WCxpFjKT5ILmivVYTTVnvT7kWCN71Yt3xD2KJZGwDK8wcDoA5M3F6fDBjbG6UU4y89j5vbP0S4LZKn1t3Nv1bdQNPwFhwX2xOFgYVFn4QTiLRFYWJSahZzVas7iHU2YHuxb127Em8RK/IWUuYtDXKt9hMRckoXU+Lv++zYMAnDOY1lmXczN208bjO/0vEuMxsRi/ZtGzLshI7YbAZ2FQWAwkl8WFeo0P+9Jf8dWsVcQri9EXbDwQOdn+e57u/TMfboV/VoEXMeYbYUFDZWZD1Iw4jRmKbCsmDu1kdpEjUWQzlpHHUKua7Ko5qi7K3p3fAVIh3ND3H1mqOTqWtH7Lr7xhIR4aSgoIRlczYDMPCkztjs1R+uE2oe/uxOLMvC8E/gKPEWkeXyTRrYVbqVq9vcxWe7/kOGK40O0V1ZkDMLEIrNQt7e+jQ2ZccSk3BbFIhFiVVMjD2ufIZcsO3I/5i1uc8CQlL4IOxGNHtKfgQEQ1WeLrw+50W25r9PUsQA+jXyDTctcK1nV9F0AAQPe0t+o2K/qleK+WnHAGxGOEOafkG4PQVbgMJAXNhxJEcMIrXoK7LL5tE34XN++nkrXQduRIXvIiasPae08uX5yC5dwrKMO3BbuSgcNIwaTkrkiQEpx5EK1mhbHXxDWJOWSdz34gUAXDH6OfbsymHZvMPfGQ91RoWZc9+mTUVhYFM2xjQ6H0MZjG9xNQAf7XibioFHELziG5daYhayr0VY5N2f7jNYZm/ZwbtzF3Hx4KXgX6g0q2x2pWPaxl5DdqawfecW+vVuzd6SPwCLvLJV5cesyHwAl5mJwk77+JvYmOfrIohxdqHUuxuvlY9FGZblYmve+3RJuidgdRARPFZR+XPlyKN//yYUuwpp1KA7sc79iZsSI3ozsuWfFHt2UujeFLzAi8KqgUTp1aGDbz2Qui2TgtxiDJvijIuPrZUcLDFpbHcRazcqjWIQEfLdOQAYGLSO7MCWkvXlrztVGKc2Po8luXM4KWVsrZf77x767mfSCgrZm9+E28aGY+GboZa6OZmMtES6D9xKvGMwl177Ps3a72R7QSxxbbcDEGZL5sft/UiKGIwlbkDRMHIEDaOGlwffEvcOHLY4vOzrthB2Fk7FWTCKj19czZBTujH8tB5HVYctee/5W9o+K7Luw+XIxO6w07vxcwcdXx3laEGU45/PkgyEYE0zq/Hgq5Q6BV/CCRvwnog8XdPveaxZMnsjpSVuxBK+/XgeF980ol53PVR0ftOTMbLfQGGA6ycIPxmA9LJUNhStBsCmHOwq3V7pvM5xPTip4VhOahj8wAtwcsd2/HfhUnJ+2IM1qBk02IwIfDV5KK6SSGylvehy3jouuedTYhOKUMqGw4jDaxUieDGlhL0lP5dfL8rRmgh7U6IcbSn2bMWkBNN041DxeMQXgO1GFB8+v4AFv+5g/u/rGDrm+ErfKo5UoWcDFSdSuMwMwCAurEvdndgSxBtuNRp8lW+u4BvAKHwzQBYppb4RkSoHH2tHZujY7nw2eRY5mYV4XF7KyjysWrSRjt2a0eAIZ5CFGodSCDZAgey/ceY0wtgXCEzx0CW2BxuL1uC1vFiYZJSl4TLLCLNVf9n7mnRDn178Me4dEGHvyL40PGsblmnRtHUG0fGl2BOy2VDwCfHJAgKGMuiceA+JYb1xmVmsyX6SSHtr0kt844K35v+HQvcGXN4M9v0cHEYMgxp/RLg9Ba8UYVeReIasYuGvO+nev81RBV6ALon34zSSSS/+Ho9VQNPoM+mYMBGnUcfHVQep6VujuR2UUgOB/xORk/3P7wcQkacOdnx9yu1Q24oKS3nilg+xO2xEx0Yw77d1xMZH8sHvVc5wrBfEvQSsLAgbXd7C2lG8hZc2PlRp0sW4Jhfze8b35HtzsWHjmrZ31ak8wAu+X8LGpVs545aTmJM7DBD/zSDf1Fxf1RTxzh50S/o/YsIOHHZW5N7GnLTxWOJBoRAsBG/5661iL6VLYuV+Xo/bi91hq7ut00MIRG6H8LZNpfnTN1Tr2M3nP3TU71dRTXc7NAUqLpWbCvSveIBS6lrgWoAWLYLb9xPKtqxJY9WibViW0CApGrEEr9t7+BPrAeU8MOtZi8g22JUDj7jL920qXEuhf3pxtD2WNlEHXw05WPqP7U3fMd2ZnXouvltBTgxDYYmrwlGCKW5+z1qAx/qLM5peiMPYP4U32tmak5r/Qok3jQV7rsASD1G21hR5NwGKxIh+B7xvfRwTXl0CWFY97HaoDn9Ktknga/kGuTh1mmVZ5GYVsXbpdj59908uuGE4JYUu5v26ln4ndsTyr5qRm1VE++Oa8uArFwW5xMGjlOLsZpfyZ8ZMYh0NMJTiopY38GfmDHaVbmN886vqTJdDRR6rgGLvNkDRPOYs2sVfz7y0Syg1dxPtaIvHysdwnMys9B8BaBnVjj4JJ1S6hsMWS5wtlhHN/wAsDOXE5c3CbovBbgR3+ao6R4D62OcL7AYqjppu5t+nHaHsvQVcMvwpRMBmMzBNiydu+aj89bXLttO+a1O2rE3DZjfo3LMFDZsGd4HOYBuUNIJBSSMq7RvT5LwglaZ6wmwJdE64l1zXUtrFX0u4PZkTm39DmXcPkfbmKKXIc2fz7d65WGLSPLL1Ia9lM/aPCw53NKyN4oek+jrOdxHQXinVGl/QnQAcel0Z7ZCWzdtU/iGxLAuH04bXY5bvK8wr5foHTqfviZ3YuSWDDt2aBa+w2lFpFXchrSr8mtiUs9JwrHhnIk92exsRsBtB//Ia+oIUfGt0dLGIeIGbgR+BdcA0EVlTk+9Zn5SVuNm0ZjemaTFsbHcio30tmZPO6Mm0+Q8zaHRXnGF2DJuiQXIM3fq2ISomnM49WmCz1d2Z46mZeWTmFx3+QO2gLEt49/tFvPDZLErdnsOfoFWhekl1amI4Wo3/2RSRH4DqpUzSyqVuy+S28W9QVurh5HP6cMv/nVWew2HHpr1cOeo5iovKeOGj62l3XNMgl7b65q3Zzm2vfknUpkImnNaXa24/JeTusgfbsi27mfLTYkSEDk2TOeuEo8/LcEyrjy1f7Z/ZvT2L609/meJCF6bXIm2nb6bWTQ+dQafuzWnVoRG52UW4XV5mzVx1mKv9M0t/WcmimcsOe9yWtCze/m4ur345m1JX1a2w1Mw83p2xEEdqMc49pXz7/hy2b9xDvmstJZ7UQBW93mvVsAHhTjtKKbq01H25R0VALFWtLdB0h1EdtHV9OspQYEJMXAR3Pe27STT6nL6MPqcvf36/gt++XQYCw8ZWcwmYI7B69joeHPcMrgaR3PjvCzn3kuEHPW79rgwue3YqHq+JzVDERYVz2eiDD4MsLnMz4ckPcbk9GHFOUMXEJkRB/Armpf8LhTAkPILw8P6ouOd1a7gKibFR/PT0tZiWEH4MDxMLnMB81pRS24FCfCuFeg83Jlj/y9Wi+Yu2sm1HJmed1ovw8EMnxx5wUmdOv2gglmlx1V2n4PhbIu2hY7uT3CSe2PhImrVODng5HWEOske2x5scwwuzllYKvh6vyfa9ubRpnEBJmbv8q5NC0bF55bKYloXNP2vKsiwsS7DZbKgkOzlDnTxw3enYI5dDKYh48FqFUPY9xD4IKiHg9apPHHYbdWcd7BAX2G6H4SKSVZ0DdfCtJdk5RfzriS8REUpK3Vx1yZBDHutw2rn23qpzDnTpefAlZQKhY992OJol4PV6CYuqPBb2hlc/Z9XWdE7u05HHLj+Fu8cPRyyL4T3akRAbhYjwwvQ/+WbuGorK3Nw7fjjjh/UgJjKcKfdewOINu3j5y79AKdanZjLk+HEYOHBSQnTZf8HZF9SxPUROq2X1dKiZ5hcR4SQi3EGpy4MrGopcLtamraZhbHNaJqYEu3gHmPrIpXw/fy1nDupaaX9qZj6mZbF9by6zV2/j2Wm/YzcMhnZvx8bUTN7/cRE/LdmI5R8D9/PSjYwf1gPLEqb+voxNu7O44bQB5BSVcuFJvqXCm8ac4bt4zITarqZ2rDuySRZJSqmK+Q8m+SeJVbzaT0opAd7522sH0MG3lkRGOPn4vWu566sZvLVuGQW2adze+2f25kSTH/EHcZHRwS5iJc2T47n+9APTU75+81n8unwTpw/owuzV20HAa1oUlJTxwOQf2LonBwU47TY6Nk/m7vOGAbAzI5dv56/FNC36dmzOHecMrdX6aNqhHMEki6zD9OOeICK7lVIpwM9KqfUiMutQB+vRDrXI493CloxVeLxe2salopTQMKoIU+rGMjaFJWX8tWrrAaMWTNPivMem0Peml9mRkct1YwfSJDGOswZ35bLRfejcPIVP/1jOca0aAb4//zZDMeWeC+jY3Neqb5ocR892TUmMi2J07w61XTVMq5TZu8/nl53DKHRvrvX31+owS1VvOwwR2e3/fwbwJXBgIo0KdMu3lpR5PZz10zTS48M5vekGCt03sMv1C46I/rSICvxNsyOVW1TKOY9OoajURb9OLXj95rPKX5vy82K2pPuGu02ftZIhXVvz9dw1tGjYgBVb0lixLZ0V29IZ3acDKfHRZOQVEV7hJuGvyzZR5vby9sRzgjaKodCzmSL3ZgSTjJJZxDjbBaUcWt2jAtDnq5SKAgwRKfQ/Hg08VtU5OvjWkrTiQtLKIjENIbxBOBcOPYlw5+hgF6vcW9/MIa/I1wLfnp7DhCc+4LLRfRndpwP/mbmw/LhT+nbk49+W8fZ38wA454SuLNywC6WgUYMYmiTGkl9cSouUeCxLWLE1jYf+OxMURIQ5OKlHcIJenLMLjaPHsGZbHk9+Eca5Q9Yxpl/nw5+o1W9CoG64NQS+9Dcu7MDHIjKzqhN08K1BBYWlTP96Cccf14zePVpy8/GD2JCzndsG3lDnxmc2S4ovf5yW40u7+OB/Z/Dkx78Q7nRQ4vJgKEXPdk1ZtW0PKHDYbFx32iDOHdqDguIyWqY04Pnpf5AcH8W4gV0ZNPE1EmIifDl1RdEgOiJItfMted49+Qmen/wxa3bsZcPOX3Tw1fAl4T/6b2MishU4okH3dSsC1CPrNqbz8JNfkZVdhGEovp82kYk9hwCHHmIWTBOG9+D7hetIzconMsxBdkEJAKUuD6cP6ExcVATp2QVsTc9hbP/OtG+aREJMJLFR4cT6h6O9+tVf/LDQt07a5t1ZeEyTPblFOGwGN54xkJ7tgj8N+rQBXVi/K4ORQeh31uooPdSsfnnu1ZlkZPpWxU1OjMHuqNtrqjkddj791yWA7wbbym1pXP/y53hMi/nrdzH0+LbMWLSBmYs3MOPf19Ch2YH91F1bNCp/vGNvLg3jY9ibW4jHtHjtqzmMH9Yz6C3+8cN6MH5YD7yWlyU5c2ga0ZJGEToD3DHNCs7b6tEONWTIwPYADO7fjinvXIm9DmcZ+zubzaBnu2ZcMrI3YU4bx7dtTLsmiSgFsVHhRIY7D3rerqz88seGUnRr3YjYSF+r2GYo1u/cWyvlr0qmaw8us4xv0j7mgx1v8sz6e1mSO5c8/0rH2jFm3zjf6mwBplu+NeSKi07govMH4HSE7o/4ilP68c6SxUzdtpYd7gK+euwK4iLDMS2LV7+aTbvGibRtkojHtOjcIoW/Vm0tP9e0hF+Wbir/o+MxLa56cRqv33wWA7u0Ckp9/sr8kS9S/wdAvCPRv74ZfLj9TSLtUTzR9W2dU+IYFIjRDv9E6EaGWuBye9mxM4s2rVPKg4iIkJ1TRHR0OH/8tYHmzRpwXKeD92WGcuAFsETw2H2fzG15eTROiAXgne/m8eEvSwBfC9drWlgitG6UgFIKkf3LVqbER5MYG8XKbemIwJRp8/ioaA733HYKLZol1mp90kp2Yfm/Y+Z4Msv3W5iUekt4dv29mGJxTvPL6RjT9VCX0eobHXxrV0mJi93pebRrk3LI1s6dD05j3YY02rZO5vabRtO5Q2OeevEHfvl9LSkpsaTv8X3N/r/7z2D4kLq1GGMgxESE8cSYkXy1ci0PjtmfXKdT8xQUvqFjLo9ZPpV4254cHHYDj9f33K4UD140kk7NU7j02U+wPBYbFqf6php/voh7Jp5Sq/U5MeVk5ub8CoDCAARB6BDdlS3F60kr8631+t6W5zkp5TRGNToTu6HT12g145gMviLCVbdMISurkPPG9eHaKw4+1XXrtgy8XosNm/Zy4+0fctH4AaxZl4ZpCbl5JeXHfTJ9Qb0MvgDn9u3GuX0rJ+se2r0tP/z7aiLDnazcms7kGQtYvDGVnu2a0jA+mpmLN2Aoxf0XjmBAZ18CoG8euxLLEu761zTWb0xn5LDaH+YV79zf0m4S3ow8Ty6lZjE7ijdjiheFgelRuB0uZuz5nKW5c3mgywu6K6Ke090OtUjEl2XMtITd6XkHPcZrWpSU7l923BLh488W8MS/xvHNjOUkxEcxZ/5m8gpK2bBpL3n5JcTHRbJ+YzpLV+xkzOhuxMfV35ViE2OjAOjfqQX9O7XA7fHisNvYmp7NprQsurZqxLjBlb+6G4bixX+PD0ZxAYiwRXJ3x6fZUbyZAUnDmJn+OT/t/QqXlKFQ2JWdLYsb0rLPbnJTY1Ct03l0zS1c3/Y+PSKivhKqNXW4JhyTwdcwFK88cwHLVuxk7MnHH/D69p1ZTLz3E8Kcdspc3vL9pmmxYMk25i/ailKK5KQYKChFKV9rWkS49d5PcLm8vDtlFm++eDGdOzSuzaoFzb7+7bZNkvjsoUuDXJpDaxbZkmaRvtZ47waDWJI7hzhHAl1ie/Brxre4SpzMm9KLRp0ySGqdT64nmyV5cxkbcX6QS67VGN3yrV2dOzQ+ZGBcsHgrhUUuDAUD+7Vl0dJteL2+GzVffbdvaR1hYL+2GAp6dW9FRLiTSe//icNuw+XyYlnCMy/N4P23rqylGmlHqlFEMx4+7hUAirwF7CzeQunwRchJldc2KPOWHPwCWr2gux3qkFHDj2PB4m00TI7lxquH8f1Pq9i0ZS/rNqZT5vKQnV1M356t+HbGCpxOG1dcfALfzVzBZ18uwRILp9OG222yMzWb1et207Vz8Gd2BULGzkxeu3kyXQZ15IL7zjr8CSHkxQ0Pke3OAONgi8roPt96TQff2rV9ZxY5OcX07N7igBsqCQ2iyvsmS8vcfPzZfAoLXb574+Lrtli2chemaVFWZlFW5qFN62Q8Xt/qwuHhNrxeC9MUfvljbb0JvtOe+5oFPyxl0cxljL5sGImNG7AxNZN4f86GuKhwwkJ0eJ3HcrP/t7Dy5yHHnXnA8Vo9ooNv7Vm5ehd3/msaIjD+7L5cc9mJBz1uweKt7ErNJr+gDNj/K2lZgt3umwnWpVMTUpJjSUmOxeGw4fGYFBe7SUmOQUQ45/TetVSrmjfwjL58P+kXwps2YMKLUxk35Hg+/GUJHq+JJZASH8V3T1wdUrP59pnY/mHW7T6Prwua4ME3FTwlrAnhtghOaXxOkEun1RQlutuhVsxftJWvv1/GwiXb8Jq+Ptypny+kU4fGHNepCQkNosqPXbkmlYee/AoRwen0tWRPOrEjv/zhSxzTrnUyN1x9Ep07NOZ/n8xl+apd3HbDCD77eikJ8REsW7kLQykiIw8+FTcUNevThu5vXMJPSzZCURm/LduMx2th+T+8mXnFuD1e7LbQq3NSeGNOaPYUtowv+SGviAhbNJe2upnmka2DXTStpunRDjWrsLCMBx//ovzG2T6WZfH4M98iwMtPT+C4Tk0ACA+zg/hW5X30wTNplBJHSnIM23ZkU1BYxkXjB7Jg8VbCnHb+8+FsRCAzs5D/vn0lK1ftYvW6z2nfJoW4ejTc7J3v5vPz0k3luXt9CxPvbzZccFLPQ+Z9CAUqbAiDmg9hUPNgl0SrTbrlW8PCwu3ExUSQnVtcaX9khBOP10IJ7ErNKQ++Hdo14q2XLsY0LTq025+t6z9vXMHX3y/joSe+wrKE2fM30ahhHOl78knbm8fa9Wn06tGSn7+6o1brVxsGdmnB1/NW0yQxliHd2jD19+UYhqJLixTuPHdonUgZqWlHLIDBVyllAxYDu0XktKqOrXfBV0RYsXoXDVPiaNwwrny/02Hnw/eu4YY7/sf2Hb4MVoahOGFAe7p0bkpRcdkBs67atj74qsKTP5iN5f+uvWNnNqeO6kZJyWZiYyNo2zr4SwLVlPU7MzGUIj27wBd4laJJQiyT7zw/ZG+0ace4wPf5TgTWAbGHOzDkf2NEhDXr0li1NpX1G9PZtiOLXbtzAMXk1y7H7jAID3NgGIrHnv2OiPAwAFo0SyB9Tz6/z95A/z5tOHNMjyrfp7CwjOISF40axnHBuf2Y8skcSku9iMCevfl8M/WWmq9skIgIz376O5/+uaLSfkuEtOwCLn3mEybfeT7REWFBKqGmHYUABV+lVDNgLPAkcNivviEdfFeuSeXd92exam3qQZZ/Fq6+dQqmaWEo6Nu7DavW+JK6GIZid3oepmnhULbym29/Z5oW2TlFOJ12Lrr6XcpcHo4/rhmbtmbQMDmO7TuzAejcodFBz68vsgtKmP7XyvLnNkNh+lv+lgibdmdx0VMf8fDFo+ndQU/D1UKLqn4y9SSl1OIKzyeJyKQKz18G7gFiqnOxkA6+dzzwKR6PWWmfUuBw2HG7vYjsCxCweNl2oqLCKCws8wdgcDhsXHnxCYwa3uWg17/3keksXbGTEUM74XJ78Xotlq7YCfhawp07NCYiwsHlF51QsxUNsoSYSIZ0a8Oqbencfd4wXvnyL9JzCisdsyszn+en/8EnD1wcpFJqWo3LEpE+B3tBKXUakCEiS5RSw6pzsdAbkFlBxbkRhv/xGaf2wOuf7NC8aQKtWvpWYIiOCuN/b1+FzT8GNSLcwR03jeaUkV3ZnZ5XHqgr2rh5L6ZpsSs1h/vvGENYhSVwBvRtw9svX8JLT03AWccWwww0w1C8eP0Z/PDvq3nusz/IyCs66HFDj29byyXTtACQam5VGwycoZTaDkwFTlJKfVjVCSEdNS48tz/vfzwXoHys6ZwFm8sD6fAhHRk1vAvX3Po/RIR/PfElpr+LobjEzTMvz8AwwFAGp47qxl23nlzp+v9+5Gx+/n0t55zRixbNEunbqxX//XAOlgjXHSINZX1mmkJhieuQry9av4vrTxtYiyXStKMUoBtuInI/cD+Av+V7l4hU+TUwZIOvy+vlxJM7oxT8b+o8TNP3E+zSsTErVqdSWuahuMTN86//REmpG6Vg7fo0wNdK3hesLQssLDZtPXB9sa6dm1aaGhwbE8HEG0bWfOXqqHCnnXduP5elm3bz7g/zKXN7sduM8j7zpsmHvcGraXVPkMb5hmy3w/n/mcqZ737InmSTyy4chMNhw+mwMXhAeya9eik2m+KzrxazfKWvj1YELrvA1yqzBOLjInA4bAzo05oJ5/TjoXtOD2Z1Qkb3Nk244uS+tGqYAPjyHndv3ZgLT+rJQxePCnLpNO0fCEy3w/7LifxxuDG+EMIt3525eZiWxeasHO69YBxxMZEU+sfqLl2xs3wmm2EoGibHYnfY6Nh+fwpJt8fE4zFZvjqVZx47L1jVCFmXjuzNA/+dAYDLa3LXecOCWyBN+wcURzTaIaBCtuX7/sXncP0J/Xny9FEopRh3Wk+8LZ2c/9+pGElOzhjTg5HDOvPJ5OvIzC5i564cPv1yEbdcN4JRw7tw582jada0AVdfOiTYVQlJA7q0JCkuiging/svGH74EzStLpL9yXUOtwVayLZ8uzdtTPem+1uyIsKzv/yFJcLrs+bx/nXnlr/Wq3sLFi7ZxqB+7Tj3zP1ZxkYOO3CI2eyM9Xy47S+ubDecfontarYSISw+OoKfnr422MXQtKMXirkdlFLPAacDbmALcIWI5Plfux+4CjCBW0Xkx6Mr6mHLwtnduzBz3SYm9K68NNAzj56L2+0lLOzwK9H+e82XZLkKyVidzxdD76qp4mqaVleE6A23n4GuInI8sJH9Qy26ABOA44BTgDf9CSdq1JOnj2bJPTdxSpcOlfYrpaoVeAFGNz4eA8WpTXrUQAk1TatrQrLbQUR+qvB0PrDvu/6ZwFQRcQHblFKbgX7AvKN5v9pwW6exTOw4Ri8XrmnHihBt+VZ0JTDD/7gpsKvCa6n+fQdQSl2rlFqslFqcmVk3lmvRgVfTjhHiG+1QnS3QDtvyVUr9Ahwsc8yDIvK1/5gHAS/w0ZEWwJ+YYhJAnz59gvQ3SNO0Y1ZdveEmIlVO6VJKXQ6cBoyQ/QkSdgMV1wNo5t+naZpWpwRrJYuj6nZQSp2CL4XaGSJSUuGlb4AJSqkwpVRroD2w8GjeS9M0rUYEeIZbdR3tON/XgTDgZ38/6XwRuV5E1iilpgFr8XVH3CQiZhXX0TRNq301FFir42hHOxxyFoKIPIkvo7umaVqdpNALaGqapgWFDr6apmnBoIOvpmlaEOjgq2maVssCNHVYKRUOzMI3AMEOTBeRR6o6RwdfTdOObYFp+bqAk0SkSCnlAGYrpWaIyPxDnaCDr6Zpx7RATB32TzDbt7Ksw79VGdZDNpm6pmlaIBxBVrOkfXlo/FulhNZKKZtSajmQAfwsIguqel/d8tU07dh1ZJMsskSkzyEv5ZtI1kMpFQ98qZTqKiKrD3W8bvlqmnZsC/wCmnnA7/hymR+SDr6aph2z9s1wO9pk6kqpZH+LF6VUBDAKWF/VObrbQdO0Y5qyAjLcoTEwxb9ijwFME5HvqjpBB19Nq6PW52TisBm0jUsMdlHqrwAl1hGRlUDPIzlHB19Nq4Pm79nJpT9+hlcsnhg4igs79gh2keqtkMznq2lazShwufBYJpYIj8z7hRt/+4q0ooJgF6t+ClI+Xx18Na2OyXeV8evOzbTzdzd4xOKHHRu56pfPcZs6LXagheTqxZqmBVZOWQlDp0+i0OPGBthQmP5m16a8LH7Yvp5xbY8LbiHrG93toGna0r27KfF6AF9MMP8WGZ5a9CcdprzAx+tXBKF09VAQVy/WwVfT6pCZOzchAgYKhSrfrwARYW9pEW7L5KH5P5HvKgteQeuJQI3z/Sd08NW0OqRpdCwOm4FSlVu90Y4wKvb2xjrDCLPpXsOAEKneFmA6+GpaHXJbj8G0j0/C/Nsve6HHVel5Yngk4XYdfANBt3w1TUMpxbb8XABiHM6D/oIaSuHSox4Co7rDzHTw1bT6792RZ5EYHkGhx40F2JWv71cBbWITuK/3UD499YKglrE+CdYNN/29RdPqmEGNW3Jd1/78e/EfGIDDsOE1vcQ4wvj17KtQSh32Glr11URgrQ4dfDWtDrq2Wz+GNmvNiqw9ZJcU886ahdx8/EAdeANNqJGbadWhg6+m1VEdGyTTsUEyADd0HxDk0tRfOreDpmkH2FmYx96SwmAXo34L0g033fLVtDpIRJi8ZjHPLpmFoRTfnH4JHfytYC1w9k2yCAbd8tW0Omj65tU8vfhP3JZJmenlopnTMK0g3Rmqz0RQVvW2qiilmiulfldKrVVKrVFKTTzcW+vgq2l10Oy0bXhlf7DNKStmyrqlzE3bEcRS1VOB6XbwAneKSBdgAHCTUqpLVSfo4KtpddDivbsrPY8Pi+SpRX9w+c/TySgpClKp6qdAzHATkXQRWep/XAisA5pWdY4OvtoxYd62nfy+cSsSpGFFR6pD/P7+XQPI95SBgjCbnXC7I3gFq28EsKR6GyQppRZX2K492CWVUq3wLSm0oKq31jfctHprS2Y2U5espGOjZB6f8TsoeOnsMcSGh9EyoQHJ0VHBLuIhpURFA77A2yYukaSISG7rPphXV8zlopmf8t7Is2gYGRPcQtYX1f97nCUifao6QCkVDXwO3CYiVS49ooOvVu+UebykFxQycfp3bMrKAXxBzAKenPkHGUXFRDjszL79Wpx1NDnN/PSdgK/MOwpyubhTd+bu2cGCvbswRRjz9RRmnHk5KZHRwS1oPRCo0Q5KKQe+wPuRiHxxuOPr5idP046AiDBx+vfM37GLx8eO4LEZv5NfVkarhPjyY/bdukrN9zVG3KbJi7/OZkKf7rRKbFD7ha7CJxtWsKMwr/y5RyyeXTwLC8qznWWXlfDD9g1c3qV3cApZjwRi6Xjlm3o4GVgnIi9W5xzd56uFvGK3m5/WbyK/tIyHv/uVrOISPKZFpMPB2C4dDnne+wuXcc7kj7HqWD/w9E0rD9gXHxaBUgpbhSQ7JzRpWcslq4cCl9VsMHAJcJJSarl/G1PVCbrlq4W86LAwTu7cnt82bq2U49Zpt3N+7+P5deNWvJYFCN4KrRxDKZw2WxBKXLXRLTuwJDO90r5+jZrzQN9hFHncLM9Mp118Au3ik4JUwvrDN8ni6P/4ishs/+WqLSDBVyl1J/A8kCwiWf4m+CvAGKAEuHzfMAxNqwmr0/fiNk32FPmGYSnggj7dGdCqOVMuORe7zSDGA9dd/CxZDRy4+jfhhbNPpUfTxhh1LFnNpZ17sXBvKov2ptImtgETOnRnfIfjUUqRArSJSwh2EeuXUM1qppRqDowGdlbYfSrQ3r/1B97y/1/TakR2cUml5zbDILekFIAezRoD8O59HyLzUklUcM8DFzOiU/taL2d1RNgdTB55TrCLccwIRMv3nwhEn+9LwD1U7hU5E/if+MwH4pVSjQPwXpp2ABEp//CF2Wx0TEliZIe2nNGtU6Xjjh/SGWUokpsmcsLxdTPwarUsVFeyUEqdCewWkb+vY90U2FXheSqHmO2hlLp236DlzMzMoymOdoyasXYjlgh2w+CFs0+loMzF/B27mL1lB5PnLaawzLf+Wf+xvfki679M2fQaYRFhQS61VjcEJrfDP3HYbgel1C9Ao4O89CDwAL4uh39MRCYBkwD69OlTt247ayEhyunEQGGKxWMzfyejsBiAO774AZthMG/bTjKLitmWnccVA3px+/DBQS6xVqfU1W4HERkpIl3/vgFbgdbACqXUdqAZsFQp1QjYDTSvcJlm/n2aFnBD27fmg0vPI9LpLA+84BvNIAhzt+xg/d4sXF4v05auCmJJtTpHgreG2z/udhCRVSKSIiKtRKQVvq6FXiKyB/gGuFT5DADyRSS9qutp2tFokRBP49jKs71MEUxLUIZvNINNKR4YPTQYxdPqMpHqbQFWU+N8f8A3zGwzvqFmV9TQ+2gaAB8vWs4W/1TivzOUgV1ZxEaEc3q3zrVcMq3OC1JnZ8CCr7/1u++xADcF6tqadjh9WjY7YJ/DMPBYFpYIwzu04faTBvPtqnU0iIzghLatar+QWp2kgpSkXk8v1uqFfi2bccdJJ5RPv3XabEy6YBwxYWEYSnFOj678vnErd301k6s+/pL523Ye5oraMUHwTbKozhZgenqxFnIsEYpcLmLDwyvtv3xAL+LCw5m/fQfdmjRmYOsW/HrLlRS53DSNj2Xutv2rQOwp1AnJNVBI0CZZ6OCrhZxL/vcZS3elcfeIIVw5cH9WL7thcF6vrpzXq2v5vriIcOIifEH69uEnkJpXQIOICE7v2umA62rHKB18Ne3wpj3/NTsn/4JxamvmbN1RKfgeTqTTwVvjz6zB0mkhSQdfTataflYBk+//mHBL6NaimIceHB7sImmhbl+fbxDoG25ayIhuEEX7Xm2w2Qxun3j2AUnQV6Xt4emf/iQtf//qLaUeD2Ueb20XVQshyrKqtQWabvlqIUFE2FVcwAtzH8ehDAyjcrvB7fVy/n+mYonw84bN/HrLVWzNyuGc9z5GKfj62otp3iA+OIXX6rDATaBQSv0HOA3I8M8CrpJu+Woh4YWlsxn1xWTGffvBAYEXoNTjLV+Z2GHzvb4hIwtLBLfX5MNFy+vcihVaHSAEcobb+8Ap1X1r3fLVQsLXi9ZhZNrYWpCLiKD843m3ZuXwxYo1rE3PICk6iuMap/DMGSdjWhYfLFyG17KwxGLqklV0adSQM4/XM9y0vwlQj4KIzPIvG18tOvhqdZqIsCwzndICj+95CcxO28GQpq3YW1DEmZM+xG2a5ceXuj3ER0awt6CI5bv3YFoWBr48Dw0iI4JUC60uC+Vk6ppWY95ZvZALZ06lNN6NhAtWA4sVWb4cTW7Ti7dC4I0ND2Ns145sy85l0c5Urujfk84NkzGUwmua/LJhU3nXhKaVq363Q9K+3OP+7dqjeVvd8tXqtKzSYkQEb7hwz+AT2VWYz6WdewEQ6XSCUiDCiA5tmLd9F4/P/B0RwWYYjO91PDcO6c8t078D4NOlqxnZsT0ntmsVxBppdYoImNXud8gSkT6BemsdfLU67a5eQ2gV24DjEhvSM7lJpdcyCvYvlum02Shxe8pf81om05etYm9hEYr9iavembOQ27/4nlfPPY3BbfTS6xp1N5m6pgVTuN3BxZ16HhB4AbZk52A3DAT4ZcMW7IaBAuz+m3ElHi8/rduEUorY8DBeP/c0luzcTZHLzRcr1tRuRbS6K0CjHZRSnwDzgI5KqVSl1FVVHa+DrxayTu7cnoGtW2AohQJuOXEg71wwjuTYaBKjIrEp5ZvAJEJhmYsf12/mxhP7c3yTRlw7qF+wi6/VBb4PSPW2w11K5AIRaSwiDhFpJiKTqzpedztoIcths/HKuWP5949/UOb1cmn/Htz2+fek5xcecKxSipSYKG4dOohbhw4KQmm1uklAgjO/WAdfLaRFOBzM2rKd3JIyPF6LFv5ZbBX7eU9s25Ir+vemY6PkYBVTq6uEI7nhFlA6+Gr1hCAIbtP09QOLhYhv/Pz87bvYlZvPjtx87h05hMsHVD8TmnYM0DfcNO2f+b9TRzC+1/FcPbA3Xyxfg9eyMAXfMDQAFNtz8xAR5m/fFcyianVRPVtAU9NqxZ6CQiZ+/j0e0+R/C5dVes2mFDbD4PxeXRnUqiW/bdrCDUP6B6mkWt1UM4G1OnTw1UKazTAwFAdNmtMxJYlx3btwUd8eGEoxolPbIJRQq9ME0AtoatqRiw1z0rlRcqUPsoFvSaGNZhbPbZrFrsK8IJVOCwlB6nbQwVcLWaUeDyNe/y9Ld6VXTkylYMLA4/FEmrhMk6WZacEqolbn+acXV2cLMN3toIWs3JJS8kpLUfiGlln+/7dJTOTGAf0pW+7BZXo5pWWH4BZUq7sERI/z1bQj0yQulkfHjGDtnkyWpaaxOTObwW1ali+S+eSg0UEuoRYSqjF7rSbo4KuFtHN6dOUcoNjtZnXaXno2axzsImmhRo920LR/LsrppH+r5sEuhhZqRII22kEHX03Tjm265atpmlbbBKmwGkpt0sFX07Rj176UkkGgg6+mace2IA0105MsNE07ZgkgllRrOxyl1ClKqQ1Kqc1KqfsOd7wOvpqmHbvEn0y9OlsVlFI24A3gVKALcIFSqktV5+huB03TjmkBuuHWD9gsIlsBlFJTgTOBtYc6oU4F3yVLlmQppXYE4FJJQFYArlNX1ff6Qf2vY32vH9R8HY96+elCcn/8RaYnVfPwcKXU4grPJ4nIJP/jpkDFZNGpQJX5S+tU8BWRgKzzopRaLCJ9AnGtuqi+1w/qfx3re/0gNOooIqcE6711n6+madrR2w1UnGLZzL/vkHTw1TRNO3qLgPZKqdZKKScwAfimqhPqVLdDAE06/CEhrb7XD+p/Het7/eDYqCMAIuJVSt0M/AjYgP+IyJqqzlESpHnNmqZpxzLd7aBpmhYEOvhqmqYFQb0MvkqpO5VSopRK8j9XSqlX/dP+ViqlegW7jP+EUuo5pdR6fx2+VErFV3jtfn/9NiilTg5iMY/KkU7RDAVKqeZKqd+VUmuVUmuUUhP9+xOUUj8rpTb5/98g2GU9Gkopm1JqmVLqO//z1kqpBf5/y0/9N6I0v3oXfJVSzYHRwM4Ku08F2vu3a4G3glC0QPgZ6CoixwMbgfsB/NMYJwDHAacAb/qnO4aUfzJFM0R4gTtFpAswALjJX6/7gF9FpD3wq/95KJsIrKvw/BngJRFpB+QCVwWlVHVUvQu+wEvAPfhyZuxzJvA/8ZkPxCulQm69GRH5SUS8/qfz8Y0lBF/9poqIS0S2AZvxTXcMNeVTNEXEDeybohnSRCRdRJb6HxfiC1BN8dVtiv+wKcC4oBQwAJRSzYCxwHv+5wo4CZjuPySk61cT6lXwVUqdCewWkRV/e+lgU/+a1lrBasaVwAz/4/pSv/pSj0NSSrUCegILgIYiku5/aQ/QMFjlCoCX8TV69mWgSQTyKjQW6t2/5dEKuXG+SqlfgEYHeelB4AF8XQ4hq6r6icjX/mMexPdV9qPaLJt2dJRS0cDnwG0iUuBrHPqIiCilQnLcp1LqNCBDRJYopYYFuTghI+SCr4iMPNh+pVQ3oDWwwv+hbgYsVUr14x9M/QuWQ9VvH6XU5cBpwAjZP0g7ZOp3GPWlHgdQSjnwBd6PROQL/+69SqnGIpLu7wbLCF4Jj8pg4Ayl1BggHIgFXsHXvWf3t37rzb9loNSbbgcRWSUiKSLSSkRa4fua00tE9uCb5nepf9TDACC/wte9kKGUOgXfV7szRKSkwkvfABOUUmFKqdb4biwuDEYZj9IRT9EMBf7+z8nAOhF5scJL3wCX+R9fBnxd22ULBBG5X0Sa+X/vJgC/ichFwO/Auf7DQrZ+NSXkWr7/0A/AGHw3okqAK4JbnH/sdSAM+Nnfup8vIteLyBql1DR8uUO9wE0iEpxVAY/CP5miGSIGA5cAq5RSy/37HgCeBqYppa4CdgDnB6d4NeZeYKpS6glgGb4/QJqfnl6saZoWBPWm20HTNC2U6OCraZoWBDr4apqmBYEOvpqmaUGgg6+maVoQ6OCraZoWBDr4apqmBcH/A9gH0lXxppQbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "mapper=UMAP()\n",
    "embed_attentions=dr.fit_transform(attentions)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "scatter=ax.scatter(embed_attentions[:,0], embed_attentions[:,1],\n",
    "                   c=cluster_labels_train,\n",
    "                   s=3\n",
    "                  )\n",
    "\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLDL without Feature weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = train_data.shape[1]\n",
    "n_attention = 10 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=40\n",
    "n_attention_out=1\n",
    "n_concat_hidden=128\n",
    "n_hidden1 =64\n",
    "n_hidden2 = 64\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=8\n",
    "\n",
    "label=\"SynthData\"\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingLocalitySensitivewoFW\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"LocalitySensitivewoFW_{}\".format(label),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"selu\"\n",
    "attention_hidden_activation=\"selu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"selu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "input_layer=Input(shape=(n_feat, ))\n",
    "\n",
    "attentions_layer=attention_model.ConcatAttentions(\n",
    "    n_attention=n_attention,\n",
    "    n_attention_hidden=n_attention_hidden,\n",
    "    n_attention_out=n_attention_out,\n",
    "    n_feat=n_feat,\n",
    "    n_hidden=n_concat_hidden,\n",
    "    activation=concat_activation, \n",
    "    kernel_initializer=kernel_initializer,\n",
    "    kernel_regularizer=l2(1E-5),\n",
    "    bias_regularizer=l2(1E-5),\n",
    "    attention_initializer=kernel_initializer,\n",
    "    attention_hidden_activation=attention_hidden_activation,\n",
    "    attention_output_activation=attention_output_activation,\n",
    "    batch_norm_kwargs={\"trainable\":False, \"renorm\":False},\n",
    ")(input_layer)\n",
    "##Removed dropout for attentions_layer because of Batch normalization\n",
    "# dropout0=Dropout(0.1)(attentions_layer)\n",
    "dense_layer1=Dense(n_hidden1, \n",
    "                   activation=hidden_activation, \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5),\n",
    "                  )(attentions_layer)\n",
    "# dropout1=Dropout(0.1)(dense_layer1)\n",
    "dense_layer2=Dense(n_hidden2,\n",
    "                   activation=hidden_activation,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5)\n",
    "                  )(dense_layer1)\n",
    "# dropout2=Dropout(0.1)(dense_layer2)\n",
    "output_layer=Dense(1, activation=\"sigmoid\")(dense_layer2)\n",
    "\n",
    "LSwoFW_model=Model(inputs=input_layer, \n",
    "                  outputs=output_layer\n",
    "                 )\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "# loss_fn=tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "LSwoFW_model.compile(loss=loss_fn,\n",
    "    #loss=BinaryCrossentropy(from_logits=False, \n",
    "#                                             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "#                                            ), \n",
    "              optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy',]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "concat_attentions (ConcatAtt (None, 128)               6730      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,211\n",
      "Trainable params: 18,699\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSwoFW_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "113/113 - 5s - loss: 0.7595 - accuracy: 0.4867 - val_loss: 0.7575 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 2/2000\n",
      "113/113 - 2s - loss: 0.7148 - accuracy: 0.5022 - val_loss: 0.7061 - val_accuracy: 0.4900\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48000 to 0.49000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 3/2000\n",
      "113/113 - 2s - loss: 0.7011 - accuracy: 0.5356 - val_loss: 0.7030 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.49000 to 0.50000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 4/2000\n",
      "113/113 - 2s - loss: 0.6919 - accuracy: 0.5500 - val_loss: 0.7011 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.53000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 5/2000\n",
      "113/113 - 2s - loss: 0.6787 - accuracy: 0.5778 - val_loss: 0.6775 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.53000 to 0.63000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 6/2000\n",
      "113/113 - 2s - loss: 0.6608 - accuracy: 0.6089 - val_loss: 0.7235 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63000\n",
      "Epoch 7/2000\n",
      "113/113 - 2s - loss: 0.6528 - accuracy: 0.6189 - val_loss: 0.6861 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.63000 to 0.64000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 8/2000\n",
      "113/113 - 2s - loss: 0.6426 - accuracy: 0.6400 - val_loss: 0.6912 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64000\n",
      "Epoch 9/2000\n",
      "113/113 - 2s - loss: 0.6379 - accuracy: 0.6333 - val_loss: 0.7109 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64000\n",
      "Epoch 10/2000\n",
      "113/113 - 2s - loss: 0.6336 - accuracy: 0.6489 - val_loss: 0.6770 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64000\n",
      "Epoch 11/2000\n",
      "113/113 - 2s - loss: 0.6128 - accuracy: 0.6467 - val_loss: 0.6637 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64000\n",
      "Epoch 12/2000\n",
      "113/113 - 2s - loss: 0.6143 - accuracy: 0.6678 - val_loss: 0.6925 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64000\n",
      "Epoch 13/2000\n",
      "113/113 - 2s - loss: 0.5894 - accuracy: 0.6800 - val_loss: 0.6628 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64000\n",
      "Epoch 14/2000\n",
      "113/113 - 2s - loss: 0.5836 - accuracy: 0.6911 - val_loss: 0.6644 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64000\n",
      "Epoch 15/2000\n",
      "113/113 - 2s - loss: 0.5763 - accuracy: 0.6989 - val_loss: 0.6522 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64000\n",
      "Epoch 16/2000\n",
      "113/113 - 2s - loss: 0.5523 - accuracy: 0.7322 - val_loss: 0.7075 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.64000 to 0.66000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 17/2000\n",
      "113/113 - 2s - loss: 0.5606 - accuracy: 0.7033 - val_loss: 0.6742 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66000\n",
      "Epoch 18/2000\n",
      "113/113 - 2s - loss: 0.5323 - accuracy: 0.7344 - val_loss: 0.6885 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66000\n",
      "Epoch 19/2000\n",
      "113/113 - 2s - loss: 0.5282 - accuracy: 0.7400 - val_loss: 0.6955 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66000\n",
      "Epoch 20/2000\n",
      "113/113 - 2s - loss: 0.5247 - accuracy: 0.7456 - val_loss: 0.6926 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66000\n",
      "Epoch 21/2000\n",
      "113/113 - 2s - loss: 0.5104 - accuracy: 0.7644 - val_loss: 0.7133 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66000\n",
      "Epoch 22/2000\n",
      "113/113 - 2s - loss: 0.5173 - accuracy: 0.7533 - val_loss: 0.7197 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66000\n",
      "Epoch 23/2000\n",
      "113/113 - 2s - loss: 0.4939 - accuracy: 0.7689 - val_loss: 0.7598 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66000\n",
      "Epoch 24/2000\n",
      "113/113 - 2s - loss: 0.4920 - accuracy: 0.7756 - val_loss: 0.7388 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66000\n",
      "Epoch 25/2000\n",
      "113/113 - 2s - loss: 0.4809 - accuracy: 0.7789 - val_loss: 0.7425 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66000\n",
      "Epoch 26/2000\n",
      "113/113 - 2s - loss: 0.4566 - accuracy: 0.7889 - val_loss: 0.8321 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66000\n",
      "Epoch 27/2000\n",
      "113/113 - 2s - loss: 0.4756 - accuracy: 0.7800 - val_loss: 0.7204 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66000\n",
      "Epoch 28/2000\n",
      "113/113 - 2s - loss: 0.4536 - accuracy: 0.7878 - val_loss: 0.7511 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66000\n",
      "Epoch 29/2000\n",
      "113/113 - 2s - loss: 0.4469 - accuracy: 0.8067 - val_loss: 0.7235 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66000\n",
      "Epoch 30/2000\n",
      "113/113 - 2s - loss: 0.4377 - accuracy: 0.8133 - val_loss: 0.7295 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66000\n",
      "Epoch 31/2000\n",
      "113/113 - 2s - loss: 0.4431 - accuracy: 0.8033 - val_loss: 0.7500 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66000\n",
      "Epoch 32/2000\n",
      "113/113 - 2s - loss: 0.4355 - accuracy: 0.8000 - val_loss: 0.8428 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66000\n",
      "Epoch 33/2000\n",
      "113/113 - 2s - loss: 0.4205 - accuracy: 0.8089 - val_loss: 0.7702 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66000\n",
      "Epoch 34/2000\n",
      "113/113 - 2s - loss: 0.4148 - accuracy: 0.8222 - val_loss: 0.7551 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66000\n",
      "Epoch 35/2000\n",
      "113/113 - 2s - loss: 0.3996 - accuracy: 0.8411 - val_loss: 0.7592 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.66000 to 0.67000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 36/2000\n",
      "113/113 - 2s - loss: 0.4084 - accuracy: 0.8256 - val_loss: 0.8496 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.67000\n",
      "Epoch 37/2000\n",
      "113/113 - 2s - loss: 0.4011 - accuracy: 0.8222 - val_loss: 0.7742 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.67000\n",
      "Epoch 38/2000\n",
      "113/113 - 2s - loss: 0.4017 - accuracy: 0.8267 - val_loss: 0.7985 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.67000\n",
      "Epoch 39/2000\n",
      "113/113 - 2s - loss: 0.3784 - accuracy: 0.8333 - val_loss: 0.8407 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67000\n",
      "Epoch 40/2000\n",
      "113/113 - 2s - loss: 0.3790 - accuracy: 0.8422 - val_loss: 0.8480 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67000\n",
      "Epoch 41/2000\n",
      "113/113 - 2s - loss: 0.3607 - accuracy: 0.8411 - val_loss: 0.8903 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.67000\n",
      "Epoch 42/2000\n",
      "113/113 - 2s - loss: 0.3646 - accuracy: 0.8333 - val_loss: 0.8339 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.67000\n",
      "Epoch 43/2000\n",
      "113/113 - 2s - loss: 0.3462 - accuracy: 0.8500 - val_loss: 0.9025 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67000\n",
      "Epoch 44/2000\n",
      "113/113 - 2s - loss: 0.3518 - accuracy: 0.8489 - val_loss: 0.8180 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67000\n",
      "Epoch 45/2000\n",
      "113/113 - 2s - loss: 0.3370 - accuracy: 0.8500 - val_loss: 0.7990 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.67000 to 0.68000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 46/2000\n",
      "113/113 - 2s - loss: 0.3405 - accuracy: 0.8522 - val_loss: 0.9236 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.68000\n",
      "Epoch 47/2000\n",
      "113/113 - 2s - loss: 0.3335 - accuracy: 0.8600 - val_loss: 0.8556 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.68000\n",
      "Epoch 48/2000\n",
      "113/113 - 2s - loss: 0.3040 - accuracy: 0.8678 - val_loss: 0.9519 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.68000\n",
      "Epoch 49/2000\n",
      "113/113 - 2s - loss: 0.3053 - accuracy: 0.8744 - val_loss: 1.0274 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.68000\n",
      "Epoch 50/2000\n",
      "113/113 - 2s - loss: 0.3019 - accuracy: 0.8822 - val_loss: 1.0928 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.68000\n",
      "Epoch 51/2000\n",
      "113/113 - 2s - loss: 0.2917 - accuracy: 0.8789 - val_loss: 1.0241 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.68000\n",
      "Epoch 52/2000\n",
      "113/113 - 2s - loss: 0.2950 - accuracy: 0.8789 - val_loss: 1.1129 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.68000\n",
      "Epoch 53/2000\n",
      "113/113 - 2s - loss: 0.2778 - accuracy: 0.8789 - val_loss: 1.0156 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.68000\n",
      "Epoch 54/2000\n",
      "113/113 - 2s - loss: 0.2654 - accuracy: 0.9022 - val_loss: 1.1527 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.68000\n",
      "Epoch 55/2000\n",
      "113/113 - 2s - loss: 0.2716 - accuracy: 0.8889 - val_loss: 1.0506 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.68000\n",
      "Epoch 56/2000\n",
      "113/113 - 2s - loss: 0.2503 - accuracy: 0.8967 - val_loss: 1.1364 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.68000\n",
      "Epoch 57/2000\n",
      "113/113 - 2s - loss: 0.2511 - accuracy: 0.9067 - val_loss: 1.0613 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.68000\n",
      "Epoch 58/2000\n",
      "113/113 - 2s - loss: 0.2625 - accuracy: 0.8967 - val_loss: 1.1587 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.68000\n",
      "Epoch 59/2000\n",
      "113/113 - 2s - loss: 0.2373 - accuracy: 0.9078 - val_loss: 1.2303 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.68000\n",
      "Epoch 60/2000\n",
      "113/113 - 2s - loss: 0.2275 - accuracy: 0.9144 - val_loss: 1.3548 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.68000\n",
      "Epoch 61/2000\n",
      "113/113 - 2s - loss: 0.2485 - accuracy: 0.9011 - val_loss: 1.1282 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.68000\n",
      "Epoch 62/2000\n",
      "113/113 - 2s - loss: 0.2282 - accuracy: 0.9089 - val_loss: 1.3577 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.68000\n",
      "Epoch 63/2000\n",
      "113/113 - 2s - loss: 0.2365 - accuracy: 0.9122 - val_loss: 1.3115 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.68000\n",
      "Epoch 64/2000\n",
      "113/113 - 2s - loss: 0.2069 - accuracy: 0.9189 - val_loss: 1.2438 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.68000\n",
      "Epoch 65/2000\n",
      "113/113 - 2s - loss: 0.1989 - accuracy: 0.9244 - val_loss: 1.4190 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.68000\n",
      "Epoch 66/2000\n",
      "113/113 - 2s - loss: 0.2103 - accuracy: 0.9311 - val_loss: 1.3132 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.68000\n",
      "Epoch 67/2000\n",
      "113/113 - 2s - loss: 0.2151 - accuracy: 0.9189 - val_loss: 1.2550 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.68000\n",
      "Epoch 68/2000\n",
      "113/113 - 2s - loss: 0.2010 - accuracy: 0.9211 - val_loss: 1.2876 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.68000\n",
      "Epoch 69/2000\n",
      "113/113 - 2s - loss: 0.1904 - accuracy: 0.9211 - val_loss: 1.2538 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.68000\n",
      "Epoch 70/2000\n",
      "113/113 - 2s - loss: 0.1964 - accuracy: 0.9222 - val_loss: 1.4462 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.68000\n",
      "Epoch 71/2000\n",
      "113/113 - 2s - loss: 0.1922 - accuracy: 0.9244 - val_loss: 1.2737 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.68000\n",
      "Epoch 72/2000\n",
      "113/113 - 2s - loss: 0.1865 - accuracy: 0.9333 - val_loss: 1.3992 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.68000\n",
      "Epoch 73/2000\n",
      "113/113 - 2s - loss: 0.1512 - accuracy: 0.9456 - val_loss: 1.4260 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.68000\n",
      "Epoch 74/2000\n",
      "113/113 - 2s - loss: 0.1664 - accuracy: 0.9422 - val_loss: 1.4831 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.68000\n",
      "Epoch 75/2000\n",
      "113/113 - 2s - loss: 0.1744 - accuracy: 0.9311 - val_loss: 1.3175 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.68000\n",
      "Epoch 76/2000\n",
      "113/113 - 2s - loss: 0.1717 - accuracy: 0.9267 - val_loss: 1.4702 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.68000 to 0.69000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 77/2000\n",
      "113/113 - 2s - loss: 0.1635 - accuracy: 0.9400 - val_loss: 1.5413 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.69000\n",
      "Epoch 78/2000\n",
      "113/113 - 2s - loss: 0.1450 - accuracy: 0.9478 - val_loss: 1.6693 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.69000\n",
      "Epoch 79/2000\n",
      "113/113 - 2s - loss: 0.1782 - accuracy: 0.9322 - val_loss: 1.4312 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.69000\n",
      "Epoch 80/2000\n",
      "113/113 - 2s - loss: 0.1622 - accuracy: 0.9422 - val_loss: 1.7226 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.69000\n",
      "Epoch 81/2000\n",
      "113/113 - 2s - loss: 0.1371 - accuracy: 0.9500 - val_loss: 1.5961 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.69000\n",
      "Epoch 82/2000\n",
      "113/113 - 2s - loss: 0.1343 - accuracy: 0.9522 - val_loss: 1.6183 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.69000\n",
      "Epoch 83/2000\n",
      "113/113 - 2s - loss: 0.1205 - accuracy: 0.9578 - val_loss: 1.4870 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.69000\n",
      "Epoch 84/2000\n",
      "113/113 - 2s - loss: 0.1447 - accuracy: 0.9444 - val_loss: 1.5354 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.69000\n",
      "Epoch 85/2000\n",
      "113/113 - 2s - loss: 0.1265 - accuracy: 0.9478 - val_loss: 1.5710 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.69000\n",
      "Epoch 86/2000\n",
      "113/113 - 2s - loss: 0.1206 - accuracy: 0.9567 - val_loss: 1.5513 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.69000\n",
      "Epoch 87/2000\n",
      "113/113 - 2s - loss: 0.1160 - accuracy: 0.9544 - val_loss: 1.6063 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.69000\n",
      "Epoch 88/2000\n",
      "113/113 - 2s - loss: 0.1622 - accuracy: 0.9300 - val_loss: 1.5725 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.69000\n",
      "Epoch 89/2000\n",
      "113/113 - 2s - loss: 0.1093 - accuracy: 0.9611 - val_loss: 1.5115 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.69000\n",
      "Epoch 90/2000\n",
      "113/113 - 2s - loss: 0.0950 - accuracy: 0.9644 - val_loss: 1.5888 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.69000\n",
      "Epoch 91/2000\n",
      "113/113 - 2s - loss: 0.1502 - accuracy: 0.9467 - val_loss: 1.7177 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.69000\n",
      "Epoch 92/2000\n",
      "113/113 - 2s - loss: 0.1424 - accuracy: 0.9433 - val_loss: 1.8163 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.69000\n",
      "Epoch 93/2000\n",
      "113/113 - 2s - loss: 0.1262 - accuracy: 0.9533 - val_loss: 1.7086 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.69000\n",
      "Epoch 94/2000\n",
      "113/113 - 2s - loss: 0.1027 - accuracy: 0.9656 - val_loss: 1.8690 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.69000\n",
      "Epoch 95/2000\n",
      "113/113 - 2s - loss: 0.0892 - accuracy: 0.9711 - val_loss: 1.7495 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.69000\n",
      "Epoch 96/2000\n",
      "113/113 - 2s - loss: 0.0836 - accuracy: 0.9700 - val_loss: 1.8907 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.69000\n",
      "Epoch 97/2000\n",
      "113/113 - 2s - loss: 0.0981 - accuracy: 0.9711 - val_loss: 2.0705 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.69000\n",
      "Epoch 98/2000\n",
      "113/113 - 2s - loss: 0.1809 - accuracy: 0.9367 - val_loss: 1.9191 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.69000\n",
      "Epoch 99/2000\n",
      "113/113 - 2s - loss: 0.0951 - accuracy: 0.9644 - val_loss: 1.7829 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.69000\n",
      "Epoch 100/2000\n",
      "113/113 - 2s - loss: 0.0823 - accuracy: 0.9700 - val_loss: 1.6367 - val_accuracy: 0.7300\n",
      "\n",
      "Epoch 00100: val_accuracy improved from 0.69000 to 0.73000, saving model to 210219_TrainingLocalitySensitivewoFW\\LocalitySensitivewoFW_SynthData\n",
      "Epoch 101/2000\n",
      "113/113 - 2s - loss: 0.1061 - accuracy: 0.9656 - val_loss: 1.8591 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.73000\n",
      "Epoch 102/2000\n",
      "113/113 - 2s - loss: 0.0750 - accuracy: 0.9744 - val_loss: 1.6451 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.73000\n",
      "Epoch 103/2000\n",
      "113/113 - 2s - loss: 0.1209 - accuracy: 0.9578 - val_loss: 1.8219 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.73000\n",
      "Epoch 104/2000\n",
      "113/113 - 2s - loss: 0.2396 - accuracy: 0.9356 - val_loss: 1.8003 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.73000\n",
      "Epoch 105/2000\n",
      "113/113 - 2s - loss: 0.0913 - accuracy: 0.9667 - val_loss: 1.7483 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.73000\n",
      "Epoch 106/2000\n",
      "113/113 - 2s - loss: 0.0691 - accuracy: 0.9744 - val_loss: 2.0646 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.73000\n",
      "Epoch 107/2000\n",
      "113/113 - 2s - loss: 0.0816 - accuracy: 0.9733 - val_loss: 1.9549 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.73000\n",
      "Epoch 108/2000\n",
      "113/113 - 2s - loss: 0.0683 - accuracy: 0.9822 - val_loss: 1.9441 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.73000\n",
      "Epoch 109/2000\n",
      "113/113 - 2s - loss: 0.0516 - accuracy: 0.9889 - val_loss: 1.9009 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.73000\n",
      "Epoch 110/2000\n",
      "113/113 - 2s - loss: 0.0519 - accuracy: 0.9822 - val_loss: 2.1051 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.73000\n",
      "Epoch 111/2000\n",
      "113/113 - 2s - loss: 0.0530 - accuracy: 0.9867 - val_loss: 1.8820 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.73000\n",
      "Epoch 112/2000\n",
      "113/113 - 2s - loss: 0.0548 - accuracy: 0.9900 - val_loss: 2.0013 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.73000\n",
      "Epoch 113/2000\n",
      "113/113 - 2s - loss: 0.0615 - accuracy: 0.9867 - val_loss: 2.2366 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.73000\n",
      "Epoch 114/2000\n",
      "113/113 - 2s - loss: 0.0999 - accuracy: 0.9633 - val_loss: 2.2259 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.73000\n",
      "Epoch 115/2000\n",
      "113/113 - 2s - loss: 0.1843 - accuracy: 0.9278 - val_loss: 2.2935 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.73000\n",
      "Epoch 116/2000\n",
      "113/113 - 2s - loss: 0.1481 - accuracy: 0.9444 - val_loss: 2.1151 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.73000\n",
      "Epoch 117/2000\n",
      "113/113 - 2s - loss: 0.0614 - accuracy: 0.9844 - val_loss: 2.2371 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.73000\n",
      "Epoch 118/2000\n",
      "113/113 - 2s - loss: 0.0463 - accuracy: 0.9889 - val_loss: 2.1168 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.73000\n",
      "Epoch 119/2000\n",
      "113/113 - 2s - loss: 0.0419 - accuracy: 0.9911 - val_loss: 2.0757 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.73000\n",
      "Epoch 120/2000\n",
      "113/113 - 2s - loss: 0.0512 - accuracy: 0.9856 - val_loss: 2.1642 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.73000\n",
      "Epoch 121/2000\n",
      "113/113 - 2s - loss: 0.0479 - accuracy: 0.9867 - val_loss: 2.3392 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.73000\n",
      "Epoch 122/2000\n",
      "113/113 - 2s - loss: 0.0474 - accuracy: 0.9867 - val_loss: 2.2406 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.73000\n",
      "Epoch 123/2000\n",
      "113/113 - 2s - loss: 0.1218 - accuracy: 0.9578 - val_loss: 2.6539 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.73000\n",
      "Epoch 124/2000\n",
      "113/113 - 2s - loss: 0.2171 - accuracy: 0.9322 - val_loss: 2.1138 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.73000\n",
      "Epoch 125/2000\n",
      "113/113 - 2s - loss: 0.1411 - accuracy: 0.9456 - val_loss: 2.2909 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.73000\n",
      "Epoch 126/2000\n",
      "113/113 - 2s - loss: 0.0578 - accuracy: 0.9789 - val_loss: 2.2462 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.73000\n",
      "Epoch 127/2000\n",
      "113/113 - 2s - loss: 0.0342 - accuracy: 0.9933 - val_loss: 2.1613 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.73000\n",
      "Epoch 128/2000\n",
      "113/113 - 2s - loss: 0.0389 - accuracy: 0.9900 - val_loss: 2.1894 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.73000\n",
      "Epoch 129/2000\n",
      "113/113 - 2s - loss: 0.0276 - accuracy: 0.9956 - val_loss: 2.1891 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.73000\n",
      "Epoch 130/2000\n",
      "113/113 - 2s - loss: 0.0307 - accuracy: 0.9956 - val_loss: 2.1151 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.73000\n",
      "Epoch 131/2000\n",
      "113/113 - 2s - loss: 0.0309 - accuracy: 0.9922 - val_loss: 2.2267 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.73000\n",
      "Epoch 132/2000\n",
      "113/113 - 2s - loss: 0.0749 - accuracy: 0.9711 - val_loss: 2.7442 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.73000\n",
      "Epoch 133/2000\n",
      "113/113 - 2s - loss: 0.2216 - accuracy: 0.9367 - val_loss: 2.0725 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.73000\n",
      "Epoch 134/2000\n",
      "113/113 - 2s - loss: 0.1141 - accuracy: 0.9600 - val_loss: 2.7836 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.73000\n",
      "Epoch 135/2000\n",
      "113/113 - 2s - loss: 0.1180 - accuracy: 0.9667 - val_loss: 2.1938 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.73000\n",
      "Epoch 136/2000\n",
      "113/113 - 2s - loss: 0.0803 - accuracy: 0.9756 - val_loss: 2.3447 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.73000\n",
      "Epoch 137/2000\n",
      "113/113 - 2s - loss: 0.0379 - accuracy: 0.9944 - val_loss: 2.4091 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.73000\n",
      "Epoch 138/2000\n",
      "113/113 - 2s - loss: 0.0276 - accuracy: 0.9933 - val_loss: 2.3120 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.73000\n",
      "Epoch 139/2000\n",
      "113/113 - 2s - loss: 0.0295 - accuracy: 0.9956 - val_loss: 2.1465 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.73000\n",
      "Epoch 140/2000\n",
      "113/113 - 2s - loss: 0.0256 - accuracy: 0.9956 - val_loss: 2.2588 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.73000\n",
      "Epoch 141/2000\n",
      "113/113 - 2s - loss: 0.0364 - accuracy: 0.9911 - val_loss: 2.4257 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.73000\n",
      "Epoch 142/2000\n",
      "113/113 - 2s - loss: 0.1258 - accuracy: 0.9667 - val_loss: 2.4791 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.73000\n",
      "Epoch 143/2000\n",
      "113/113 - 2s - loss: 0.1253 - accuracy: 0.9589 - val_loss: 2.3179 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.73000\n",
      "Epoch 144/2000\n",
      "113/113 - 2s - loss: 0.0954 - accuracy: 0.9700 - val_loss: 2.3860 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.73000\n",
      "Epoch 145/2000\n",
      "113/113 - 2s - loss: 0.0453 - accuracy: 0.9867 - val_loss: 2.5374 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.73000\n",
      "Epoch 146/2000\n",
      "113/113 - 2s - loss: 0.0272 - accuracy: 0.9922 - val_loss: 2.3992 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.73000\n",
      "Epoch 147/2000\n",
      "113/113 - 2s - loss: 0.0222 - accuracy: 0.9967 - val_loss: 2.5344 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.73000\n",
      "Epoch 148/2000\n",
      "113/113 - 2s - loss: 0.1159 - accuracy: 0.9678 - val_loss: 2.1446 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.73000\n",
      "Epoch 149/2000\n",
      "113/113 - 2s - loss: 0.0865 - accuracy: 0.9722 - val_loss: 2.5347 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.73000\n",
      "Epoch 150/2000\n",
      "113/113 - 2s - loss: 0.0994 - accuracy: 0.9722 - val_loss: 2.5446 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.73000\n",
      "Epoch 151/2000\n",
      "113/113 - 2s - loss: 0.0822 - accuracy: 0.9722 - val_loss: 2.6438 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.73000\n",
      "Epoch 152/2000\n",
      "113/113 - 2s - loss: 0.0631 - accuracy: 0.9767 - val_loss: 2.2801 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.73000\n",
      "Epoch 153/2000\n",
      "113/113 - 2s - loss: 0.0970 - accuracy: 0.9678 - val_loss: 2.4816 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.73000\n",
      "Epoch 154/2000\n",
      "113/113 - 2s - loss: 0.0397 - accuracy: 0.9900 - val_loss: 2.7960 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.73000\n",
      "Epoch 155/2000\n",
      "113/113 - 2s - loss: 0.0559 - accuracy: 0.9833 - val_loss: 2.4764 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.73000\n",
      "Epoch 156/2000\n",
      "113/113 - 2s - loss: 0.0471 - accuracy: 0.9844 - val_loss: 2.4708 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.73000\n",
      "Epoch 157/2000\n",
      "113/113 - 2s - loss: 0.0287 - accuracy: 0.9944 - val_loss: 2.4559 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.73000\n",
      "Epoch 158/2000\n",
      "113/113 - 2s - loss: 0.0208 - accuracy: 0.9978 - val_loss: 2.5048 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.73000\n",
      "Epoch 159/2000\n",
      "113/113 - 2s - loss: 0.0163 - accuracy: 0.9978 - val_loss: 2.4993 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.73000\n",
      "Epoch 160/2000\n",
      "113/113 - 2s - loss: 0.0230 - accuracy: 0.9956 - val_loss: 2.5490 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.73000\n",
      "Epoch 161/2000\n",
      "113/113 - 2s - loss: 0.0239 - accuracy: 0.9967 - val_loss: 2.7043 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.73000\n",
      "Epoch 162/2000\n",
      "113/113 - 2s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.4500 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.73000\n",
      "Epoch 163/2000\n",
      "113/113 - 2s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6023 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.73000\n",
      "Epoch 164/2000\n",
      "113/113 - 2s - loss: 0.0138 - accuracy: 0.9978 - val_loss: 2.4202 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.73000\n",
      "Epoch 165/2000\n",
      "113/113 - 2s - loss: 0.0186 - accuracy: 0.9956 - val_loss: 2.7177 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.73000\n",
      "Epoch 166/2000\n",
      "113/113 - 2s - loss: 0.0338 - accuracy: 0.9933 - val_loss: 2.5632 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.73000\n",
      "Epoch 167/2000\n",
      "113/113 - 2s - loss: 0.0325 - accuracy: 0.9911 - val_loss: 2.7998 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.73000\n",
      "Epoch 168/2000\n",
      "113/113 - 2s - loss: 0.1367 - accuracy: 0.9633 - val_loss: 2.5698 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.73000\n",
      "Epoch 169/2000\n",
      "113/113 - 2s - loss: 0.4265 - accuracy: 0.8878 - val_loss: 2.6003 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.73000\n",
      "Epoch 170/2000\n",
      "113/113 - 2s - loss: 0.1311 - accuracy: 0.9489 - val_loss: 2.9799 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.73000\n",
      "Epoch 171/2000\n",
      "113/113 - 2s - loss: 0.0707 - accuracy: 0.9711 - val_loss: 2.3946 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.73000\n",
      "Epoch 172/2000\n",
      "113/113 - 2s - loss: 0.0245 - accuracy: 0.9978 - val_loss: 2.5970 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.73000\n",
      "Epoch 173/2000\n",
      "113/113 - 2s - loss: 0.0204 - accuracy: 0.9989 - val_loss: 2.4422 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.73000\n",
      "Epoch 174/2000\n",
      "113/113 - 2s - loss: 0.0171 - accuracy: 0.9978 - val_loss: 2.5131 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.73000\n",
      "Epoch 175/2000\n",
      "113/113 - 2s - loss: 0.0175 - accuracy: 0.9989 - val_loss: 2.5440 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.73000\n",
      "Epoch 176/2000\n",
      "113/113 - 2s - loss: 0.0134 - accuracy: 0.9989 - val_loss: 2.6384 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.73000\n",
      "Epoch 177/2000\n",
      "113/113 - 2s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.4875 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.73000\n",
      "Epoch 178/2000\n",
      "113/113 - 2s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.5463 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.73000\n",
      "Epoch 179/2000\n",
      "113/113 - 2s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.73000\n",
      "Epoch 180/2000\n",
      "113/113 - 2s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.5132 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.73000\n",
      "Epoch 181/2000\n",
      "113/113 - 2s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.6012 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.73000\n",
      "Epoch 182/2000\n",
      "113/113 - 2s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.5819 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.73000\n",
      "Epoch 183/2000\n",
      "113/113 - 2s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5907 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.73000\n",
      "Epoch 184/2000\n",
      "113/113 - 2s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5703 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.73000\n",
      "Epoch 185/2000\n",
      "113/113 - 2s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.73000\n",
      "Epoch 186/2000\n",
      "113/113 - 2s - loss: 0.1233 - accuracy: 0.9556 - val_loss: 2.9194 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.73000\n",
      "Epoch 187/2000\n",
      "113/113 - 2s - loss: 0.4406 - accuracy: 0.8967 - val_loss: 2.8676 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.73000\n",
      "Epoch 188/2000\n",
      "113/113 - 2s - loss: 0.0983 - accuracy: 0.9633 - val_loss: 2.3492 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.73000\n",
      "Epoch 189/2000\n",
      "113/113 - 2s - loss: 0.0300 - accuracy: 0.9944 - val_loss: 2.5694 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.73000\n",
      "Epoch 190/2000\n",
      "113/113 - 2s - loss: 0.0242 - accuracy: 0.9956 - val_loss: 2.4413 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.73000\n",
      "Epoch 191/2000\n",
      "113/113 - 2s - loss: 0.0168 - accuracy: 0.9978 - val_loss: 2.4470 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.73000\n",
      "Epoch 192/2000\n",
      "113/113 - 2s - loss: 0.0140 - accuracy: 0.9989 - val_loss: 2.3863 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.73000\n",
      "Epoch 193/2000\n",
      "113/113 - 2s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.4193 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.73000\n",
      "Epoch 194/2000\n",
      "113/113 - 2s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.4294 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.73000\n",
      "Epoch 195/2000\n",
      "113/113 - 2s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.4680 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.73000\n",
      "Epoch 196/2000\n",
      "113/113 - 2s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.4372 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.73000\n",
      "Epoch 197/2000\n",
      "113/113 - 2s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.4270 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.73000\n",
      "Epoch 198/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.4660 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.73000\n",
      "Epoch 199/2000\n",
      "113/113 - 2s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4680 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.73000\n",
      "Epoch 200/2000\n",
      "113/113 - 2s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.4957 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.73000\n",
      "Epoch 201/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5743 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.73000\n",
      "Epoch 202/2000\n",
      "113/113 - 2s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.5729 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.73000\n",
      "Epoch 203/2000\n",
      "113/113 - 2s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.5659 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.73000\n",
      "Epoch 204/2000\n",
      "113/113 - 2s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.5630 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.73000\n",
      "Epoch 205/2000\n",
      "113/113 - 2s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5487 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.73000\n",
      "Epoch 206/2000\n",
      "113/113 - 2s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.73000\n",
      "Epoch 207/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.6150 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.73000\n",
      "Epoch 208/2000\n",
      "113/113 - 2s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.5959 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.73000\n",
      "Epoch 209/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.73000\n",
      "Epoch 210/2000\n",
      "113/113 - 2s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.6087 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.73000\n",
      "Epoch 211/2000\n",
      "113/113 - 2s - loss: 0.0561 - accuracy: 0.9911 - val_loss: 2.8982 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.73000\n",
      "Epoch 212/2000\n",
      "113/113 - 2s - loss: 0.7660 - accuracy: 0.8500 - val_loss: 2.3737 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.73000\n",
      "Epoch 213/2000\n",
      "113/113 - 2s - loss: 0.2405 - accuracy: 0.9244 - val_loss: 2.4051 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.73000\n",
      "Epoch 214/2000\n",
      "113/113 - 2s - loss: 0.0694 - accuracy: 0.9733 - val_loss: 2.3454 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.73000\n",
      "Epoch 215/2000\n",
      "113/113 - 2s - loss: 0.0217 - accuracy: 0.9967 - val_loss: 2.2655 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.73000\n",
      "Epoch 216/2000\n",
      "113/113 - 2s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.2862 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.73000\n",
      "Epoch 217/2000\n",
      "113/113 - 2s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.2844 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.73000\n",
      "Epoch 218/2000\n",
      "113/113 - 2s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.3257 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.73000\n",
      "Epoch 219/2000\n",
      "113/113 - 2s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.3807 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.73000\n",
      "Epoch 220/2000\n",
      "113/113 - 2s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.3894 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.73000\n",
      "Epoch 221/2000\n",
      "113/113 - 2s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.3706 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.73000\n",
      "Epoch 222/2000\n",
      "113/113 - 2s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.3739 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.73000\n",
      "Epoch 223/2000\n",
      "113/113 - 2s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.3996 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.73000\n",
      "Epoch 224/2000\n",
      "113/113 - 2s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4494 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.73000\n",
      "Epoch 225/2000\n",
      "113/113 - 2s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4564 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.73000\n",
      "Epoch 226/2000\n",
      "113/113 - 2s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.4983 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.73000\n",
      "Epoch 227/2000\n",
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.4634 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.73000\n",
      "Epoch 228/2000\n",
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5300 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.73000\n",
      "Epoch 229/2000\n",
      "113/113 - 2s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.5017 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.73000\n",
      "Epoch 230/2000\n",
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5246 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.73000\n",
      "Epoch 231/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.5397 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.73000\n",
      "Epoch 232/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.5830 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.73000\n",
      "Epoch 233/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.6042 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.73000\n",
      "Epoch 234/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5669 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.73000\n",
      "Epoch 235/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.6232 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.73000\n",
      "Epoch 236/2000\n",
      "113/113 - 2s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.6177 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.73000\n",
      "Epoch 237/2000\n",
      "113/113 - 2s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.6643 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.73000\n",
      "Epoch 238/2000\n",
      "113/113 - 2s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.7266 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.73000\n",
      "Epoch 239/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.6882 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.73000\n",
      "Epoch 240/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.7249 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.73000\n",
      "Epoch 241/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.6896 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.73000\n",
      "Epoch 242/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.73000\n",
      "Epoch 243/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.7552 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.73000\n",
      "Epoch 244/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.7323 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.73000\n",
      "Epoch 245/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.7151 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.73000\n",
      "Epoch 246/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.7438 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.73000\n",
      "Epoch 247/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.8140 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.73000\n",
      "Epoch 248/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.8122 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.73000\n",
      "Epoch 249/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.73000\n",
      "Epoch 250/2000\n",
      "113/113 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.7655 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.73000\n",
      "Epoch 251/2000\n",
      "113/113 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.73000\n",
      "Epoch 252/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.73000\n",
      "Epoch 253/2000\n",
      "113/113 - 2s - loss: 0.8896 - accuracy: 0.8678 - val_loss: 2.8977 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.73000\n",
      "Epoch 254/2000\n",
      "113/113 - 2s - loss: 0.5470 - accuracy: 0.8778 - val_loss: 2.2430 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.73000\n",
      "Epoch 255/2000\n",
      "113/113 - 2s - loss: 0.1473 - accuracy: 0.9478 - val_loss: 2.3043 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.73000\n",
      "Epoch 256/2000\n",
      "113/113 - 2s - loss: 0.0616 - accuracy: 0.9789 - val_loss: 2.0499 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.73000\n",
      "Epoch 257/2000\n",
      "113/113 - 2s - loss: 0.0265 - accuracy: 0.9956 - val_loss: 2.3377 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.73000\n",
      "Epoch 258/2000\n",
      "113/113 - 2s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.2062 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.73000\n",
      "Epoch 259/2000\n",
      "113/113 - 2s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.2087 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.73000\n",
      "Epoch 260/2000\n",
      "113/113 - 2s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.2235 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.73000\n",
      "Epoch 261/2000\n",
      "113/113 - 2s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.2348 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.73000\n",
      "Epoch 262/2000\n",
      "113/113 - 2s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2267 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.73000\n",
      "Epoch 263/2000\n",
      "113/113 - 2s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.2258 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.73000\n",
      "Epoch 264/2000\n",
      "113/113 - 2s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.2829 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.73000\n",
      "Epoch 265/2000\n",
      "113/113 - 2s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.2903 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.73000\n",
      "Epoch 266/2000\n",
      "113/113 - 2s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.3108 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.73000\n",
      "Epoch 267/2000\n",
      "113/113 - 2s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.3440 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.73000\n",
      "Epoch 268/2000\n",
      "113/113 - 2s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.3686 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.73000\n",
      "Epoch 269/2000\n",
      "113/113 - 2s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.3365 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.73000\n",
      "Epoch 270/2000\n",
      "113/113 - 2s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.3522 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.73000\n",
      "Epoch 271/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.3829 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.73000\n",
      "Epoch 272/2000\n",
      "113/113 - 2s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3759 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.73000\n",
      "Epoch 273/2000\n",
      "113/113 - 2s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.4194 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.73000\n",
      "Epoch 274/2000\n",
      "113/113 - 2s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.4436 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.73000\n",
      "Epoch 275/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.4118 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.73000\n",
      "Epoch 276/2000\n",
      "113/113 - 2s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4597 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.73000\n",
      "Epoch 277/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.4762 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.73000\n",
      "Epoch 278/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5067 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.73000\n",
      "Epoch 279/2000\n",
      "113/113 - 2s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.5040 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.73000\n",
      "Epoch 280/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.5113 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.73000\n",
      "Epoch 281/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.5264 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.73000\n",
      "Epoch 282/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5460 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.73000\n",
      "Epoch 283/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5533 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.73000\n",
      "Epoch 284/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.6064 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.73000\n",
      "Epoch 285/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.6035 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.73000\n",
      "Epoch 286/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.6012 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.73000\n",
      "Epoch 287/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6200 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.73000\n",
      "Epoch 288/2000\n",
      "113/113 - 2s - loss: 0.4915 - accuracy: 0.9056 - val_loss: 2.7947 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.73000\n",
      "Epoch 289/2000\n",
      "113/113 - 2s - loss: 0.4196 - accuracy: 0.8833 - val_loss: 2.5451 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.73000\n",
      "Epoch 290/2000\n",
      "113/113 - 2s - loss: 0.1053 - accuracy: 0.9611 - val_loss: 2.0552 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.73000\n",
      "Epoch 291/2000\n",
      "113/113 - 2s - loss: 0.0291 - accuracy: 0.9956 - val_loss: 2.1555 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.73000\n",
      "Epoch 292/2000\n",
      "113/113 - 2s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.1460 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.73000\n",
      "Epoch 293/2000\n",
      "113/113 - 2s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.1944 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.73000\n",
      "Epoch 294/2000\n",
      "113/113 - 2s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.2323 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.73000\n",
      "Epoch 295/2000\n",
      "113/113 - 2s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.2265 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.73000\n",
      "Epoch 296/2000\n",
      "113/113 - 2s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.2720 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.73000\n",
      "Epoch 297/2000\n",
      "113/113 - 2s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3095 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.73000\n",
      "Epoch 298/2000\n",
      "113/113 - 2s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.73000\n",
      "Epoch 299/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.3513 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.73000\n",
      "Epoch 300/2000\n",
      "113/113 - 2s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.3368 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.73000\n",
      "Epoch 301/2000\n",
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.3901 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.73000\n",
      "Epoch 302/2000\n",
      "113/113 - 2s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.3758 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.73000\n",
      "Epoch 303/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.3808 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.73000\n",
      "Epoch 304/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.4521 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.73000\n",
      "Epoch 305/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.4487 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.73000\n",
      "Epoch 306/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.4386 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.73000\n",
      "Epoch 307/2000\n",
      "113/113 - 2s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4653 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.73000\n",
      "Epoch 308/2000\n",
      "113/113 - 2s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4725 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.73000\n",
      "Epoch 309/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.4945 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.73000\n",
      "Epoch 310/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.5172 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.73000\n",
      "Epoch 311/2000\n",
      "113/113 - 2s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.5332 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.73000\n",
      "Epoch 312/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5465 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.73000\n",
      "Epoch 313/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5610 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.73000\n",
      "Epoch 314/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5833 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.73000\n",
      "Epoch 315/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.5711 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.73000\n",
      "Epoch 316/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.5924 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.73000\n",
      "Epoch 317/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6412 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.73000\n",
      "Epoch 318/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6342 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.73000\n",
      "Epoch 319/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.6213 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.73000\n",
      "Epoch 320/2000\n",
      "113/113 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.6496 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.73000\n",
      "Epoch 321/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.6857 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.73000\n",
      "Epoch 322/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.6474 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.73000\n",
      "Epoch 323/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.73000\n",
      "Epoch 324/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.73000\n",
      "Epoch 325/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.7523 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.73000\n",
      "Epoch 326/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.7220 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.73000\n",
      "Epoch 327/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.7472 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.73000\n",
      "Epoch 328/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.7454 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.73000\n",
      "Epoch 329/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.7497 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.73000\n",
      "Epoch 330/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.73000\n",
      "Epoch 331/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.7611 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.73000\n",
      "Epoch 332/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.7551 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.73000\n",
      "Epoch 333/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.73000\n",
      "Epoch 334/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.73000\n",
      "Epoch 335/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.7683 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.73000\n",
      "Epoch 336/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.73000\n",
      "Epoch 337/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.73000\n",
      "Epoch 338/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.8725 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.73000\n",
      "Epoch 339/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.8450 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.73000\n",
      "Epoch 340/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.8642 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.73000\n",
      "Epoch 341/2000\n",
      "113/113 - 2s - loss: 0.8226 - accuracy: 0.8844 - val_loss: 3.5743 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.73000\n",
      "Epoch 342/2000\n",
      "113/113 - 2s - loss: 0.6743 - accuracy: 0.8478 - val_loss: 2.2713 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.73000\n",
      "Epoch 343/2000\n",
      "113/113 - 2s - loss: 0.1312 - accuracy: 0.9511 - val_loss: 2.3963 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.73000\n",
      "Epoch 344/2000\n",
      "113/113 - 2s - loss: 0.0645 - accuracy: 0.9800 - val_loss: 2.2539 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.73000\n",
      "Epoch 345/2000\n",
      "113/113 - 2s - loss: 0.0268 - accuracy: 0.9967 - val_loss: 2.3612 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.73000\n",
      "Epoch 346/2000\n",
      "113/113 - 2s - loss: 0.0150 - accuracy: 0.9989 - val_loss: 2.2357 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.73000\n",
      "Epoch 347/2000\n",
      "113/113 - 2s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.2746 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.73000\n",
      "Epoch 348/2000\n",
      "113/113 - 2s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2752 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.73000\n",
      "Epoch 349/2000\n",
      "113/113 - 2s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.2867 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.73000\n",
      "Epoch 350/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.3240 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.73000\n",
      "Epoch 351/2000\n",
      "113/113 - 2s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.3070 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.73000\n",
      "Epoch 352/2000\n",
      "113/113 - 2s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.3193 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.73000\n",
      "Epoch 353/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.3469 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.73000\n",
      "Epoch 354/2000\n",
      "113/113 - 2s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.73000\n",
      "Epoch 355/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.3588 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.73000\n",
      "Epoch 356/2000\n",
      "113/113 - 2s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.3851 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.73000\n",
      "Epoch 357/2000\n",
      "113/113 - 2s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.3918 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.73000\n",
      "Epoch 358/2000\n",
      "113/113 - 2s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.4002 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.73000\n",
      "Epoch 359/2000\n",
      "113/113 - 2s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.4007 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.73000\n",
      "Epoch 360/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.4180 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.73000\n",
      "Epoch 361/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.4282 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.73000\n",
      "Epoch 362/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4529 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.73000\n",
      "Epoch 363/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4679 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.73000\n",
      "Epoch 364/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4717 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.73000\n",
      "Epoch 365/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.73000\n",
      "Epoch 366/2000\n",
      "113/113 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.4856 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.73000\n",
      "Epoch 367/2000\n",
      "113/113 - 2s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5105 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.73000\n",
      "Epoch 368/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5276 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.73000\n",
      "Epoch 369/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.5312 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.73000\n",
      "Epoch 370/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.5440 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.73000\n",
      "Epoch 371/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.73000\n",
      "Epoch 372/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5681 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.73000\n",
      "Epoch 373/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5567 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.73000\n",
      "Epoch 374/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5793 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.73000\n",
      "Epoch 375/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.6018 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.73000\n",
      "Epoch 376/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6136 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.73000\n",
      "Epoch 377/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.73000\n",
      "Epoch 378/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.6365 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.73000\n",
      "Epoch 379/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.73000\n",
      "Epoch 380/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.6527 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.73000\n",
      "Epoch 381/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6501 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.73000\n",
      "Epoch 382/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6784 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.73000\n",
      "Epoch 383/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6982 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.73000\n",
      "Epoch 384/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6925 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.73000\n",
      "Epoch 385/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.7067 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.73000\n",
      "Epoch 386/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6996 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.73000\n",
      "Epoch 387/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7203 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.73000\n",
      "Epoch 388/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7382 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.73000\n",
      "Epoch 389/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7565 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.73000\n",
      "Epoch 390/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7483 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.73000\n",
      "Epoch 391/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.73000\n",
      "Epoch 392/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7843 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.73000\n",
      "Epoch 393/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.73000\n",
      "Epoch 394/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.73000\n",
      "Epoch 395/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7671 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.73000\n",
      "Epoch 396/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7695 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.73000\n",
      "Epoch 397/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8017 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.73000\n",
      "Epoch 398/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8149 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.73000\n",
      "Epoch 399/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8388 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.73000\n",
      "Epoch 400/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7634 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.73000\n",
      "Epoch 401/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.8635 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.73000\n",
      "Epoch 402/2000\n",
      "113/113 - 2s - loss: 0.7395 - accuracy: 0.8856 - val_loss: 3.2304 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.73000\n",
      "Epoch 403/2000\n",
      "113/113 - 2s - loss: 0.6750 - accuracy: 0.8600 - val_loss: 2.0803 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.73000\n",
      "Epoch 404/2000\n",
      "113/113 - 2s - loss: 0.1173 - accuracy: 0.9567 - val_loss: 2.0241 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.73000\n",
      "Epoch 405/2000\n",
      "113/113 - 2s - loss: 0.0377 - accuracy: 0.9922 - val_loss: 2.1750 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.73000\n",
      "Epoch 406/2000\n",
      "113/113 - 2s - loss: 0.0193 - accuracy: 0.9989 - val_loss: 2.1991 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.73000\n",
      "Epoch 407/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2194 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.73000\n",
      "Epoch 408/2000\n",
      "113/113 - 2s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2582 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.73000\n",
      "Epoch 409/2000\n",
      "113/113 - 2s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.2885 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.73000\n",
      "Epoch 410/2000\n",
      "113/113 - 2s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.3367 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.73000\n",
      "Epoch 411/2000\n",
      "113/113 - 2s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.3483 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.73000\n",
      "Epoch 412/2000\n",
      "113/113 - 2s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.3746 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.73000\n",
      "Epoch 413/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.4120 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.73000\n",
      "Epoch 414/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.4365 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.73000\n",
      "Epoch 415/2000\n",
      "113/113 - 2s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4504 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.73000\n",
      "Epoch 416/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.4956 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.73000\n",
      "Epoch 417/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.4928 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.73000\n",
      "Epoch 418/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.73000\n",
      "Epoch 419/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.5365 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.73000\n",
      "Epoch 420/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.5633 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.73000\n",
      "Epoch 421/2000\n",
      "113/113 - 2s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5639 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.73000\n",
      "Epoch 422/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5798 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.73000\n",
      "Epoch 423/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.5877 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.73000\n",
      "Epoch 424/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5960 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.73000\n",
      "Epoch 425/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.6245 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.73000\n",
      "Epoch 426/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.6274 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.73000\n",
      "Epoch 427/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6438 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.73000\n",
      "Epoch 428/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.6693 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.73000\n",
      "Epoch 429/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.6855 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.73000\n",
      "Epoch 430/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6850 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.73000\n",
      "Epoch 431/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6905 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.73000\n",
      "Epoch 432/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6972 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.73000\n",
      "Epoch 433/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7332 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.73000\n",
      "Epoch 434/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.73000\n",
      "Epoch 435/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.7270 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.73000\n",
      "Epoch 436/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7364 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.73000\n",
      "Epoch 437/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7492 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.73000\n",
      "Epoch 438/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7591 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.73000\n",
      "Epoch 439/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7704 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.73000\n",
      "Epoch 440/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7789 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.73000\n",
      "Epoch 441/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7585 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.73000\n",
      "Epoch 442/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.73000\n",
      "Epoch 443/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.73000\n",
      "Epoch 444/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.73000\n",
      "Epoch 445/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.73000\n",
      "Epoch 446/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.73000\n",
      "Epoch 447/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8547 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.73000\n",
      "Epoch 448/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.73000\n",
      "Epoch 449/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.8159 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.73000\n",
      "Epoch 450/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.73000\n",
      "Epoch 451/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.8707 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.73000\n",
      "Epoch 452/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.8316 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.73000\n",
      "Epoch 453/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.73000\n",
      "Epoch 454/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.8752 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.73000\n",
      "Epoch 455/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.9065 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.73000\n",
      "Epoch 456/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8534 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.73000\n",
      "Epoch 457/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8807 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.73000\n",
      "Epoch 458/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.8840 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.73000\n",
      "Epoch 459/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8951 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.73000\n",
      "Epoch 460/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.73000\n",
      "Epoch 461/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.9012 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.73000\n",
      "Epoch 462/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.8945 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.73000\n",
      "Epoch 463/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8367 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.73000\n",
      "Epoch 464/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8485 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.73000\n",
      "Epoch 465/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8953 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.73000\n",
      "Epoch 466/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.73000\n",
      "Epoch 467/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8728 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.73000\n",
      "Epoch 468/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8560 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.73000\n",
      "Epoch 469/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.9151 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.73000\n",
      "Epoch 470/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.73000\n",
      "Epoch 471/2000\n",
      "113/113 - 2s - loss: 0.0141 - accuracy: 0.9967 - val_loss: 3.8928 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.73000\n",
      "Epoch 472/2000\n",
      "113/113 - 2s - loss: 1.5996 - accuracy: 0.7744 - val_loss: 3.1971 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.73000\n",
      "Epoch 473/2000\n",
      "113/113 - 2s - loss: 0.2951 - accuracy: 0.9044 - val_loss: 2.3903 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.73000\n",
      "Epoch 474/2000\n",
      "113/113 - 2s - loss: 0.0897 - accuracy: 0.9667 - val_loss: 2.2993 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.73000\n",
      "Epoch 475/2000\n",
      "113/113 - 2s - loss: 0.0351 - accuracy: 0.9889 - val_loss: 2.2436 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.73000\n",
      "Epoch 476/2000\n",
      "113/113 - 2s - loss: 0.0246 - accuracy: 0.9967 - val_loss: 2.3332 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.73000\n",
      "Epoch 477/2000\n",
      "113/113 - 2s - loss: 0.0160 - accuracy: 0.9989 - val_loss: 2.3201 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.73000\n",
      "Epoch 478/2000\n",
      "113/113 - 2s - loss: 0.0131 - accuracy: 0.9989 - val_loss: 2.3296 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.73000\n",
      "Epoch 479/2000\n",
      "113/113 - 2s - loss: 0.0119 - accuracy: 0.9989 - val_loss: 2.3459 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.73000\n",
      "Epoch 480/2000\n",
      "113/113 - 2s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.3841 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.73000\n",
      "Epoch 481/2000\n",
      "113/113 - 2s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3800 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.73000\n",
      "Epoch 482/2000\n",
      "113/113 - 2s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.3911 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.73000\n",
      "Epoch 483/2000\n",
      "113/113 - 2s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.4088 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.73000\n",
      "Epoch 484/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.4166 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.73000\n",
      "Epoch 485/2000\n",
      "113/113 - 2s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4314 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.73000\n",
      "Epoch 486/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.4469 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.73000\n",
      "Epoch 487/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.4769 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.73000\n",
      "Epoch 488/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4901 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.73000\n",
      "Epoch 489/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4907 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.73000\n",
      "Epoch 490/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4977 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.73000\n",
      "Epoch 491/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.5169 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.73000\n",
      "Epoch 492/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.73000\n",
      "Epoch 493/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5431 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.73000\n",
      "Epoch 494/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.5644 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.73000\n",
      "Epoch 495/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.5618 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.73000\n",
      "Epoch 496/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5935 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.73000\n",
      "Epoch 497/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5881 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.73000\n",
      "Epoch 498/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.73000\n",
      "Epoch 499/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6098 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.73000\n",
      "Epoch 500/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.6368 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.73000\n",
      "Epoch 501/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00501: val_accuracy did not improve from 0.73000\n",
      "Epoch 502/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.6649 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00502: val_accuracy did not improve from 0.73000\n",
      "Epoch 503/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6840 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00503: val_accuracy did not improve from 0.73000\n",
      "Epoch 504/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6769 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00504: val_accuracy did not improve from 0.73000\n",
      "Epoch 505/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6900 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00505: val_accuracy did not improve from 0.73000\n",
      "Epoch 506/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6852 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00506: val_accuracy did not improve from 0.73000\n",
      "Epoch 507/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.7193 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00507: val_accuracy did not improve from 0.73000\n",
      "Epoch 508/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.7140 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00508: val_accuracy did not improve from 0.73000\n",
      "Epoch 509/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7286 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00509: val_accuracy did not improve from 0.73000\n",
      "Epoch 510/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7455 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00510: val_accuracy did not improve from 0.73000\n",
      "Epoch 511/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7707 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00511: val_accuracy did not improve from 0.73000\n",
      "Epoch 512/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00512: val_accuracy did not improve from 0.73000\n",
      "Epoch 513/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00513: val_accuracy did not improve from 0.73000\n",
      "Epoch 514/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00514: val_accuracy did not improve from 0.73000\n",
      "Epoch 515/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00515: val_accuracy did not improve from 0.73000\n",
      "Epoch 516/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00516: val_accuracy did not improve from 0.73000\n",
      "Epoch 517/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8541 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00517: val_accuracy did not improve from 0.73000\n",
      "Epoch 518/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.8458 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00518: val_accuracy did not improve from 0.73000\n",
      "Epoch 519/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8572 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00519: val_accuracy did not improve from 0.73000\n",
      "Epoch 520/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.9017 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00520: val_accuracy did not improve from 0.73000\n",
      "Epoch 521/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8820 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00521: val_accuracy did not improve from 0.73000\n",
      "Epoch 522/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8854 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00522: val_accuracy did not improve from 0.73000\n",
      "Epoch 523/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.9158 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00523: val_accuracy did not improve from 0.73000\n",
      "Epoch 524/2000\n",
      "113/113 - 2s - loss: 1.0171 - accuracy: 0.8222 - val_loss: 2.6340 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00524: val_accuracy did not improve from 0.73000\n",
      "Epoch 525/2000\n",
      "113/113 - 2s - loss: 0.3202 - accuracy: 0.8967 - val_loss: 1.8329 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00525: val_accuracy did not improve from 0.73000\n",
      "Epoch 526/2000\n",
      "113/113 - 2s - loss: 0.0723 - accuracy: 0.9722 - val_loss: 2.0243 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00526: val_accuracy did not improve from 0.73000\n",
      "Epoch 527/2000\n",
      "113/113 - 2s - loss: 0.0314 - accuracy: 0.9922 - val_loss: 2.0381 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00527: val_accuracy did not improve from 0.73000\n",
      "Epoch 528/2000\n",
      "113/113 - 2s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.0982 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00528: val_accuracy did not improve from 0.73000\n",
      "Epoch 529/2000\n",
      "113/113 - 2s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00529: val_accuracy did not improve from 0.73000\n",
      "Epoch 530/2000\n",
      "113/113 - 2s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.1962 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00530: val_accuracy did not improve from 0.73000\n",
      "Epoch 531/2000\n",
      "113/113 - 2s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.1977 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00531: val_accuracy did not improve from 0.73000\n",
      "Epoch 532/2000\n",
      "113/113 - 2s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.2655 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00532: val_accuracy did not improve from 0.73000\n",
      "Epoch 533/2000\n",
      "113/113 - 2s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.2972 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00533: val_accuracy did not improve from 0.73000\n",
      "Epoch 534/2000\n",
      "113/113 - 2s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.3105 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00534: val_accuracy did not improve from 0.73000\n",
      "Epoch 535/2000\n",
      "113/113 - 2s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00535: val_accuracy did not improve from 0.73000\n",
      "Epoch 536/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.3504 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00536: val_accuracy did not improve from 0.73000\n",
      "Epoch 537/2000\n",
      "113/113 - 2s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.3720 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00537: val_accuracy did not improve from 0.73000\n",
      "Epoch 538/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3914 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00538: val_accuracy did not improve from 0.73000\n",
      "Epoch 539/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4183 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00539: val_accuracy did not improve from 0.73000\n",
      "Epoch 540/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4229 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00540: val_accuracy did not improve from 0.73000\n",
      "Epoch 541/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.4606 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00541: val_accuracy did not improve from 0.73000\n",
      "Epoch 542/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.4917 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00542: val_accuracy did not improve from 0.73000\n",
      "Epoch 543/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.4782 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00543: val_accuracy did not improve from 0.73000\n",
      "Epoch 544/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.5254 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00544: val_accuracy did not improve from 0.73000\n",
      "Epoch 545/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5306 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00545: val_accuracy did not improve from 0.73000\n",
      "Epoch 546/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5390 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00546: val_accuracy did not improve from 0.73000\n",
      "Epoch 547/2000\n",
      "113/113 - 3s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.5770 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00547: val_accuracy did not improve from 0.73000\n",
      "Epoch 548/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.5763 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00548: val_accuracy did not improve from 0.73000\n",
      "Epoch 549/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.5753 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00549: val_accuracy did not improve from 0.73000\n",
      "Epoch 550/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.5950 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00550: val_accuracy did not improve from 0.73000\n",
      "Epoch 551/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00551: val_accuracy did not improve from 0.73000\n",
      "Epoch 552/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6385 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00552: val_accuracy did not improve from 0.73000\n",
      "Epoch 553/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6296 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00553: val_accuracy did not improve from 0.73000\n",
      "Epoch 554/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.6293 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00554: val_accuracy did not improve from 0.73000\n",
      "Epoch 555/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.6680 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00555: val_accuracy did not improve from 0.73000\n",
      "Epoch 556/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00556: val_accuracy did not improve from 0.73000\n",
      "Epoch 557/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6825 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00557: val_accuracy did not improve from 0.73000\n",
      "Epoch 558/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6891 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00558: val_accuracy did not improve from 0.73000\n",
      "Epoch 559/2000\n",
      "113/113 - 3s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.7114 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00559: val_accuracy did not improve from 0.73000\n",
      "Epoch 560/2000\n",
      "113/113 - 3s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00560: val_accuracy did not improve from 0.73000\n",
      "Epoch 561/2000\n",
      "113/113 - 3s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7343 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00561: val_accuracy did not improve from 0.73000\n",
      "Epoch 562/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7403 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00562: val_accuracy did not improve from 0.73000\n",
      "Epoch 563/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00563: val_accuracy did not improve from 0.73000\n",
      "Epoch 564/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7671 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00564: val_accuracy did not improve from 0.73000\n",
      "Epoch 565/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7686 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00565: val_accuracy did not improve from 0.73000\n",
      "Epoch 566/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7835 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00566: val_accuracy did not improve from 0.73000\n",
      "Epoch 567/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00567: val_accuracy did not improve from 0.73000\n",
      "Epoch 568/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7925 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00568: val_accuracy did not improve from 0.73000\n",
      "Epoch 569/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.8159 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00569: val_accuracy did not improve from 0.73000\n",
      "Epoch 570/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00570: val_accuracy did not improve from 0.73000\n",
      "Epoch 571/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.8099 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00571: val_accuracy did not improve from 0.73000\n",
      "Epoch 572/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.8470 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00572: val_accuracy did not improve from 0.73000\n",
      "Epoch 573/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8451 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00573: val_accuracy did not improve from 0.73000\n",
      "Epoch 574/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8576 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00574: val_accuracy did not improve from 0.73000\n",
      "Epoch 575/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8587 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00575: val_accuracy did not improve from 0.73000\n",
      "Epoch 576/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8659 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00576: val_accuracy did not improve from 0.73000\n",
      "Epoch 577/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.8698 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00577: val_accuracy did not improve from 0.73000\n",
      "Epoch 578/2000\n",
      "113/113 - 3s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.8692 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00578: val_accuracy did not improve from 0.73000\n",
      "Epoch 579/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.9117 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00579: val_accuracy did not improve from 0.73000\n",
      "Epoch 580/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.8905 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00580: val_accuracy did not improve from 0.73000\n",
      "Epoch 581/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9137 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00581: val_accuracy did not improve from 0.73000\n",
      "Epoch 582/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9284 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00582: val_accuracy did not improve from 0.73000\n",
      "Epoch 583/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00583: val_accuracy did not improve from 0.73000\n",
      "Epoch 584/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9371 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00584: val_accuracy did not improve from 0.73000\n",
      "Epoch 585/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9665 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00585: val_accuracy did not improve from 0.73000\n",
      "Epoch 586/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00586: val_accuracy did not improve from 0.73000\n",
      "Epoch 587/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9010 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00587: val_accuracy did not improve from 0.73000\n",
      "Epoch 588/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00588: val_accuracy did not improve from 0.73000\n",
      "Epoch 589/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.0795 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00589: val_accuracy did not improve from 0.73000\n",
      "Epoch 590/2000\n",
      "113/113 - 2s - loss: 1.0873 - accuracy: 0.8300 - val_loss: 2.9270 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00590: val_accuracy did not improve from 0.73000\n",
      "Epoch 591/2000\n",
      "113/113 - 2s - loss: 0.3185 - accuracy: 0.8967 - val_loss: 2.0548 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00591: val_accuracy did not improve from 0.73000\n",
      "Epoch 592/2000\n",
      "113/113 - 2s - loss: 0.0718 - accuracy: 0.9789 - val_loss: 2.1178 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00592: val_accuracy did not improve from 0.73000\n",
      "Epoch 593/2000\n",
      "113/113 - 2s - loss: 0.0264 - accuracy: 0.9978 - val_loss: 2.1327 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00593: val_accuracy did not improve from 0.73000\n",
      "Epoch 594/2000\n",
      "113/113 - 2s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.2417 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00594: val_accuracy did not improve from 0.73000\n",
      "Epoch 595/2000\n",
      "113/113 - 2s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.2360 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00595: val_accuracy did not improve from 0.73000\n",
      "Epoch 596/2000\n",
      "113/113 - 2s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.2605 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00596: val_accuracy did not improve from 0.73000\n",
      "Epoch 597/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.2939 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00597: val_accuracy did not improve from 0.73000\n",
      "Epoch 598/2000\n",
      "113/113 - 2s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.3140 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00598: val_accuracy did not improve from 0.73000\n",
      "Epoch 599/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.3599 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00599: val_accuracy did not improve from 0.73000\n",
      "Epoch 600/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.3619 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00600: val_accuracy did not improve from 0.73000\n",
      "Epoch 601/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.4176 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00601: val_accuracy did not improve from 0.73000\n",
      "Epoch 602/2000\n",
      "113/113 - 2s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4093 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00602: val_accuracy did not improve from 0.73000\n",
      "Epoch 603/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4388 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00603: val_accuracy did not improve from 0.73000\n",
      "Epoch 604/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.4522 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00604: val_accuracy did not improve from 0.73000\n",
      "Epoch 605/2000\n",
      "113/113 - 2s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.4810 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00605: val_accuracy did not improve from 0.73000\n",
      "Epoch 606/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4903 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00606: val_accuracy did not improve from 0.73000\n",
      "Epoch 607/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5241 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00607: val_accuracy did not improve from 0.73000\n",
      "Epoch 608/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.5294 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00608: val_accuracy did not improve from 0.73000\n",
      "Epoch 609/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.5319 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00609: val_accuracy did not improve from 0.73000\n",
      "Epoch 610/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.5534 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00610: val_accuracy did not improve from 0.73000\n",
      "Epoch 611/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5754 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00611: val_accuracy did not improve from 0.73000\n",
      "Epoch 612/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5901 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00612: val_accuracy did not improve from 0.73000\n",
      "Epoch 613/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00613: val_accuracy did not improve from 0.73000\n",
      "Epoch 614/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6094 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00614: val_accuracy did not improve from 0.73000\n",
      "Epoch 615/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6049 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00615: val_accuracy did not improve from 0.73000\n",
      "Epoch 616/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.6309 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00616: val_accuracy did not improve from 0.73000\n",
      "Epoch 617/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.6262 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00617: val_accuracy did not improve from 0.73000\n",
      "Epoch 618/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6566 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00618: val_accuracy did not improve from 0.73000\n",
      "Epoch 619/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00619: val_accuracy did not improve from 0.73000\n",
      "Epoch 620/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6721 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00620: val_accuracy did not improve from 0.73000\n",
      "Epoch 621/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6781 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00621: val_accuracy did not improve from 0.73000\n",
      "Epoch 622/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6973 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00622: val_accuracy did not improve from 0.73000\n",
      "Epoch 623/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6875 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00623: val_accuracy did not improve from 0.73000\n",
      "Epoch 624/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.7014 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00624: val_accuracy did not improve from 0.73000\n",
      "Epoch 625/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.7123 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00625: val_accuracy did not improve from 0.73000\n",
      "Epoch 626/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.7154 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00626: val_accuracy did not improve from 0.73000\n",
      "Epoch 627/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7425 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00627: val_accuracy did not improve from 0.73000\n",
      "Epoch 628/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00628: val_accuracy did not improve from 0.73000\n",
      "Epoch 629/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7374 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00629: val_accuracy did not improve from 0.73000\n",
      "Epoch 630/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7613 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00630: val_accuracy did not improve from 0.73000\n",
      "Epoch 631/2000\n",
      "113/113 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00631: val_accuracy did not improve from 0.73000\n",
      "Epoch 632/2000\n",
      "113/113 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00632: val_accuracy did not improve from 0.73000\n",
      "Epoch 633/2000\n",
      "113/113 - 3s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00633: val_accuracy did not improve from 0.73000\n",
      "Epoch 634/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7919 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00634: val_accuracy did not improve from 0.73000\n",
      "Epoch 635/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8178 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00635: val_accuracy did not improve from 0.73000\n",
      "Epoch 636/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00636: val_accuracy did not improve from 0.73000\n",
      "Epoch 637/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8078 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00637: val_accuracy did not improve from 0.73000\n",
      "Epoch 638/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8256 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00638: val_accuracy did not improve from 0.73000\n",
      "Epoch 639/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8227 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00639: val_accuracy did not improve from 0.73000\n",
      "Epoch 640/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00640: val_accuracy did not improve from 0.73000\n",
      "Epoch 641/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8318 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00641: val_accuracy did not improve from 0.73000\n",
      "Epoch 642/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00642: val_accuracy did not improve from 0.73000\n",
      "Epoch 643/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00643: val_accuracy did not improve from 0.73000\n",
      "Epoch 644/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00644: val_accuracy did not improve from 0.73000\n",
      "Epoch 645/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8429 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00645: val_accuracy did not improve from 0.73000\n",
      "Epoch 646/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8560 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00646: val_accuracy did not improve from 0.73000\n",
      "Epoch 647/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8760 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00647: val_accuracy did not improve from 0.73000\n",
      "Epoch 648/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8735 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00648: val_accuracy did not improve from 0.73000\n",
      "Epoch 649/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8948 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00649: val_accuracy did not improve from 0.73000\n",
      "Epoch 650/2000\n",
      "113/113 - 3s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8984 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00650: val_accuracy did not improve from 0.73000\n",
      "Epoch 651/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00651: val_accuracy did not improve from 0.73000\n",
      "Epoch 652/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.9234 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00652: val_accuracy did not improve from 0.73000\n",
      "Epoch 653/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8693 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00653: val_accuracy did not improve from 0.73000\n",
      "Epoch 654/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.9132 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00654: val_accuracy did not improve from 0.73000\n",
      "Epoch 655/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8882 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00655: val_accuracy did not improve from 0.73000\n",
      "Epoch 656/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.0012 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00656: val_accuracy did not improve from 0.73000\n",
      "Epoch 657/2000\n",
      "113/113 - 2s - loss: 0.9347 - accuracy: 0.8389 - val_loss: 2.4105 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00657: val_accuracy did not improve from 0.73000\n",
      "Epoch 658/2000\n",
      "113/113 - 2s - loss: 0.2734 - accuracy: 0.9100 - val_loss: 2.1292 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00658: val_accuracy did not improve from 0.73000\n",
      "Epoch 659/2000\n",
      "113/113 - 2s - loss: 0.0926 - accuracy: 0.9722 - val_loss: 2.1898 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00659: val_accuracy did not improve from 0.73000\n",
      "Epoch 660/2000\n",
      "113/113 - 2s - loss: 0.0422 - accuracy: 0.9933 - val_loss: 2.1790 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00660: val_accuracy did not improve from 0.73000\n",
      "Epoch 661/2000\n",
      "113/113 - 2s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.2112 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00661: val_accuracy did not improve from 0.73000\n",
      "Epoch 662/2000\n",
      "113/113 - 2s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.2169 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00662: val_accuracy did not improve from 0.73000\n",
      "Epoch 663/2000\n",
      "113/113 - 2s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2460 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00663: val_accuracy did not improve from 0.73000\n",
      "Epoch 664/2000\n",
      "113/113 - 2s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.2757 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00664: val_accuracy did not improve from 0.73000\n",
      "Epoch 665/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.2779 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00665: val_accuracy did not improve from 0.73000\n",
      "Epoch 666/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.3028 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00666: val_accuracy did not improve from 0.73000\n",
      "Epoch 667/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.3057 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00667: val_accuracy did not improve from 0.73000\n",
      "Epoch 668/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.3287 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00668: val_accuracy did not improve from 0.73000\n",
      "Epoch 669/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.3555 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00669: val_accuracy did not improve from 0.73000\n",
      "Epoch 670/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.3541 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00670: val_accuracy did not improve from 0.73000\n",
      "Epoch 671/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.3636 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00671: val_accuracy did not improve from 0.73000\n",
      "Epoch 672/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.3850 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00672: val_accuracy did not improve from 0.73000\n",
      "Epoch 673/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4072 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00673: val_accuracy did not improve from 0.73000\n",
      "Epoch 674/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4108 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00674: val_accuracy did not improve from 0.73000\n",
      "Epoch 675/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.4327 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00675: val_accuracy did not improve from 0.73000\n",
      "Epoch 676/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4381 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00676: val_accuracy did not improve from 0.73000\n",
      "Epoch 677/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.4574 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00677: val_accuracy did not improve from 0.73000\n",
      "Epoch 678/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4735 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00678: val_accuracy did not improve from 0.73000\n",
      "Epoch 679/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4769 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00679: val_accuracy did not improve from 0.73000\n",
      "Epoch 680/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4838 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00680: val_accuracy did not improve from 0.73000\n",
      "Epoch 681/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.4984 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00681: val_accuracy did not improve from 0.73000\n",
      "Epoch 682/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.5198 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00682: val_accuracy did not improve from 0.73000\n",
      "Epoch 683/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5487 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00683: val_accuracy did not improve from 0.73000\n",
      "Epoch 684/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5359 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00684: val_accuracy did not improve from 0.73000\n",
      "Epoch 685/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5417 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00685: val_accuracy did not improve from 0.73000\n",
      "Epoch 686/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5586 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00686: val_accuracy did not improve from 0.73000\n",
      "Epoch 687/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5822 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00687: val_accuracy did not improve from 0.73000\n",
      "Epoch 688/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5792 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00688: val_accuracy did not improve from 0.73000\n",
      "Epoch 689/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5957 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00689: val_accuracy did not improve from 0.73000\n",
      "Epoch 690/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6093 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00690: val_accuracy did not improve from 0.73000\n",
      "Epoch 691/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6113 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00691: val_accuracy did not improve from 0.73000\n",
      "Epoch 692/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6335 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00692: val_accuracy did not improve from 0.73000\n",
      "Epoch 693/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6379 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00693: val_accuracy did not improve from 0.73000\n",
      "Epoch 694/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6549 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00694: val_accuracy did not improve from 0.73000\n",
      "Epoch 695/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6724 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00695: val_accuracy did not improve from 0.73000\n",
      "Epoch 696/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6782 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00696: val_accuracy did not improve from 0.73000\n",
      "Epoch 697/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6801 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00697: val_accuracy did not improve from 0.73000\n",
      "Epoch 698/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7028 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00698: val_accuracy did not improve from 0.73000\n",
      "Epoch 699/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7157 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00699: val_accuracy did not improve from 0.73000\n",
      "Epoch 700/2000\n",
      "113/113 - 3s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7199 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00700: val_accuracy did not improve from 0.73000\n",
      "Epoch 701/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7360 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00701: val_accuracy did not improve from 0.73000\n",
      "Epoch 702/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7290 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00702: val_accuracy did not improve from 0.73000\n",
      "Epoch 703/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7578 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00703: val_accuracy did not improve from 0.73000\n",
      "Epoch 704/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7668 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00704: val_accuracy did not improve from 0.73000\n",
      "Epoch 705/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7644 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00705: val_accuracy did not improve from 0.73000\n",
      "Epoch 706/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00706: val_accuracy did not improve from 0.73000\n",
      "Epoch 707/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7672 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00707: val_accuracy did not improve from 0.73000\n",
      "Epoch 708/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00708: val_accuracy did not improve from 0.73000\n",
      "Epoch 709/2000\n",
      "113/113 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.7877 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00709: val_accuracy did not improve from 0.73000\n",
      "Epoch 710/2000\n",
      "113/113 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00710: val_accuracy did not improve from 0.73000\n",
      "Epoch 711/2000\n",
      "113/113 - 3s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8229 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00711: val_accuracy did not improve from 0.73000\n",
      "Epoch 712/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00712: val_accuracy did not improve from 0.73000\n",
      "Epoch 713/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8460 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00713: val_accuracy did not improve from 0.73000\n",
      "Epoch 714/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8632 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00714: val_accuracy did not improve from 0.73000\n",
      "Epoch 715/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8602 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00715: val_accuracy did not improve from 0.73000\n",
      "Epoch 716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8793 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00716: val_accuracy did not improve from 0.73000\n",
      "Epoch 717/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8606 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00717: val_accuracy did not improve from 0.73000\n",
      "Epoch 718/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8509 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00718: val_accuracy did not improve from 0.73000\n",
      "Epoch 719/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8923 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00719: val_accuracy did not improve from 0.73000\n",
      "Epoch 720/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00720: val_accuracy did not improve from 0.73000\n",
      "Epoch 721/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9311 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00721: val_accuracy did not improve from 0.73000\n",
      "Epoch 722/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9101 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00722: val_accuracy did not improve from 0.73000\n",
      "Epoch 723/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9182 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00723: val_accuracy did not improve from 0.73000\n",
      "Epoch 724/2000\n",
      "113/113 - 2s - loss: 0.3636 - accuracy: 0.9489 - val_loss: 4.2867 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00724: val_accuracy did not improve from 0.73000\n",
      "Epoch 725/2000\n",
      "113/113 - 2s - loss: 0.7781 - accuracy: 0.8389 - val_loss: 2.2387 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00725: val_accuracy did not improve from 0.73000\n",
      "Epoch 726/2000\n",
      "113/113 - 2s - loss: 0.1938 - accuracy: 0.9411 - val_loss: 2.4730 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00726: val_accuracy did not improve from 0.73000\n",
      "Epoch 727/2000\n",
      "113/113 - 2s - loss: 0.0556 - accuracy: 0.9811 - val_loss: 2.3142 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00727: val_accuracy did not improve from 0.73000\n",
      "Epoch 728/2000\n",
      "113/113 - 2s - loss: 0.0233 - accuracy: 0.9967 - val_loss: 2.4245 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00728: val_accuracy did not improve from 0.73000\n",
      "Epoch 729/2000\n",
      "113/113 - 2s - loss: 0.0129 - accuracy: 0.9989 - val_loss: 2.2997 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00729: val_accuracy did not improve from 0.73000\n",
      "Epoch 730/2000\n",
      "113/113 - 2s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.3484 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00730: val_accuracy did not improve from 0.73000\n",
      "Epoch 731/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3790 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00731: val_accuracy did not improve from 0.73000\n",
      "Epoch 732/2000\n",
      "113/113 - 2s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.3983 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00732: val_accuracy did not improve from 0.73000\n",
      "Epoch 733/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.4282 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00733: val_accuracy did not improve from 0.73000\n",
      "Epoch 734/2000\n",
      "113/113 - 2s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.4526 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00734: val_accuracy did not improve from 0.73000\n",
      "Epoch 735/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4648 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00735: val_accuracy did not improve from 0.73000\n",
      "Epoch 736/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4759 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00736: val_accuracy did not improve from 0.73000\n",
      "Epoch 737/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4965 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00737: val_accuracy did not improve from 0.73000\n",
      "Epoch 738/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5115 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00738: val_accuracy did not improve from 0.73000\n",
      "Epoch 739/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5315 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00739: val_accuracy did not improve from 0.73000\n",
      "Epoch 740/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5481 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00740: val_accuracy did not improve from 0.73000\n",
      "Epoch 741/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5577 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00741: val_accuracy did not improve from 0.73000\n",
      "Epoch 742/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.5663 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00742: val_accuracy did not improve from 0.73000\n",
      "Epoch 743/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5848 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00743: val_accuracy did not improve from 0.73000\n",
      "Epoch 744/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.5999 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00744: val_accuracy did not improve from 0.73000\n",
      "Epoch 745/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6189 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00745: val_accuracy did not improve from 0.73000\n",
      "Epoch 746/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00746: val_accuracy did not improve from 0.73000\n",
      "Epoch 747/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.6358 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00747: val_accuracy did not improve from 0.73000\n",
      "Epoch 748/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.6570 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00748: val_accuracy did not improve from 0.73000\n",
      "Epoch 749/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.6734 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00749: val_accuracy did not improve from 0.73000\n",
      "Epoch 750/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.6860 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00750: val_accuracy did not improve from 0.73000\n",
      "Epoch 751/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6983 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00751: val_accuracy did not improve from 0.73000\n",
      "Epoch 752/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00752: val_accuracy did not improve from 0.73000\n",
      "Epoch 753/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.7132 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00753: val_accuracy did not improve from 0.73000\n",
      "Epoch 754/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7368 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00754: val_accuracy did not improve from 0.73000\n",
      "Epoch 755/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7533 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00755: val_accuracy did not improve from 0.73000\n",
      "Epoch 756/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00756: val_accuracy did not improve from 0.73000\n",
      "Epoch 757/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7616 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00757: val_accuracy did not improve from 0.73000\n",
      "Epoch 758/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7697 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00758: val_accuracy did not improve from 0.73000\n",
      "Epoch 759/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00759: val_accuracy did not improve from 0.73000\n",
      "Epoch 760/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8003 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00760: val_accuracy did not improve from 0.73000\n",
      "Epoch 761/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00761: val_accuracy did not improve from 0.73000\n",
      "Epoch 762/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00762: val_accuracy did not improve from 0.73000\n",
      "Epoch 763/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8318 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00763: val_accuracy did not improve from 0.73000\n",
      "Epoch 764/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00764: val_accuracy did not improve from 0.73000\n",
      "Epoch 765/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8494 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00765: val_accuracy did not improve from 0.73000\n",
      "Epoch 766/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8510 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00766: val_accuracy did not improve from 0.73000\n",
      "Epoch 767/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8619 - val_accuracy: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00767: val_accuracy did not improve from 0.73000\n",
      "Epoch 768/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8853 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00768: val_accuracy did not improve from 0.73000\n",
      "Epoch 769/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8747 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00769: val_accuracy did not improve from 0.73000\n",
      "Epoch 770/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8866 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00770: val_accuracy did not improve from 0.73000\n",
      "Epoch 771/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8854 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00771: val_accuracy did not improve from 0.73000\n",
      "Epoch 772/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8824 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00772: val_accuracy did not improve from 0.73000\n",
      "Epoch 773/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9006 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00773: val_accuracy did not improve from 0.73000\n",
      "Epoch 774/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8996 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00774: val_accuracy did not improve from 0.73000\n",
      "Epoch 775/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9111 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00775: val_accuracy did not improve from 0.73000\n",
      "Epoch 776/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9265 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00776: val_accuracy did not improve from 0.73000\n",
      "Epoch 777/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00777: val_accuracy did not improve from 0.73000\n",
      "Epoch 778/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9336 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00778: val_accuracy did not improve from 0.73000\n",
      "Epoch 779/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9417 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00779: val_accuracy did not improve from 0.73000\n",
      "Epoch 780/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9699 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00780: val_accuracy did not improve from 0.73000\n",
      "Epoch 781/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9424 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00781: val_accuracy did not improve from 0.73000\n",
      "Epoch 782/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9650 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00782: val_accuracy did not improve from 0.73000\n",
      "Epoch 783/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9775 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00783: val_accuracy did not improve from 0.73000\n",
      "Epoch 784/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9763 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00784: val_accuracy did not improve from 0.73000\n",
      "Epoch 785/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9668 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00785: val_accuracy did not improve from 0.73000\n",
      "Epoch 786/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9821 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00786: val_accuracy did not improve from 0.73000\n",
      "Epoch 787/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9745 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00787: val_accuracy did not improve from 0.73000\n",
      "Epoch 788/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00788: val_accuracy did not improve from 0.73000\n",
      "Epoch 789/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9801 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00789: val_accuracy did not improve from 0.73000\n",
      "Epoch 790/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9737 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00790: val_accuracy did not improve from 0.73000\n",
      "Epoch 791/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0146 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00791: val_accuracy did not improve from 0.73000\n",
      "Epoch 792/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0338 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00792: val_accuracy did not improve from 0.73000\n",
      "Epoch 793/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00793: val_accuracy did not improve from 0.73000\n",
      "Epoch 794/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0166 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00794: val_accuracy did not improve from 0.73000\n",
      "Epoch 795/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00795: val_accuracy did not improve from 0.73000\n",
      "Epoch 796/2000\n",
      "113/113 - 2s - loss: 0.2183 - accuracy: 0.9622 - val_loss: 3.0747 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00796: val_accuracy did not improve from 0.73000\n",
      "Epoch 797/2000\n",
      "113/113 - 2s - loss: 0.9089 - accuracy: 0.8267 - val_loss: 2.4992 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00797: val_accuracy did not improve from 0.73000\n",
      "Epoch 798/2000\n",
      "113/113 - 2s - loss: 0.1913 - accuracy: 0.9433 - val_loss: 2.5393 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00798: val_accuracy did not improve from 0.73000\n",
      "Epoch 799/2000\n",
      "113/113 - 2s - loss: 0.0420 - accuracy: 0.9922 - val_loss: 2.5578 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00799: val_accuracy did not improve from 0.73000\n",
      "Epoch 800/2000\n",
      "113/113 - 2s - loss: 0.0165 - accuracy: 0.9989 - val_loss: 2.5067 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00800: val_accuracy did not improve from 0.73000\n",
      "Epoch 801/2000\n",
      "113/113 - 2s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.5939 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00801: val_accuracy did not improve from 0.73000\n",
      "Epoch 802/2000\n",
      "113/113 - 2s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.6082 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00802: val_accuracy did not improve from 0.73000\n",
      "Epoch 803/2000\n",
      "113/113 - 2s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.6257 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00803: val_accuracy did not improve from 0.73000\n",
      "Epoch 804/2000\n",
      "113/113 - 2s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.6578 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00804: val_accuracy did not improve from 0.73000\n",
      "Epoch 805/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6530 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00805: val_accuracy did not improve from 0.73000\n",
      "Epoch 806/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6817 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00806: val_accuracy did not improve from 0.73000\n",
      "Epoch 807/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6977 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00807: val_accuracy did not improve from 0.73000\n",
      "Epoch 808/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.7103 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00808: val_accuracy did not improve from 0.73000\n",
      "Epoch 809/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7222 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00809: val_accuracy did not improve from 0.73000\n",
      "Epoch 810/2000\n",
      "113/113 - 2s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7291 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00810: val_accuracy did not improve from 0.73000\n",
      "Epoch 811/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7447 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00811: val_accuracy did not improve from 0.73000\n",
      "Epoch 812/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.7688 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00812: val_accuracy did not improve from 0.73000\n",
      "Epoch 813/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.7751 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00813: val_accuracy did not improve from 0.73000\n",
      "Epoch 814/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00814: val_accuracy did not improve from 0.73000\n",
      "Epoch 815/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7982 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00815: val_accuracy did not improve from 0.73000\n",
      "Epoch 816/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00816: val_accuracy did not improve from 0.73000\n",
      "Epoch 817/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8243 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00817: val_accuracy did not improve from 0.73000\n",
      "Epoch 818/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8358 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00818: val_accuracy did not improve from 0.73000\n",
      "Epoch 819/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8523 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00819: val_accuracy did not improve from 0.73000\n",
      "Epoch 820/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8590 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00820: val_accuracy did not improve from 0.73000\n",
      "Epoch 821/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8678 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00821: val_accuracy did not improve from 0.73000\n",
      "Epoch 822/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8794 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00822: val_accuracy did not improve from 0.73000\n",
      "Epoch 823/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.9003 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00823: val_accuracy did not improve from 0.73000\n",
      "Epoch 824/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.9062 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00824: val_accuracy did not improve from 0.73000\n",
      "Epoch 825/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.9226 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00825: val_accuracy did not improve from 0.73000\n",
      "Epoch 826/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00826: val_accuracy did not improve from 0.73000\n",
      "Epoch 827/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00827: val_accuracy did not improve from 0.73000\n",
      "Epoch 828/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00828: val_accuracy did not improve from 0.73000\n",
      "Epoch 829/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9667 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00829: val_accuracy did not improve from 0.73000\n",
      "Epoch 830/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9729 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00830: val_accuracy did not improve from 0.73000\n",
      "Epoch 831/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9787 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00831: val_accuracy did not improve from 0.73000\n",
      "Epoch 832/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9855 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00832: val_accuracy did not improve from 0.73000\n",
      "Epoch 833/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9958 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00833: val_accuracy did not improve from 0.73000\n",
      "Epoch 834/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9918 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00834: val_accuracy did not improve from 0.73000\n",
      "Epoch 835/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0006 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00835: val_accuracy did not improve from 0.73000\n",
      "Epoch 836/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0242 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00836: val_accuracy did not improve from 0.73000\n",
      "Epoch 837/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0384 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00837: val_accuracy did not improve from 0.73000\n",
      "Epoch 838/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0336 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00838: val_accuracy did not improve from 0.73000\n",
      "Epoch 839/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.0479 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00839: val_accuracy did not improve from 0.73000\n",
      "Epoch 840/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0554 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00840: val_accuracy did not improve from 0.73000\n",
      "Epoch 841/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0543 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00841: val_accuracy did not improve from 0.73000\n",
      "Epoch 842/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0869 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00842: val_accuracy did not improve from 0.73000\n",
      "Epoch 843/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0657 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00843: val_accuracy did not improve from 0.73000\n",
      "Epoch 844/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0958 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00844: val_accuracy did not improve from 0.73000\n",
      "Epoch 845/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0930 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00845: val_accuracy did not improve from 0.73000\n",
      "Epoch 846/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0894 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00846: val_accuracy did not improve from 0.73000\n",
      "Epoch 847/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1170 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00847: val_accuracy did not improve from 0.73000\n",
      "Epoch 848/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1092 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00848: val_accuracy did not improve from 0.73000\n",
      "Epoch 849/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.0994 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00849: val_accuracy did not improve from 0.73000\n",
      "Epoch 850/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1156 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00850: val_accuracy did not improve from 0.73000\n",
      "Epoch 851/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1228 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00851: val_accuracy did not improve from 0.73000\n",
      "Epoch 852/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1197 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00852: val_accuracy did not improve from 0.73000\n",
      "Epoch 853/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1435 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00853: val_accuracy did not improve from 0.73000\n",
      "Epoch 854/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1283 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00854: val_accuracy did not improve from 0.73000\n",
      "Epoch 855/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00855: val_accuracy did not improve from 0.73000\n",
      "Epoch 856/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00856: val_accuracy did not improve from 0.73000\n",
      "Epoch 857/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.1609 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00857: val_accuracy did not improve from 0.73000\n",
      "Epoch 858/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1453 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00858: val_accuracy did not improve from 0.73000\n",
      "Epoch 859/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1559 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00859: val_accuracy did not improve from 0.73000\n",
      "Epoch 860/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1640 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00860: val_accuracy did not improve from 0.73000\n",
      "Epoch 861/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00861: val_accuracy did not improve from 0.73000\n",
      "Epoch 862/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1533 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00862: val_accuracy did not improve from 0.73000\n",
      "Epoch 863/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1592 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00863: val_accuracy did not improve from 0.73000\n",
      "Epoch 864/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1498 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00864: val_accuracy did not improve from 0.73000\n",
      "Epoch 865/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00865: val_accuracy did not improve from 0.73000\n",
      "Epoch 866/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1308 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00866: val_accuracy did not improve from 0.73000\n",
      "Epoch 867/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1293 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00867: val_accuracy did not improve from 0.73000\n",
      "Epoch 868/2000\n",
      "113/113 - 2s - loss: 0.6307 - accuracy: 0.9067 - val_loss: 3.1067 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00868: val_accuracy did not improve from 0.73000\n",
      "Epoch 869/2000\n",
      "113/113 - 2s - loss: 0.5070 - accuracy: 0.8900 - val_loss: 2.5034 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00869: val_accuracy did not improve from 0.73000\n",
      "Epoch 870/2000\n",
      "113/113 - 2s - loss: 0.1341 - accuracy: 0.9567 - val_loss: 2.3521 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00870: val_accuracy did not improve from 0.73000\n",
      "Epoch 871/2000\n",
      "113/113 - 2s - loss: 0.0220 - accuracy: 0.9956 - val_loss: 2.3583 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00871: val_accuracy did not improve from 0.73000\n",
      "Epoch 872/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.3872 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00872: val_accuracy did not improve from 0.73000\n",
      "Epoch 873/2000\n",
      "113/113 - 2s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.3998 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00873: val_accuracy did not improve from 0.73000\n",
      "Epoch 874/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.4180 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00874: val_accuracy did not improve from 0.73000\n",
      "Epoch 875/2000\n",
      "113/113 - 2s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4424 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00875: val_accuracy did not improve from 0.73000\n",
      "Epoch 876/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.4692 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00876: val_accuracy did not improve from 0.73000\n",
      "Epoch 877/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4856 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00877: val_accuracy did not improve from 0.73000\n",
      "Epoch 878/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5042 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00878: val_accuracy did not improve from 0.73000\n",
      "Epoch 879/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5215 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00879: val_accuracy did not improve from 0.73000\n",
      "Epoch 880/2000\n",
      "113/113 - 3s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5336 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00880: val_accuracy did not improve from 0.73000\n",
      "Epoch 881/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5602 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00881: val_accuracy did not improve from 0.73000\n",
      "Epoch 882/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5848 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00882: val_accuracy did not improve from 0.73000\n",
      "Epoch 883/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5994 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00883: val_accuracy did not improve from 0.73000\n",
      "Epoch 884/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6222 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00884: val_accuracy did not improve from 0.73000\n",
      "Epoch 885/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6410 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00885: val_accuracy did not improve from 0.73000\n",
      "Epoch 886/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.6544 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00886: val_accuracy did not improve from 0.73000\n",
      "Epoch 887/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6735 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00887: val_accuracy did not improve from 0.73000\n",
      "Epoch 888/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6935 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00888: val_accuracy did not improve from 0.73000\n",
      "Epoch 889/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6994 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00889: val_accuracy did not improve from 0.73000\n",
      "Epoch 890/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00890: val_accuracy did not improve from 0.73000\n",
      "Epoch 891/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00891: val_accuracy did not improve from 0.73000\n",
      "Epoch 892/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7353 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00892: val_accuracy did not improve from 0.73000\n",
      "Epoch 893/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7556 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00893: val_accuracy did not improve from 0.73000\n",
      "Epoch 894/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7684 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00894: val_accuracy did not improve from 0.73000\n",
      "Epoch 895/2000\n",
      "113/113 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7864 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00895: val_accuracy did not improve from 0.73000\n",
      "Epoch 896/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7893 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00896: val_accuracy did not improve from 0.73000\n",
      "Epoch 897/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7919 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00897: val_accuracy did not improve from 0.73000\n",
      "Epoch 898/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00898: val_accuracy did not improve from 0.73000\n",
      "Epoch 899/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8206 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00899: val_accuracy did not improve from 0.73000\n",
      "Epoch 900/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00900: val_accuracy did not improve from 0.73000\n",
      "Epoch 901/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00901: val_accuracy did not improve from 0.73000\n",
      "Epoch 902/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8549 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00902: val_accuracy did not improve from 0.73000\n",
      "Epoch 903/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8529 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00903: val_accuracy did not improve from 0.73000\n",
      "Epoch 904/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8636 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00904: val_accuracy did not improve from 0.73000\n",
      "Epoch 905/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8771 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00905: val_accuracy did not improve from 0.73000\n",
      "Epoch 906/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8786 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00906: val_accuracy did not improve from 0.73000\n",
      "Epoch 907/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8924 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00907: val_accuracy did not improve from 0.73000\n",
      "Epoch 908/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8949 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00908: val_accuracy did not improve from 0.73000\n",
      "Epoch 909/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9110 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00909: val_accuracy did not improve from 0.73000\n",
      "Epoch 910/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9267 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00910: val_accuracy did not improve from 0.73000\n",
      "Epoch 911/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9175 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00911: val_accuracy did not improve from 0.73000\n",
      "Epoch 912/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9227 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00912: val_accuracy did not improve from 0.73000\n",
      "Epoch 913/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9415 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00913: val_accuracy did not improve from 0.73000\n",
      "Epoch 914/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9527 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00914: val_accuracy did not improve from 0.73000\n",
      "Epoch 915/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9584 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00915: val_accuracy did not improve from 0.73000\n",
      "Epoch 916/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9800 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00916: val_accuracy did not improve from 0.73000\n",
      "Epoch 917/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9805 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00917: val_accuracy did not improve from 0.73000\n",
      "Epoch 918/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9857 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00918: val_accuracy did not improve from 0.73000\n",
      "Epoch 919/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9887 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00919: val_accuracy did not improve from 0.73000\n",
      "Epoch 920/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0127 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00920: val_accuracy did not improve from 0.73000\n",
      "Epoch 921/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.9947 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00921: val_accuracy did not improve from 0.73000\n",
      "Epoch 922/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0132 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00922: val_accuracy did not improve from 0.73000\n",
      "Epoch 923/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0279 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00923: val_accuracy did not improve from 0.73000\n",
      "Epoch 924/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0205 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00924: val_accuracy did not improve from 0.73000\n",
      "Epoch 925/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0377 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00925: val_accuracy did not improve from 0.73000\n",
      "Epoch 926/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0320 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00926: val_accuracy did not improve from 0.73000\n",
      "Epoch 927/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0350 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00927: val_accuracy did not improve from 0.73000\n",
      "Epoch 928/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0367 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00928: val_accuracy did not improve from 0.73000\n",
      "Epoch 929/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0545 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00929: val_accuracy did not improve from 0.73000\n",
      "Epoch 930/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0539 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00930: val_accuracy did not improve from 0.73000\n",
      "Epoch 931/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0474 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00931: val_accuracy did not improve from 0.73000\n",
      "Epoch 932/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0790 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00932: val_accuracy did not improve from 0.73000\n",
      "Epoch 933/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0662 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00933: val_accuracy did not improve from 0.73000\n",
      "Epoch 934/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0774 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00934: val_accuracy did not improve from 0.73000\n",
      "Epoch 935/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0631 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00935: val_accuracy did not improve from 0.73000\n",
      "Epoch 936/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0297 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00936: val_accuracy did not improve from 0.73000\n",
      "Epoch 937/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0784 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00937: val_accuracy did not improve from 0.73000\n",
      "Epoch 938/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0923 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00938: val_accuracy did not improve from 0.73000\n",
      "Epoch 939/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0628 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00939: val_accuracy did not improve from 0.73000\n",
      "Epoch 940/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.1670 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00940: val_accuracy did not improve from 0.73000\n",
      "Epoch 941/2000\n",
      "113/113 - 2s - loss: 0.8290 - accuracy: 0.8578 - val_loss: 2.8405 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00941: val_accuracy did not improve from 0.73000\n",
      "Epoch 942/2000\n",
      "113/113 - 2s - loss: 0.2488 - accuracy: 0.9233 - val_loss: 2.4609 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00942: val_accuracy did not improve from 0.73000\n",
      "Epoch 943/2000\n",
      "113/113 - 2s - loss: 0.0540 - accuracy: 0.9811 - val_loss: 2.3914 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00943: val_accuracy did not improve from 0.73000\n",
      "Epoch 944/2000\n",
      "113/113 - 2s - loss: 0.0175 - accuracy: 0.9978 - val_loss: 2.5839 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00944: val_accuracy did not improve from 0.73000\n",
      "Epoch 945/2000\n",
      "113/113 - 2s - loss: 0.0092 - accuracy: 0.9989 - val_loss: 2.5435 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00945: val_accuracy did not improve from 0.73000\n",
      "Epoch 946/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00946: val_accuracy did not improve from 0.73000\n",
      "Epoch 947/2000\n",
      "113/113 - 2s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.5294 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00947: val_accuracy did not improve from 0.73000\n",
      "Epoch 948/2000\n",
      "113/113 - 2s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5403 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00948: val_accuracy did not improve from 0.73000\n",
      "Epoch 949/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00949: val_accuracy did not improve from 0.73000\n",
      "Epoch 950/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5535 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00950: val_accuracy did not improve from 0.73000\n",
      "Epoch 951/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5589 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00951: val_accuracy did not improve from 0.73000\n",
      "Epoch 952/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5708 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00952: val_accuracy did not improve from 0.73000\n",
      "Epoch 953/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5759 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00953: val_accuracy did not improve from 0.73000\n",
      "Epoch 954/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.5889 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00954: val_accuracy did not improve from 0.73000\n",
      "Epoch 955/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5852 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00955: val_accuracy did not improve from 0.73000\n",
      "Epoch 956/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5984 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00956: val_accuracy did not improve from 0.73000\n",
      "Epoch 957/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6096 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00957: val_accuracy did not improve from 0.73000\n",
      "Epoch 958/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6173 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00958: val_accuracy did not improve from 0.73000\n",
      "Epoch 959/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6262 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00959: val_accuracy did not improve from 0.73000\n",
      "Epoch 960/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6331 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00960: val_accuracy did not improve from 0.73000\n",
      "Epoch 961/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6402 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00961: val_accuracy did not improve from 0.73000\n",
      "Epoch 962/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6478 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00962: val_accuracy did not improve from 0.73000\n",
      "Epoch 963/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6525 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00963: val_accuracy did not improve from 0.73000\n",
      "Epoch 964/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6648 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00964: val_accuracy did not improve from 0.73000\n",
      "Epoch 965/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6759 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00965: val_accuracy did not improve from 0.73000\n",
      "Epoch 966/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6840 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00966: val_accuracy did not improve from 0.73000\n",
      "Epoch 967/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6924 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00967: val_accuracy did not improve from 0.73000\n",
      "Epoch 968/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6939 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00968: val_accuracy did not improve from 0.73000\n",
      "Epoch 969/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7054 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00969: val_accuracy did not improve from 0.73000\n",
      "Epoch 970/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7101 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00970: val_accuracy did not improve from 0.73000\n",
      "Epoch 971/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7128 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00971: val_accuracy did not improve from 0.73000\n",
      "Epoch 972/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7269 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00972: val_accuracy did not improve from 0.73000\n",
      "Epoch 973/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00973: val_accuracy did not improve from 0.73000\n",
      "Epoch 974/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7474 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00974: val_accuracy did not improve from 0.73000\n",
      "Epoch 975/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7513 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00975: val_accuracy did not improve from 0.73000\n",
      "Epoch 976/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7686 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00976: val_accuracy did not improve from 0.73000\n",
      "Epoch 977/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00977: val_accuracy did not improve from 0.73000\n",
      "Epoch 978/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00978: val_accuracy did not improve from 0.73000\n",
      "Epoch 979/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7854 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00979: val_accuracy did not improve from 0.73000\n",
      "Epoch 980/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00980: val_accuracy did not improve from 0.73000\n",
      "Epoch 981/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00981: val_accuracy did not improve from 0.73000\n",
      "Epoch 982/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00982: val_accuracy did not improve from 0.73000\n",
      "Epoch 983/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8304 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00983: val_accuracy did not improve from 0.73000\n",
      "Epoch 984/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00984: val_accuracy did not improve from 0.73000\n",
      "Epoch 985/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8383 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00985: val_accuracy did not improve from 0.73000\n",
      "Epoch 986/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8441 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00986: val_accuracy did not improve from 0.73000\n",
      "Epoch 987/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00987: val_accuracy did not improve from 0.73000\n",
      "Epoch 988/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8642 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00988: val_accuracy did not improve from 0.73000\n",
      "Epoch 989/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8742 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00989: val_accuracy did not improve from 0.73000\n",
      "Epoch 990/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8806 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00990: val_accuracy did not improve from 0.73000\n",
      "Epoch 991/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8857 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00991: val_accuracy did not improve from 0.73000\n",
      "Epoch 992/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8872 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00992: val_accuracy did not improve from 0.73000\n",
      "Epoch 993/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8927 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00993: val_accuracy did not improve from 0.73000\n",
      "Epoch 994/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9073 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00994: val_accuracy did not improve from 0.73000\n",
      "Epoch 995/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9251 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00995: val_accuracy did not improve from 0.73000\n",
      "Epoch 996/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9214 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00996: val_accuracy did not improve from 0.73000\n",
      "Epoch 997/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00997: val_accuracy did not improve from 0.73000\n",
      "Epoch 998/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9297 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00998: val_accuracy did not improve from 0.73000\n",
      "Epoch 999/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9392 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00999: val_accuracy did not improve from 0.73000\n",
      "Epoch 1000/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9377 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01000: val_accuracy did not improve from 0.73000\n",
      "Epoch 1001/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9562 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01001: val_accuracy did not improve from 0.73000\n",
      "Epoch 1002/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9368 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01002: val_accuracy did not improve from 0.73000\n",
      "Epoch 1003/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9612 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01003: val_accuracy did not improve from 0.73000\n",
      "Epoch 1004/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9467 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01004: val_accuracy did not improve from 0.73000\n",
      "Epoch 1005/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0002 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01005: val_accuracy did not improve from 0.73000\n",
      "Epoch 1006/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9736 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01006: val_accuracy did not improve from 0.73000\n",
      "Epoch 1007/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9742 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01007: val_accuracy did not improve from 0.73000\n",
      "Epoch 1008/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9753 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01008: val_accuracy did not improve from 0.73000\n",
      "Epoch 1009/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0231 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01009: val_accuracy did not improve from 0.73000\n",
      "Epoch 1010/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9599 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01010: val_accuracy did not improve from 0.73000\n",
      "Epoch 1011/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0357 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01011: val_accuracy did not improve from 0.73000\n",
      "Epoch 1012/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9953 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01012: val_accuracy did not improve from 0.73000\n",
      "Epoch 1013/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0156 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01013: val_accuracy did not improve from 0.73000\n",
      "Epoch 1014/2000\n",
      "113/113 - 2s - loss: 0.4157 - accuracy: 0.9422 - val_loss: 4.3392 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01014: val_accuracy did not improve from 0.73000\n",
      "Epoch 1015/2000\n",
      "113/113 - 2s - loss: 0.7370 - accuracy: 0.8378 - val_loss: 2.0643 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01015: val_accuracy did not improve from 0.73000\n",
      "Epoch 1016/2000\n",
      "113/113 - 2s - loss: 0.0859 - accuracy: 0.9667 - val_loss: 2.1610 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01016: val_accuracy did not improve from 0.73000\n",
      "Epoch 1017/2000\n",
      "113/113 - 2s - loss: 0.0362 - accuracy: 0.9900 - val_loss: 2.1518 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01017: val_accuracy did not improve from 0.73000\n",
      "Epoch 1018/2000\n",
      "113/113 - 2s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.1962 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01018: val_accuracy did not improve from 0.73000\n",
      "Epoch 1019/2000\n",
      "113/113 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.2646 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01019: val_accuracy did not improve from 0.73000\n",
      "Epoch 1020/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.3279 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01020: val_accuracy did not improve from 0.73000\n",
      "Epoch 1021/2000\n",
      "113/113 - 2s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.3629 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01021: val_accuracy did not improve from 0.73000\n",
      "Epoch 1022/2000\n",
      "113/113 - 2s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01022: val_accuracy did not improve from 0.73000\n",
      "Epoch 1023/2000\n",
      "113/113 - 2s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4646 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01023: val_accuracy did not improve from 0.73000\n",
      "Epoch 1024/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.4901 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01024: val_accuracy did not improve from 0.73000\n",
      "Epoch 1025/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5151 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01025: val_accuracy did not improve from 0.73000\n",
      "Epoch 1026/2000\n",
      "113/113 - 2s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5395 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01026: val_accuracy did not improve from 0.73000\n",
      "Epoch 1027/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01027: val_accuracy did not improve from 0.73000\n",
      "Epoch 1028/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.5865 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01028: val_accuracy did not improve from 0.73000\n",
      "Epoch 1029/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6041 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01029: val_accuracy did not improve from 0.73000\n",
      "Epoch 1030/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6319 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01030: val_accuracy did not improve from 0.73000\n",
      "Epoch 1031/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6435 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01031: val_accuracy did not improve from 0.73000\n",
      "Epoch 1032/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6531 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01032: val_accuracy did not improve from 0.73000\n",
      "Epoch 1033/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6674 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01033: val_accuracy did not improve from 0.73000\n",
      "Epoch 1034/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6742 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01034: val_accuracy did not improve from 0.73000\n",
      "Epoch 1035/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.7002 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01035: val_accuracy did not improve from 0.73000\n",
      "Epoch 1036/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7140 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01036: val_accuracy did not improve from 0.73000\n",
      "Epoch 1037/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7129 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01037: val_accuracy did not improve from 0.73000\n",
      "Epoch 1038/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7337 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01038: val_accuracy did not improve from 0.73000\n",
      "Epoch 1039/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7523 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01039: val_accuracy did not improve from 0.73000\n",
      "Epoch 1040/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7704 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01040: val_accuracy did not improve from 0.73000\n",
      "Epoch 1041/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7765 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01041: val_accuracy did not improve from 0.73000\n",
      "Epoch 1042/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7810 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01042: val_accuracy did not improve from 0.73000\n",
      "Epoch 1043/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01043: val_accuracy did not improve from 0.73000\n",
      "Epoch 1044/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01044: val_accuracy did not improve from 0.73000\n",
      "Epoch 1045/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8250 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01045: val_accuracy did not improve from 0.73000\n",
      "Epoch 1046/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.8342 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01046: val_accuracy did not improve from 0.73000\n",
      "Epoch 1047/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01047: val_accuracy did not improve from 0.73000\n",
      "Epoch 1048/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8507 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01048: val_accuracy did not improve from 0.73000\n",
      "Epoch 1049/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8562 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01049: val_accuracy did not improve from 0.73000\n",
      "Epoch 1050/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8639 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01050: val_accuracy did not improve from 0.73000\n",
      "Epoch 1051/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8742 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01051: val_accuracy did not improve from 0.73000\n",
      "Epoch 1052/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8774 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01052: val_accuracy did not improve from 0.73000\n",
      "Epoch 1053/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9020 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01053: val_accuracy did not improve from 0.73000\n",
      "Epoch 1054/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9103 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01054: val_accuracy did not improve from 0.73000\n",
      "Epoch 1055/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9048 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01055: val_accuracy did not improve from 0.73000\n",
      "Epoch 1056/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9124 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01056: val_accuracy did not improve from 0.73000\n",
      "Epoch 1057/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01057: val_accuracy did not improve from 0.73000\n",
      "Epoch 1058/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9312 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01058: val_accuracy did not improve from 0.73000\n",
      "Epoch 1059/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9365 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01059: val_accuracy did not improve from 0.73000\n",
      "Epoch 1060/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9459 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01060: val_accuracy did not improve from 0.73000\n",
      "Epoch 1061/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9494 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01061: val_accuracy did not improve from 0.73000\n",
      "Epoch 1062/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9558 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01062: val_accuracy did not improve from 0.73000\n",
      "Epoch 1063/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9582 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01063: val_accuracy did not improve from 0.73000\n",
      "Epoch 1064/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9597 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01064: val_accuracy did not improve from 0.73000\n",
      "Epoch 1065/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9714 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01065: val_accuracy did not improve from 0.73000\n",
      "Epoch 1066/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9740 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01066: val_accuracy did not improve from 0.73000\n",
      "Epoch 1067/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9984 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01067: val_accuracy did not improve from 0.73000\n",
      "Epoch 1068/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0115 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01068: val_accuracy did not improve from 0.73000\n",
      "Epoch 1069/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9922 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01069: val_accuracy did not improve from 0.73000\n",
      "Epoch 1070/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9834 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01070: val_accuracy did not improve from 0.73000\n",
      "Epoch 1071/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0224 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01071: val_accuracy did not improve from 0.73000\n",
      "Epoch 1072/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0032 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01072: val_accuracy did not improve from 0.73000\n",
      "Epoch 1073/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0085 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01073: val_accuracy did not improve from 0.73000\n",
      "Epoch 1074/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0199 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01074: val_accuracy did not improve from 0.73000\n",
      "Epoch 1075/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0309 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01075: val_accuracy did not improve from 0.73000\n",
      "Epoch 1076/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0064 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01076: val_accuracy did not improve from 0.73000\n",
      "Epoch 1077/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9785 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01077: val_accuracy did not improve from 0.73000\n",
      "Epoch 1078/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0259 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01078: val_accuracy did not improve from 0.73000\n",
      "Epoch 1079/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0288 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01079: val_accuracy did not improve from 0.73000\n",
      "Epoch 1080/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0019 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01080: val_accuracy did not improve from 0.73000\n",
      "Epoch 1081/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0135 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01081: val_accuracy did not improve from 0.73000\n",
      "Epoch 1082/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0075 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01082: val_accuracy did not improve from 0.73000\n",
      "Epoch 1083/2000\n",
      "113/113 - 2s - loss: 0.7250 - accuracy: 0.8833 - val_loss: 3.0689 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01083: val_accuracy did not improve from 0.73000\n",
      "Epoch 1084/2000\n",
      "113/113 - 2s - loss: 0.3008 - accuracy: 0.9233 - val_loss: 2.2753 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01084: val_accuracy did not improve from 0.73000\n",
      "Epoch 1085/2000\n",
      "113/113 - 2s - loss: 0.0402 - accuracy: 0.9889 - val_loss: 2.4213 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01085: val_accuracy did not improve from 0.73000\n",
      "Epoch 1086/2000\n",
      "113/113 - 2s - loss: 0.0179 - accuracy: 0.9967 - val_loss: 2.4449 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01086: val_accuracy did not improve from 0.73000\n",
      "Epoch 1087/2000\n",
      "113/113 - 2s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.4286 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01087: val_accuracy did not improve from 0.73000\n",
      "Epoch 1088/2000\n",
      "113/113 - 2s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.4737 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01088: val_accuracy did not improve from 0.73000\n",
      "Epoch 1089/2000\n",
      "113/113 - 2s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4970 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01089: val_accuracy did not improve from 0.73000\n",
      "Epoch 1090/2000\n",
      "113/113 - 2s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5171 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01090: val_accuracy did not improve from 0.73000\n",
      "Epoch 1091/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5478 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01091: val_accuracy did not improve from 0.73000\n",
      "Epoch 1092/2000\n",
      "113/113 - 2s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.5573 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01092: val_accuracy did not improve from 0.73000\n",
      "Epoch 1093/2000\n",
      "113/113 - 2s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5797 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01093: val_accuracy did not improve from 0.73000\n",
      "Epoch 1094/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.5970 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01094: val_accuracy did not improve from 0.73000\n",
      "Epoch 1095/2000\n",
      "113/113 - 2s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6154 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01095: val_accuracy did not improve from 0.73000\n",
      "Epoch 1096/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6277 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01096: val_accuracy did not improve from 0.73000\n",
      "Epoch 1097/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6357 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01097: val_accuracy did not improve from 0.73000\n",
      "Epoch 1098/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6540 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01098: val_accuracy did not improve from 0.73000\n",
      "Epoch 1099/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6625 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01099: val_accuracy did not improve from 0.73000\n",
      "Epoch 1100/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6790 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01100: val_accuracy did not improve from 0.73000\n",
      "Epoch 1101/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6804 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01101: val_accuracy did not improve from 0.73000\n",
      "Epoch 1102/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01102: val_accuracy did not improve from 0.73000\n",
      "Epoch 1103/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7094 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01103: val_accuracy did not improve from 0.73000\n",
      "Epoch 1104/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7192 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01104: val_accuracy did not improve from 0.73000\n",
      "Epoch 1105/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01105: val_accuracy did not improve from 0.73000\n",
      "Epoch 1106/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7362 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01106: val_accuracy did not improve from 0.73000\n",
      "Epoch 1107/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01107: val_accuracy did not improve from 0.73000\n",
      "Epoch 1108/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7490 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01108: val_accuracy did not improve from 0.73000\n",
      "Epoch 1109/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7576 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01109: val_accuracy did not improve from 0.73000\n",
      "Epoch 1110/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7597 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01110: val_accuracy did not improve from 0.73000\n",
      "Epoch 1111/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01111: val_accuracy did not improve from 0.73000\n",
      "Epoch 1112/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7825 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01112: val_accuracy did not improve from 0.73000\n",
      "Epoch 1113/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01113: val_accuracy did not improve from 0.73000\n",
      "Epoch 1114/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01114: val_accuracy did not improve from 0.73000\n",
      "Epoch 1115/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01115: val_accuracy did not improve from 0.73000\n",
      "Epoch 1116/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8098 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01116: val_accuracy did not improve from 0.73000\n",
      "Epoch 1117/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01117: val_accuracy did not improve from 0.73000\n",
      "Epoch 1118/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8337 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01118: val_accuracy did not improve from 0.73000\n",
      "Epoch 1119/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8408 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01119: val_accuracy did not improve from 0.73000\n",
      "Epoch 1120/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8387 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01120: val_accuracy did not improve from 0.73000\n",
      "Epoch 1121/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8534 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01121: val_accuracy did not improve from 0.73000\n",
      "Epoch 1122/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8542 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01122: val_accuracy did not improve from 0.73000\n",
      "Epoch 1123/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8579 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01123: val_accuracy did not improve from 0.73000\n",
      "Epoch 1124/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8790 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01124: val_accuracy did not improve from 0.73000\n",
      "Epoch 1125/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8785 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01125: val_accuracy did not improve from 0.73000\n",
      "Epoch 1126/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8830 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01126: val_accuracy did not improve from 0.73000\n",
      "Epoch 1127/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8934 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01127: val_accuracy did not improve from 0.73000\n",
      "Epoch 1128/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8880 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01128: val_accuracy did not improve from 0.73000\n",
      "Epoch 1129/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9133 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01129: val_accuracy did not improve from 0.73000\n",
      "Epoch 1130/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9102 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01130: val_accuracy did not improve from 0.73000\n",
      "Epoch 1131/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9208 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01131: val_accuracy did not improve from 0.73000\n",
      "Epoch 1132/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9152 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01132: val_accuracy did not improve from 0.73000\n",
      "Epoch 1133/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9245 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01133: val_accuracy did not improve from 0.73000\n",
      "Epoch 1134/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9247 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01134: val_accuracy did not improve from 0.73000\n",
      "Epoch 1135/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9338 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01135: val_accuracy did not improve from 0.73000\n",
      "Epoch 1136/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9388 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01136: val_accuracy did not improve from 0.73000\n",
      "Epoch 1137/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9505 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01137: val_accuracy did not improve from 0.73000\n",
      "Epoch 1138/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9566 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01138: val_accuracy did not improve from 0.73000\n",
      "Epoch 1139/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9672 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01139: val_accuracy did not improve from 0.73000\n",
      "Epoch 1140/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9661 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01140: val_accuracy did not improve from 0.73000\n",
      "Epoch 1141/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9589 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01141: val_accuracy did not improve from 0.73000\n",
      "Epoch 1142/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9732 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01142: val_accuracy did not improve from 0.73000\n",
      "Epoch 1143/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9724 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01143: val_accuracy did not improve from 0.73000\n",
      "Epoch 1144/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01144: val_accuracy did not improve from 0.73000\n",
      "Epoch 1145/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01145: val_accuracy did not improve from 0.73000\n",
      "Epoch 1146/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9888 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01146: val_accuracy did not improve from 0.73000\n",
      "Epoch 1147/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9952 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01147: val_accuracy did not improve from 0.73000\n",
      "Epoch 1148/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9794 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01148: val_accuracy did not improve from 0.73000\n",
      "Epoch 1149/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9829 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01149: val_accuracy did not improve from 0.73000\n",
      "Epoch 1150/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9863 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01150: val_accuracy did not improve from 0.73000\n",
      "Epoch 1151/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0528 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01151: val_accuracy did not improve from 0.73000\n",
      "Epoch 1152/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9875 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01152: val_accuracy did not improve from 0.73000\n",
      "Epoch 1153/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0407 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01153: val_accuracy did not improve from 0.73000\n",
      "Epoch 1154/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0338 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01154: val_accuracy did not improve from 0.73000\n",
      "Epoch 1155/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8800 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01155: val_accuracy did not improve from 0.73000\n",
      "Epoch 1156/2000\n",
      "113/113 - 2s - loss: 0.7832 - accuracy: 0.8389 - val_loss: 1.9192 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01156: val_accuracy did not improve from 0.73000\n",
      "Epoch 1157/2000\n",
      "113/113 - 2s - loss: 0.1149 - accuracy: 0.9611 - val_loss: 2.0254 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01157: val_accuracy did not improve from 0.73000\n",
      "Epoch 1158/2000\n",
      "113/113 - 2s - loss: 0.0401 - accuracy: 0.9900 - val_loss: 2.1797 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01158: val_accuracy did not improve from 0.73000\n",
      "Epoch 1159/2000\n",
      "113/113 - 2s - loss: 0.0167 - accuracy: 0.9967 - val_loss: 2.2719 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01159: val_accuracy did not improve from 0.73000\n",
      "Epoch 1160/2000\n",
      "113/113 - 2s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.4131 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01160: val_accuracy did not improve from 0.73000\n",
      "Epoch 1161/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4653 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01161: val_accuracy did not improve from 0.73000\n",
      "Epoch 1162/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5119 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01162: val_accuracy did not improve from 0.73000\n",
      "Epoch 1163/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5696 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01163: val_accuracy did not improve from 0.73000\n",
      "Epoch 1164/2000\n",
      "113/113 - 2s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5873 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01164: val_accuracy did not improve from 0.73000\n",
      "Epoch 1165/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6031 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 01165: val_accuracy did not improve from 0.73000\n",
      "Epoch 1166/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6354 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 01166: val_accuracy did not improve from 0.73000\n",
      "Epoch 1167/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6470 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01167: val_accuracy did not improve from 0.73000\n",
      "Epoch 1168/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6721 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01168: val_accuracy did not improve from 0.73000\n",
      "Epoch 1169/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6831 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01169: val_accuracy did not improve from 0.73000\n",
      "Epoch 1170/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7026 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01170: val_accuracy did not improve from 0.73000\n",
      "Epoch 1171/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7095 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01171: val_accuracy did not improve from 0.73000\n",
      "Epoch 1172/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7218 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01172: val_accuracy did not improve from 0.73000\n",
      "Epoch 1173/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7292 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01173: val_accuracy did not improve from 0.73000\n",
      "Epoch 1174/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7485 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01174: val_accuracy did not improve from 0.73000\n",
      "Epoch 1175/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7491 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01175: val_accuracy did not improve from 0.73000\n",
      "Epoch 1176/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7621 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01176: val_accuracy did not improve from 0.73000\n",
      "Epoch 1177/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7654 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01177: val_accuracy did not improve from 0.73000\n",
      "Epoch 1178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01178: val_accuracy did not improve from 0.73000\n",
      "Epoch 1179/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7875 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01179: val_accuracy did not improve from 0.73000\n",
      "Epoch 1180/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01180: val_accuracy did not improve from 0.73000\n",
      "Epoch 1181/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8014 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01181: val_accuracy did not improve from 0.73000\n",
      "Epoch 1182/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8105 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01182: val_accuracy did not improve from 0.73000\n",
      "Epoch 1183/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8129 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01183: val_accuracy did not improve from 0.73000\n",
      "Epoch 1184/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8318 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01184: val_accuracy did not improve from 0.73000\n",
      "Epoch 1185/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01185: val_accuracy did not improve from 0.73000\n",
      "Epoch 1186/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8379 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01186: val_accuracy did not improve from 0.73000\n",
      "Epoch 1187/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8489 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01187: val_accuracy did not improve from 0.73000\n",
      "Epoch 1188/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8491 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01188: val_accuracy did not improve from 0.73000\n",
      "Epoch 1189/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8580 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01189: val_accuracy did not improve from 0.73000\n",
      "Epoch 1190/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8642 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01190: val_accuracy did not improve from 0.73000\n",
      "Epoch 1191/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8757 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01191: val_accuracy did not improve from 0.73000\n",
      "Epoch 1192/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8819 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01192: val_accuracy did not improve from 0.73000\n",
      "Epoch 1193/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01193: val_accuracy did not improve from 0.73000\n",
      "Epoch 1194/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8972 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01194: val_accuracy did not improve from 0.73000\n",
      "Epoch 1195/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8991 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01195: val_accuracy did not improve from 0.73000\n",
      "Epoch 1196/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9018 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01196: val_accuracy did not improve from 0.73000\n",
      "Epoch 1197/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9071 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01197: val_accuracy did not improve from 0.73000\n",
      "Epoch 1198/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9097 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01198: val_accuracy did not improve from 0.73000\n",
      "Epoch 1199/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9134 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01199: val_accuracy did not improve from 0.73000\n",
      "Epoch 1200/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9213 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01200: val_accuracy did not improve from 0.73000\n",
      "Epoch 1201/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9277 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01201: val_accuracy did not improve from 0.73000\n",
      "Epoch 1202/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9347 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01202: val_accuracy did not improve from 0.73000\n",
      "Epoch 1203/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9415 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01203: val_accuracy did not improve from 0.73000\n",
      "Epoch 1204/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9430 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01204: val_accuracy did not improve from 0.73000\n",
      "Epoch 1205/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9544 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01205: val_accuracy did not improve from 0.73000\n",
      "Epoch 1206/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9427 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01206: val_accuracy did not improve from 0.73000\n",
      "Epoch 1207/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9514 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01207: val_accuracy did not improve from 0.73000\n",
      "Epoch 1208/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9516 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01208: val_accuracy did not improve from 0.73000\n",
      "Epoch 1209/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9447 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01209: val_accuracy did not improve from 0.73000\n",
      "Epoch 1210/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9578 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01210: val_accuracy did not improve from 0.73000\n",
      "Epoch 1211/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9496 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01211: val_accuracy did not improve from 0.73000\n",
      "Epoch 1212/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9619 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01212: val_accuracy did not improve from 0.73000\n",
      "Epoch 1213/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9806 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01213: val_accuracy did not improve from 0.73000\n",
      "Epoch 1214/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9773 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01214: val_accuracy did not improve from 0.73000\n",
      "Epoch 1215/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9793 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01215: val_accuracy did not improve from 0.73000\n",
      "Epoch 1216/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0112 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01216: val_accuracy did not improve from 0.73000\n",
      "Epoch 1217/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9770 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01217: val_accuracy did not improve from 0.73000\n",
      "Epoch 1218/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0304 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01218: val_accuracy did not improve from 0.73000\n",
      "Epoch 1219/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0237 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01219: val_accuracy did not improve from 0.73000\n",
      "Epoch 1220/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9881 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01220: val_accuracy did not improve from 0.73000\n",
      "Epoch 1221/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9673 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01221: val_accuracy did not improve from 0.73000\n",
      "Epoch 1222/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9820 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01222: val_accuracy did not improve from 0.73000\n",
      "Epoch 1223/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9717 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01223: val_accuracy did not improve from 0.73000\n",
      "Epoch 1224/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9652 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01224: val_accuracy did not improve from 0.73000\n",
      "Epoch 1225/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0239 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01225: val_accuracy did not improve from 0.73000\n",
      "Epoch 1226/2000\n",
      "113/113 - 2s - loss: 0.6365 - accuracy: 0.9100 - val_loss: 2.9668 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01226: val_accuracy did not improve from 0.73000\n",
      "Epoch 1227/2000\n",
      "113/113 - 2s - loss: 0.3297 - accuracy: 0.9167 - val_loss: 2.5075 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01227: val_accuracy did not improve from 0.73000\n",
      "Epoch 1228/2000\n",
      "113/113 - 2s - loss: 0.0465 - accuracy: 0.9822 - val_loss: 2.3235 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01228: val_accuracy did not improve from 0.73000\n",
      "Epoch 1229/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0316 - accuracy: 0.9933 - val_loss: 2.3813 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01229: val_accuracy did not improve from 0.73000\n",
      "Epoch 1230/2000\n",
      "113/113 - 2s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.4555 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01230: val_accuracy did not improve from 0.73000\n",
      "Epoch 1231/2000\n",
      "113/113 - 2s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4436 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01231: val_accuracy did not improve from 0.73000\n",
      "Epoch 1232/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4714 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01232: val_accuracy did not improve from 0.73000\n",
      "Epoch 1233/2000\n",
      "113/113 - 2s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.4899 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01233: val_accuracy did not improve from 0.73000\n",
      "Epoch 1234/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.5048 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01234: val_accuracy did not improve from 0.73000\n",
      "Epoch 1235/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01235: val_accuracy did not improve from 0.73000\n",
      "Epoch 1236/2000\n",
      "113/113 - 2s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.5367 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01236: val_accuracy did not improve from 0.73000\n",
      "Epoch 1237/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5494 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01237: val_accuracy did not improve from 0.73000\n",
      "Epoch 1238/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5533 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01238: val_accuracy did not improve from 0.73000\n",
      "Epoch 1239/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5661 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01239: val_accuracy did not improve from 0.73000\n",
      "Epoch 1240/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5835 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01240: val_accuracy did not improve from 0.73000\n",
      "Epoch 1241/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5927 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01241: val_accuracy did not improve from 0.73000\n",
      "Epoch 1242/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6092 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01242: val_accuracy did not improve from 0.73000\n",
      "Epoch 1243/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6187 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01243: val_accuracy did not improve from 0.73000\n",
      "Epoch 1244/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6280 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01244: val_accuracy did not improve from 0.73000\n",
      "Epoch 1245/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6416 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01245: val_accuracy did not improve from 0.73000\n",
      "Epoch 1246/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6503 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01246: val_accuracy did not improve from 0.73000\n",
      "Epoch 1247/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6581 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01247: val_accuracy did not improve from 0.73000\n",
      "Epoch 1248/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6655 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01248: val_accuracy did not improve from 0.73000\n",
      "Epoch 1249/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6757 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01249: val_accuracy did not improve from 0.73000\n",
      "Epoch 1250/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01250: val_accuracy did not improve from 0.73000\n",
      "Epoch 1251/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7020 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01251: val_accuracy did not improve from 0.73000\n",
      "Epoch 1252/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7090 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01252: val_accuracy did not improve from 0.73000\n",
      "Epoch 1253/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7219 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01253: val_accuracy did not improve from 0.73000\n",
      "Epoch 1254/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7316 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01254: val_accuracy did not improve from 0.73000\n",
      "Epoch 1255/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7409 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01255: val_accuracy did not improve from 0.73000\n",
      "Epoch 1256/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7567 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01256: val_accuracy did not improve from 0.73000\n",
      "Epoch 1257/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7565 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01257: val_accuracy did not improve from 0.73000\n",
      "Epoch 1258/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7663 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01258: val_accuracy did not improve from 0.73000\n",
      "Epoch 1259/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7799 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01259: val_accuracy did not improve from 0.73000\n",
      "Epoch 1260/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01260: val_accuracy did not improve from 0.73000\n",
      "Epoch 1261/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01261: val_accuracy did not improve from 0.73000\n",
      "Epoch 1262/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01262: val_accuracy did not improve from 0.73000\n",
      "Epoch 1263/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8233 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01263: val_accuracy did not improve from 0.73000\n",
      "Epoch 1264/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8339 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01264: val_accuracy did not improve from 0.73000\n",
      "Epoch 1265/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8421 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01265: val_accuracy did not improve from 0.73000\n",
      "Epoch 1266/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8445 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01266: val_accuracy did not improve from 0.73000\n",
      "Epoch 1267/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8663 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01267: val_accuracy did not improve from 0.73000\n",
      "Epoch 1268/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8683 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01268: val_accuracy did not improve from 0.73000\n",
      "Epoch 1269/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8706 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01269: val_accuracy did not improve from 0.73000\n",
      "Epoch 1270/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8763 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01270: val_accuracy did not improve from 0.73000\n",
      "Epoch 1271/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8907 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01271: val_accuracy did not improve from 0.73000\n",
      "Epoch 1272/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01272: val_accuracy did not improve from 0.73000\n",
      "Epoch 1273/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8993 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01273: val_accuracy did not improve from 0.73000\n",
      "Epoch 1274/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9057 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01274: val_accuracy did not improve from 0.73000\n",
      "Epoch 1275/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9155 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01275: val_accuracy did not improve from 0.73000\n",
      "Epoch 1276/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9307 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01276: val_accuracy did not improve from 0.73000\n",
      "Epoch 1277/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01277: val_accuracy did not improve from 0.73000\n",
      "Epoch 1278/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9295 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01278: val_accuracy did not improve from 0.73000\n",
      "Epoch 1279/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9399 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01279: val_accuracy did not improve from 0.73000\n",
      "Epoch 1280/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9454 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01280: val_accuracy did not improve from 0.73000\n",
      "Epoch 1281/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9593 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01281: val_accuracy did not improve from 0.73000\n",
      "Epoch 1282/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9611 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01282: val_accuracy did not improve from 0.73000\n",
      "Epoch 1283/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9601 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01283: val_accuracy did not improve from 0.73000\n",
      "Epoch 1284/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9808 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01284: val_accuracy did not improve from 0.73000\n",
      "Epoch 1285/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9812 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01285: val_accuracy did not improve from 0.73000\n",
      "Epoch 1286/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9829 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01286: val_accuracy did not improve from 0.73000\n",
      "Epoch 1287/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9798 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01287: val_accuracy did not improve from 0.73000\n",
      "Epoch 1288/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0016 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01288: val_accuracy did not improve from 0.73000\n",
      "Epoch 1289/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01289: val_accuracy did not improve from 0.73000\n",
      "Epoch 1290/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9999 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01290: val_accuracy did not improve from 0.73000\n",
      "Epoch 1291/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0023 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01291: val_accuracy did not improve from 0.73000\n",
      "Epoch 1292/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0084 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01292: val_accuracy did not improve from 0.73000\n",
      "Epoch 1293/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0091 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01293: val_accuracy did not improve from 0.73000\n",
      "Epoch 1294/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0372 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01294: val_accuracy did not improve from 0.73000\n",
      "Epoch 1295/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01295: val_accuracy did not improve from 0.73000\n",
      "Epoch 1296/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9961 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01296: val_accuracy did not improve from 0.73000\n",
      "Epoch 1297/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0313 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01297: val_accuracy did not improve from 0.73000\n",
      "Epoch 1298/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0193 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01298: val_accuracy did not improve from 0.73000\n",
      "Epoch 1299/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01299: val_accuracy did not improve from 0.73000\n",
      "Epoch 1300/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0615 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01300: val_accuracy did not improve from 0.73000\n",
      "Epoch 1301/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0503 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01301: val_accuracy did not improve from 0.73000\n",
      "Epoch 1302/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0601 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01302: val_accuracy did not improve from 0.73000\n",
      "Epoch 1303/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 0.9989 - val_loss: 3.0911 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01303: val_accuracy did not improve from 0.73000\n",
      "Epoch 1304/2000\n",
      "113/113 - 2s - loss: 0.9052 - accuracy: 0.8522 - val_loss: 3.1052 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01304: val_accuracy did not improve from 0.73000\n",
      "Epoch 1305/2000\n",
      "113/113 - 2s - loss: 0.1898 - accuracy: 0.9411 - val_loss: 2.4347 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01305: val_accuracy did not improve from 0.73000\n",
      "Epoch 1306/2000\n",
      "113/113 - 2s - loss: 0.0212 - accuracy: 0.9933 - val_loss: 2.6185 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01306: val_accuracy did not improve from 0.73000\n",
      "Epoch 1307/2000\n",
      "113/113 - 2s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.6319 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01307: val_accuracy did not improve from 0.73000\n",
      "Epoch 1308/2000\n",
      "113/113 - 2s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6309 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01308: val_accuracy did not improve from 0.73000\n",
      "Epoch 1309/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6259 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01309: val_accuracy did not improve from 0.73000\n",
      "Epoch 1310/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6415 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01310: val_accuracy did not improve from 0.73000\n",
      "Epoch 1311/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6417 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01311: val_accuracy did not improve from 0.73000\n",
      "Epoch 1312/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6458 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01312: val_accuracy did not improve from 0.73000\n",
      "Epoch 1313/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6531 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01313: val_accuracy did not improve from 0.73000\n",
      "Epoch 1314/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6635 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01314: val_accuracy did not improve from 0.73000\n",
      "Epoch 1315/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6698 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01315: val_accuracy did not improve from 0.73000\n",
      "Epoch 1316/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6785 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01316: val_accuracy did not improve from 0.73000\n",
      "Epoch 1317/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6776 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01317: val_accuracy did not improve from 0.73000\n",
      "Epoch 1318/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6794 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01318: val_accuracy did not improve from 0.73000\n",
      "Epoch 1319/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01319: val_accuracy did not improve from 0.73000\n",
      "Epoch 1320/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7030 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01320: val_accuracy did not improve from 0.73000\n",
      "Epoch 1321/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.7193 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01321: val_accuracy did not improve from 0.73000\n",
      "Epoch 1322/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01322: val_accuracy did not improve from 0.73000\n",
      "Epoch 1323/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7321 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01323: val_accuracy did not improve from 0.73000\n",
      "Epoch 1324/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7290 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01324: val_accuracy did not improve from 0.73000\n",
      "Epoch 1325/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7375 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01325: val_accuracy did not improve from 0.73000\n",
      "Epoch 1326/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01326: val_accuracy did not improve from 0.73000\n",
      "Epoch 1327/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7501 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01327: val_accuracy did not improve from 0.73000\n",
      "Epoch 1328/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7593 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01328: val_accuracy did not improve from 0.73000\n",
      "Epoch 1329/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7564 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01329: val_accuracy did not improve from 0.73000\n",
      "Epoch 1330/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7710 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01330: val_accuracy did not improve from 0.73000\n",
      "Epoch 1331/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7740 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01331: val_accuracy did not improve from 0.73000\n",
      "Epoch 1332/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7797 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01332: val_accuracy did not improve from 0.73000\n",
      "Epoch 1333/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7878 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01333: val_accuracy did not improve from 0.73000\n",
      "Epoch 1334/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7912 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01334: val_accuracy did not improve from 0.73000\n",
      "Epoch 1335/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8050 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01335: val_accuracy did not improve from 0.73000\n",
      "Epoch 1336/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01336: val_accuracy did not improve from 0.73000\n",
      "Epoch 1337/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01337: val_accuracy did not improve from 0.73000\n",
      "Epoch 1338/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8231 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01338: val_accuracy did not improve from 0.73000\n",
      "Epoch 1339/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8393 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01339: val_accuracy did not improve from 0.73000\n",
      "Epoch 1340/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01340: val_accuracy did not improve from 0.73000\n",
      "Epoch 1341/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8419 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01341: val_accuracy did not improve from 0.73000\n",
      "Epoch 1342/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8425 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01342: val_accuracy did not improve from 0.73000\n",
      "Epoch 1343/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8400 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01343: val_accuracy did not improve from 0.73000\n",
      "Epoch 1344/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8690 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01344: val_accuracy did not improve from 0.73000\n",
      "Epoch 1345/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8668 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01345: val_accuracy did not improve from 0.73000\n",
      "Epoch 1346/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8777 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01346: val_accuracy did not improve from 0.73000\n",
      "Epoch 1347/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8833 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01347: val_accuracy did not improve from 0.73000\n",
      "Epoch 1348/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8900 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01348: val_accuracy did not improve from 0.73000\n",
      "Epoch 1349/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8803 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01349: val_accuracy did not improve from 0.73000\n",
      "Epoch 1350/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8929 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01350: val_accuracy did not improve from 0.73000\n",
      "Epoch 1351/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01351: val_accuracy did not improve from 0.73000\n",
      "Epoch 1352/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8936 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01352: val_accuracy did not improve from 0.73000\n",
      "Epoch 1353/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8927 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01353: val_accuracy did not improve from 0.73000\n",
      "Epoch 1354/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9064 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01354: val_accuracy did not improve from 0.73000\n",
      "Epoch 1355/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9164 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01355: val_accuracy did not improve from 0.73000\n",
      "Epoch 1356/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9290 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01356: val_accuracy did not improve from 0.73000\n",
      "Epoch 1357/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9178 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01357: val_accuracy did not improve from 0.73000\n",
      "Epoch 1358/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9221 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01358: val_accuracy did not improve from 0.73000\n",
      "Epoch 1359/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9425 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01359: val_accuracy did not improve from 0.73000\n",
      "Epoch 1360/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9547 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01360: val_accuracy did not improve from 0.73000\n",
      "Epoch 1361/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9349 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01361: val_accuracy did not improve from 0.73000\n",
      "Epoch 1362/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9613 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01362: val_accuracy did not improve from 0.73000\n",
      "Epoch 1363/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9369 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01363: val_accuracy did not improve from 0.73000\n",
      "Epoch 1364/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9748 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01364: val_accuracy did not improve from 0.73000\n",
      "Epoch 1365/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9765 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01365: val_accuracy did not improve from 0.73000\n",
      "Epoch 1366/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9641 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01366: val_accuracy did not improve from 0.73000\n",
      "Epoch 1367/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9534 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01367: val_accuracy did not improve from 0.73000\n",
      "Epoch 1368/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01368: val_accuracy did not improve from 0.73000\n",
      "Epoch 1369/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9614 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01369: val_accuracy did not improve from 0.73000\n",
      "Epoch 1370/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9912 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01370: val_accuracy did not improve from 0.73000\n",
      "Epoch 1371/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9938 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01371: val_accuracy did not improve from 0.73000\n",
      "Epoch 1372/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9908 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01372: val_accuracy did not improve from 0.73000\n",
      "Epoch 1373/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0041 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01373: val_accuracy did not improve from 0.73000\n",
      "Epoch 1374/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0266 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01374: val_accuracy did not improve from 0.73000\n",
      "Epoch 1375/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0240 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01375: val_accuracy did not improve from 0.73000\n",
      "Epoch 1376/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0244 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01376: val_accuracy did not improve from 0.73000\n",
      "Epoch 1377/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0204 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01377: val_accuracy did not improve from 0.73000\n",
      "Epoch 1378/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0067 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01378: val_accuracy did not improve from 0.73000\n",
      "Epoch 1379/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0230 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01379: val_accuracy did not improve from 0.73000\n",
      "Epoch 1380/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0399 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01380: val_accuracy did not improve from 0.73000\n",
      "Epoch 1381/2000\n",
      "113/113 - 2s - loss: 0.0198 - accuracy: 0.9944 - val_loss: 3.7466 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01381: val_accuracy did not improve from 0.73000\n",
      "Epoch 1382/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.9483 - accuracy: 0.8456 - val_loss: 2.3765 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01382: val_accuracy did not improve from 0.73000\n",
      "Epoch 1383/2000\n",
      "113/113 - 2s - loss: 0.1123 - accuracy: 0.9633 - val_loss: 2.5650 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01383: val_accuracy did not improve from 0.73000\n",
      "Epoch 1384/2000\n",
      "113/113 - 2s - loss: 0.0270 - accuracy: 0.9933 - val_loss: 2.5591 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01384: val_accuracy did not improve from 0.73000\n",
      "Epoch 1385/2000\n",
      "113/113 - 2s - loss: 0.0077 - accuracy: 0.9989 - val_loss: 2.5487 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01385: val_accuracy did not improve from 0.73000\n",
      "Epoch 1386/2000\n",
      "113/113 - 2s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5579 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01386: val_accuracy did not improve from 0.73000\n",
      "Epoch 1387/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.5794 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01387: val_accuracy did not improve from 0.73000\n",
      "Epoch 1388/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01388: val_accuracy did not improve from 0.73000\n",
      "Epoch 1389/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6012 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01389: val_accuracy did not improve from 0.73000\n",
      "Epoch 1390/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6088 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01390: val_accuracy did not improve from 0.73000\n",
      "Epoch 1391/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01391: val_accuracy did not improve from 0.73000\n",
      "Epoch 1392/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6227 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01392: val_accuracy did not improve from 0.73000\n",
      "Epoch 1393/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6270 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01393: val_accuracy did not improve from 0.73000\n",
      "Epoch 1394/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01394: val_accuracy did not improve from 0.73000\n",
      "Epoch 1395/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6494 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01395: val_accuracy did not improve from 0.73000\n",
      "Epoch 1396/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6546 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01396: val_accuracy did not improve from 0.73000\n",
      "Epoch 1397/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01397: val_accuracy did not improve from 0.73000\n",
      "Epoch 1398/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6734 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01398: val_accuracy did not improve from 0.73000\n",
      "Epoch 1399/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6768 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01399: val_accuracy did not improve from 0.73000\n",
      "Epoch 1400/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6883 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01400: val_accuracy did not improve from 0.73000\n",
      "Epoch 1401/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7016 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01401: val_accuracy did not improve from 0.73000\n",
      "Epoch 1402/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7180 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01402: val_accuracy did not improve from 0.73000\n",
      "Epoch 1403/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7222 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01403: val_accuracy did not improve from 0.73000\n",
      "Epoch 1404/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7420 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01404: val_accuracy did not improve from 0.73000\n",
      "Epoch 1405/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7421 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01405: val_accuracy did not improve from 0.73000\n",
      "Epoch 1406/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01406: val_accuracy did not improve from 0.73000\n",
      "Epoch 1407/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7614 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01407: val_accuracy did not improve from 0.73000\n",
      "Epoch 1408/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01408: val_accuracy did not improve from 0.73000\n",
      "Epoch 1409/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01409: val_accuracy did not improve from 0.73000\n",
      "Epoch 1410/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01410: val_accuracy did not improve from 0.73000\n",
      "Epoch 1411/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7985 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01411: val_accuracy did not improve from 0.73000\n",
      "Epoch 1412/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01412: val_accuracy did not improve from 0.73000\n",
      "Epoch 1413/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8243 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01413: val_accuracy did not improve from 0.73000\n",
      "Epoch 1414/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8389 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01414: val_accuracy did not improve from 0.73000\n",
      "Epoch 1415/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8413 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01415: val_accuracy did not improve from 0.73000\n",
      "Epoch 1416/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8555 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01416: val_accuracy did not improve from 0.73000\n",
      "Epoch 1417/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8690 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01417: val_accuracy did not improve from 0.73000\n",
      "Epoch 1418/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8792 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01418: val_accuracy did not improve from 0.73000\n",
      "Epoch 1419/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8782 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01419: val_accuracy did not improve from 0.73000\n",
      "Epoch 1420/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8906 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01420: val_accuracy did not improve from 0.73000\n",
      "Epoch 1421/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8934 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01421: val_accuracy did not improve from 0.73000\n",
      "Epoch 1422/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9118 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01422: val_accuracy did not improve from 0.73000\n",
      "Epoch 1423/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9306 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01423: val_accuracy did not improve from 0.73000\n",
      "Epoch 1424/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9185 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01424: val_accuracy did not improve from 0.73000\n",
      "Epoch 1425/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01425: val_accuracy did not improve from 0.73000\n",
      "Epoch 1426/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9326 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01426: val_accuracy did not improve from 0.73000\n",
      "Epoch 1427/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9542 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01427: val_accuracy did not improve from 0.73000\n",
      "Epoch 1428/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9716 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01428: val_accuracy did not improve from 0.73000\n",
      "Epoch 1429/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9818 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01429: val_accuracy did not improve from 0.73000\n",
      "Epoch 1430/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9599 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01430: val_accuracy did not improve from 0.73000\n",
      "Epoch 1431/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9698 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01431: val_accuracy did not improve from 0.73000\n",
      "Epoch 1432/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9972 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01432: val_accuracy did not improve from 0.73000\n",
      "Epoch 1433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01433: val_accuracy did not improve from 0.73000\n",
      "Epoch 1434/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9898 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01434: val_accuracy did not improve from 0.73000\n",
      "Epoch 1435/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0037 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01435: val_accuracy did not improve from 0.73000\n",
      "Epoch 1436/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0358 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01436: val_accuracy did not improve from 0.73000\n",
      "Epoch 1437/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01437: val_accuracy did not improve from 0.73000\n",
      "Epoch 1438/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0202 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01438: val_accuracy did not improve from 0.73000\n",
      "Epoch 1439/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0407 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01439: val_accuracy did not improve from 0.73000\n",
      "Epoch 1440/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0245 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01440: val_accuracy did not improve from 0.73000\n",
      "Epoch 1441/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0221 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01441: val_accuracy did not improve from 0.73000\n",
      "Epoch 1442/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0487 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01442: val_accuracy did not improve from 0.73000\n",
      "Epoch 1443/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0396 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01443: val_accuracy did not improve from 0.73000\n",
      "Epoch 1444/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0728 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01444: val_accuracy did not improve from 0.73000\n",
      "Epoch 1445/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0670 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01445: val_accuracy did not improve from 0.73000\n",
      "Epoch 1446/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0383 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01446: val_accuracy did not improve from 0.73000\n",
      "Epoch 1447/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0974 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01447: val_accuracy did not improve from 0.73000\n",
      "Epoch 1448/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0301 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01448: val_accuracy did not improve from 0.73000\n",
      "Epoch 1449/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01449: val_accuracy did not improve from 0.73000\n",
      "Epoch 1450/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0755 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01450: val_accuracy did not improve from 0.73000\n",
      "Epoch 1451/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1136 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01451: val_accuracy did not improve from 0.73000\n",
      "Epoch 1452/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1010 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01452: val_accuracy did not improve from 0.73000\n",
      "Epoch 1453/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0722 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01453: val_accuracy did not improve from 0.73000\n",
      "Epoch 1454/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0876 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01454: val_accuracy did not improve from 0.73000\n",
      "Epoch 1455/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0774 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01455: val_accuracy did not improve from 0.73000\n",
      "Epoch 1456/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1135 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01456: val_accuracy did not improve from 0.73000\n",
      "Epoch 1457/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1145 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01457: val_accuracy did not improve from 0.73000\n",
      "Epoch 1458/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1060 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01458: val_accuracy did not improve from 0.73000\n",
      "Epoch 1459/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1324 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01459: val_accuracy did not improve from 0.73000\n",
      "Epoch 1460/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1748 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01460: val_accuracy did not improve from 0.73000\n",
      "Epoch 1461/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1635 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01461: val_accuracy did not improve from 0.73000\n",
      "Epoch 1462/2000\n",
      "113/113 - 2s - loss: 0.5618 - accuracy: 0.8767 - val_loss: 2.5284 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01462: val_accuracy did not improve from 0.73000\n",
      "Epoch 1463/2000\n",
      "113/113 - 2s - loss: 0.1722 - accuracy: 0.9467 - val_loss: 2.6188 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01463: val_accuracy did not improve from 0.73000\n",
      "Epoch 1464/2000\n",
      "113/113 - 2s - loss: 0.0306 - accuracy: 0.9889 - val_loss: 2.4157 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01464: val_accuracy did not improve from 0.73000\n",
      "Epoch 1465/2000\n",
      "113/113 - 2s - loss: 0.0271 - accuracy: 0.9922 - val_loss: 2.5647 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01465: val_accuracy did not improve from 0.73000\n",
      "Epoch 1466/2000\n",
      "113/113 - 2s - loss: 0.0072 - accuracy: 0.9989 - val_loss: 2.6863 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01466: val_accuracy did not improve from 0.73000\n",
      "Epoch 1467/2000\n",
      "113/113 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01467: val_accuracy did not improve from 0.73000\n",
      "Epoch 1468/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6398 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01468: val_accuracy did not improve from 0.73000\n",
      "Epoch 1469/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01469: val_accuracy did not improve from 0.73000\n",
      "Epoch 1470/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6329 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01470: val_accuracy did not improve from 0.73000\n",
      "Epoch 1471/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6384 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01471: val_accuracy did not improve from 0.73000\n",
      "Epoch 1472/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6371 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01472: val_accuracy did not improve from 0.73000\n",
      "Epoch 1473/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6446 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01473: val_accuracy did not improve from 0.73000\n",
      "Epoch 1474/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01474: val_accuracy did not improve from 0.73000\n",
      "Epoch 1475/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6609 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01475: val_accuracy did not improve from 0.73000\n",
      "Epoch 1476/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6591 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01476: val_accuracy did not improve from 0.73000\n",
      "Epoch 1477/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01477: val_accuracy did not improve from 0.73000\n",
      "Epoch 1478/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6726 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01478: val_accuracy did not improve from 0.73000\n",
      "Epoch 1479/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6708 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01479: val_accuracy did not improve from 0.73000\n",
      "Epoch 1480/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6811 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01480: val_accuracy did not improve from 0.73000\n",
      "Epoch 1481/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6889 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01481: val_accuracy did not improve from 0.73000\n",
      "Epoch 1482/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6890 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01482: val_accuracy did not improve from 0.73000\n",
      "Epoch 1483/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01483: val_accuracy did not improve from 0.73000\n",
      "Epoch 1484/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7017 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01484: val_accuracy did not improve from 0.73000\n",
      "Epoch 1485/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7155 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01485: val_accuracy did not improve from 0.73000\n",
      "Epoch 1486/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7131 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01486: val_accuracy did not improve from 0.73000\n",
      "Epoch 1487/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7213 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01487: val_accuracy did not improve from 0.73000\n",
      "Epoch 1488/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7225 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01488: val_accuracy did not improve from 0.73000\n",
      "Epoch 1489/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01489: val_accuracy did not improve from 0.73000\n",
      "Epoch 1490/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7350 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01490: val_accuracy did not improve from 0.73000\n",
      "Epoch 1491/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7440 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01491: val_accuracy did not improve from 0.73000\n",
      "Epoch 1492/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7493 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01492: val_accuracy did not improve from 0.73000\n",
      "Epoch 1493/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7455 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01493: val_accuracy did not improve from 0.73000\n",
      "Epoch 1494/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7621 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01494: val_accuracy did not improve from 0.73000\n",
      "Epoch 1495/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7694 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01495: val_accuracy did not improve from 0.73000\n",
      "Epoch 1496/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01496: val_accuracy did not improve from 0.73000\n",
      "Epoch 1497/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01497: val_accuracy did not improve from 0.73000\n",
      "Epoch 1498/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7906 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01498: val_accuracy did not improve from 0.73000\n",
      "Epoch 1499/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7973 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01499: val_accuracy did not improve from 0.73000\n",
      "Epoch 1500/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01500: val_accuracy did not improve from 0.73000\n",
      "Epoch 1501/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01501: val_accuracy did not improve from 0.73000\n",
      "Epoch 1502/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8127 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01502: val_accuracy did not improve from 0.73000\n",
      "Epoch 1503/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01503: val_accuracy did not improve from 0.73000\n",
      "Epoch 1504/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8339 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01504: val_accuracy did not improve from 0.73000\n",
      "Epoch 1505/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01505: val_accuracy did not improve from 0.73000\n",
      "Epoch 1506/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8417 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01506: val_accuracy did not improve from 0.73000\n",
      "Epoch 1507/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8426 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01507: val_accuracy did not improve from 0.73000\n",
      "Epoch 1508/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01508: val_accuracy did not improve from 0.73000\n",
      "Epoch 1509/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01509: val_accuracy did not improve from 0.73000\n",
      "Epoch 1510/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8713 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01510: val_accuracy did not improve from 0.73000\n",
      "Epoch 1511/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8696 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01511: val_accuracy did not improve from 0.73000\n",
      "Epoch 1512/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8777 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01512: val_accuracy did not improve from 0.73000\n",
      "Epoch 1513/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8731 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01513: val_accuracy did not improve from 0.73000\n",
      "Epoch 1514/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01514: val_accuracy did not improve from 0.73000\n",
      "Epoch 1515/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.8902 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01515: val_accuracy did not improve from 0.73000\n",
      "Epoch 1516/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9002 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01516: val_accuracy did not improve from 0.73000\n",
      "Epoch 1517/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01517: val_accuracy did not improve from 0.73000\n",
      "Epoch 1518/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9048 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01518: val_accuracy did not improve from 0.73000\n",
      "Epoch 1519/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9103 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01519: val_accuracy did not improve from 0.73000\n",
      "Epoch 1520/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9017 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01520: val_accuracy did not improve from 0.73000\n",
      "Epoch 1521/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9166 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01521: val_accuracy did not improve from 0.73000\n",
      "Epoch 1522/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9246 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01522: val_accuracy did not improve from 0.73000\n",
      "Epoch 1523/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9258 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01523: val_accuracy did not improve from 0.73000\n",
      "Epoch 1524/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9102 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01524: val_accuracy did not improve from 0.73000\n",
      "Epoch 1525/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9207 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01525: val_accuracy did not improve from 0.73000\n",
      "Epoch 1526/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9198 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01526: val_accuracy did not improve from 0.73000\n",
      "Epoch 1527/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9519 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01527: val_accuracy did not improve from 0.73000\n",
      "Epoch 1528/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01528: val_accuracy did not improve from 0.73000\n",
      "Epoch 1529/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9602 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01529: val_accuracy did not improve from 0.73000\n",
      "Epoch 1530/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9492 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01530: val_accuracy did not improve from 0.73000\n",
      "Epoch 1531/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9586 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01531: val_accuracy did not improve from 0.73000\n",
      "Epoch 1532/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9694 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01532: val_accuracy did not improve from 0.73000\n",
      "Epoch 1533/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9572 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01533: val_accuracy did not improve from 0.73000\n",
      "Epoch 1534/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9713 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01534: val_accuracy did not improve from 0.73000\n",
      "Epoch 1535/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9923 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01535: val_accuracy did not improve from 0.73000\n",
      "Epoch 1536/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9919 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01536: val_accuracy did not improve from 0.73000\n",
      "Epoch 1537/2000\n",
      "113/113 - 2s - loss: 0.2877 - accuracy: 0.9489 - val_loss: 3.1803 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01537: val_accuracy did not improve from 0.73000\n",
      "Epoch 1538/2000\n",
      "113/113 - 2s - loss: 0.4976 - accuracy: 0.8922 - val_loss: 2.9469 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01538: val_accuracy did not improve from 0.73000\n",
      "Epoch 1539/2000\n",
      "113/113 - 2s - loss: 0.0891 - accuracy: 0.9644 - val_loss: 2.3764 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01539: val_accuracy did not improve from 0.73000\n",
      "Epoch 1540/2000\n",
      "113/113 - 2s - loss: 0.0249 - accuracy: 0.9956 - val_loss: 2.5893 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01540: val_accuracy did not improve from 0.73000\n",
      "Epoch 1541/2000\n",
      "113/113 - 2s - loss: 0.0134 - accuracy: 0.9967 - val_loss: 2.6235 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01541: val_accuracy did not improve from 0.73000\n",
      "Epoch 1542/2000\n",
      "113/113 - 2s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6098 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01542: val_accuracy did not improve from 0.73000\n",
      "Epoch 1543/2000\n",
      "113/113 - 2s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6261 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01543: val_accuracy did not improve from 0.73000\n",
      "Epoch 1544/2000\n",
      "113/113 - 2s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6314 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01544: val_accuracy did not improve from 0.73000\n",
      "Epoch 1545/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.6374 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01545: val_accuracy did not improve from 0.73000\n",
      "Epoch 1546/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6502 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01546: val_accuracy did not improve from 0.73000\n",
      "Epoch 1547/2000\n",
      "113/113 - 2s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6640 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01547: val_accuracy did not improve from 0.73000\n",
      "Epoch 1548/2000\n",
      "113/113 - 2s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6707 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01548: val_accuracy did not improve from 0.73000\n",
      "Epoch 1549/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6730 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01549: val_accuracy did not improve from 0.73000\n",
      "Epoch 1550/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6854 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01550: val_accuracy did not improve from 0.73000\n",
      "Epoch 1551/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6880 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01551: val_accuracy did not improve from 0.73000\n",
      "Epoch 1552/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7038 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01552: val_accuracy did not improve from 0.73000\n",
      "Epoch 1553/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01553: val_accuracy did not improve from 0.73000\n",
      "Epoch 1554/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7154 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01554: val_accuracy did not improve from 0.73000\n",
      "Epoch 1555/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7251 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01555: val_accuracy did not improve from 0.73000\n",
      "Epoch 1556/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7308 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01556: val_accuracy did not improve from 0.73000\n",
      "Epoch 1557/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7443 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01557: val_accuracy did not improve from 0.73000\n",
      "Epoch 1558/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7421 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01558: val_accuracy did not improve from 0.73000\n",
      "Epoch 1559/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7687 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01559: val_accuracy did not improve from 0.73000\n",
      "Epoch 1560/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7804 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01560: val_accuracy did not improve from 0.73000\n",
      "Epoch 1561/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7884 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01561: val_accuracy did not improve from 0.73000\n",
      "Epoch 1562/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01562: val_accuracy did not improve from 0.73000\n",
      "Epoch 1563/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7900 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01563: val_accuracy did not improve from 0.73000\n",
      "Epoch 1564/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8034 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01564: val_accuracy did not improve from 0.73000\n",
      "Epoch 1565/2000\n",
      "113/113 - 3s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8144 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01565: val_accuracy did not improve from 0.73000\n",
      "Epoch 1566/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8280 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01566: val_accuracy did not improve from 0.73000\n",
      "Epoch 1567/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01567: val_accuracy did not improve from 0.73000\n",
      "Epoch 1568/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8438 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01568: val_accuracy did not improve from 0.73000\n",
      "Epoch 1569/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8482 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01569: val_accuracy did not improve from 0.73000\n",
      "Epoch 1570/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8515 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01570: val_accuracy did not improve from 0.73000\n",
      "Epoch 1571/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8591 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01571: val_accuracy did not improve from 0.73000\n",
      "Epoch 1572/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8647 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01572: val_accuracy did not improve from 0.73000\n",
      "Epoch 1573/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8764 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01573: val_accuracy did not improve from 0.73000\n",
      "Epoch 1574/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8881 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01574: val_accuracy did not improve from 0.73000\n",
      "Epoch 1575/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8815 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01575: val_accuracy did not improve from 0.73000\n",
      "Epoch 1576/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01576: val_accuracy did not improve from 0.73000\n",
      "Epoch 1577/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8953 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01577: val_accuracy did not improve from 0.73000\n",
      "Epoch 1578/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01578: val_accuracy did not improve from 0.73000\n",
      "Epoch 1579/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9281 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01579: val_accuracy did not improve from 0.73000\n",
      "Epoch 1580/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01580: val_accuracy did not improve from 0.73000\n",
      "Epoch 1581/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9375 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01581: val_accuracy did not improve from 0.73000\n",
      "Epoch 1582/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9262 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01582: val_accuracy did not improve from 0.73000\n",
      "Epoch 1583/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9429 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01583: val_accuracy did not improve from 0.73000\n",
      "Epoch 1584/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9394 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01584: val_accuracy did not improve from 0.73000\n",
      "Epoch 1585/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9410 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01585: val_accuracy did not improve from 0.73000\n",
      "Epoch 1586/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9691 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01586: val_accuracy did not improve from 0.73000\n",
      "Epoch 1587/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9674 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01587: val_accuracy did not improve from 0.73000\n",
      "Epoch 1588/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01588: val_accuracy did not improve from 0.73000\n",
      "Epoch 1589/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9657 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01589: val_accuracy did not improve from 0.73000\n",
      "Epoch 1590/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9718 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01590: val_accuracy did not improve from 0.73000\n",
      "Epoch 1591/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9920 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01591: val_accuracy did not improve from 0.73000\n",
      "Epoch 1592/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0028 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01592: val_accuracy did not improve from 0.73000\n",
      "Epoch 1593/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0101 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01593: val_accuracy did not improve from 0.73000\n",
      "Epoch 1594/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0228 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01594: val_accuracy did not improve from 0.73000\n",
      "Epoch 1595/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0184 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01595: val_accuracy did not improve from 0.73000\n",
      "Epoch 1596/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0143 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01596: val_accuracy did not improve from 0.73000\n",
      "Epoch 1597/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0046 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01597: val_accuracy did not improve from 0.73000\n",
      "Epoch 1598/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0211 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01598: val_accuracy did not improve from 0.73000\n",
      "Epoch 1599/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0296 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01599: val_accuracy did not improve from 0.73000\n",
      "Epoch 1600/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0337 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01600: val_accuracy did not improve from 0.73000\n",
      "Epoch 1601/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0477 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01601: val_accuracy did not improve from 0.73000\n",
      "Epoch 1602/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0527 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01602: val_accuracy did not improve from 0.73000\n",
      "Epoch 1603/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0707 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01603: val_accuracy did not improve from 0.73000\n",
      "Epoch 1604/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0568 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01604: val_accuracy did not improve from 0.73000\n",
      "Epoch 1605/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0520 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01605: val_accuracy did not improve from 0.73000\n",
      "Epoch 1606/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0656 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01606: val_accuracy did not improve from 0.73000\n",
      "Epoch 1607/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0626 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01607: val_accuracy did not improve from 0.73000\n",
      "Epoch 1608/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0543 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01608: val_accuracy did not improve from 0.73000\n",
      "Epoch 1609/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0563 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01609: val_accuracy did not improve from 0.73000\n",
      "Epoch 1610/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0411 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01610: val_accuracy did not improve from 0.73000\n",
      "Epoch 1611/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1038 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01611: val_accuracy did not improve from 0.73000\n",
      "Epoch 1612/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0659 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01612: val_accuracy did not improve from 0.73000\n",
      "Epoch 1613/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1133 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01613: val_accuracy did not improve from 0.73000\n",
      "Epoch 1614/2000\n",
      "113/113 - 2s - loss: 0.3212 - accuracy: 0.9356 - val_loss: 3.2460 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01614: val_accuracy did not improve from 0.73000\n",
      "Epoch 1615/2000\n",
      "113/113 - 2s - loss: 0.3014 - accuracy: 0.9189 - val_loss: 2.9776 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01615: val_accuracy did not improve from 0.73000\n",
      "Epoch 1616/2000\n",
      "113/113 - 2s - loss: 0.1738 - accuracy: 0.9556 - val_loss: 2.8276 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01616: val_accuracy did not improve from 0.73000\n",
      "Epoch 1617/2000\n",
      "113/113 - 2s - loss: 0.0173 - accuracy: 0.9944 - val_loss: 2.8109 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01617: val_accuracy did not improve from 0.73000\n",
      "Epoch 1618/2000\n",
      "113/113 - 2s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.9184 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01618: val_accuracy did not improve from 0.73000\n",
      "Epoch 1619/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9133 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01619: val_accuracy did not improve from 0.73000\n",
      "Epoch 1620/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9211 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01620: val_accuracy did not improve from 0.73000\n",
      "Epoch 1621/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9283 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01621: val_accuracy did not improve from 0.73000\n",
      "Epoch 1622/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9298 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01622: val_accuracy did not improve from 0.73000\n",
      "Epoch 1623/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9362 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01623: val_accuracy did not improve from 0.73000\n",
      "Epoch 1624/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9450 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01624: val_accuracy did not improve from 0.73000\n",
      "Epoch 1625/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9489 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01625: val_accuracy did not improve from 0.73000\n",
      "Epoch 1626/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9506 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01626: val_accuracy did not improve from 0.73000\n",
      "Epoch 1627/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9591 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01627: val_accuracy did not improve from 0.73000\n",
      "Epoch 1628/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9627 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01628: val_accuracy did not improve from 0.73000\n",
      "Epoch 1629/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9681 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01629: val_accuracy did not improve from 0.73000\n",
      "Epoch 1630/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9752 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01630: val_accuracy did not improve from 0.73000\n",
      "Epoch 1631/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9822 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01631: val_accuracy did not improve from 0.73000\n",
      "Epoch 1632/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9843 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01632: val_accuracy did not improve from 0.73000\n",
      "Epoch 1633/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01633: val_accuracy did not improve from 0.73000\n",
      "Epoch 1634/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9956 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01634: val_accuracy did not improve from 0.73000\n",
      "Epoch 1635/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0042 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01635: val_accuracy did not improve from 0.73000\n",
      "Epoch 1636/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0108 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01636: val_accuracy did not improve from 0.73000\n",
      "Epoch 1637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0137 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01637: val_accuracy did not improve from 0.73000\n",
      "Epoch 1638/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01638: val_accuracy did not improve from 0.73000\n",
      "Epoch 1639/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0268 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01639: val_accuracy did not improve from 0.73000\n",
      "Epoch 1640/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0311 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01640: val_accuracy did not improve from 0.73000\n",
      "Epoch 1641/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0357 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01641: val_accuracy did not improve from 0.73000\n",
      "Epoch 1642/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0428 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01642: val_accuracy did not improve from 0.73000\n",
      "Epoch 1643/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0453 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01643: val_accuracy did not improve from 0.73000\n",
      "Epoch 1644/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0453 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01644: val_accuracy did not improve from 0.73000\n",
      "Epoch 1645/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0574 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01645: val_accuracy did not improve from 0.73000\n",
      "Epoch 1646/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0679 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01646: val_accuracy did not improve from 0.73000\n",
      "Epoch 1647/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0645 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01647: val_accuracy did not improve from 0.73000\n",
      "Epoch 1648/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0658 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01648: val_accuracy did not improve from 0.73000\n",
      "Epoch 1649/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0783 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01649: val_accuracy did not improve from 0.73000\n",
      "Epoch 1650/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0836 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01650: val_accuracy did not improve from 0.73000\n",
      "Epoch 1651/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0824 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01651: val_accuracy did not improve from 0.73000\n",
      "Epoch 1652/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0915 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01652: val_accuracy did not improve from 0.73000\n",
      "Epoch 1653/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0905 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01653: val_accuracy did not improve from 0.73000\n",
      "Epoch 1654/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0978 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01654: val_accuracy did not improve from 0.73000\n",
      "Epoch 1655/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1027 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01655: val_accuracy did not improve from 0.73000\n",
      "Epoch 1656/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1095 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01656: val_accuracy did not improve from 0.73000\n",
      "Epoch 1657/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1141 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01657: val_accuracy did not improve from 0.73000\n",
      "Epoch 1658/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1197 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01658: val_accuracy did not improve from 0.73000\n",
      "Epoch 1659/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1125 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01659: val_accuracy did not improve from 0.73000\n",
      "Epoch 1660/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1163 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01660: val_accuracy did not improve from 0.73000\n",
      "Epoch 1661/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1148 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01661: val_accuracy did not improve from 0.73000\n",
      "Epoch 1662/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1319 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01662: val_accuracy did not improve from 0.73000\n",
      "Epoch 1663/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1279 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01663: val_accuracy did not improve from 0.73000\n",
      "Epoch 1664/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1307 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01664: val_accuracy did not improve from 0.73000\n",
      "Epoch 1665/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1356 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01665: val_accuracy did not improve from 0.73000\n",
      "Epoch 1666/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1399 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01666: val_accuracy did not improve from 0.73000\n",
      "Epoch 1667/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1437 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01667: val_accuracy did not improve from 0.73000\n",
      "Epoch 1668/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1532 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01668: val_accuracy did not improve from 0.73000\n",
      "Epoch 1669/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1556 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01669: val_accuracy did not improve from 0.73000\n",
      "Epoch 1670/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1484 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01670: val_accuracy did not improve from 0.73000\n",
      "Epoch 1671/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1628 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01671: val_accuracy did not improve from 0.73000\n",
      "Epoch 1672/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1598 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01672: val_accuracy did not improve from 0.73000\n",
      "Epoch 1673/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1760 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01673: val_accuracy did not improve from 0.73000\n",
      "Epoch 1674/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1726 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01674: val_accuracy did not improve from 0.73000\n",
      "Epoch 1675/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1732 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01675: val_accuracy did not improve from 0.73000\n",
      "Epoch 1676/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1519 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01676: val_accuracy did not improve from 0.73000\n",
      "Epoch 1677/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1663 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01677: val_accuracy did not improve from 0.73000\n",
      "Epoch 1678/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1951 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01678: val_accuracy did not improve from 0.73000\n",
      "Epoch 1679/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1914 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01679: val_accuracy did not improve from 0.73000\n",
      "Epoch 1680/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2010 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01680: val_accuracy did not improve from 0.73000\n",
      "Epoch 1681/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1976 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01681: val_accuracy did not improve from 0.73000\n",
      "Epoch 1682/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1782 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01682: val_accuracy did not improve from 0.73000\n",
      "Epoch 1683/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1935 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01683: val_accuracy did not improve from 0.73000\n",
      "Epoch 1684/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1866 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01684: val_accuracy did not improve from 0.73000\n",
      "Epoch 1685/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1723 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01685: val_accuracy did not improve from 0.73000\n",
      "Epoch 1686/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2235 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01686: val_accuracy did not improve from 0.73000\n",
      "Epoch 1687/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1692 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01687: val_accuracy did not improve from 0.73000\n",
      "Epoch 1688/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1956 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01688: val_accuracy did not improve from 0.73000\n",
      "Epoch 1689/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2076 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01689: val_accuracy did not improve from 0.73000\n",
      "Epoch 1690/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1775 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01690: val_accuracy did not improve from 0.73000\n",
      "Epoch 1691/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2043 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01691: val_accuracy did not improve from 0.73000\n",
      "Epoch 1692/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2306 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01692: val_accuracy did not improve from 0.73000\n",
      "Epoch 1693/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0859 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01693: val_accuracy did not improve from 0.73000\n",
      "Epoch 1694/2000\n",
      "113/113 - 2s - loss: 0.6197 - accuracy: 0.8844 - val_loss: 3.6285 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01694: val_accuracy did not improve from 0.73000\n",
      "Epoch 1695/2000\n",
      "113/113 - 2s - loss: 0.1063 - accuracy: 0.9656 - val_loss: 3.1169 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01695: val_accuracy did not improve from 0.73000\n",
      "Epoch 1696/2000\n",
      "113/113 - 2s - loss: 0.0266 - accuracy: 0.9956 - val_loss: 3.0465 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01696: val_accuracy did not improve from 0.73000\n",
      "Epoch 1697/2000\n",
      "113/113 - 2s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.0508 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01697: val_accuracy did not improve from 0.73000\n",
      "Epoch 1698/2000\n",
      "113/113 - 2s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.0234 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01698: val_accuracy did not improve from 0.73000\n",
      "Epoch 1699/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0176 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01699: val_accuracy did not improve from 0.73000\n",
      "Epoch 1700/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0162 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01700: val_accuracy did not improve from 0.73000\n",
      "Epoch 1701/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0119 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01701: val_accuracy did not improve from 0.73000\n",
      "Epoch 1702/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0057 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01702: val_accuracy did not improve from 0.73000\n",
      "Epoch 1703/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0026 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01703: val_accuracy did not improve from 0.73000\n",
      "Epoch 1704/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0079 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01704: val_accuracy did not improve from 0.73000\n",
      "Epoch 1705/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9974 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01705: val_accuracy did not improve from 0.73000\n",
      "Epoch 1706/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9973 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01706: val_accuracy did not improve from 0.73000\n",
      "Epoch 1707/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0007 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01707: val_accuracy did not improve from 0.73000\n",
      "Epoch 1708/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9947 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01708: val_accuracy did not improve from 0.73000\n",
      "Epoch 1709/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0049 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01709: val_accuracy did not improve from 0.73000\n",
      "Epoch 1710/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0021 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01710: val_accuracy did not improve from 0.73000\n",
      "Epoch 1711/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0014 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01711: val_accuracy did not improve from 0.73000\n",
      "Epoch 1712/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0009 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01712: val_accuracy did not improve from 0.73000\n",
      "Epoch 1713/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0140 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01713: val_accuracy did not improve from 0.73000\n",
      "Epoch 1714/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0071 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01714: val_accuracy did not improve from 0.73000\n",
      "Epoch 1715/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0040 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01715: val_accuracy did not improve from 0.73000\n",
      "Epoch 1716/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0053 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01716: val_accuracy did not improve from 0.73000\n",
      "Epoch 1717/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0124 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01717: val_accuracy did not improve from 0.73000\n",
      "Epoch 1718/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0198 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01718: val_accuracy did not improve from 0.73000\n",
      "Epoch 1719/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0210 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01719: val_accuracy did not improve from 0.73000\n",
      "Epoch 1720/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0252 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01720: val_accuracy did not improve from 0.73000\n",
      "Epoch 1721/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0334 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01721: val_accuracy did not improve from 0.73000\n",
      "Epoch 1722/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0386 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01722: val_accuracy did not improve from 0.73000\n",
      "Epoch 1723/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0384 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01723: val_accuracy did not improve from 0.73000\n",
      "Epoch 1724/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0418 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01724: val_accuracy did not improve from 0.73000\n",
      "Epoch 1725/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0467 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01725: val_accuracy did not improve from 0.73000\n",
      "Epoch 1726/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0492 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01726: val_accuracy did not improve from 0.73000\n",
      "Epoch 1727/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0580 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01727: val_accuracy did not improve from 0.73000\n",
      "Epoch 1728/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0640 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01728: val_accuracy did not improve from 0.73000\n",
      "Epoch 1729/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0773 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01729: val_accuracy did not improve from 0.73000\n",
      "Epoch 1730/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0721 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01730: val_accuracy did not improve from 0.73000\n",
      "Epoch 1731/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0729 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01731: val_accuracy did not improve from 0.73000\n",
      "Epoch 1732/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0910 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01732: val_accuracy did not improve from 0.73000\n",
      "Epoch 1733/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0855 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01733: val_accuracy did not improve from 0.73000\n",
      "Epoch 1734/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0886 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01734: val_accuracy did not improve from 0.73000\n",
      "Epoch 1735/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1017 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01735: val_accuracy did not improve from 0.73000\n",
      "Epoch 1736/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0954 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01736: val_accuracy did not improve from 0.73000\n",
      "Epoch 1737/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1178 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01737: val_accuracy did not improve from 0.73000\n",
      "Epoch 1738/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1171 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01738: val_accuracy did not improve from 0.73000\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1078 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01739: val_accuracy did not improve from 0.73000\n",
      "Epoch 1740/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1250 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01740: val_accuracy did not improve from 0.73000\n",
      "Epoch 1741/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1333 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01741: val_accuracy did not improve from 0.73000\n",
      "Epoch 1742/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1149 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01742: val_accuracy did not improve from 0.73000\n",
      "Epoch 1743/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1306 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01743: val_accuracy did not improve from 0.73000\n",
      "Epoch 1744/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1384 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01744: val_accuracy did not improve from 0.73000\n",
      "Epoch 1745/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1506 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01745: val_accuracy did not improve from 0.73000\n",
      "Epoch 1746/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1459 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01746: val_accuracy did not improve from 0.73000\n",
      "Epoch 1747/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1583 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01747: val_accuracy did not improve from 0.73000\n",
      "Epoch 1748/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1761 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01748: val_accuracy did not improve from 0.73000\n",
      "Epoch 1749/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1619 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01749: val_accuracy did not improve from 0.73000\n",
      "Epoch 1750/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1516 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01750: val_accuracy did not improve from 0.73000\n",
      "Epoch 1751/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1685 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01751: val_accuracy did not improve from 0.73000\n",
      "Epoch 1752/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1542 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01752: val_accuracy did not improve from 0.73000\n",
      "Epoch 1753/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1682 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01753: val_accuracy did not improve from 0.73000\n",
      "Epoch 1754/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1633 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01754: val_accuracy did not improve from 0.73000\n",
      "Epoch 1755/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01755: val_accuracy did not improve from 0.73000\n",
      "Epoch 1756/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1482 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01756: val_accuracy did not improve from 0.73000\n",
      "Epoch 1757/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1823 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01757: val_accuracy did not improve from 0.73000\n",
      "Epoch 1758/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1593 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01758: val_accuracy did not improve from 0.73000\n",
      "Epoch 1759/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2090 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01759: val_accuracy did not improve from 0.73000\n",
      "Epoch 1760/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1996 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01760: val_accuracy did not improve from 0.73000\n",
      "Epoch 1761/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1634 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01761: val_accuracy did not improve from 0.73000\n",
      "Epoch 1762/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1915 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01762: val_accuracy did not improve from 0.73000\n",
      "Epoch 1763/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2266 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01763: val_accuracy did not improve from 0.73000\n",
      "Epoch 1764/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2131 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01764: val_accuracy did not improve from 0.73000\n",
      "Epoch 1765/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2466 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01765: val_accuracy did not improve from 0.73000\n",
      "Epoch 1766/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2269 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01766: val_accuracy did not improve from 0.73000\n",
      "Epoch 1767/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2360 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01767: val_accuracy did not improve from 0.73000\n",
      "Epoch 1768/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01768: val_accuracy did not improve from 0.73000\n",
      "Epoch 1769/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1757 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01769: val_accuracy did not improve from 0.73000\n",
      "Epoch 1770/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1753 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01770: val_accuracy did not improve from 0.73000\n",
      "Epoch 1771/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2503 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01771: val_accuracy did not improve from 0.73000\n",
      "Epoch 1772/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2474 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01772: val_accuracy did not improve from 0.73000\n",
      "Epoch 1773/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2495 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01773: val_accuracy did not improve from 0.73000\n",
      "Epoch 1774/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1921 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01774: val_accuracy did not improve from 0.73000\n",
      "Epoch 1775/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1930 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01775: val_accuracy did not improve from 0.73000\n",
      "Epoch 1776/2000\n",
      "113/113 - 2s - loss: 0.3896 - accuracy: 0.9322 - val_loss: 3.6951 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01776: val_accuracy did not improve from 0.73000\n",
      "Epoch 1777/2000\n",
      "113/113 - 2s - loss: 0.4028 - accuracy: 0.9133 - val_loss: 3.5151 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01777: val_accuracy did not improve from 0.73000\n",
      "Epoch 1778/2000\n",
      "113/113 - 2s - loss: 0.0365 - accuracy: 0.9900 - val_loss: 3.1945 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01778: val_accuracy did not improve from 0.73000\n",
      "Epoch 1779/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1226 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01779: val_accuracy did not improve from 0.73000\n",
      "Epoch 1780/2000\n",
      "113/113 - 2s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1001 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01780: val_accuracy did not improve from 0.73000\n",
      "Epoch 1781/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0964 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01781: val_accuracy did not improve from 0.73000\n",
      "Epoch 1782/2000\n",
      "113/113 - 2s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0893 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01782: val_accuracy did not improve from 0.73000\n",
      "Epoch 1783/2000\n",
      "113/113 - 2s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0875 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01783: val_accuracy did not improve from 0.73000\n",
      "Epoch 1784/2000\n",
      "113/113 - 2s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0839 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01784: val_accuracy did not improve from 0.73000\n",
      "Epoch 1785/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0864 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01785: val_accuracy did not improve from 0.73000\n",
      "Epoch 1786/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0844 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01786: val_accuracy did not improve from 0.73000\n",
      "Epoch 1787/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0856 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01787: val_accuracy did not improve from 0.73000\n",
      "Epoch 1788/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0832 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01788: val_accuracy did not improve from 0.73000\n",
      "Epoch 1789/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0912 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01789: val_accuracy did not improve from 0.73000\n",
      "Epoch 1790/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0916 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01790: val_accuracy did not improve from 0.73000\n",
      "Epoch 1791/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0923 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01791: val_accuracy did not improve from 0.73000\n",
      "Epoch 1792/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0963 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01792: val_accuracy did not improve from 0.73000\n",
      "Epoch 1793/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0932 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01793: val_accuracy did not improve from 0.73000\n",
      "Epoch 1794/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0923 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01794: val_accuracy did not improve from 0.73000\n",
      "Epoch 1795/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0947 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01795: val_accuracy did not improve from 0.73000\n",
      "Epoch 1796/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0903 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01796: val_accuracy did not improve from 0.73000\n",
      "Epoch 1797/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1073 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01797: val_accuracy did not improve from 0.73000\n",
      "Epoch 1798/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1016 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01798: val_accuracy did not improve from 0.73000\n",
      "Epoch 1799/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1044 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01799: val_accuracy did not improve from 0.73000\n",
      "Epoch 1800/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1105 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01800: val_accuracy did not improve from 0.73000\n",
      "Epoch 1801/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1074 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01801: val_accuracy did not improve from 0.73000\n",
      "Epoch 1802/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1139 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01802: val_accuracy did not improve from 0.73000\n",
      "Epoch 1803/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1211 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01803: val_accuracy did not improve from 0.73000\n",
      "Epoch 1804/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1262 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01804: val_accuracy did not improve from 0.73000\n",
      "Epoch 1805/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1332 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01805: val_accuracy did not improve from 0.73000\n",
      "Epoch 1806/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1373 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01806: val_accuracy did not improve from 0.73000\n",
      "Epoch 1807/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01807: val_accuracy did not improve from 0.73000\n",
      "Epoch 1808/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1421 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01808: val_accuracy did not improve from 0.73000\n",
      "Epoch 1809/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1483 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01809: val_accuracy did not improve from 0.73000\n",
      "Epoch 1810/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1610 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01810: val_accuracy did not improve from 0.73000\n",
      "Epoch 1811/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1589 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01811: val_accuracy did not improve from 0.73000\n",
      "Epoch 1812/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1656 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01812: val_accuracy did not improve from 0.73000\n",
      "Epoch 1813/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1750 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01813: val_accuracy did not improve from 0.73000\n",
      "Epoch 1814/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1671 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01814: val_accuracy did not improve from 0.73000\n",
      "Epoch 1815/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1809 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01815: val_accuracy did not improve from 0.73000\n",
      "Epoch 1816/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1853 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01816: val_accuracy did not improve from 0.73000\n",
      "Epoch 1817/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1962 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01817: val_accuracy did not improve from 0.73000\n",
      "Epoch 1818/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1957 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01818: val_accuracy did not improve from 0.73000\n",
      "Epoch 1819/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1888 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01819: val_accuracy did not improve from 0.73000\n",
      "Epoch 1820/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01820: val_accuracy did not improve from 0.73000\n",
      "Epoch 1821/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2020 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01821: val_accuracy did not improve from 0.73000\n",
      "Epoch 1822/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1966 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01822: val_accuracy did not improve from 0.73000\n",
      "Epoch 1823/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2052 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01823: val_accuracy did not improve from 0.73000\n",
      "Epoch 1824/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2316 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01824: val_accuracy did not improve from 0.73000\n",
      "Epoch 1825/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2167 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01825: val_accuracy did not improve from 0.73000\n",
      "Epoch 1826/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2205 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01826: val_accuracy did not improve from 0.73000\n",
      "Epoch 1827/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2270 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01827: val_accuracy did not improve from 0.73000\n",
      "Epoch 1828/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2212 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01828: val_accuracy did not improve from 0.73000\n",
      "Epoch 1829/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2351 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01829: val_accuracy did not improve from 0.73000\n",
      "Epoch 1830/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2478 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01830: val_accuracy did not improve from 0.73000\n",
      "Epoch 1831/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2492 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01831: val_accuracy did not improve from 0.73000\n",
      "Epoch 1832/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2550 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01832: val_accuracy did not improve from 0.73000\n",
      "Epoch 1833/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2962 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01833: val_accuracy did not improve from 0.73000\n",
      "Epoch 1834/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2481 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01834: val_accuracy did not improve from 0.73000\n",
      "Epoch 1835/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2748 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01835: val_accuracy did not improve from 0.73000\n",
      "Epoch 1836/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2781 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01836: val_accuracy did not improve from 0.73000\n",
      "Epoch 1837/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2986 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01837: val_accuracy did not improve from 0.73000\n",
      "Epoch 1838/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2822 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01838: val_accuracy did not improve from 0.73000\n",
      "Epoch 1839/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3027 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01839: val_accuracy did not improve from 0.73000\n",
      "Epoch 1840/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2740 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01840: val_accuracy did not improve from 0.73000\n",
      "Epoch 1841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3056 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01841: val_accuracy did not improve from 0.73000\n",
      "Epoch 1842/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3034 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01842: val_accuracy did not improve from 0.73000\n",
      "Epoch 1843/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2839 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01843: val_accuracy did not improve from 0.73000\n",
      "Epoch 1844/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3166 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01844: val_accuracy did not improve from 0.73000\n",
      "Epoch 1845/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3110 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01845: val_accuracy did not improve from 0.73000\n",
      "Epoch 1846/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3049 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01846: val_accuracy did not improve from 0.73000\n",
      "Epoch 1847/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3171 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01847: val_accuracy did not improve from 0.73000\n",
      "Epoch 1848/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3517 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01848: val_accuracy did not improve from 0.73000\n",
      "Epoch 1849/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3319 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01849: val_accuracy did not improve from 0.73000\n",
      "Epoch 1850/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2766 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01850: val_accuracy did not improve from 0.73000\n",
      "Epoch 1851/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3462 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01851: val_accuracy did not improve from 0.73000\n",
      "Epoch 1852/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3127 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01852: val_accuracy did not improve from 0.73000\n",
      "Epoch 1853/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3305 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01853: val_accuracy did not improve from 0.73000\n",
      "Epoch 1854/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3125 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01854: val_accuracy did not improve from 0.73000\n",
      "Epoch 1855/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2595 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01855: val_accuracy did not improve from 0.73000\n",
      "Epoch 1856/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3003 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01856: val_accuracy did not improve from 0.73000\n",
      "Epoch 1857/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2662 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01857: val_accuracy did not improve from 0.73000\n",
      "Epoch 1858/2000\n",
      "113/113 - 2s - loss: 0.4324 - accuracy: 0.9200 - val_loss: 3.5961 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01858: val_accuracy did not improve from 0.73000\n",
      "Epoch 1859/2000\n",
      "113/113 - 2s - loss: 0.2028 - accuracy: 0.9422 - val_loss: 2.9016 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01859: val_accuracy did not improve from 0.73000\n",
      "Epoch 1860/2000\n",
      "113/113 - 2s - loss: 0.0105 - accuracy: 0.9989 - val_loss: 3.1067 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01860: val_accuracy did not improve from 0.73000\n",
      "Epoch 1861/2000\n",
      "113/113 - 2s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 2.9358 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01861: val_accuracy did not improve from 0.73000\n",
      "Epoch 1862/2000\n",
      "113/113 - 2s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9624 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01862: val_accuracy did not improve from 0.73000\n",
      "Epoch 1863/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9788 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01863: val_accuracy did not improve from 0.73000\n",
      "Epoch 1864/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9963 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01864: val_accuracy did not improve from 0.73000\n",
      "Epoch 1865/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0084 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01865: val_accuracy did not improve from 0.73000\n",
      "Epoch 1866/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0168 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01866: val_accuracy did not improve from 0.73000\n",
      "Epoch 1867/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0289 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01867: val_accuracy did not improve from 0.73000\n",
      "Epoch 1868/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0343 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01868: val_accuracy did not improve from 0.73000\n",
      "Epoch 1869/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0380 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01869: val_accuracy did not improve from 0.73000\n",
      "Epoch 1870/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0472 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01870: val_accuracy did not improve from 0.73000\n",
      "Epoch 1871/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0559 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01871: val_accuracy did not improve from 0.73000\n",
      "Epoch 1872/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0651 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01872: val_accuracy did not improve from 0.73000\n",
      "Epoch 1873/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0770 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01873: val_accuracy did not improve from 0.73000\n",
      "Epoch 1874/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0846 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01874: val_accuracy did not improve from 0.73000\n",
      "Epoch 1875/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0945 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01875: val_accuracy did not improve from 0.73000\n",
      "Epoch 1876/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0971 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01876: val_accuracy did not improve from 0.73000\n",
      "Epoch 1877/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1068 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01877: val_accuracy did not improve from 0.73000\n",
      "Epoch 1878/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1231 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01878: val_accuracy did not improve from 0.73000\n",
      "Epoch 1879/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1201 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01879: val_accuracy did not improve from 0.73000\n",
      "Epoch 1880/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1239 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01880: val_accuracy did not improve from 0.73000\n",
      "Epoch 1881/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1287 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01881: val_accuracy did not improve from 0.73000\n",
      "Epoch 1882/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01882: val_accuracy did not improve from 0.73000\n",
      "Epoch 1883/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1507 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01883: val_accuracy did not improve from 0.73000\n",
      "Epoch 1884/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1538 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01884: val_accuracy did not improve from 0.73000\n",
      "Epoch 1885/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1592 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01885: val_accuracy did not improve from 0.73000\n",
      "Epoch 1886/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1652 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01886: val_accuracy did not improve from 0.73000\n",
      "Epoch 1887/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1684 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01887: val_accuracy did not improve from 0.73000\n",
      "Epoch 1888/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1764 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01888: val_accuracy did not improve from 0.73000\n",
      "Epoch 1889/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1863 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01889: val_accuracy did not improve from 0.73000\n",
      "Epoch 1890/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1879 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01890: val_accuracy did not improve from 0.73000\n",
      "Epoch 1891/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01891: val_accuracy did not improve from 0.73000\n",
      "Epoch 1892/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1944 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01892: val_accuracy did not improve from 0.73000\n",
      "Epoch 1893/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2087 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01893: val_accuracy did not improve from 0.73000\n",
      "Epoch 1894/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2049 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01894: val_accuracy did not improve from 0.73000\n",
      "Epoch 1895/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2218 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01895: val_accuracy did not improve from 0.73000\n",
      "Epoch 1896/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2155 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01896: val_accuracy did not improve from 0.73000\n",
      "Epoch 1897/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2296 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01897: val_accuracy did not improve from 0.73000\n",
      "Epoch 1898/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2311 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01898: val_accuracy did not improve from 0.73000\n",
      "Epoch 1899/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2475 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01899: val_accuracy did not improve from 0.73000\n",
      "Epoch 1900/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2471 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01900: val_accuracy did not improve from 0.73000\n",
      "Epoch 1901/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2564 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01901: val_accuracy did not improve from 0.73000\n",
      "Epoch 1902/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2712 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01902: val_accuracy did not improve from 0.73000\n",
      "Epoch 1903/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2630 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01903: val_accuracy did not improve from 0.73000\n",
      "Epoch 1904/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2699 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01904: val_accuracy did not improve from 0.73000\n",
      "Epoch 1905/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2814 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01905: val_accuracy did not improve from 0.73000\n",
      "Epoch 1906/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2727 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01906: val_accuracy did not improve from 0.73000\n",
      "Epoch 1907/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2725 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01907: val_accuracy did not improve from 0.73000\n",
      "Epoch 1908/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2851 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01908: val_accuracy did not improve from 0.73000\n",
      "Epoch 1909/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2710 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01909: val_accuracy did not improve from 0.73000\n",
      "Epoch 1910/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2920 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01910: val_accuracy did not improve from 0.73000\n",
      "Epoch 1911/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2805 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01911: val_accuracy did not improve from 0.73000\n",
      "Epoch 1912/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2895 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01912: val_accuracy did not improve from 0.73000\n",
      "Epoch 1913/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2838 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01913: val_accuracy did not improve from 0.73000\n",
      "Epoch 1914/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2969 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01914: val_accuracy did not improve from 0.73000\n",
      "Epoch 1915/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2993 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01915: val_accuracy did not improve from 0.73000\n",
      "Epoch 1916/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3073 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01916: val_accuracy did not improve from 0.73000\n",
      "Epoch 1917/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3224 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01917: val_accuracy did not improve from 0.73000\n",
      "Epoch 1918/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3044 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01918: val_accuracy did not improve from 0.73000\n",
      "Epoch 1919/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3147 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01919: val_accuracy did not improve from 0.73000\n",
      "Epoch 1920/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3090 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01920: val_accuracy did not improve from 0.73000\n",
      "Epoch 1921/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3147 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01921: val_accuracy did not improve from 0.73000\n",
      "Epoch 1922/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3061 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01922: val_accuracy did not improve from 0.73000\n",
      "Epoch 1923/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3218 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01923: val_accuracy did not improve from 0.73000\n",
      "Epoch 1924/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3287 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01924: val_accuracy did not improve from 0.73000\n",
      "Epoch 1925/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3155 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01925: val_accuracy did not improve from 0.73000\n",
      "Epoch 1926/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3133 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01926: val_accuracy did not improve from 0.73000\n",
      "Epoch 1927/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3306 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01927: val_accuracy did not improve from 0.73000\n",
      "Epoch 1928/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2955 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01928: val_accuracy did not improve from 0.73000\n",
      "Epoch 1929/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3299 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01929: val_accuracy did not improve from 0.73000\n",
      "Epoch 1930/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3200 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01930: val_accuracy did not improve from 0.73000\n",
      "Epoch 1931/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3375 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01931: val_accuracy did not improve from 0.73000\n",
      "Epoch 1932/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2977 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01932: val_accuracy did not improve from 0.73000\n",
      "Epoch 1933/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3659 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01933: val_accuracy did not improve from 0.73000\n",
      "Epoch 1934/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3343 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01934: val_accuracy did not improve from 0.73000\n",
      "Epoch 1935/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3573 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01935: val_accuracy did not improve from 0.73000\n",
      "Epoch 1936/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3298 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01936: val_accuracy did not improve from 0.73000\n",
      "Epoch 1937/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2924 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01937: val_accuracy did not improve from 0.73000\n",
      "Epoch 1938/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3646 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01938: val_accuracy did not improve from 0.73000\n",
      "Epoch 1939/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3856 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01939: val_accuracy did not improve from 0.73000\n",
      "Epoch 1940/2000\n",
      "113/113 - 2s - loss: 0.3665 - accuracy: 0.9389 - val_loss: 3.5243 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01940: val_accuracy did not improve from 0.73000\n",
      "Epoch 1941/2000\n",
      "113/113 - 2s - loss: 0.2917 - accuracy: 0.9189 - val_loss: 2.7582 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01941: val_accuracy did not improve from 0.73000\n",
      "Epoch 1942/2000\n",
      "113/113 - 2s - loss: 0.0359 - accuracy: 0.9889 - val_loss: 3.2202 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01942: val_accuracy did not improve from 0.73000\n",
      "Epoch 1943/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0112 - accuracy: 0.9967 - val_loss: 3.1033 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01943: val_accuracy did not improve from 0.73000\n",
      "Epoch 1944/2000\n",
      "113/113 - 2s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0574 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01944: val_accuracy did not improve from 0.73000\n",
      "Epoch 1945/2000\n",
      "113/113 - 2s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0741 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01945: val_accuracy did not improve from 0.73000\n",
      "Epoch 1946/2000\n",
      "113/113 - 2s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1027 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01946: val_accuracy did not improve from 0.73000\n",
      "Epoch 1947/2000\n",
      "113/113 - 2s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.1036 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01947: val_accuracy did not improve from 0.73000\n",
      "Epoch 1948/2000\n",
      "113/113 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1034 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01948: val_accuracy did not improve from 0.73000\n",
      "Epoch 1949/2000\n",
      "113/113 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.1040 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01949: val_accuracy did not improve from 0.73000\n",
      "Epoch 1950/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.1188 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01950: val_accuracy did not improve from 0.73000\n",
      "Epoch 1951/2000\n",
      "113/113 - 2s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.1218 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01951: val_accuracy did not improve from 0.73000\n",
      "Epoch 1952/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1217 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01952: val_accuracy did not improve from 0.73000\n",
      "Epoch 1953/2000\n",
      "113/113 - 2s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1259 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01953: val_accuracy did not improve from 0.73000\n",
      "Epoch 1954/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1277 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01954: val_accuracy did not improve from 0.73000\n",
      "Epoch 1955/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1297 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01955: val_accuracy did not improve from 0.73000\n",
      "Epoch 1956/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1389 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01956: val_accuracy did not improve from 0.73000\n",
      "Epoch 1957/2000\n",
      "113/113 - 2s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1440 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01957: val_accuracy did not improve from 0.73000\n",
      "Epoch 1958/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01958: val_accuracy did not improve from 0.73000\n",
      "Epoch 1959/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1517 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01959: val_accuracy did not improve from 0.73000\n",
      "Epoch 1960/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1522 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01960: val_accuracy did not improve from 0.73000\n",
      "Epoch 1961/2000\n",
      "113/113 - 2s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1538 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01961: val_accuracy did not improve from 0.73000\n",
      "Epoch 1962/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1530 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01962: val_accuracy did not improve from 0.73000\n",
      "Epoch 1963/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1593 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01963: val_accuracy did not improve from 0.73000\n",
      "Epoch 1964/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1633 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01964: val_accuracy did not improve from 0.73000\n",
      "Epoch 1965/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1601 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01965: val_accuracy did not improve from 0.73000\n",
      "Epoch 1966/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1703 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01966: val_accuracy did not improve from 0.73000\n",
      "Epoch 1967/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1673 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01967: val_accuracy did not improve from 0.73000\n",
      "Epoch 1968/2000\n",
      "113/113 - 2s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1809 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01968: val_accuracy did not improve from 0.73000\n",
      "Epoch 1969/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1882 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01969: val_accuracy did not improve from 0.73000\n",
      "Epoch 1970/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1729 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01970: val_accuracy did not improve from 0.73000\n",
      "Epoch 1971/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1855 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01971: val_accuracy did not improve from 0.73000\n",
      "Epoch 1972/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1869 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01972: val_accuracy did not improve from 0.73000\n",
      "Epoch 1973/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1907 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01973: val_accuracy did not improve from 0.73000\n",
      "Epoch 1974/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1923 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01974: val_accuracy did not improve from 0.73000\n",
      "Epoch 1975/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2011 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01975: val_accuracy did not improve from 0.73000\n",
      "Epoch 1976/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1974 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01976: val_accuracy did not improve from 0.73000\n",
      "Epoch 1977/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2037 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01977: val_accuracy did not improve from 0.73000\n",
      "Epoch 1978/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2095 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01978: val_accuracy did not improve from 0.73000\n",
      "Epoch 1979/2000\n",
      "113/113 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2098 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01979: val_accuracy did not improve from 0.73000\n",
      "Epoch 1980/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2105 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01980: val_accuracy did not improve from 0.73000\n",
      "Epoch 1981/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2198 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01981: val_accuracy did not improve from 0.73000\n",
      "Epoch 1982/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2292 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01982: val_accuracy did not improve from 0.73000\n",
      "Epoch 1983/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2259 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01983: val_accuracy did not improve from 0.73000\n",
      "Epoch 1984/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2310 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01984: val_accuracy did not improve from 0.73000\n",
      "Epoch 1985/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2314 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01985: val_accuracy did not improve from 0.73000\n",
      "Epoch 1986/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2483 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01986: val_accuracy did not improve from 0.73000\n",
      "Epoch 1987/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2425 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01987: val_accuracy did not improve from 0.73000\n",
      "Epoch 1988/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2496 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01988: val_accuracy did not improve from 0.73000\n",
      "Epoch 1989/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2575 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01989: val_accuracy did not improve from 0.73000\n",
      "Epoch 1990/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2627 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01990: val_accuracy did not improve from 0.73000\n",
      "Epoch 1991/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2577 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01991: val_accuracy did not improve from 0.73000\n",
      "Epoch 1992/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2705 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01992: val_accuracy did not improve from 0.73000\n",
      "Epoch 1993/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01993: val_accuracy did not improve from 0.73000\n",
      "Epoch 1994/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2761 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01994: val_accuracy did not improve from 0.73000\n",
      "Epoch 1995/2000\n",
      "113/113 - 2s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2854 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01995: val_accuracy did not improve from 0.73000\n",
      "Epoch 1996/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2885 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01996: val_accuracy did not improve from 0.73000\n",
      "Epoch 1997/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2782 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01997: val_accuracy did not improve from 0.73000\n",
      "Epoch 1998/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2974 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01998: val_accuracy did not improve from 0.73000\n",
      "Epoch 1999/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2946 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01999: val_accuracy did not improve from 0.73000\n",
      "Epoch 2000/2000\n",
      "113/113 - 2s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2896 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 02000: val_accuracy did not improve from 0.73000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1635fbe5cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "n_epoch=2000\n",
    "\n",
    "\n",
    "LSwoFW_model.fit(train_data, \n",
    "                train_targets, \n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_data, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x299d8e64280>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSwoFW_model.load_weights(os.path.join(\"210210_TrainingLocalitySensitivewoFW\",\n",
    "                                      \"LocalitySensitivewoFW_label\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions=[LSwoFW_model.layers[1].attention_layers[i](train_data).numpy() for i in range(10)]\n",
    "attentions=np.reshape(attentions, (900,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "attentions=LSwoFW_model.layers[1](train_data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x16363e87610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "dr=TSNE()\n",
    "embed_attentions=dr.fit_transform(attentions)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "scatter=ax.scatter(embed_attentions[:,0], embed_attentions[:,1],\n",
    "                   c=cluster_labels_train,\n",
    "                   s=3\n",
    "                  )\n",
    "\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = train_data.shape[1]\n",
    "n_attention = 10 #Reduced from 20 to 10. 10 works better\n",
    "n_attention_hidden=40\n",
    "n_attention_out=1\n",
    "n_concat_hidden=128\n",
    "n_hidden1 =64\n",
    "n_hidden2 = 64\n",
    "momentum=0.8\n",
    "learning_rate=0.001\n",
    "\n",
    "n_batch=8\n",
    "\n",
    "label=\"SynthData\"\n",
    "\n",
    "save_folder=os.path.join(time.strftime(\"%y%m%d_TrainingDense\",\n",
    "                                       time.localtime()))\n",
    "checkpoint_path = os.path.join(save_folder, \n",
    "                               \"Dense_{}\".format(\"label\"),\n",
    "                               )\n",
    "\n",
    "try: \n",
    "    os.mkdir(save_folder) \n",
    "except OSError as error: \n",
    "    print(error) \n",
    "    \n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "concat_activation=\"selu\"\n",
    "attention_hidden_activation=\"selu\"\n",
    "attention_output_activation=\"sigmoid\"\n",
    "kernel_initializer=VarianceScaling()\n",
    "hidden_activation=\"selu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import attention_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "input_layer=Input(shape=(n_feat, ))\n",
    "\n",
    "dense_layer0=Dense(n_attention_hidden*n_attention,\n",
    "                   activation=\"sigmoid\", \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5),\n",
    "                  )(input_layer)\n",
    "# attentions_layer=attention_model.ConcatAttentions(\n",
    "#     n_attention=n_attention,\n",
    "#     n_attention_hidden=n_attention_hidden,\n",
    "#     n_attention_out=n_attention_out,\n",
    "#     n_feat=n_feat,\n",
    "#     n_hidden=n_concat_hidden,\n",
    "#     activation=concat_activation, \n",
    "#     kernel_initializer=kernel_initializer,\n",
    "#     kernel_regularizer=l2(1E-5),\n",
    "#     bias_regularizer=l2(1E-5),\n",
    "#     attention_initializer=kernel_initializer,\n",
    "#     attention_hidden_activation=attention_hidden_activation,\n",
    "#     attention_output_activation=attention_output_activation,\n",
    "#     batch_norm_kwargs={\"trainable\":False, \"renorm\":False},\n",
    "# )(input_layer)\n",
    "##Removed dropout for attentions_layer because of Batch normalization\n",
    "# dropout0=Dropout(0.1)(attentions_layer)\n",
    "dense_layer1=Dense(n_hidden1, \n",
    "                   activation=hidden_activation, \n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5),\n",
    "                  )(dense_layer0)\n",
    "# dropout1=Dropout(0.1)(dense_layer1)\n",
    "dense_layer2=Dense(n_hidden2,\n",
    "                   activation=hidden_activation,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   kernel_regularizer=l2(1E-5),\n",
    "                   bias_regularizer=l2(1E-5)\n",
    "                  )(dense_layer1)\n",
    "# dropout2=Dropout(0.1)(dense_layer2)\n",
    "output_layer=Dense(1, activation=\"sigmoid\")(dense_layer2)\n",
    "\n",
    "dense_model=Model(inputs=input_layer, \n",
    "                  outputs=output_layer\n",
    "                 )\n",
    "\n",
    "weights_dicts=get_weights_dicts(np.expand_dims(train_targets,1))\n",
    "loss_fn=BinaryCrossEntropyIgnoreNaN(weights_dicts=weights_dicts)\n",
    "\n",
    "# loss_fn=tf.nn.sigmoid_cross_entropy_with_logits\n",
    "\n",
    "dense_model.compile(loss=loss_fn,\n",
    "    #loss=BinaryCrossentropy(from_logits=False, \n",
    "#                                             reduction=tf.keras.losses.Reduction.AUTO,\n",
    "#                                            ), \n",
    "              optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy',]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                25664     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 34,289\n",
      "Trainable params: 34,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "113/113 - 1s - loss: 0.7663 - accuracy: 0.4722 - val_loss: 0.7422 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 2/2000\n",
      "113/113 - 1s - loss: 0.7212 - accuracy: 0.5178 - val_loss: 0.7377 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48000 to 0.52000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 3/2000\n",
      "113/113 - 1s - loss: 0.7181 - accuracy: 0.4711 - val_loss: 0.7076 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.52000\n",
      "Epoch 4/2000\n",
      "113/113 - 1s - loss: 0.7005 - accuracy: 0.5344 - val_loss: 0.7372 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.52000\n",
      "Epoch 5/2000\n",
      "113/113 - 1s - loss: 0.7177 - accuracy: 0.5011 - val_loss: 0.7127 - val_accuracy: 0.4700\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52000\n",
      "Epoch 6/2000\n",
      "113/113 - 1s - loss: 0.7135 - accuracy: 0.5044 - val_loss: 0.7233 - val_accuracy: 0.4200\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.52000\n",
      "Epoch 7/2000\n",
      "113/113 - 1s - loss: 0.7131 - accuracy: 0.5167 - val_loss: 0.7011 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.52000\n",
      "Epoch 8/2000\n",
      "113/113 - 1s - loss: 0.7058 - accuracy: 0.5311 - val_loss: 0.7237 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.52000\n",
      "Epoch 9/2000\n",
      "113/113 - 1s - loss: 0.7032 - accuracy: 0.5122 - val_loss: 0.7172 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.52000\n",
      "Epoch 10/2000\n",
      "113/113 - 1s - loss: 0.7289 - accuracy: 0.5200 - val_loss: 0.7347 - val_accuracy: 0.4300\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.52000\n",
      "Epoch 11/2000\n",
      "113/113 - 1s - loss: 0.6956 - accuracy: 0.5544 - val_loss: 0.7149 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.52000 to 0.53000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 12/2000\n",
      "113/113 - 1s - loss: 0.6985 - accuracy: 0.5733 - val_loss: 0.6920 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.53000 to 0.58000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 13/2000\n",
      "113/113 - 1s - loss: 0.6847 - accuracy: 0.5733 - val_loss: 0.6864 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.58000 to 0.59000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 14/2000\n",
      "113/113 - 1s - loss: 0.6751 - accuracy: 0.6156 - val_loss: 0.7180 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.59000\n",
      "Epoch 15/2000\n",
      "113/113 - 1s - loss: 0.6819 - accuracy: 0.5944 - val_loss: 0.6869 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.59000\n",
      "Epoch 16/2000\n",
      "113/113 - 1s - loss: 0.6666 - accuracy: 0.6156 - val_loss: 0.7130 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59000\n",
      "Epoch 17/2000\n",
      "113/113 - 1s - loss: 0.6896 - accuracy: 0.6022 - val_loss: 0.7295 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59000\n",
      "Epoch 18/2000\n",
      "113/113 - 1s - loss: 0.6692 - accuracy: 0.6044 - val_loss: 0.8567 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59000\n",
      "Epoch 19/2000\n",
      "113/113 - 1s - loss: 0.6633 - accuracy: 0.6178 - val_loss: 0.7011 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59000\n",
      "Epoch 20/2000\n",
      "113/113 - 1s - loss: 0.6591 - accuracy: 0.6222 - val_loss: 0.6690 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.59000 to 0.61000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 21/2000\n",
      "113/113 - 1s - loss: 0.6479 - accuracy: 0.6233 - val_loss: 0.7389 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.61000\n",
      "Epoch 22/2000\n",
      "113/113 - 1s - loss: 0.6339 - accuracy: 0.6411 - val_loss: 0.7376 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.61000\n",
      "Epoch 23/2000\n",
      "113/113 - 1s - loss: 0.6378 - accuracy: 0.6467 - val_loss: 0.6829 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.61000 to 0.65000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 24/2000\n",
      "113/113 - 1s - loss: 0.6381 - accuracy: 0.6367 - val_loss: 0.6992 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65000\n",
      "Epoch 25/2000\n",
      "113/113 - 1s - loss: 0.6265 - accuracy: 0.6489 - val_loss: 0.7226 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65000\n",
      "Epoch 26/2000\n",
      "113/113 - 1s - loss: 0.6165 - accuracy: 0.6478 - val_loss: 0.7408 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65000\n",
      "Epoch 27/2000\n",
      "113/113 - 1s - loss: 0.6317 - accuracy: 0.6467 - val_loss: 0.7118 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65000\n",
      "Epoch 28/2000\n",
      "113/113 - 1s - loss: 0.6056 - accuracy: 0.6700 - val_loss: 0.7275 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.65000\n",
      "Epoch 29/2000\n",
      "113/113 - 1s - loss: 0.6015 - accuracy: 0.6689 - val_loss: 0.6856 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.65000\n",
      "Epoch 30/2000\n",
      "113/113 - 1s - loss: 0.5991 - accuracy: 0.6744 - val_loss: 0.7064 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.65000\n",
      "Epoch 31/2000\n",
      "113/113 - 1s - loss: 0.6041 - accuracy: 0.6744 - val_loss: 0.6823 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.65000\n",
      "Epoch 32/2000\n",
      "113/113 - 1s - loss: 0.5917 - accuracy: 0.6989 - val_loss: 0.7629 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.65000\n",
      "Epoch 33/2000\n",
      "113/113 - 1s - loss: 0.5855 - accuracy: 0.6867 - val_loss: 0.6669 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65000\n",
      "Epoch 34/2000\n",
      "113/113 - 1s - loss: 0.5918 - accuracy: 0.6756 - val_loss: 0.6910 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.65000\n",
      "Epoch 35/2000\n",
      "113/113 - 1s - loss: 0.5625 - accuracy: 0.7089 - val_loss: 0.6903 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65000\n",
      "Epoch 36/2000\n",
      "113/113 - 1s - loss: 0.5727 - accuracy: 0.6867 - val_loss: 0.7440 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.65000\n",
      "Epoch 37/2000\n",
      "113/113 - 1s - loss: 0.5758 - accuracy: 0.6944 - val_loss: 0.6683 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65000\n",
      "Epoch 38/2000\n",
      "113/113 - 1s - loss: 0.5559 - accuracy: 0.7156 - val_loss: 0.6579 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65000\n",
      "Epoch 39/2000\n",
      "113/113 - 1s - loss: 0.5484 - accuracy: 0.7156 - val_loss: 0.6962 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65000\n",
      "Epoch 40/2000\n",
      "113/113 - 1s - loss: 0.5542 - accuracy: 0.7067 - val_loss: 0.6948 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65000\n",
      "Epoch 41/2000\n",
      "113/113 - 1s - loss: 0.5377 - accuracy: 0.7322 - val_loss: 0.7116 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65000\n",
      "Epoch 42/2000\n",
      "113/113 - 1s - loss: 0.5426 - accuracy: 0.7311 - val_loss: 0.7030 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.65000 to 0.67000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 43/2000\n",
      "113/113 - 1s - loss: 0.5284 - accuracy: 0.7422 - val_loss: 0.6736 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.67000\n",
      "Epoch 44/2000\n",
      "113/113 - 1s - loss: 0.5159 - accuracy: 0.7511 - val_loss: 0.6825 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.67000\n",
      "Epoch 45/2000\n",
      "113/113 - 1s - loss: 0.5094 - accuracy: 0.7622 - val_loss: 0.7129 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.67000\n",
      "Epoch 46/2000\n",
      "113/113 - 1s - loss: 0.4992 - accuracy: 0.7589 - val_loss: 0.7238 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.67000\n",
      "Epoch 47/2000\n",
      "113/113 - 1s - loss: 0.4981 - accuracy: 0.7644 - val_loss: 0.8052 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.67000\n",
      "Epoch 48/2000\n",
      "113/113 - 1s - loss: 0.5035 - accuracy: 0.7500 - val_loss: 0.7077 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67000\n",
      "Epoch 49/2000\n",
      "113/113 - 1s - loss: 0.4925 - accuracy: 0.7689 - val_loss: 0.8573 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67000\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.4957 - accuracy: 0.7622 - val_loss: 0.7763 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67000\n",
      "Epoch 51/2000\n",
      "113/113 - 1s - loss: 0.4801 - accuracy: 0.7667 - val_loss: 0.6675 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.67000 to 0.71000, saving model to 210219_TrainingDense\\Dense_label\n",
      "Epoch 52/2000\n",
      "113/113 - 1s - loss: 0.4819 - accuracy: 0.7700 - val_loss: 0.8231 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.71000\n",
      "Epoch 53/2000\n",
      "113/113 - 1s - loss: 0.4628 - accuracy: 0.7989 - val_loss: 0.7567 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.71000\n",
      "Epoch 54/2000\n",
      "113/113 - 1s - loss: 0.4940 - accuracy: 0.7433 - val_loss: 0.7015 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.71000\n",
      "Epoch 55/2000\n",
      "113/113 - 1s - loss: 0.4509 - accuracy: 0.8011 - val_loss: 0.7274 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.71000\n",
      "Epoch 56/2000\n",
      "113/113 - 1s - loss: 0.4567 - accuracy: 0.7978 - val_loss: 0.7849 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.71000\n",
      "Epoch 57/2000\n",
      "113/113 - 1s - loss: 0.4505 - accuracy: 0.7844 - val_loss: 0.7684 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.71000\n",
      "Epoch 58/2000\n",
      "113/113 - 1s - loss: 0.4410 - accuracy: 0.8000 - val_loss: 0.7050 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.71000\n",
      "Epoch 59/2000\n",
      "113/113 - 1s - loss: 0.4281 - accuracy: 0.8100 - val_loss: 0.7418 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.71000\n",
      "Epoch 60/2000\n",
      "113/113 - 1s - loss: 0.4146 - accuracy: 0.8144 - val_loss: 0.7498 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.71000\n",
      "Epoch 61/2000\n",
      "113/113 - 1s - loss: 0.4075 - accuracy: 0.8200 - val_loss: 0.7916 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.71000\n",
      "Epoch 62/2000\n",
      "113/113 - 1s - loss: 0.4166 - accuracy: 0.8211 - val_loss: 0.8165 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.71000\n",
      "Epoch 63/2000\n",
      "113/113 - 1s - loss: 0.4224 - accuracy: 0.8100 - val_loss: 0.7953 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.71000\n",
      "Epoch 64/2000\n",
      "113/113 - 1s - loss: 0.4048 - accuracy: 0.8267 - val_loss: 0.8410 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.71000\n",
      "Epoch 65/2000\n",
      "113/113 - 1s - loss: 0.3902 - accuracy: 0.8322 - val_loss: 0.7727 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.71000\n",
      "Epoch 66/2000\n",
      "113/113 - 1s - loss: 0.3957 - accuracy: 0.8189 - val_loss: 0.7667 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.71000\n",
      "Epoch 67/2000\n",
      "113/113 - 1s - loss: 0.3698 - accuracy: 0.8500 - val_loss: 0.8628 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.71000\n",
      "Epoch 68/2000\n",
      "113/113 - 1s - loss: 0.3846 - accuracy: 0.8411 - val_loss: 0.8663 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.71000\n",
      "Epoch 69/2000\n",
      "113/113 - 1s - loss: 0.3764 - accuracy: 0.8411 - val_loss: 0.8792 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.71000\n",
      "Epoch 70/2000\n",
      "113/113 - 1s - loss: 0.3633 - accuracy: 0.8500 - val_loss: 0.9053 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.71000\n",
      "Epoch 71/2000\n",
      "113/113 - 1s - loss: 0.3520 - accuracy: 0.8511 - val_loss: 0.8949 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.71000\n",
      "Epoch 72/2000\n",
      "113/113 - 1s - loss: 0.3352 - accuracy: 0.8656 - val_loss: 0.8223 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.71000\n",
      "Epoch 73/2000\n",
      "113/113 - 1s - loss: 0.3419 - accuracy: 0.8533 - val_loss: 0.9303 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.71000\n",
      "Epoch 74/2000\n",
      "113/113 - 1s - loss: 0.3146 - accuracy: 0.8711 - val_loss: 0.9225 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.71000\n",
      "Epoch 75/2000\n",
      "113/113 - 1s - loss: 0.3394 - accuracy: 0.8589 - val_loss: 0.9850 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.71000\n",
      "Epoch 76/2000\n",
      "113/113 - 1s - loss: 0.3273 - accuracy: 0.8600 - val_loss: 0.9098 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.71000\n",
      "Epoch 77/2000\n",
      "113/113 - 1s - loss: 0.3158 - accuracy: 0.8811 - val_loss: 0.9777 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.71000\n",
      "Epoch 78/2000\n",
      "113/113 - 1s - loss: 0.3094 - accuracy: 0.8678 - val_loss: 0.9959 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.71000\n",
      "Epoch 79/2000\n",
      "113/113 - 1s - loss: 0.2997 - accuracy: 0.8800 - val_loss: 0.9946 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.71000\n",
      "Epoch 80/2000\n",
      "113/113 - 1s - loss: 0.2922 - accuracy: 0.8856 - val_loss: 0.9665 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.71000\n",
      "Epoch 81/2000\n",
      "113/113 - 1s - loss: 0.2823 - accuracy: 0.9011 - val_loss: 1.0964 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.71000\n",
      "Epoch 82/2000\n",
      "113/113 - 1s - loss: 0.2820 - accuracy: 0.8878 - val_loss: 1.0120 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.71000\n",
      "Epoch 83/2000\n",
      "113/113 - 1s - loss: 0.3040 - accuracy: 0.8800 - val_loss: 1.0366 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.71000\n",
      "Epoch 84/2000\n",
      "113/113 - 1s - loss: 0.2820 - accuracy: 0.8944 - val_loss: 1.1486 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.71000\n",
      "Epoch 85/2000\n",
      "113/113 - 1s - loss: 0.2629 - accuracy: 0.8933 - val_loss: 1.0507 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.71000\n",
      "Epoch 86/2000\n",
      "113/113 - 1s - loss: 0.2446 - accuracy: 0.9000 - val_loss: 1.1391 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.71000\n",
      "Epoch 87/2000\n",
      "113/113 - 1s - loss: 0.2551 - accuracy: 0.9011 - val_loss: 1.0452 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.71000\n",
      "Epoch 88/2000\n",
      "113/113 - 1s - loss: 0.2521 - accuracy: 0.8944 - val_loss: 1.0763 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.71000\n",
      "Epoch 89/2000\n",
      "113/113 - 1s - loss: 0.2433 - accuracy: 0.9144 - val_loss: 1.1833 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.71000\n",
      "Epoch 90/2000\n",
      "113/113 - 1s - loss: 0.2278 - accuracy: 0.9133 - val_loss: 1.1985 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.71000\n",
      "Epoch 91/2000\n",
      "113/113 - 1s - loss: 0.2134 - accuracy: 0.9267 - val_loss: 1.2402 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.71000\n",
      "Epoch 92/2000\n",
      "113/113 - 1s - loss: 0.2174 - accuracy: 0.9256 - val_loss: 1.1391 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.71000\n",
      "Epoch 93/2000\n",
      "113/113 - 1s - loss: 0.2066 - accuracy: 0.9278 - val_loss: 1.2002 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.71000\n",
      "Epoch 94/2000\n",
      "113/113 - 1s - loss: 0.2085 - accuracy: 0.9244 - val_loss: 1.1161 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.71000\n",
      "Epoch 95/2000\n",
      "113/113 - 1s - loss: 0.2048 - accuracy: 0.9211 - val_loss: 1.2596 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.71000\n",
      "Epoch 96/2000\n",
      "113/113 - 1s - loss: 0.2100 - accuracy: 0.9211 - val_loss: 1.1358 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.71000\n",
      "Epoch 97/2000\n",
      "113/113 - 1s - loss: 0.1806 - accuracy: 0.9344 - val_loss: 1.1705 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.71000\n",
      "Epoch 98/2000\n",
      "113/113 - 1s - loss: 0.1867 - accuracy: 0.9344 - val_loss: 1.2809 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.71000\n",
      "Epoch 99/2000\n",
      "113/113 - 1s - loss: 0.1550 - accuracy: 0.9500 - val_loss: 1.3403 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.71000\n",
      "Epoch 100/2000\n",
      "113/113 - 1s - loss: 0.1574 - accuracy: 0.9500 - val_loss: 1.5158 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.71000\n",
      "Epoch 101/2000\n",
      "113/113 - 1s - loss: 0.1567 - accuracy: 0.9444 - val_loss: 1.3759 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.71000\n",
      "Epoch 102/2000\n",
      "113/113 - 1s - loss: 0.1419 - accuracy: 0.9667 - val_loss: 1.3992 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.71000\n",
      "Epoch 103/2000\n",
      "113/113 - 1s - loss: 0.1620 - accuracy: 0.9478 - val_loss: 1.3686 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.71000\n",
      "Epoch 104/2000\n",
      "113/113 - 1s - loss: 0.1614 - accuracy: 0.9367 - val_loss: 1.3560 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.71000\n",
      "Epoch 105/2000\n",
      "113/113 - 1s - loss: 0.1366 - accuracy: 0.9578 - val_loss: 1.4247 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.71000\n",
      "Epoch 106/2000\n",
      "113/113 - 1s - loss: 0.1379 - accuracy: 0.9667 - val_loss: 1.3834 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.71000\n",
      "Epoch 107/2000\n",
      "113/113 - 1s - loss: 0.1242 - accuracy: 0.9656 - val_loss: 1.3345 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.71000\n",
      "Epoch 108/2000\n",
      "113/113 - 1s - loss: 0.1184 - accuracy: 0.9689 - val_loss: 1.4622 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.71000\n",
      "Epoch 109/2000\n",
      "113/113 - 1s - loss: 0.1171 - accuracy: 0.9678 - val_loss: 1.5814 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.71000\n",
      "Epoch 110/2000\n",
      "113/113 - 1s - loss: 0.1411 - accuracy: 0.9556 - val_loss: 1.5164 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.71000\n",
      "Epoch 111/2000\n",
      "113/113 - 1s - loss: 0.1097 - accuracy: 0.9689 - val_loss: 1.6387 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.71000\n",
      "Epoch 112/2000\n",
      "113/113 - 1s - loss: 0.1045 - accuracy: 0.9756 - val_loss: 1.5687 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.71000\n",
      "Epoch 113/2000\n",
      "113/113 - 1s - loss: 0.0940 - accuracy: 0.9833 - val_loss: 1.5096 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.71000\n",
      "Epoch 114/2000\n",
      "113/113 - 1s - loss: 0.1116 - accuracy: 0.9656 - val_loss: 1.9616 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.71000\n",
      "Epoch 115/2000\n",
      "113/113 - 1s - loss: 0.1042 - accuracy: 0.9756 - val_loss: 1.6270 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.71000\n",
      "Epoch 116/2000\n",
      "113/113 - 1s - loss: 0.0909 - accuracy: 0.9800 - val_loss: 1.7014 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.71000\n",
      "Epoch 117/2000\n",
      "113/113 - 1s - loss: 0.0755 - accuracy: 0.9911 - val_loss: 1.6271 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.71000\n",
      "Epoch 118/2000\n",
      "113/113 - 1s - loss: 0.0781 - accuracy: 0.9844 - val_loss: 1.8017 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.71000\n",
      "Epoch 119/2000\n",
      "113/113 - 1s - loss: 0.0858 - accuracy: 0.9811 - val_loss: 1.7534 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.71000\n",
      "Epoch 120/2000\n",
      "113/113 - 1s - loss: 0.0789 - accuracy: 0.9833 - val_loss: 1.6863 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.71000\n",
      "Epoch 121/2000\n",
      "113/113 - 1s - loss: 0.0762 - accuracy: 0.9811 - val_loss: 1.7770 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.71000\n",
      "Epoch 122/2000\n",
      "113/113 - 1s - loss: 0.0714 - accuracy: 0.9878 - val_loss: 1.8697 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.71000\n",
      "Epoch 123/2000\n",
      "113/113 - 1s - loss: 0.0984 - accuracy: 0.9756 - val_loss: 1.8475 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.71000\n",
      "Epoch 124/2000\n",
      "113/113 - 1s - loss: 0.0572 - accuracy: 0.9967 - val_loss: 1.9803 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.71000\n",
      "Epoch 125/2000\n",
      "113/113 - 1s - loss: 0.0583 - accuracy: 0.9933 - val_loss: 1.8973 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.71000\n",
      "Epoch 126/2000\n",
      "113/113 - 1s - loss: 0.0621 - accuracy: 0.9867 - val_loss: 1.9132 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.71000\n",
      "Epoch 127/2000\n",
      "113/113 - 1s - loss: 0.0585 - accuracy: 0.9911 - val_loss: 2.0782 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.71000\n",
      "Epoch 128/2000\n",
      "113/113 - 1s - loss: 0.1239 - accuracy: 0.9589 - val_loss: 2.1528 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.71000\n",
      "Epoch 129/2000\n",
      "113/113 - 1s - loss: 0.0981 - accuracy: 0.9711 - val_loss: 1.9528 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.71000\n",
      "Epoch 130/2000\n",
      "113/113 - 1s - loss: 0.0756 - accuracy: 0.9811 - val_loss: 1.9857 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.71000\n",
      "Epoch 131/2000\n",
      "113/113 - 1s - loss: 0.0773 - accuracy: 0.9789 - val_loss: 2.2933 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.71000\n",
      "Epoch 132/2000\n",
      "113/113 - 1s - loss: 0.1201 - accuracy: 0.9644 - val_loss: 2.0189 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.71000\n",
      "Epoch 133/2000\n",
      "113/113 - 1s - loss: 0.1207 - accuracy: 0.9667 - val_loss: 1.8649 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.71000\n",
      "Epoch 134/2000\n",
      "113/113 - 1s - loss: 0.0592 - accuracy: 0.9889 - val_loss: 1.8885 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.71000\n",
      "Epoch 135/2000\n",
      "113/113 - 1s - loss: 0.0589 - accuracy: 0.9944 - val_loss: 1.9624 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.71000\n",
      "Epoch 136/2000\n",
      "113/113 - 1s - loss: 0.0440 - accuracy: 0.9944 - val_loss: 1.9388 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.71000\n",
      "Epoch 137/2000\n",
      "113/113 - 1s - loss: 0.0397 - accuracy: 0.9956 - val_loss: 2.0696 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.71000\n",
      "Epoch 138/2000\n",
      "113/113 - 1s - loss: 0.0399 - accuracy: 0.9967 - val_loss: 1.9705 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.71000\n",
      "Epoch 139/2000\n",
      "113/113 - 1s - loss: 0.0389 - accuracy: 0.9978 - val_loss: 2.1304 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.71000\n",
      "Epoch 140/2000\n",
      "113/113 - 1s - loss: 0.0350 - accuracy: 0.9989 - val_loss: 2.1771 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.71000\n",
      "Epoch 141/2000\n",
      "113/113 - 1s - loss: 0.0488 - accuracy: 0.9933 - val_loss: 2.0932 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.71000\n",
      "Epoch 142/2000\n",
      "113/113 - 1s - loss: 0.0566 - accuracy: 0.9922 - val_loss: 2.2473 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.71000\n",
      "Epoch 143/2000\n",
      "113/113 - 1s - loss: 0.0363 - accuracy: 0.9989 - val_loss: 2.2793 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.71000\n",
      "Epoch 144/2000\n",
      "113/113 - 1s - loss: 0.0403 - accuracy: 0.9956 - val_loss: 2.5570 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.71000\n",
      "Epoch 145/2000\n",
      "113/113 - 1s - loss: 0.0418 - accuracy: 0.9978 - val_loss: 2.2029 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.71000\n",
      "Epoch 146/2000\n",
      "113/113 - 1s - loss: 0.0392 - accuracy: 0.9978 - val_loss: 2.1459 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.71000\n",
      "Epoch 147/2000\n",
      "113/113 - 1s - loss: 0.1470 - accuracy: 0.9567 - val_loss: 2.3549 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.71000\n",
      "Epoch 148/2000\n",
      "113/113 - 1s - loss: 0.2100 - accuracy: 0.9289 - val_loss: 2.0344 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.71000\n",
      "Epoch 149/2000\n",
      "113/113 - 1s - loss: 0.1116 - accuracy: 0.9744 - val_loss: 2.3266 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.71000\n",
      "Epoch 150/2000\n",
      "113/113 - 1s - loss: 0.0499 - accuracy: 0.9900 - val_loss: 2.1643 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.71000\n",
      "Epoch 151/2000\n",
      "113/113 - 1s - loss: 0.0344 - accuracy: 0.9978 - val_loss: 2.1891 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.71000\n",
      "Epoch 152/2000\n",
      "113/113 - 1s - loss: 0.0322 - accuracy: 1.0000 - val_loss: 2.1612 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.71000\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.2135 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.71000\n",
      "Epoch 154/2000\n",
      "113/113 - 1s - loss: 0.0266 - accuracy: 1.0000 - val_loss: 2.1764 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.71000\n",
      "Epoch 155/2000\n",
      "113/113 - 1s - loss: 0.0263 - accuracy: 1.0000 - val_loss: 2.1810 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.71000\n",
      "Epoch 156/2000\n",
      "113/113 - 1s - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.2217 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.71000\n",
      "Epoch 157/2000\n",
      "113/113 - 1s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.2496 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.71000\n",
      "Epoch 158/2000\n",
      "113/113 - 1s - loss: 0.0254 - accuracy: 1.0000 - val_loss: 2.2421 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.71000\n",
      "Epoch 159/2000\n",
      "113/113 - 1s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.2521 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.71000\n",
      "Epoch 160/2000\n",
      "113/113 - 1s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 2.2704 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.71000\n",
      "Epoch 161/2000\n",
      "113/113 - 1s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.3036 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.71000\n",
      "Epoch 162/2000\n",
      "113/113 - 1s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.2670 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.71000\n",
      "Epoch 163/2000\n",
      "113/113 - 1s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.3109 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.71000\n",
      "Epoch 164/2000\n",
      "113/113 - 1s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 2.2924 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.71000\n",
      "Epoch 165/2000\n",
      "113/113 - 1s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 2.3811 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.71000\n",
      "Epoch 166/2000\n",
      "113/113 - 1s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.2940 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.71000\n",
      "Epoch 167/2000\n",
      "113/113 - 1s - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.3054 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.71000\n",
      "Epoch 168/2000\n",
      "113/113 - 1s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.3423 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.71000\n",
      "Epoch 169/2000\n",
      "113/113 - 1s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.3463 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.71000\n",
      "Epoch 170/2000\n",
      "113/113 - 1s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.3480 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.71000\n",
      "Epoch 171/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.3715 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.71000\n",
      "Epoch 172/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.3257 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.71000\n",
      "Epoch 173/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.4268 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.71000\n",
      "Epoch 174/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.3683 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.71000\n",
      "Epoch 175/2000\n",
      "113/113 - 1s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.4415 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.71000\n",
      "Epoch 176/2000\n",
      "113/113 - 1s - loss: 0.6017 - accuracy: 0.8622 - val_loss: 2.1143 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.71000\n",
      "Epoch 177/2000\n",
      "113/113 - 1s - loss: 0.3511 - accuracy: 0.8933 - val_loss: 2.5214 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.71000\n",
      "Epoch 178/2000\n",
      "113/113 - 1s - loss: 0.1453 - accuracy: 0.9578 - val_loss: 2.1671 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.71000\n",
      "Epoch 179/2000\n",
      "113/113 - 1s - loss: 0.0817 - accuracy: 0.9833 - val_loss: 2.2298 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.71000\n",
      "Epoch 180/2000\n",
      "113/113 - 1s - loss: 0.0414 - accuracy: 0.9967 - val_loss: 2.1347 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.71000\n",
      "Epoch 181/2000\n",
      "113/113 - 1s - loss: 0.0319 - accuracy: 1.0000 - val_loss: 2.1819 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.71000\n",
      "Epoch 182/2000\n",
      "113/113 - 1s - loss: 0.0280 - accuracy: 1.0000 - val_loss: 2.2181 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.71000\n",
      "Epoch 183/2000\n",
      "113/113 - 1s - loss: 0.0271 - accuracy: 1.0000 - val_loss: 2.2078 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.71000\n",
      "Epoch 184/2000\n",
      "113/113 - 1s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 2.2487 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.71000\n",
      "Epoch 185/2000\n",
      "113/113 - 1s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 2.2627 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.71000\n",
      "Epoch 186/2000\n",
      "113/113 - 1s - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.2625 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.71000\n",
      "Epoch 187/2000\n",
      "113/113 - 1s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.3075 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.71000\n",
      "Epoch 188/2000\n",
      "113/113 - 1s - loss: 0.0255 - accuracy: 1.0000 - val_loss: 2.2932 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.71000\n",
      "Epoch 189/2000\n",
      "113/113 - 1s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.3277 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.71000\n",
      "Epoch 190/2000\n",
      "113/113 - 1s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 2.3766 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.71000\n",
      "Epoch 191/2000\n",
      "113/113 - 1s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.3343 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.71000\n",
      "Epoch 192/2000\n",
      "113/113 - 1s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 2.3560 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.71000\n",
      "Epoch 193/2000\n",
      "113/113 - 1s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.3630 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.71000\n",
      "Epoch 194/2000\n",
      "113/113 - 1s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.3137 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.71000\n",
      "Epoch 195/2000\n",
      "113/113 - 1s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.3711 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.71000\n",
      "Epoch 196/2000\n",
      "113/113 - 1s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.4179 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.71000\n",
      "Epoch 197/2000\n",
      "113/113 - 1s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.4085 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.71000\n",
      "Epoch 198/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.3945 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.71000\n",
      "Epoch 199/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.4343 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.71000\n",
      "Epoch 200/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.4014 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.71000\n",
      "Epoch 201/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.3917 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.71000\n",
      "Epoch 202/2000\n",
      "113/113 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.4254 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.71000\n",
      "Epoch 203/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.4759 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.71000\n",
      "Epoch 204/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.4355 - val_accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.71000\n",
      "Epoch 205/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.4598 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.71000\n",
      "Epoch 206/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.4905 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.71000\n",
      "Epoch 207/2000\n",
      "113/113 - 1s - loss: 0.0296 - accuracy: 0.9989 - val_loss: 2.5203 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.71000\n",
      "Epoch 208/2000\n",
      "113/113 - 1s - loss: 0.7347 - accuracy: 0.8267 - val_loss: 3.2812 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.71000\n",
      "Epoch 209/2000\n",
      "113/113 - 1s - loss: 0.3171 - accuracy: 0.9122 - val_loss: 2.2199 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.71000\n",
      "Epoch 210/2000\n",
      "113/113 - 1s - loss: 0.1002 - accuracy: 0.9733 - val_loss: 2.5066 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.71000\n",
      "Epoch 211/2000\n",
      "113/113 - 1s - loss: 0.0434 - accuracy: 0.9956 - val_loss: 2.5434 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.71000\n",
      "Epoch 212/2000\n",
      "113/113 - 1s - loss: 0.0337 - accuracy: 0.9989 - val_loss: 2.4416 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.71000\n",
      "Epoch 213/2000\n",
      "113/113 - 1s - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.4546 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.71000\n",
      "Epoch 214/2000\n",
      "113/113 - 1s - loss: 0.0276 - accuracy: 1.0000 - val_loss: 2.4817 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.71000\n",
      "Epoch 215/2000\n",
      "113/113 - 1s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 2.4449 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.71000\n",
      "Epoch 216/2000\n",
      "113/113 - 1s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 2.5181 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.71000\n",
      "Epoch 217/2000\n",
      "113/113 - 1s - loss: 0.0257 - accuracy: 1.0000 - val_loss: 2.5232 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.71000\n",
      "Epoch 218/2000\n",
      "113/113 - 1s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.5276 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.71000\n",
      "Epoch 219/2000\n",
      "113/113 - 1s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.5217 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.71000\n",
      "Epoch 220/2000\n",
      "113/113 - 1s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 2.5174 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.71000\n",
      "Epoch 221/2000\n",
      "113/113 - 1s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.5512 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.71000\n",
      "Epoch 222/2000\n",
      "113/113 - 1s - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.5170 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.71000\n",
      "Epoch 223/2000\n",
      "113/113 - 1s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.5725 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.71000\n",
      "Epoch 224/2000\n",
      "113/113 - 1s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.5861 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.71000\n",
      "Epoch 225/2000\n",
      "113/113 - 1s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.5807 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.71000\n",
      "Epoch 226/2000\n",
      "113/113 - 1s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.5627 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.71000\n",
      "Epoch 227/2000\n",
      "113/113 - 1s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.5824 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.71000\n",
      "Epoch 228/2000\n",
      "113/113 - 1s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.71000\n",
      "Epoch 229/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.5901 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.71000\n",
      "Epoch 230/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.5908 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.71000\n",
      "Epoch 231/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.5831 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.71000\n",
      "Epoch 232/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.5962 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.71000\n",
      "Epoch 233/2000\n",
      "113/113 - 1s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.6395 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.71000\n",
      "Epoch 234/2000\n",
      "113/113 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.6532 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.71000\n",
      "Epoch 235/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.6416 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.71000\n",
      "Epoch 236/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.6449 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.71000\n",
      "Epoch 237/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.71000\n",
      "Epoch 238/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.6558 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.71000\n",
      "Epoch 239/2000\n",
      "113/113 - 1s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.6206 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.71000\n",
      "Epoch 240/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.6367 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.71000\n",
      "Epoch 241/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.6634 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.71000\n",
      "Epoch 242/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.6641 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.71000\n",
      "Epoch 243/2000\n",
      "113/113 - 1s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.6438 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.71000\n",
      "Epoch 244/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.6723 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.71000\n",
      "Epoch 245/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.6491 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.71000\n",
      "Epoch 246/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.6937 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.71000\n",
      "Epoch 247/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.6939 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.71000\n",
      "Epoch 248/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.7665 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.71000\n",
      "Epoch 249/2000\n",
      "113/113 - 1s - loss: 0.5571 - accuracy: 0.8722 - val_loss: 2.7186 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.71000\n",
      "Epoch 250/2000\n",
      "113/113 - 1s - loss: 0.2114 - accuracy: 0.9367 - val_loss: 2.3931 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.71000\n",
      "Epoch 251/2000\n",
      "113/113 - 1s - loss: 0.0876 - accuracy: 0.9767 - val_loss: 2.7141 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.71000\n",
      "Epoch 252/2000\n",
      "113/113 - 1s - loss: 0.0886 - accuracy: 0.9744 - val_loss: 2.5964 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.71000\n",
      "Epoch 253/2000\n",
      "113/113 - 1s - loss: 0.0340 - accuracy: 1.0000 - val_loss: 2.6820 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.71000\n",
      "Epoch 254/2000\n",
      "113/113 - 1s - loss: 0.0273 - accuracy: 1.0000 - val_loss: 2.7043 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.71000\n",
      "Epoch 255/2000\n",
      "113/113 - 1s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.6931 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.71000\n",
      "Epoch 256/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.7198 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.71000\n",
      "Epoch 257/2000\n",
      "113/113 - 1s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.7132 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.71000\n",
      "Epoch 258/2000\n",
      "113/113 - 1s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.71000\n",
      "Epoch 259/2000\n",
      "113/113 - 1s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.7594 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.71000\n",
      "Epoch 260/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.7436 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.71000\n",
      "Epoch 261/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.7628 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.71000\n",
      "Epoch 262/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.7768 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.71000\n",
      "Epoch 263/2000\n",
      "113/113 - 1s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.7662 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.71000\n",
      "Epoch 264/2000\n",
      "113/113 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.7892 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.71000\n",
      "Epoch 265/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.8016 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.71000\n",
      "Epoch 266/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.8025 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.71000\n",
      "Epoch 267/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.71000\n",
      "Epoch 268/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.7839 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.71000\n",
      "Epoch 269/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.71000\n",
      "Epoch 270/2000\n",
      "113/113 - 1s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.71000\n",
      "Epoch 271/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.71000\n",
      "Epoch 272/2000\n",
      "113/113 - 1s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.71000\n",
      "Epoch 273/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.8087 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.71000\n",
      "Epoch 274/2000\n",
      "113/113 - 1s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.71000\n",
      "Epoch 275/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.71000\n",
      "Epoch 276/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.8457 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.71000\n",
      "Epoch 277/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.71000\n",
      "Epoch 278/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.71000\n",
      "Epoch 279/2000\n",
      "113/113 - 1s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.71000\n",
      "Epoch 280/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.8647 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.71000\n",
      "Epoch 281/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.71000\n",
      "Epoch 282/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.8396 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.71000\n",
      "Epoch 283/2000\n",
      "113/113 - 1s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.71000\n",
      "Epoch 284/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.8122 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.71000\n",
      "Epoch 285/2000\n",
      "113/113 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.8131 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.71000\n",
      "Epoch 286/2000\n",
      "113/113 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.8019 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.71000\n",
      "Epoch 287/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.8443 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.71000\n",
      "Epoch 288/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.8046 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.71000\n",
      "Epoch 289/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.7790 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.71000\n",
      "Epoch 290/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.71000\n",
      "Epoch 291/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.71000\n",
      "Epoch 292/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.8781 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.71000\n",
      "Epoch 293/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.8322 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.71000\n",
      "Epoch 294/2000\n",
      "113/113 - 1s - loss: 0.3808 - accuracy: 0.9356 - val_loss: 3.1002 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.71000\n",
      "Epoch 295/2000\n",
      "113/113 - 1s - loss: 0.6821 - accuracy: 0.8444 - val_loss: 2.4456 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.71000\n",
      "Epoch 296/2000\n",
      "113/113 - 1s - loss: 0.1400 - accuracy: 0.9556 - val_loss: 2.3861 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.71000\n",
      "Epoch 297/2000\n",
      "113/113 - 1s - loss: 0.0839 - accuracy: 0.9711 - val_loss: 2.3723 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.71000\n",
      "Epoch 298/2000\n",
      "113/113 - 1s - loss: 0.0368 - accuracy: 0.9978 - val_loss: 2.5020 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.71000\n",
      "Epoch 299/2000\n",
      "113/113 - 1s - loss: 0.0293 - accuracy: 0.9989 - val_loss: 2.5136 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.71000\n",
      "Epoch 300/2000\n",
      "113/113 - 1s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 2.5755 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.71000\n",
      "Epoch 301/2000\n",
      "113/113 - 1s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.71000\n",
      "Epoch 302/2000\n",
      "113/113 - 1s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.6411 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.71000\n",
      "Epoch 303/2000\n",
      "113/113 - 1s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.6417 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.71000\n",
      "Epoch 304/2000\n",
      "113/113 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.71000\n",
      "Epoch 305/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.6829 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.71000\n",
      "Epoch 306/2000\n",
      "113/113 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.7020 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.71000\n",
      "Epoch 307/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.6973 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.71000\n",
      "Epoch 308/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.7151 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.71000\n",
      "Epoch 309/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.7216 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.71000\n",
      "Epoch 310/2000\n",
      "113/113 - 1s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.7332 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.71000\n",
      "Epoch 311/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.71000\n",
      "Epoch 312/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.7279 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.71000\n",
      "Epoch 313/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.7490 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.71000\n",
      "Epoch 314/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.7764 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.71000\n",
      "Epoch 315/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.7441 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.71000\n",
      "Epoch 316/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.7762 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.71000\n",
      "Epoch 317/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.71000\n",
      "Epoch 318/2000\n",
      "113/113 - 1s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.7833 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.71000\n",
      "Epoch 319/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.71000\n",
      "Epoch 320/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.8055 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.71000\n",
      "Epoch 321/2000\n",
      "113/113 - 1s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.71000\n",
      "Epoch 322/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.8216 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.71000\n",
      "Epoch 323/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.7994 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.71000\n",
      "Epoch 324/2000\n",
      "113/113 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.71000\n",
      "Epoch 325/2000\n",
      "113/113 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.8217 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.71000\n",
      "Epoch 326/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.8245 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.71000\n",
      "Epoch 327/2000\n",
      "113/113 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.71000\n",
      "Epoch 328/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.8155 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.71000\n",
      "Epoch 329/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.8416 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.71000\n",
      "Epoch 330/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.8249 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.71000\n",
      "Epoch 331/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.71000\n",
      "Epoch 332/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.8383 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.71000\n",
      "Epoch 333/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.71000\n",
      "Epoch 334/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.71000\n",
      "Epoch 335/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.8745 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.71000\n",
      "Epoch 336/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.8478 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.71000\n",
      "Epoch 337/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.8019 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.71000\n",
      "Epoch 338/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.71000\n",
      "Epoch 339/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.71000\n",
      "Epoch 340/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.71000\n",
      "Epoch 341/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.8407 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.71000\n",
      "Epoch 342/2000\n",
      "113/113 - 1s - loss: 0.6176 - accuracy: 0.8956 - val_loss: 2.7450 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.71000\n",
      "Epoch 343/2000\n",
      "113/113 - 1s - loss: 0.5726 - accuracy: 0.8644 - val_loss: 2.0909 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.71000\n",
      "Epoch 344/2000\n",
      "113/113 - 1s - loss: 0.1022 - accuracy: 0.9633 - val_loss: 2.3851 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.71000\n",
      "Epoch 345/2000\n",
      "113/113 - 1s - loss: 0.0558 - accuracy: 0.9889 - val_loss: 2.6698 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.71000\n",
      "Epoch 346/2000\n",
      "113/113 - 1s - loss: 0.0458 - accuracy: 0.9933 - val_loss: 2.7635 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.71000\n",
      "Epoch 347/2000\n",
      "113/113 - 1s - loss: 0.0322 - accuracy: 0.9989 - val_loss: 2.6201 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.71000\n",
      "Epoch 348/2000\n",
      "113/113 - 1s - loss: 0.0255 - accuracy: 1.0000 - val_loss: 2.6562 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.71000\n",
      "Epoch 349/2000\n",
      "113/113 - 1s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.6630 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.71000\n",
      "Epoch 350/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 2.6559 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.71000\n",
      "Epoch 351/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.71000\n",
      "Epoch 352/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.71000\n",
      "Epoch 353/2000\n",
      "113/113 - 1s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.6844 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.71000\n",
      "Epoch 354/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.6944 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.71000\n",
      "Epoch 355/2000\n",
      "113/113 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.7049 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.71000\n",
      "Epoch 356/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.7293 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.71000\n",
      "Epoch 357/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.71000\n",
      "Epoch 358/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.7216 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.71000\n",
      "Epoch 359/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.7292 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.71000\n",
      "Epoch 360/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.7446 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.71000\n",
      "Epoch 361/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.7123 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.71000\n",
      "Epoch 362/2000\n",
      "113/113 - 1s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.7188 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.71000\n",
      "Epoch 363/2000\n",
      "113/113 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.71000\n",
      "Epoch 364/2000\n",
      "113/113 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.7577 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.71000\n",
      "Epoch 365/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.71000\n",
      "Epoch 366/2000\n",
      "113/113 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.71000\n",
      "Epoch 367/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.7328 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.71000\n",
      "Epoch 368/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.7644 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.71000\n",
      "Epoch 369/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.7748 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.71000\n",
      "Epoch 370/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.71000\n",
      "Epoch 371/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.8105 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.71000\n",
      "Epoch 372/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.7742 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.71000\n",
      "Epoch 373/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.71000\n",
      "Epoch 374/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.8277 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.71000\n",
      "Epoch 375/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.8116 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.71000\n",
      "Epoch 376/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.7438 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.71000\n",
      "Epoch 377/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.7387 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.71000\n",
      "Epoch 378/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.71000\n",
      "Epoch 379/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.8196 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.71000\n",
      "Epoch 380/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.7674 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.71000\n",
      "Epoch 381/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.8140 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.71000\n",
      "Epoch 382/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.8681 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.71000\n",
      "Epoch 383/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7868 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.71000\n",
      "Epoch 384/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7562 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.71000\n",
      "Epoch 385/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7779 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.71000\n",
      "Epoch 386/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.8236 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.71000\n",
      "Epoch 387/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.9439 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.71000\n",
      "Epoch 388/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.8046 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.71000\n",
      "Epoch 389/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.8868 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.71000\n",
      "Epoch 390/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.8165 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.71000\n",
      "Epoch 391/2000\n",
      "113/113 - 1s - loss: 0.7112 - accuracy: 0.8822 - val_loss: 2.8265 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.71000\n",
      "Epoch 392/2000\n",
      "113/113 - 1s - loss: 0.4315 - accuracy: 0.8744 - val_loss: 2.5138 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.71000\n",
      "Epoch 393/2000\n",
      "113/113 - 1s - loss: 0.0812 - accuracy: 0.9767 - val_loss: 2.3285 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.71000\n",
      "Epoch 394/2000\n",
      "113/113 - 1s - loss: 0.0497 - accuracy: 0.9889 - val_loss: 2.5090 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.71000\n",
      "Epoch 395/2000\n",
      "113/113 - 1s - loss: 0.0291 - accuracy: 0.9989 - val_loss: 2.4493 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.71000\n",
      "Epoch 396/2000\n",
      "113/113 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.4948 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.71000\n",
      "Epoch 397/2000\n",
      "113/113 - 1s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.5318 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.71000\n",
      "Epoch 398/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.5285 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.71000\n",
      "Epoch 399/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.5390 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.71000\n",
      "Epoch 400/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.5628 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.71000\n",
      "Epoch 401/2000\n",
      "113/113 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.5692 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.71000\n",
      "Epoch 402/2000\n",
      "113/113 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.5979 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.71000\n",
      "Epoch 403/2000\n",
      "113/113 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.5977 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.71000\n",
      "Epoch 404/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.71000\n",
      "Epoch 405/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.5968 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.71000\n",
      "Epoch 406/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.6337 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.71000\n",
      "Epoch 407/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.71000\n",
      "Epoch 408/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.6379 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.71000\n",
      "Epoch 409/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.6396 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.71000\n",
      "Epoch 410/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6685 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.71000\n",
      "Epoch 411/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.6463 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.71000\n",
      "Epoch 412/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.6796 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.71000\n",
      "Epoch 413/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6934 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.71000\n",
      "Epoch 414/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.7008 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.71000\n",
      "Epoch 415/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.6994 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.71000\n",
      "Epoch 416/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.7447 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.71000\n",
      "Epoch 417/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.7341 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.71000\n",
      "Epoch 418/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.7146 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.71000\n",
      "Epoch 419/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7168 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.71000\n",
      "Epoch 420/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7037 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.71000\n",
      "Epoch 421/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.7376 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.71000\n",
      "Epoch 422/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7713 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.71000\n",
      "Epoch 423/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7296 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.71000\n",
      "Epoch 424/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7271 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.71000\n",
      "Epoch 425/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7469 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.71000\n",
      "Epoch 426/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.7226 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.71000\n",
      "Epoch 427/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.71000\n",
      "Epoch 428/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7424 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.71000\n",
      "Epoch 429/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.71000\n",
      "Epoch 430/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.7656 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.71000\n",
      "Epoch 431/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7544 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.71000\n",
      "Epoch 432/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.8270 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.71000\n",
      "Epoch 433/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7706 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.71000\n",
      "Epoch 434/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7702 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.71000\n",
      "Epoch 435/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7790 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.71000\n",
      "Epoch 436/2000\n",
      "113/113 - 1s - loss: 0.2221 - accuracy: 0.9567 - val_loss: 4.1431 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.71000\n",
      "Epoch 437/2000\n",
      "113/113 - 1s - loss: 0.9130 - accuracy: 0.7933 - val_loss: 2.6885 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.71000\n",
      "Epoch 438/2000\n",
      "113/113 - 1s - loss: 0.2221 - accuracy: 0.9167 - val_loss: 2.2182 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.71000\n",
      "Epoch 439/2000\n",
      "113/113 - 1s - loss: 0.1019 - accuracy: 0.9656 - val_loss: 2.2455 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.71000\n",
      "Epoch 440/2000\n",
      "113/113 - 1s - loss: 0.0402 - accuracy: 0.9956 - val_loss: 2.3341 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.71000\n",
      "Epoch 441/2000\n",
      "113/113 - 1s - loss: 0.0297 - accuracy: 1.0000 - val_loss: 2.3078 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.71000\n",
      "Epoch 442/2000\n",
      "113/113 - 1s - loss: 0.0264 - accuracy: 1.0000 - val_loss: 2.3314 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.71000\n",
      "Epoch 443/2000\n",
      "113/113 - 1s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 2.3215 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.71000\n",
      "Epoch 444/2000\n",
      "113/113 - 1s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.3407 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.71000\n",
      "Epoch 445/2000\n",
      "113/113 - 1s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.3451 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.71000\n",
      "Epoch 446/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.3772 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.71000\n",
      "Epoch 447/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.3661 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.71000\n",
      "Epoch 448/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.3909 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.71000\n",
      "Epoch 449/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.3884 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.71000\n",
      "Epoch 450/2000\n",
      "113/113 - 1s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.4022 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.71000\n",
      "Epoch 451/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.3864 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.71000\n",
      "Epoch 452/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.4264 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.71000\n",
      "Epoch 453/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.3889 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.71000\n",
      "Epoch 454/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.4497 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.71000\n",
      "Epoch 455/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.71000\n",
      "Epoch 456/2000\n",
      "113/113 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 2.4417 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.71000\n",
      "Epoch 457/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.4692 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.71000\n",
      "Epoch 458/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.4847 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.71000\n",
      "Epoch 459/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.4282 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.71000\n",
      "Epoch 460/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.4839 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.71000\n",
      "Epoch 461/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.5269 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.71000\n",
      "Epoch 462/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.4936 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.71000\n",
      "Epoch 463/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.5164 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.71000\n",
      "Epoch 464/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.5597 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.71000\n",
      "Epoch 465/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.5950 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.71000\n",
      "Epoch 466/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6022 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.71000\n",
      "Epoch 467/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.71000\n",
      "Epoch 468/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.6446 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.71000\n",
      "Epoch 469/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6085 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.71000\n",
      "Epoch 470/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6543 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.71000\n",
      "Epoch 471/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.6237 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.71000\n",
      "Epoch 472/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7021 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.71000\n",
      "Epoch 473/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.71000\n",
      "Epoch 474/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.7210 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.71000\n",
      "Epoch 475/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7192 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.71000\n",
      "Epoch 476/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7302 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.71000\n",
      "Epoch 477/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6889 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.71000\n",
      "Epoch 478/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7728 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.71000\n",
      "Epoch 479/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7477 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.71000\n",
      "Epoch 480/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7863 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.71000\n",
      "Epoch 481/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.71000\n",
      "Epoch 482/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.71000\n",
      "Epoch 483/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.8240 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.71000\n",
      "Epoch 484/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.8549 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.71000\n",
      "Epoch 485/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.71000\n",
      "Epoch 486/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.8149 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.71000\n",
      "Epoch 487/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7175 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.71000\n",
      "Epoch 488/2000\n",
      "113/113 - 1s - loss: 0.6339 - accuracy: 0.8900 - val_loss: 2.7779 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.71000\n",
      "Epoch 489/2000\n",
      "113/113 - 1s - loss: 0.4379 - accuracy: 0.8778 - val_loss: 2.5292 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.71000\n",
      "Epoch 490/2000\n",
      "113/113 - 1s - loss: 0.1323 - accuracy: 0.9589 - val_loss: 2.6129 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.71000\n",
      "Epoch 491/2000\n",
      "113/113 - 1s - loss: 0.0600 - accuracy: 0.9856 - val_loss: 2.5216 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.71000\n",
      "Epoch 492/2000\n",
      "113/113 - 1s - loss: 0.0361 - accuracy: 0.9956 - val_loss: 2.6889 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.71000\n",
      "Epoch 493/2000\n",
      "113/113 - 1s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.7053 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.71000\n",
      "Epoch 494/2000\n",
      "113/113 - 1s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.6842 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.71000\n",
      "Epoch 495/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.6697 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.71000\n",
      "Epoch 496/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.7134 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.71000\n",
      "Epoch 497/2000\n",
      "113/113 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.6867 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.71000\n",
      "Epoch 498/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.71000\n",
      "Epoch 499/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.7077 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.71000\n",
      "Epoch 500/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.7302 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.71000\n",
      "Epoch 501/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00501: val_accuracy did not improve from 0.71000\n",
      "Epoch 502/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00502: val_accuracy did not improve from 0.71000\n",
      "Epoch 503/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.7132 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00503: val_accuracy did not improve from 0.71000\n",
      "Epoch 504/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.7171 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00504: val_accuracy did not improve from 0.71000\n",
      "Epoch 505/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.7430 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00505: val_accuracy did not improve from 0.71000\n",
      "Epoch 506/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7535 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00506: val_accuracy did not improve from 0.71000\n",
      "Epoch 507/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.7378 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00507: val_accuracy did not improve from 0.71000\n",
      "Epoch 508/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.7763 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00508: val_accuracy did not improve from 0.71000\n",
      "Epoch 509/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00509: val_accuracy did not improve from 0.71000\n",
      "Epoch 510/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7690 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00510: val_accuracy did not improve from 0.71000\n",
      "Epoch 511/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.7608 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00511: val_accuracy did not improve from 0.71000\n",
      "Epoch 512/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.7729 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00512: val_accuracy did not improve from 0.71000\n",
      "Epoch 513/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7710 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00513: val_accuracy did not improve from 0.71000\n",
      "Epoch 514/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7978 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00514: val_accuracy did not improve from 0.71000\n",
      "Epoch 515/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7947 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00515: val_accuracy did not improve from 0.71000\n",
      "Epoch 516/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00516: val_accuracy did not improve from 0.71000\n",
      "Epoch 517/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7858 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00517: val_accuracy did not improve from 0.71000\n",
      "Epoch 518/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7926 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00518: val_accuracy did not improve from 0.71000\n",
      "Epoch 519/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.8086 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00519: val_accuracy did not improve from 0.71000\n",
      "Epoch 520/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7998 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00520: val_accuracy did not improve from 0.71000\n",
      "Epoch 521/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.8250 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00521: val_accuracy did not improve from 0.71000\n",
      "Epoch 522/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.8209 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00522: val_accuracy did not improve from 0.71000\n",
      "Epoch 523/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.8208 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00523: val_accuracy did not improve from 0.71000\n",
      "Epoch 524/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00524: val_accuracy did not improve from 0.71000\n",
      "Epoch 525/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.8329 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00525: val_accuracy did not improve from 0.71000\n",
      "Epoch 526/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00526: val_accuracy did not improve from 0.71000\n",
      "Epoch 527/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.8562 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00527: val_accuracy did not improve from 0.71000\n",
      "Epoch 528/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.8437 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00528: val_accuracy did not improve from 0.71000\n",
      "Epoch 529/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.8661 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00529: val_accuracy did not improve from 0.71000\n",
      "Epoch 530/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.8555 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00530: val_accuracy did not improve from 0.71000\n",
      "Epoch 531/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.8411 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00531: val_accuracy did not improve from 0.71000\n",
      "Epoch 532/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8461 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00532: val_accuracy did not improve from 0.71000\n",
      "Epoch 533/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8547 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00533: val_accuracy did not improve from 0.71000\n",
      "Epoch 534/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.8692 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00534: val_accuracy did not improve from 0.71000\n",
      "Epoch 535/2000\n",
      "113/113 - 1s - loss: 0.2970 - accuracy: 0.9622 - val_loss: 4.7929 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00535: val_accuracy did not improve from 0.71000\n",
      "Epoch 536/2000\n",
      "113/113 - 1s - loss: 0.6896 - accuracy: 0.8367 - val_loss: 2.6923 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00536: val_accuracy did not improve from 0.71000\n",
      "Epoch 537/2000\n",
      "113/113 - 1s - loss: 0.1317 - accuracy: 0.9533 - val_loss: 2.5678 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00537: val_accuracy did not improve from 0.71000\n",
      "Epoch 538/2000\n",
      "113/113 - 1s - loss: 0.0654 - accuracy: 0.9856 - val_loss: 2.5466 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00538: val_accuracy did not improve from 0.71000\n",
      "Epoch 539/2000\n",
      "113/113 - 1s - loss: 0.0345 - accuracy: 0.9956 - val_loss: 2.5260 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00539: val_accuracy did not improve from 0.71000\n",
      "Epoch 540/2000\n",
      "113/113 - 1s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.5589 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00540: val_accuracy did not improve from 0.71000\n",
      "Epoch 541/2000\n",
      "113/113 - 1s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.6057 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00541: val_accuracy did not improve from 0.71000\n",
      "Epoch 542/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.6189 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00542: val_accuracy did not improve from 0.71000\n",
      "Epoch 543/2000\n",
      "113/113 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.6115 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00543: val_accuracy did not improve from 0.71000\n",
      "Epoch 544/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.6363 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00544: val_accuracy did not improve from 0.71000\n",
      "Epoch 545/2000\n",
      "113/113 - 1s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.6394 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00545: val_accuracy did not improve from 0.71000\n",
      "Epoch 546/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.6616 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00546: val_accuracy did not improve from 0.71000\n",
      "Epoch 547/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.6523 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00547: val_accuracy did not improve from 0.71000\n",
      "Epoch 548/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00548: val_accuracy did not improve from 0.71000\n",
      "Epoch 549/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.6480 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00549: val_accuracy did not improve from 0.71000\n",
      "Epoch 550/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6596 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00550: val_accuracy did not improve from 0.71000\n",
      "Epoch 551/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.6592 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00551: val_accuracy did not improve from 0.71000\n",
      "Epoch 552/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6926 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00552: val_accuracy did not improve from 0.71000\n",
      "Epoch 553/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.6982 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00553: val_accuracy did not improve from 0.71000\n",
      "Epoch 554/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6774 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00554: val_accuracy did not improve from 0.71000\n",
      "Epoch 555/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7271 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00555: val_accuracy did not improve from 0.71000\n",
      "Epoch 556/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.6765 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00556: val_accuracy did not improve from 0.71000\n",
      "Epoch 557/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7042 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00557: val_accuracy did not improve from 0.71000\n",
      "Epoch 558/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.6913 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00558: val_accuracy did not improve from 0.71000\n",
      "Epoch 559/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.6947 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00559: val_accuracy did not improve from 0.71000\n",
      "Epoch 560/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7000 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00560: val_accuracy did not improve from 0.71000\n",
      "Epoch 561/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.7141 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00561: val_accuracy did not improve from 0.71000\n",
      "Epoch 562/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6786 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00562: val_accuracy did not improve from 0.71000\n",
      "Epoch 563/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7187 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00563: val_accuracy did not improve from 0.71000\n",
      "Epoch 564/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7190 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00564: val_accuracy did not improve from 0.71000\n",
      "Epoch 565/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7142 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00565: val_accuracy did not improve from 0.71000\n",
      "Epoch 566/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7261 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00566: val_accuracy did not improve from 0.71000\n",
      "Epoch 567/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.7360 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00567: val_accuracy did not improve from 0.71000\n",
      "Epoch 568/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6987 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00568: val_accuracy did not improve from 0.71000\n",
      "Epoch 569/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7614 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00569: val_accuracy did not improve from 0.71000\n",
      "Epoch 570/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.7533 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00570: val_accuracy did not improve from 0.71000\n",
      "Epoch 571/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00571: val_accuracy did not improve from 0.71000\n",
      "Epoch 572/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.7269 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00572: val_accuracy did not improve from 0.71000\n",
      "Epoch 573/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00573: val_accuracy did not improve from 0.71000\n",
      "Epoch 574/2000\n",
      "113/113 - 1s - loss: 0.3184 - accuracy: 0.9389 - val_loss: 2.6734 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00574: val_accuracy did not improve from 0.71000\n",
      "Epoch 575/2000\n",
      "113/113 - 1s - loss: 0.5779 - accuracy: 0.8556 - val_loss: 2.9545 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00575: val_accuracy did not improve from 0.71000\n",
      "Epoch 576/2000\n",
      "113/113 - 1s - loss: 0.1145 - accuracy: 0.9678 - val_loss: 2.6589 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00576: val_accuracy did not improve from 0.71000\n",
      "Epoch 577/2000\n",
      "113/113 - 1s - loss: 0.0587 - accuracy: 0.9889 - val_loss: 2.6975 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00577: val_accuracy did not improve from 0.71000\n",
      "Epoch 578/2000\n",
      "113/113 - 1s - loss: 0.0282 - accuracy: 0.9978 - val_loss: 2.6533 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00578: val_accuracy did not improve from 0.71000\n",
      "Epoch 579/2000\n",
      "113/113 - 1s - loss: 0.0279 - accuracy: 0.9989 - val_loss: 2.5926 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00579: val_accuracy did not improve from 0.71000\n",
      "Epoch 580/2000\n",
      "113/113 - 1s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.6058 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00580: val_accuracy did not improve from 0.71000\n",
      "Epoch 581/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.6242 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00581: val_accuracy did not improve from 0.71000\n",
      "Epoch 582/2000\n",
      "113/113 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.6322 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00582: val_accuracy did not improve from 0.71000\n",
      "Epoch 583/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.6444 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00583: val_accuracy did not improve from 0.71000\n",
      "Epoch 584/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.6606 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00584: val_accuracy did not improve from 0.71000\n",
      "Epoch 585/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6572 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00585: val_accuracy did not improve from 0.71000\n",
      "Epoch 586/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.6892 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00586: val_accuracy did not improve from 0.71000\n",
      "Epoch 587/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6748 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00587: val_accuracy did not improve from 0.71000\n",
      "Epoch 588/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6826 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00588: val_accuracy did not improve from 0.71000\n",
      "Epoch 589/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.6903 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00589: val_accuracy did not improve from 0.71000\n",
      "Epoch 590/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6995 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00590: val_accuracy did not improve from 0.71000\n",
      "Epoch 591/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6897 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00591: val_accuracy did not improve from 0.71000\n",
      "Epoch 592/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00592: val_accuracy did not improve from 0.71000\n",
      "Epoch 593/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.7153 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00593: val_accuracy did not improve from 0.71000\n",
      "Epoch 594/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7218 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00594: val_accuracy did not improve from 0.71000\n",
      "Epoch 595/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.7312 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00595: val_accuracy did not improve from 0.71000\n",
      "Epoch 596/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7388 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00596: val_accuracy did not improve from 0.71000\n",
      "Epoch 597/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00597: val_accuracy did not improve from 0.71000\n",
      "Epoch 598/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7333 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00598: val_accuracy did not improve from 0.71000\n",
      "Epoch 599/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.7356 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00599: val_accuracy did not improve from 0.71000\n",
      "Epoch 600/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7366 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00600: val_accuracy did not improve from 0.71000\n",
      "Epoch 601/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7615 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00601: val_accuracy did not improve from 0.71000\n",
      "Epoch 602/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00602: val_accuracy did not improve from 0.71000\n",
      "Epoch 603/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7540 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00603: val_accuracy did not improve from 0.71000\n",
      "Epoch 604/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.7604 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00604: val_accuracy did not improve from 0.71000\n",
      "Epoch 605/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7640 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00605: val_accuracy did not improve from 0.71000\n",
      "Epoch 606/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7668 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00606: val_accuracy did not improve from 0.71000\n",
      "Epoch 607/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.8055 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00607: val_accuracy did not improve from 0.71000\n",
      "Epoch 608/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7841 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00608: val_accuracy did not improve from 0.71000\n",
      "Epoch 609/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00609: val_accuracy did not improve from 0.71000\n",
      "Epoch 610/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.8040 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00610: val_accuracy did not improve from 0.71000\n",
      "Epoch 611/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00611: val_accuracy did not improve from 0.71000\n",
      "Epoch 612/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00612: val_accuracy did not improve from 0.71000\n",
      "Epoch 613/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.8812 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00613: val_accuracy did not improve from 0.71000\n",
      "Epoch 614/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8182 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00614: val_accuracy did not improve from 0.71000\n",
      "Epoch 615/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00615: val_accuracy did not improve from 0.71000\n",
      "Epoch 616/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00616: val_accuracy did not improve from 0.71000\n",
      "Epoch 617/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.8625 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00617: val_accuracy did not improve from 0.71000\n",
      "Epoch 618/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.8135 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00618: val_accuracy did not improve from 0.71000\n",
      "Epoch 619/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.8580 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00619: val_accuracy did not improve from 0.71000\n",
      "Epoch 620/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.8503 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00620: val_accuracy did not improve from 0.71000\n",
      "Epoch 621/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8119 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00621: val_accuracy did not improve from 0.71000\n",
      "Epoch 622/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8493 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00622: val_accuracy did not improve from 0.71000\n",
      "Epoch 623/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8321 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00623: val_accuracy did not improve from 0.71000\n",
      "Epoch 624/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8731 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00624: val_accuracy did not improve from 0.71000\n",
      "Epoch 625/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00625: val_accuracy did not improve from 0.71000\n",
      "Epoch 626/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8242 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00626: val_accuracy did not improve from 0.71000\n",
      "Epoch 627/2000\n",
      "113/113 - 1s - loss: 0.8658 - accuracy: 0.8267 - val_loss: 2.8281 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00627: val_accuracy did not improve from 0.71000\n",
      "Epoch 628/2000\n",
      "113/113 - 1s - loss: 0.2263 - accuracy: 0.9200 - val_loss: 2.3897 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00628: val_accuracy did not improve from 0.71000\n",
      "Epoch 629/2000\n",
      "113/113 - 1s - loss: 0.0727 - accuracy: 0.9822 - val_loss: 2.4686 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00629: val_accuracy did not improve from 0.71000\n",
      "Epoch 630/2000\n",
      "113/113 - 1s - loss: 0.0334 - accuracy: 0.9989 - val_loss: 2.5404 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00630: val_accuracy did not improve from 0.71000\n",
      "Epoch 631/2000\n",
      "113/113 - 1s - loss: 0.0296 - accuracy: 0.9989 - val_loss: 2.7647 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00631: val_accuracy did not improve from 0.71000\n",
      "Epoch 632/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.6650 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00632: val_accuracy did not improve from 0.71000\n",
      "Epoch 633/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.6667 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00633: val_accuracy did not improve from 0.71000\n",
      "Epoch 634/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.7111 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00634: val_accuracy did not improve from 0.71000\n",
      "Epoch 635/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.6947 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00635: val_accuracy did not improve from 0.71000\n",
      "Epoch 636/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.7136 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00636: val_accuracy did not improve from 0.71000\n",
      "Epoch 637/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.7248 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00637: val_accuracy did not improve from 0.71000\n",
      "Epoch 638/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7305 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00638: val_accuracy did not improve from 0.71000\n",
      "Epoch 639/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.7263 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00639: val_accuracy did not improve from 0.71000\n",
      "Epoch 640/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7417 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00640: val_accuracy did not improve from 0.71000\n",
      "Epoch 641/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.7466 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00641: val_accuracy did not improve from 0.71000\n",
      "Epoch 642/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00642: val_accuracy did not improve from 0.71000\n",
      "Epoch 643/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7702 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00643: val_accuracy did not improve from 0.71000\n",
      "Epoch 644/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7690 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00644: val_accuracy did not improve from 0.71000\n",
      "Epoch 645/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00645: val_accuracy did not improve from 0.71000\n",
      "Epoch 646/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.7604 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00646: val_accuracy did not improve from 0.71000\n",
      "Epoch 647/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7639 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00647: val_accuracy did not improve from 0.71000\n",
      "Epoch 648/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00648: val_accuracy did not improve from 0.71000\n",
      "Epoch 649/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00649: val_accuracy did not improve from 0.71000\n",
      "Epoch 650/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00650: val_accuracy did not improve from 0.71000\n",
      "Epoch 651/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.8007 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00651: val_accuracy did not improve from 0.71000\n",
      "Epoch 652/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.7998 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00652: val_accuracy did not improve from 0.71000\n",
      "Epoch 653/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00653: val_accuracy did not improve from 0.71000\n",
      "Epoch 654/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00654: val_accuracy did not improve from 0.71000\n",
      "Epoch 655/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8076 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00655: val_accuracy did not improve from 0.71000\n",
      "Epoch 656/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00656: val_accuracy did not improve from 0.71000\n",
      "Epoch 657/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8150 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00657: val_accuracy did not improve from 0.71000\n",
      "Epoch 658/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00658: val_accuracy did not improve from 0.71000\n",
      "Epoch 659/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.8474 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00659: val_accuracy did not improve from 0.71000\n",
      "Epoch 660/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00660: val_accuracy did not improve from 0.71000\n",
      "Epoch 661/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.8396 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00661: val_accuracy did not improve from 0.71000\n",
      "Epoch 662/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7865 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00662: val_accuracy did not improve from 0.71000\n",
      "Epoch 663/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00663: val_accuracy did not improve from 0.71000\n",
      "Epoch 664/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8695 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00664: val_accuracy did not improve from 0.71000\n",
      "Epoch 665/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8462 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00665: val_accuracy did not improve from 0.71000\n",
      "Epoch 666/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8359 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00666: val_accuracy did not improve from 0.71000\n",
      "Epoch 667/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8747 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00667: val_accuracy did not improve from 0.71000\n",
      "Epoch 668/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8414 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00668: val_accuracy did not improve from 0.71000\n",
      "Epoch 669/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.8903 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00669: val_accuracy did not improve from 0.71000\n",
      "Epoch 670/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.8185 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00670: val_accuracy did not improve from 0.71000\n",
      "Epoch 671/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7959 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00671: val_accuracy did not improve from 0.71000\n",
      "Epoch 672/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8766 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00672: val_accuracy did not improve from 0.71000\n",
      "Epoch 673/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.8870 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00673: val_accuracy did not improve from 0.71000\n",
      "Epoch 674/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00674: val_accuracy did not improve from 0.71000\n",
      "Epoch 675/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.8348 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00675: val_accuracy did not improve from 0.71000\n",
      "Epoch 676/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8954 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00676: val_accuracy did not improve from 0.71000\n",
      "Epoch 677/2000\n",
      "113/113 - 1s - loss: 0.0341 - accuracy: 0.9911 - val_loss: 3.5692 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00677: val_accuracy did not improve from 0.71000\n",
      "Epoch 678/2000\n",
      "113/113 - 1s - loss: 1.1020 - accuracy: 0.7778 - val_loss: 2.8535 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00678: val_accuracy did not improve from 0.71000\n",
      "Epoch 679/2000\n",
      "113/113 - 1s - loss: 0.2217 - accuracy: 0.9322 - val_loss: 2.5240 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00679: val_accuracy did not improve from 0.71000\n",
      "Epoch 680/2000\n",
      "113/113 - 1s - loss: 0.0621 - accuracy: 0.9844 - val_loss: 2.5263 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00680: val_accuracy did not improve from 0.71000\n",
      "Epoch 681/2000\n",
      "113/113 - 1s - loss: 0.0449 - accuracy: 0.9922 - val_loss: 2.9545 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00681: val_accuracy did not improve from 0.71000\n",
      "Epoch 682/2000\n",
      "113/113 - 1s - loss: 0.0306 - accuracy: 0.9978 - val_loss: 2.7873 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00682: val_accuracy did not improve from 0.71000\n",
      "Epoch 683/2000\n",
      "113/113 - 1s - loss: 0.0290 - accuracy: 0.9978 - val_loss: 2.4746 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00683: val_accuracy did not improve from 0.71000\n",
      "Epoch 684/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.6521 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00684: val_accuracy did not improve from 0.71000\n",
      "Epoch 685/2000\n",
      "113/113 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.6366 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00685: val_accuracy did not improve from 0.71000\n",
      "Epoch 686/2000\n",
      "113/113 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.6198 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00686: val_accuracy did not improve from 0.71000\n",
      "Epoch 687/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.6573 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00687: val_accuracy did not improve from 0.71000\n",
      "Epoch 688/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.6446 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00688: val_accuracy did not improve from 0.71000\n",
      "Epoch 689/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.6844 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00689: val_accuracy did not improve from 0.71000\n",
      "Epoch 690/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.6651 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00690: val_accuracy did not improve from 0.71000\n",
      "Epoch 691/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6847 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00691: val_accuracy did not improve from 0.71000\n",
      "Epoch 692/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.7023 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00692: val_accuracy did not improve from 0.71000\n",
      "Epoch 693/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7086 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00693: val_accuracy did not improve from 0.71000\n",
      "Epoch 694/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6961 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00694: val_accuracy did not improve from 0.71000\n",
      "Epoch 695/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7103 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00695: val_accuracy did not improve from 0.71000\n",
      "Epoch 696/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00696: val_accuracy did not improve from 0.71000\n",
      "Epoch 697/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00697: val_accuracy did not improve from 0.71000\n",
      "Epoch 698/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7179 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00698: val_accuracy did not improve from 0.71000\n",
      "Epoch 699/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.7496 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00699: val_accuracy did not improve from 0.71000\n",
      "Epoch 700/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.7574 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00700: val_accuracy did not improve from 0.71000\n",
      "Epoch 701/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.7540 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00701: val_accuracy did not improve from 0.71000\n",
      "Epoch 702/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.7599 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00702: val_accuracy did not improve from 0.71000\n",
      "Epoch 703/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00703: val_accuracy did not improve from 0.71000\n",
      "Epoch 704/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00704: val_accuracy did not improve from 0.71000\n",
      "Epoch 705/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7732 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00705: val_accuracy did not improve from 0.71000\n",
      "Epoch 706/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7750 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00706: val_accuracy did not improve from 0.71000\n",
      "Epoch 707/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.7912 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00707: val_accuracy did not improve from 0.71000\n",
      "Epoch 708/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.8254 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00708: val_accuracy did not improve from 0.71000\n",
      "Epoch 709/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.8115 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00709: val_accuracy did not improve from 0.71000\n",
      "Epoch 710/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8246 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00710: val_accuracy did not improve from 0.71000\n",
      "Epoch 711/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8183 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00711: val_accuracy did not improve from 0.71000\n",
      "Epoch 712/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8258 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00712: val_accuracy did not improve from 0.71000\n",
      "Epoch 713/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00713: val_accuracy did not improve from 0.71000\n",
      "Epoch 714/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7973 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00714: val_accuracy did not improve from 0.71000\n",
      "Epoch 715/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00715: val_accuracy did not improve from 0.71000\n",
      "Epoch 716/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00716: val_accuracy did not improve from 0.71000\n",
      "Epoch 717/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.8476 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00717: val_accuracy did not improve from 0.71000\n",
      "Epoch 718/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8595 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00718: val_accuracy did not improve from 0.71000\n",
      "Epoch 719/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8757 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00719: val_accuracy did not improve from 0.71000\n",
      "Epoch 720/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7975 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00720: val_accuracy did not improve from 0.71000\n",
      "Epoch 721/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.8161 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00721: val_accuracy did not improve from 0.71000\n",
      "Epoch 722/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00722: val_accuracy did not improve from 0.71000\n",
      "Epoch 723/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8173 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00723: val_accuracy did not improve from 0.71000\n",
      "Epoch 724/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00724: val_accuracy did not improve from 0.71000\n",
      "Epoch 725/2000\n",
      "113/113 - 1s - loss: 0.3718 - accuracy: 0.9489 - val_loss: 2.9391 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00725: val_accuracy did not improve from 0.71000\n",
      "Epoch 726/2000\n",
      "113/113 - 1s - loss: 0.7790 - accuracy: 0.8178 - val_loss: 2.4356 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00726: val_accuracy did not improve from 0.71000\n",
      "Epoch 727/2000\n",
      "113/113 - 1s - loss: 0.2101 - accuracy: 0.9411 - val_loss: 2.2918 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00727: val_accuracy did not improve from 0.71000\n",
      "Epoch 728/2000\n",
      "113/113 - 1s - loss: 0.0653 - accuracy: 0.9889 - val_loss: 2.4663 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00728: val_accuracy did not improve from 0.71000\n",
      "Epoch 729/2000\n",
      "113/113 - 1s - loss: 0.0384 - accuracy: 0.9956 - val_loss: 2.4695 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00729: val_accuracy did not improve from 0.71000\n",
      "Epoch 730/2000\n",
      "113/113 - 1s - loss: 0.0285 - accuracy: 0.9989 - val_loss: 2.5365 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00730: val_accuracy did not improve from 0.71000\n",
      "Epoch 731/2000\n",
      "113/113 - 1s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.4427 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00731: val_accuracy did not improve from 0.71000\n",
      "Epoch 732/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.4564 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00732: val_accuracy did not improve from 0.71000\n",
      "Epoch 733/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.4673 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00733: val_accuracy did not improve from 0.71000\n",
      "Epoch 734/2000\n",
      "113/113 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.4788 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00734: val_accuracy did not improve from 0.71000\n",
      "Epoch 735/2000\n",
      "113/113 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.5054 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00735: val_accuracy did not improve from 0.71000\n",
      "Epoch 736/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.5068 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00736: val_accuracy did not improve from 0.71000\n",
      "Epoch 737/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.4972 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00737: val_accuracy did not improve from 0.71000\n",
      "Epoch 738/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.5167 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00738: val_accuracy did not improve from 0.71000\n",
      "Epoch 739/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.5305 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00739: val_accuracy did not improve from 0.71000\n",
      "Epoch 740/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.5450 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00740: val_accuracy did not improve from 0.71000\n",
      "Epoch 741/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00741: val_accuracy did not improve from 0.71000\n",
      "Epoch 742/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.5328 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00742: val_accuracy did not improve from 0.71000\n",
      "Epoch 743/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.5303 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00743: val_accuracy did not improve from 0.71000\n",
      "Epoch 744/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00744: val_accuracy did not improve from 0.71000\n",
      "Epoch 745/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.5338 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00745: val_accuracy did not improve from 0.71000\n",
      "Epoch 746/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.5696 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00746: val_accuracy did not improve from 0.71000\n",
      "Epoch 747/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00747: val_accuracy did not improve from 0.71000\n",
      "Epoch 748/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.5456 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00748: val_accuracy did not improve from 0.71000\n",
      "Epoch 749/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.5612 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00749: val_accuracy did not improve from 0.71000\n",
      "Epoch 750/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.5779 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00750: val_accuracy did not improve from 0.71000\n",
      "Epoch 751/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.5697 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00751: val_accuracy did not improve from 0.71000\n",
      "Epoch 752/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.6044 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00752: val_accuracy did not improve from 0.71000\n",
      "Epoch 753/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.5777 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00753: val_accuracy did not improve from 0.71000\n",
      "Epoch 754/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.5835 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00754: val_accuracy did not improve from 0.71000\n",
      "Epoch 755/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.5844 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00755: val_accuracy did not improve from 0.71000\n",
      "Epoch 756/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.6189 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00756: val_accuracy did not improve from 0.71000\n",
      "Epoch 757/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.5898 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00757: val_accuracy did not improve from 0.71000\n",
      "Epoch 758/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6463 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00758: val_accuracy did not improve from 0.71000\n",
      "Epoch 759/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00759: val_accuracy did not improve from 0.71000\n",
      "Epoch 760/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.6336 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00760: val_accuracy did not improve from 0.71000\n",
      "Epoch 761/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.6582 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00761: val_accuracy did not improve from 0.71000\n",
      "Epoch 762/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00762: val_accuracy did not improve from 0.71000\n",
      "Epoch 763/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.6735 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00763: val_accuracy did not improve from 0.71000\n",
      "Epoch 764/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6750 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00764: val_accuracy did not improve from 0.71000\n",
      "Epoch 765/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6263 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00765: val_accuracy did not improve from 0.71000\n",
      "Epoch 766/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6568 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00766: val_accuracy did not improve from 0.71000\n",
      "Epoch 767/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6497 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00767: val_accuracy did not improve from 0.71000\n",
      "Epoch 768/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6673 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00768: val_accuracy did not improve from 0.71000\n",
      "Epoch 769/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.6935 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00769: val_accuracy did not improve from 0.71000\n",
      "Epoch 770/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7249 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00770: val_accuracy did not improve from 0.71000\n",
      "Epoch 771/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00771: val_accuracy did not improve from 0.71000\n",
      "Epoch 772/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7233 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00772: val_accuracy did not improve from 0.71000\n",
      "Epoch 773/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00773: val_accuracy did not improve from 0.71000\n",
      "Epoch 774/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8076 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00774: val_accuracy did not improve from 0.71000\n",
      "Epoch 775/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00775: val_accuracy did not improve from 0.71000\n",
      "Epoch 776/2000\n",
      "113/113 - 1s - loss: 0.2819 - accuracy: 0.9533 - val_loss: 2.7317 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00776: val_accuracy did not improve from 0.71000\n",
      "Epoch 777/2000\n",
      "113/113 - 1s - loss: 1.2825 - accuracy: 0.7567 - val_loss: 2.6567 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00777: val_accuracy did not improve from 0.71000\n",
      "Epoch 778/2000\n",
      "113/113 - 1s - loss: 0.3306 - accuracy: 0.9067 - val_loss: 2.5561 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00778: val_accuracy did not improve from 0.71000\n",
      "Epoch 779/2000\n",
      "113/113 - 1s - loss: 0.1192 - accuracy: 0.9611 - val_loss: 2.6123 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00779: val_accuracy did not improve from 0.71000\n",
      "Epoch 780/2000\n",
      "113/113 - 1s - loss: 0.0458 - accuracy: 0.9911 - val_loss: 2.4372 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00780: val_accuracy did not improve from 0.71000\n",
      "Epoch 781/2000\n",
      "113/113 - 1s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 2.5674 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00781: val_accuracy did not improve from 0.71000\n",
      "Epoch 782/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00782: val_accuracy did not improve from 0.71000\n",
      "Epoch 783/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.6088 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00783: val_accuracy did not improve from 0.71000\n",
      "Epoch 784/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6303 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00784: val_accuracy did not improve from 0.71000\n",
      "Epoch 785/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6282 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00785: val_accuracy did not improve from 0.71000\n",
      "Epoch 786/2000\n",
      "113/113 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.6383 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00786: val_accuracy did not improve from 0.71000\n",
      "Epoch 787/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.6377 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00787: val_accuracy did not improve from 0.71000\n",
      "Epoch 788/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6521 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00788: val_accuracy did not improve from 0.71000\n",
      "Epoch 789/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.6702 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00789: val_accuracy did not improve from 0.71000\n",
      "Epoch 790/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6718 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00790: val_accuracy did not improve from 0.71000\n",
      "Epoch 791/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6704 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00791: val_accuracy did not improve from 0.71000\n",
      "Epoch 792/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6771 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00792: val_accuracy did not improve from 0.71000\n",
      "Epoch 793/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7016 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00793: val_accuracy did not improve from 0.71000\n",
      "Epoch 794/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.6935 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00794: val_accuracy did not improve from 0.71000\n",
      "Epoch 795/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.7284 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00795: val_accuracy did not improve from 0.71000\n",
      "Epoch 796/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.7123 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00796: val_accuracy did not improve from 0.71000\n",
      "Epoch 797/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00797: val_accuracy did not improve from 0.71000\n",
      "Epoch 798/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7219 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00798: val_accuracy did not improve from 0.71000\n",
      "Epoch 799/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7059 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00799: val_accuracy did not improve from 0.71000\n",
      "Epoch 800/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7197 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00800: val_accuracy did not improve from 0.71000\n",
      "Epoch 801/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.7276 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00801: val_accuracy did not improve from 0.71000\n",
      "Epoch 802/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7137 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00802: val_accuracy did not improve from 0.71000\n",
      "Epoch 803/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7335 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00803: val_accuracy did not improve from 0.71000\n",
      "Epoch 804/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7380 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00804: val_accuracy did not improve from 0.71000\n",
      "Epoch 805/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00805: val_accuracy did not improve from 0.71000\n",
      "Epoch 806/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7657 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00806: val_accuracy did not improve from 0.71000\n",
      "Epoch 807/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7575 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00807: val_accuracy did not improve from 0.71000\n",
      "Epoch 808/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7608 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00808: val_accuracy did not improve from 0.71000\n",
      "Epoch 809/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00809: val_accuracy did not improve from 0.71000\n",
      "Epoch 810/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7752 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00810: val_accuracy did not improve from 0.71000\n",
      "Epoch 811/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00811: val_accuracy did not improve from 0.71000\n",
      "Epoch 812/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7499 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00812: val_accuracy did not improve from 0.71000\n",
      "Epoch 813/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8213 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00813: val_accuracy did not improve from 0.71000\n",
      "Epoch 814/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00814: val_accuracy did not improve from 0.71000\n",
      "Epoch 815/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.8021 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00815: val_accuracy did not improve from 0.71000\n",
      "Epoch 816/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00816: val_accuracy did not improve from 0.71000\n",
      "Epoch 817/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00817: val_accuracy did not improve from 0.71000\n",
      "Epoch 818/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00818: val_accuracy did not improve from 0.71000\n",
      "Epoch 819/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8380 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00819: val_accuracy did not improve from 0.71000\n",
      "Epoch 820/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7743 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00820: val_accuracy did not improve from 0.71000\n",
      "Epoch 821/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8404 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00821: val_accuracy did not improve from 0.71000\n",
      "Epoch 822/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8088 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00822: val_accuracy did not improve from 0.71000\n",
      "Epoch 823/2000\n",
      "113/113 - 1s - loss: 0.0636 - accuracy: 0.9878 - val_loss: 3.8808 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00823: val_accuracy did not improve from 0.71000\n",
      "Epoch 824/2000\n",
      "113/113 - 1s - loss: 0.8224 - accuracy: 0.8156 - val_loss: 2.4898 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00824: val_accuracy did not improve from 0.71000\n",
      "Epoch 825/2000\n",
      "113/113 - 1s - loss: 0.1830 - accuracy: 0.9333 - val_loss: 2.6883 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00825: val_accuracy did not improve from 0.71000\n",
      "Epoch 826/2000\n",
      "113/113 - 1s - loss: 0.0690 - accuracy: 0.9778 - val_loss: 2.4870 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00826: val_accuracy did not improve from 0.71000\n",
      "Epoch 827/2000\n",
      "113/113 - 1s - loss: 0.0420 - accuracy: 0.9922 - val_loss: 2.5243 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00827: val_accuracy did not improve from 0.71000\n",
      "Epoch 828/2000\n",
      "113/113 - 1s - loss: 0.0255 - accuracy: 0.9989 - val_loss: 2.6391 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00828: val_accuracy did not improve from 0.71000\n",
      "Epoch 829/2000\n",
      "113/113 - 1s - loss: 0.0249 - accuracy: 0.9989 - val_loss: 2.5394 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00829: val_accuracy did not improve from 0.71000\n",
      "Epoch 830/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.5975 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00830: val_accuracy did not improve from 0.71000\n",
      "Epoch 831/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.5902 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00831: val_accuracy did not improve from 0.71000\n",
      "Epoch 832/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.6157 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00832: val_accuracy did not improve from 0.71000\n",
      "Epoch 833/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6273 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00833: val_accuracy did not improve from 0.71000\n",
      "Epoch 834/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6303 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00834: val_accuracy did not improve from 0.71000\n",
      "Epoch 835/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6451 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00835: val_accuracy did not improve from 0.71000\n",
      "Epoch 836/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.6621 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00836: val_accuracy did not improve from 0.71000\n",
      "Epoch 837/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.6819 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00837: val_accuracy did not improve from 0.71000\n",
      "Epoch 838/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6818 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00838: val_accuracy did not improve from 0.71000\n",
      "Epoch 839/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00839: val_accuracy did not improve from 0.71000\n",
      "Epoch 840/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.6911 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00840: val_accuracy did not improve from 0.71000\n",
      "Epoch 841/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.6817 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00841: val_accuracy did not improve from 0.71000\n",
      "Epoch 842/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.6904 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00842: val_accuracy did not improve from 0.71000\n",
      "Epoch 843/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.6955 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00843: val_accuracy did not improve from 0.71000\n",
      "Epoch 844/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6868 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00844: val_accuracy did not improve from 0.71000\n",
      "Epoch 845/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7114 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00845: val_accuracy did not improve from 0.71000\n",
      "Epoch 846/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00846: val_accuracy did not improve from 0.71000\n",
      "Epoch 847/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7131 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00847: val_accuracy did not improve from 0.71000\n",
      "Epoch 848/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7403 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00848: val_accuracy did not improve from 0.71000\n",
      "Epoch 849/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00849: val_accuracy did not improve from 0.71000\n",
      "Epoch 850/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7318 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00850: val_accuracy did not improve from 0.71000\n",
      "Epoch 851/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7091 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00851: val_accuracy did not improve from 0.71000\n",
      "Epoch 852/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7370 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00852: val_accuracy did not improve from 0.71000\n",
      "Epoch 853/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7601 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00853: val_accuracy did not improve from 0.71000\n",
      "Epoch 854/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7595 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00854: val_accuracy did not improve from 0.71000\n",
      "Epoch 855/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7358 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00855: val_accuracy did not improve from 0.71000\n",
      "Epoch 856/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7730 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00856: val_accuracy did not improve from 0.71000\n",
      "Epoch 857/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7536 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00857: val_accuracy did not improve from 0.71000\n",
      "Epoch 858/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7728 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00858: val_accuracy did not improve from 0.71000\n",
      "Epoch 859/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00859: val_accuracy did not improve from 0.71000\n",
      "Epoch 860/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7970 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00860: val_accuracy did not improve from 0.71000\n",
      "Epoch 861/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7461 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00861: val_accuracy did not improve from 0.71000\n",
      "Epoch 862/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7727 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00862: val_accuracy did not improve from 0.71000\n",
      "Epoch 863/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00863: val_accuracy did not improve from 0.71000\n",
      "Epoch 864/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7712 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00864: val_accuracy did not improve from 0.71000\n",
      "Epoch 865/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7559 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00865: val_accuracy did not improve from 0.71000\n",
      "Epoch 866/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8127 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00866: val_accuracy did not improve from 0.71000\n",
      "Epoch 867/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00867: val_accuracy did not improve from 0.71000\n",
      "Epoch 868/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00868: val_accuracy did not improve from 0.71000\n",
      "Epoch 869/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00869: val_accuracy did not improve from 0.71000\n",
      "Epoch 870/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00870: val_accuracy did not improve from 0.71000\n",
      "Epoch 871/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00871: val_accuracy did not improve from 0.71000\n",
      "Epoch 872/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00872: val_accuracy did not improve from 0.71000\n",
      "Epoch 873/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8728 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00873: val_accuracy did not improve from 0.71000\n",
      "Epoch 874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.6312 - accuracy: 0.8533 - val_loss: 2.0260 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00874: val_accuracy did not improve from 0.71000\n",
      "Epoch 875/2000\n",
      "113/113 - 1s - loss: 0.3818 - accuracy: 0.8800 - val_loss: 2.2041 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00875: val_accuracy did not improve from 0.71000\n",
      "Epoch 876/2000\n",
      "113/113 - 1s - loss: 0.1296 - accuracy: 0.9600 - val_loss: 2.3828 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00876: val_accuracy did not improve from 0.71000\n",
      "Epoch 877/2000\n",
      "113/113 - 1s - loss: 0.0516 - accuracy: 0.9900 - val_loss: 2.4683 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00877: val_accuracy did not improve from 0.71000\n",
      "Epoch 878/2000\n",
      "113/113 - 1s - loss: 0.0542 - accuracy: 0.9856 - val_loss: 2.6147 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00878: val_accuracy did not improve from 0.71000\n",
      "Epoch 879/2000\n",
      "113/113 - 1s - loss: 0.0295 - accuracy: 0.9978 - val_loss: 2.5750 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00879: val_accuracy did not improve from 0.71000\n",
      "Epoch 880/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.6388 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00880: val_accuracy did not improve from 0.71000\n",
      "Epoch 881/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.6496 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00881: val_accuracy did not improve from 0.71000\n",
      "Epoch 882/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6751 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00882: val_accuracy did not improve from 0.71000\n",
      "Epoch 883/2000\n",
      "113/113 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6953 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00883: val_accuracy did not improve from 0.71000\n",
      "Epoch 884/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.6831 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00884: val_accuracy did not improve from 0.71000\n",
      "Epoch 885/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7187 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00885: val_accuracy did not improve from 0.71000\n",
      "Epoch 886/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7458 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00886: val_accuracy did not improve from 0.71000\n",
      "Epoch 887/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7510 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00887: val_accuracy did not improve from 0.71000\n",
      "Epoch 888/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.7619 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00888: val_accuracy did not improve from 0.71000\n",
      "Epoch 889/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7576 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00889: val_accuracy did not improve from 0.71000\n",
      "Epoch 890/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.8028 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00890: val_accuracy did not improve from 0.71000\n",
      "Epoch 891/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00891: val_accuracy did not improve from 0.71000\n",
      "Epoch 892/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00892: val_accuracy did not improve from 0.71000\n",
      "Epoch 893/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8139 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00893: val_accuracy did not improve from 0.71000\n",
      "Epoch 894/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8099 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00894: val_accuracy did not improve from 0.71000\n",
      "Epoch 895/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8417 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00895: val_accuracy did not improve from 0.71000\n",
      "Epoch 896/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.8375 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00896: val_accuracy did not improve from 0.71000\n",
      "Epoch 897/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.8333 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00897: val_accuracy did not improve from 0.71000\n",
      "Epoch 898/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8316 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00898: val_accuracy did not improve from 0.71000\n",
      "Epoch 899/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8533 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00899: val_accuracy did not improve from 0.71000\n",
      "Epoch 900/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8678 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00900: val_accuracy did not improve from 0.71000\n",
      "Epoch 901/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.8668 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00901: val_accuracy did not improve from 0.71000\n",
      "Epoch 902/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8814 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00902: val_accuracy did not improve from 0.71000\n",
      "Epoch 903/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00903: val_accuracy did not improve from 0.71000\n",
      "Epoch 904/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.8835 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00904: val_accuracy did not improve from 0.71000\n",
      "Epoch 905/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8787 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00905: val_accuracy did not improve from 0.71000\n",
      "Epoch 906/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.8620 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00906: val_accuracy did not improve from 0.71000\n",
      "Epoch 907/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9225 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00907: val_accuracy did not improve from 0.71000\n",
      "Epoch 908/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8801 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00908: val_accuracy did not improve from 0.71000\n",
      "Epoch 909/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.9066 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00909: val_accuracy did not improve from 0.71000\n",
      "Epoch 910/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.9175 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00910: val_accuracy did not improve from 0.71000\n",
      "Epoch 911/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.8900 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00911: val_accuracy did not improve from 0.71000\n",
      "Epoch 912/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.9202 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00912: val_accuracy did not improve from 0.71000\n",
      "Epoch 913/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8941 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00913: val_accuracy did not improve from 0.71000\n",
      "Epoch 914/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.9571 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00914: val_accuracy did not improve from 0.71000\n",
      "Epoch 915/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.9201 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00915: val_accuracy did not improve from 0.71000\n",
      "Epoch 916/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8739 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00916: val_accuracy did not improve from 0.71000\n",
      "Epoch 917/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.9735 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00917: val_accuracy did not improve from 0.71000\n",
      "Epoch 918/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8576 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00918: val_accuracy did not improve from 0.71000\n",
      "Epoch 919/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9288 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00919: val_accuracy did not improve from 0.71000\n",
      "Epoch 920/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.9063 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00920: val_accuracy did not improve from 0.71000\n",
      "Epoch 921/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00921: val_accuracy did not improve from 0.71000\n",
      "Epoch 922/2000\n",
      "113/113 - 1s - loss: 0.1544 - accuracy: 0.9700 - val_loss: 3.4108 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00922: val_accuracy did not improve from 0.71000\n",
      "Epoch 923/2000\n",
      "113/113 - 1s - loss: 0.7130 - accuracy: 0.8322 - val_loss: 2.4734 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00923: val_accuracy did not improve from 0.71000\n",
      "Epoch 924/2000\n",
      "113/113 - 1s - loss: 0.1202 - accuracy: 0.9611 - val_loss: 2.4119 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00924: val_accuracy did not improve from 0.71000\n",
      "Epoch 925/2000\n",
      "113/113 - 1s - loss: 0.0519 - accuracy: 0.9844 - val_loss: 2.4367 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00925: val_accuracy did not improve from 0.71000\n",
      "Epoch 926/2000\n",
      "113/113 - 1s - loss: 0.0276 - accuracy: 1.0000 - val_loss: 2.4146 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00926: val_accuracy did not improve from 0.71000\n",
      "Epoch 927/2000\n",
      "113/113 - 1s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 2.4426 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00927: val_accuracy did not improve from 0.71000\n",
      "Epoch 928/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.4910 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00928: val_accuracy did not improve from 0.71000\n",
      "Epoch 929/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.5432 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00929: val_accuracy did not improve from 0.71000\n",
      "Epoch 930/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.5804 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00930: val_accuracy did not improve from 0.71000\n",
      "Epoch 931/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00931: val_accuracy did not improve from 0.71000\n",
      "Epoch 932/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00932: val_accuracy did not improve from 0.71000\n",
      "Epoch 933/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6420 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00933: val_accuracy did not improve from 0.71000\n",
      "Epoch 934/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.6421 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00934: val_accuracy did not improve from 0.71000\n",
      "Epoch 935/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.6681 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00935: val_accuracy did not improve from 0.71000\n",
      "Epoch 936/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6809 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00936: val_accuracy did not improve from 0.71000\n",
      "Epoch 937/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00937: val_accuracy did not improve from 0.71000\n",
      "Epoch 938/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.7177 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00938: val_accuracy did not improve from 0.71000\n",
      "Epoch 939/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7341 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00939: val_accuracy did not improve from 0.71000\n",
      "Epoch 940/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7258 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00940: val_accuracy did not improve from 0.71000\n",
      "Epoch 941/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7488 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00941: val_accuracy did not improve from 0.71000\n",
      "Epoch 942/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7357 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00942: val_accuracy did not improve from 0.71000\n",
      "Epoch 943/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00943: val_accuracy did not improve from 0.71000\n",
      "Epoch 944/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7419 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00944: val_accuracy did not improve from 0.71000\n",
      "Epoch 945/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7644 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00945: val_accuracy did not improve from 0.71000\n",
      "Epoch 946/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7709 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00946: val_accuracy did not improve from 0.71000\n",
      "Epoch 947/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7819 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00947: val_accuracy did not improve from 0.71000\n",
      "Epoch 948/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00948: val_accuracy did not improve from 0.71000\n",
      "Epoch 949/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7726 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00949: val_accuracy did not improve from 0.71000\n",
      "Epoch 950/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7721 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00950: val_accuracy did not improve from 0.71000\n",
      "Epoch 951/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.8160 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00951: val_accuracy did not improve from 0.71000\n",
      "Epoch 952/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8023 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00952: val_accuracy did not improve from 0.71000\n",
      "Epoch 953/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8053 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00953: val_accuracy did not improve from 0.71000\n",
      "Epoch 954/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00954: val_accuracy did not improve from 0.71000\n",
      "Epoch 955/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00955: val_accuracy did not improve from 0.71000\n",
      "Epoch 956/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8045 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00956: val_accuracy did not improve from 0.71000\n",
      "Epoch 957/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8316 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00957: val_accuracy did not improve from 0.71000\n",
      "Epoch 958/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00958: val_accuracy did not improve from 0.71000\n",
      "Epoch 959/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8199 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00959: val_accuracy did not improve from 0.71000\n",
      "Epoch 960/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8324 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00960: val_accuracy did not improve from 0.71000\n",
      "Epoch 961/2000\n",
      "113/113 - 1s - loss: 0.3394 - accuracy: 0.9300 - val_loss: 2.9398 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00961: val_accuracy did not improve from 0.71000\n",
      "Epoch 962/2000\n",
      "113/113 - 1s - loss: 0.5298 - accuracy: 0.8478 - val_loss: 2.4257 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00962: val_accuracy did not improve from 0.71000\n",
      "Epoch 963/2000\n",
      "113/113 - 1s - loss: 0.1468 - accuracy: 0.9511 - val_loss: 2.4537 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 00963: val_accuracy did not improve from 0.71000\n",
      "Epoch 964/2000\n",
      "113/113 - 1s - loss: 0.0503 - accuracy: 0.9856 - val_loss: 2.6824 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00964: val_accuracy did not improve from 0.71000\n",
      "Epoch 965/2000\n",
      "113/113 - 1s - loss: 0.0396 - accuracy: 0.9956 - val_loss: 2.4492 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00965: val_accuracy did not improve from 0.71000\n",
      "Epoch 966/2000\n",
      "113/113 - 1s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.4713 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00966: val_accuracy did not improve from 0.71000\n",
      "Epoch 967/2000\n",
      "113/113 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.4720 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00967: val_accuracy did not improve from 0.71000\n",
      "Epoch 968/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.4841 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00968: val_accuracy did not improve from 0.71000\n",
      "Epoch 969/2000\n",
      "113/113 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.5060 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00969: val_accuracy did not improve from 0.71000\n",
      "Epoch 970/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.5252 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00970: val_accuracy did not improve from 0.71000\n",
      "Epoch 971/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.5341 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00971: val_accuracy did not improve from 0.71000\n",
      "Epoch 972/2000\n",
      "113/113 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.5638 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00972: val_accuracy did not improve from 0.71000\n",
      "Epoch 973/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6147 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00973: val_accuracy did not improve from 0.71000\n",
      "Epoch 974/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.6428 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00974: val_accuracy did not improve from 0.71000\n",
      "Epoch 975/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6607 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00975: val_accuracy did not improve from 0.71000\n",
      "Epoch 976/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6513 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00976: val_accuracy did not improve from 0.71000\n",
      "Epoch 977/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.6877 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00977: val_accuracy did not improve from 0.71000\n",
      "Epoch 978/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.6625 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00978: val_accuracy did not improve from 0.71000\n",
      "Epoch 979/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00979: val_accuracy did not improve from 0.71000\n",
      "Epoch 980/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.6571 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00980: val_accuracy did not improve from 0.71000\n",
      "Epoch 981/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.7003 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00981: val_accuracy did not improve from 0.71000\n",
      "Epoch 982/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.7100 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00982: val_accuracy did not improve from 0.71000\n",
      "Epoch 983/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.7017 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00983: val_accuracy did not improve from 0.71000\n",
      "Epoch 984/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6927 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00984: val_accuracy did not improve from 0.71000\n",
      "Epoch 985/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7223 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00985: val_accuracy did not improve from 0.71000\n",
      "Epoch 986/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7087 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00986: val_accuracy did not improve from 0.71000\n",
      "Epoch 987/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7147 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00987: val_accuracy did not improve from 0.71000\n",
      "Epoch 988/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7269 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00988: val_accuracy did not improve from 0.71000\n",
      "Epoch 989/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7247 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00989: val_accuracy did not improve from 0.71000\n",
      "Epoch 990/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7523 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00990: val_accuracy did not improve from 0.71000\n",
      "Epoch 991/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7266 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00991: val_accuracy did not improve from 0.71000\n",
      "Epoch 992/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00992: val_accuracy did not improve from 0.71000\n",
      "Epoch 993/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7705 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00993: val_accuracy did not improve from 0.71000\n",
      "Epoch 994/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00994: val_accuracy did not improve from 0.71000\n",
      "Epoch 995/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00995: val_accuracy did not improve from 0.71000\n",
      "Epoch 996/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7423 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 00996: val_accuracy did not improve from 0.71000\n",
      "Epoch 997/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7480 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00997: val_accuracy did not improve from 0.71000\n",
      "Epoch 998/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7429 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00998: val_accuracy did not improve from 0.71000\n",
      "Epoch 999/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7448 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00999: val_accuracy did not improve from 0.71000\n",
      "Epoch 1000/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7831 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01000: val_accuracy did not improve from 0.71000\n",
      "Epoch 1001/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01001: val_accuracy did not improve from 0.71000\n",
      "Epoch 1002/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01002: val_accuracy did not improve from 0.71000\n",
      "Epoch 1003/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7451 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01003: val_accuracy did not improve from 0.71000\n",
      "Epoch 1004/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01004: val_accuracy did not improve from 0.71000\n",
      "Epoch 1005/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7468 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01005: val_accuracy did not improve from 0.71000\n",
      "Epoch 1006/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7349 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01006: val_accuracy did not improve from 0.71000\n",
      "Epoch 1007/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01007: val_accuracy did not improve from 0.71000\n",
      "Epoch 1008/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7697 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01008: val_accuracy did not improve from 0.71000\n",
      "Epoch 1009/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01009: val_accuracy did not improve from 0.71000\n",
      "Epoch 1010/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7088 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01010: val_accuracy did not improve from 0.71000\n",
      "Epoch 1011/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 3.2132 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01011: val_accuracy did not improve from 0.71000\n",
      "Epoch 1012/2000\n",
      "113/113 - 1s - loss: 0.9563 - accuracy: 0.8300 - val_loss: 2.5926 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01012: val_accuracy did not improve from 0.71000\n",
      "Epoch 1013/2000\n",
      "113/113 - 1s - loss: 0.3744 - accuracy: 0.9000 - val_loss: 2.1435 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01013: val_accuracy did not improve from 0.71000\n",
      "Epoch 1014/2000\n",
      "113/113 - 1s - loss: 0.1147 - accuracy: 0.9611 - val_loss: 2.2599 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01014: val_accuracy did not improve from 0.71000\n",
      "Epoch 1015/2000\n",
      "113/113 - 1s - loss: 0.0342 - accuracy: 0.9944 - val_loss: 2.4163 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01015: val_accuracy did not improve from 0.71000\n",
      "Epoch 1016/2000\n",
      "113/113 - 1s - loss: 0.0262 - accuracy: 0.9978 - val_loss: 2.3430 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01016: val_accuracy did not improve from 0.71000\n",
      "Epoch 1017/2000\n",
      "113/113 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.3836 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01017: val_accuracy did not improve from 0.71000\n",
      "Epoch 1018/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.4447 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01018: val_accuracy did not improve from 0.71000\n",
      "Epoch 1019/2000\n",
      "113/113 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.4722 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01019: val_accuracy did not improve from 0.71000\n",
      "Epoch 1020/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.4553 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01020: val_accuracy did not improve from 0.71000\n",
      "Epoch 1021/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.4738 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01021: val_accuracy did not improve from 0.71000\n",
      "Epoch 1022/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.4859 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01022: val_accuracy did not improve from 0.71000\n",
      "Epoch 1023/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.4851 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01023: val_accuracy did not improve from 0.71000\n",
      "Epoch 1024/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.5044 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01024: val_accuracy did not improve from 0.71000\n",
      "Epoch 1025/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.4997 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01025: val_accuracy did not improve from 0.71000\n",
      "Epoch 1026/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.5085 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01026: val_accuracy did not improve from 0.71000\n",
      "Epoch 1027/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.4923 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01027: val_accuracy did not improve from 0.71000\n",
      "Epoch 1028/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.4994 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01028: val_accuracy did not improve from 0.71000\n",
      "Epoch 1029/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.5191 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01029: val_accuracy did not improve from 0.71000\n",
      "Epoch 1030/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.5403 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01030: val_accuracy did not improve from 0.71000\n",
      "Epoch 1031/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5064 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01031: val_accuracy did not improve from 0.71000\n",
      "Epoch 1032/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.5358 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01032: val_accuracy did not improve from 0.71000\n",
      "Epoch 1033/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.5239 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01033: val_accuracy did not improve from 0.71000\n",
      "Epoch 1034/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.5379 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01034: val_accuracy did not improve from 0.71000\n",
      "Epoch 1035/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01035: val_accuracy did not improve from 0.71000\n",
      "Epoch 1036/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5531 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01036: val_accuracy did not improve from 0.71000\n",
      "Epoch 1037/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5640 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01037: val_accuracy did not improve from 0.71000\n",
      "Epoch 1038/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.5507 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01038: val_accuracy did not improve from 0.71000\n",
      "Epoch 1039/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.5655 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01039: val_accuracy did not improve from 0.71000\n",
      "Epoch 1040/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.5694 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01040: val_accuracy did not improve from 0.71000\n",
      "Epoch 1041/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5700 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01041: val_accuracy did not improve from 0.71000\n",
      "Epoch 1042/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5955 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01042: val_accuracy did not improve from 0.71000\n",
      "Epoch 1043/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6272 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01043: val_accuracy did not improve from 0.71000\n",
      "Epoch 1044/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6069 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01044: val_accuracy did not improve from 0.71000\n",
      "Epoch 1045/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.6053 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01045: val_accuracy did not improve from 0.71000\n",
      "Epoch 1046/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.6333 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01046: val_accuracy did not improve from 0.71000\n",
      "Epoch 1047/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.6536 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01047: val_accuracy did not improve from 0.71000\n",
      "Epoch 1048/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.6369 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01048: val_accuracy did not improve from 0.71000\n",
      "Epoch 1049/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6442 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01049: val_accuracy did not improve from 0.71000\n",
      "Epoch 1050/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6635 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01050: val_accuracy did not improve from 0.71000\n",
      "Epoch 1051/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01051: val_accuracy did not improve from 0.71000\n",
      "Epoch 1052/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6861 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01052: val_accuracy did not improve from 0.71000\n",
      "Epoch 1053/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7138 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01053: val_accuracy did not improve from 0.71000\n",
      "Epoch 1054/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6836 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01054: val_accuracy did not improve from 0.71000\n",
      "Epoch 1055/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7129 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01055: val_accuracy did not improve from 0.71000\n",
      "Epoch 1056/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6688 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01056: val_accuracy did not improve from 0.71000\n",
      "Epoch 1057/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01057: val_accuracy did not improve from 0.71000\n",
      "Epoch 1058/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7178 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01058: val_accuracy did not improve from 0.71000\n",
      "Epoch 1059/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7827 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01059: val_accuracy did not improve from 0.71000\n",
      "Epoch 1060/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01060: val_accuracy did not improve from 0.71000\n",
      "Epoch 1061/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01061: val_accuracy did not improve from 0.71000\n",
      "Epoch 1062/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8157 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01062: val_accuracy did not improve from 0.71000\n",
      "Epoch 1063/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01063: val_accuracy did not improve from 0.71000\n",
      "Epoch 1064/2000\n",
      "113/113 - 1s - loss: 0.9630 - accuracy: 0.8078 - val_loss: 2.0566 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01064: val_accuracy did not improve from 0.71000\n",
      "Epoch 1065/2000\n",
      "113/113 - 1s - loss: 0.3054 - accuracy: 0.9111 - val_loss: 1.9891 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01065: val_accuracy did not improve from 0.71000\n",
      "Epoch 1066/2000\n",
      "113/113 - 1s - loss: 0.0993 - accuracy: 0.9689 - val_loss: 2.1797 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01066: val_accuracy did not improve from 0.71000\n",
      "Epoch 1067/2000\n",
      "113/113 - 1s - loss: 0.0499 - accuracy: 0.9922 - val_loss: 2.2965 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01067: val_accuracy did not improve from 0.71000\n",
      "Epoch 1068/2000\n",
      "113/113 - 1s - loss: 0.0261 - accuracy: 0.9989 - val_loss: 2.2957 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01068: val_accuracy did not improve from 0.71000\n",
      "Epoch 1069/2000\n",
      "113/113 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.3183 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01069: val_accuracy did not improve from 0.71000\n",
      "Epoch 1070/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.3072 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01070: val_accuracy did not improve from 0.71000\n",
      "Epoch 1071/2000\n",
      "113/113 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.3320 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01071: val_accuracy did not improve from 0.71000\n",
      "Epoch 1072/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.3359 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01072: val_accuracy did not improve from 0.71000\n",
      "Epoch 1073/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.3392 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01073: val_accuracy did not improve from 0.71000\n",
      "Epoch 1074/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.3645 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01074: val_accuracy did not improve from 0.71000\n",
      "Epoch 1075/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.3712 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01075: val_accuracy did not improve from 0.71000\n",
      "Epoch 1076/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01076: val_accuracy did not improve from 0.71000\n",
      "Epoch 1077/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.3701 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01077: val_accuracy did not improve from 0.71000\n",
      "Epoch 1078/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.3852 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01078: val_accuracy did not improve from 0.71000\n",
      "Epoch 1079/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.4040 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01079: val_accuracy did not improve from 0.71000\n",
      "Epoch 1080/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.4348 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01080: val_accuracy did not improve from 0.71000\n",
      "Epoch 1081/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.4632 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01081: val_accuracy did not improve from 0.71000\n",
      "Epoch 1082/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.4440 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01082: val_accuracy did not improve from 0.71000\n",
      "Epoch 1083/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.4696 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01083: val_accuracy did not improve from 0.71000\n",
      "Epoch 1084/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.4739 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01084: val_accuracy did not improve from 0.71000\n",
      "Epoch 1085/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.4964 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01085: val_accuracy did not improve from 0.71000\n",
      "Epoch 1086/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.4971 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01086: val_accuracy did not improve from 0.71000\n",
      "Epoch 1087/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.4978 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01087: val_accuracy did not improve from 0.71000\n",
      "Epoch 1088/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.5303 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01088: val_accuracy did not improve from 0.71000\n",
      "Epoch 1089/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5292 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01089: val_accuracy did not improve from 0.71000\n",
      "Epoch 1090/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5409 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01090: val_accuracy did not improve from 0.71000\n",
      "Epoch 1091/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5424 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01091: val_accuracy did not improve from 0.71000\n",
      "Epoch 1092/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5477 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01092: val_accuracy did not improve from 0.71000\n",
      "Epoch 1093/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.5702 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01093: val_accuracy did not improve from 0.71000\n",
      "Epoch 1094/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.5909 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01094: val_accuracy did not improve from 0.71000\n",
      "Epoch 1095/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01095: val_accuracy did not improve from 0.71000\n",
      "Epoch 1096/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5881 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01096: val_accuracy did not improve from 0.71000\n",
      "Epoch 1097/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6180 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01097: val_accuracy did not improve from 0.71000\n",
      "Epoch 1098/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6266 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01098: val_accuracy did not improve from 0.71000\n",
      "Epoch 1099/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6133 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01099: val_accuracy did not improve from 0.71000\n",
      "Epoch 1100/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6313 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01100: val_accuracy did not improve from 0.71000\n",
      "Epoch 1101/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6872 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01101: val_accuracy did not improve from 0.71000\n",
      "Epoch 1102/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6568 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01102: val_accuracy did not improve from 0.71000\n",
      "Epoch 1103/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6347 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01103: val_accuracy did not improve from 0.71000\n",
      "Epoch 1104/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01104: val_accuracy did not improve from 0.71000\n",
      "Epoch 1105/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6955 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01105: val_accuracy did not improve from 0.71000\n",
      "Epoch 1106/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6754 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01106: val_accuracy did not improve from 0.71000\n",
      "Epoch 1107/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6846 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01107: val_accuracy did not improve from 0.71000\n",
      "Epoch 1108/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6763 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01108: val_accuracy did not improve from 0.71000\n",
      "Epoch 1109/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7671 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01109: val_accuracy did not improve from 0.71000\n",
      "Epoch 1110/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7170 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01110: val_accuracy did not improve from 0.71000\n",
      "Epoch 1111/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7137 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01111: val_accuracy did not improve from 0.71000\n",
      "Epoch 1112/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01112: val_accuracy did not improve from 0.71000\n",
      "Epoch 1113/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01113: val_accuracy did not improve from 0.71000\n",
      "Epoch 1114/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 3.0097 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01114: val_accuracy did not improve from 0.71000\n",
      "Epoch 1115/2000\n",
      "113/113 - 1s - loss: 0.9028 - accuracy: 0.7978 - val_loss: 2.7470 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01115: val_accuracy did not improve from 0.71000\n",
      "Epoch 1116/2000\n",
      "113/113 - 1s - loss: 0.2301 - accuracy: 0.9211 - val_loss: 1.9349 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 01116: val_accuracy did not improve from 0.71000\n",
      "Epoch 1117/2000\n",
      "113/113 - 1s - loss: 0.0709 - accuracy: 0.9800 - val_loss: 2.5994 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01117: val_accuracy did not improve from 0.71000\n",
      "Epoch 1118/2000\n",
      "113/113 - 1s - loss: 0.0344 - accuracy: 0.9967 - val_loss: 2.4487 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01118: val_accuracy did not improve from 0.71000\n",
      "Epoch 1119/2000\n",
      "113/113 - 1s - loss: 0.0272 - accuracy: 0.9989 - val_loss: 2.3769 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01119: val_accuracy did not improve from 0.71000\n",
      "Epoch 1120/2000\n",
      "113/113 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.3448 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01120: val_accuracy did not improve from 0.71000\n",
      "Epoch 1121/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.3450 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01121: val_accuracy did not improve from 0.71000\n",
      "Epoch 1122/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.3716 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01122: val_accuracy did not improve from 0.71000\n",
      "Epoch 1123/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.3453 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01123: val_accuracy did not improve from 0.71000\n",
      "Epoch 1124/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.3440 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01124: val_accuracy did not improve from 0.71000\n",
      "Epoch 1125/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.3356 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01125: val_accuracy did not improve from 0.71000\n",
      "Epoch 1126/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.3383 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01126: val_accuracy did not improve from 0.71000\n",
      "Epoch 1127/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.3565 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01127: val_accuracy did not improve from 0.71000\n",
      "Epoch 1128/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.3916 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01128: val_accuracy did not improve from 0.71000\n",
      "Epoch 1129/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.3935 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01129: val_accuracy did not improve from 0.71000\n",
      "Epoch 1130/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.3862 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01130: val_accuracy did not improve from 0.71000\n",
      "Epoch 1131/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.4080 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01131: val_accuracy did not improve from 0.71000\n",
      "Epoch 1132/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.4361 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01132: val_accuracy did not improve from 0.71000\n",
      "Epoch 1133/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.4287 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01133: val_accuracy did not improve from 0.71000\n",
      "Epoch 1134/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.4388 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01134: val_accuracy did not improve from 0.71000\n",
      "Epoch 1135/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.4455 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01135: val_accuracy did not improve from 0.71000\n",
      "Epoch 1136/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.4701 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01136: val_accuracy did not improve from 0.71000\n",
      "Epoch 1137/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.4699 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01137: val_accuracy did not improve from 0.71000\n",
      "Epoch 1138/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.4777 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01138: val_accuracy did not improve from 0.71000\n",
      "Epoch 1139/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.4851 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01139: val_accuracy did not improve from 0.71000\n",
      "Epoch 1140/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4918 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01140: val_accuracy did not improve from 0.71000\n",
      "Epoch 1141/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4910 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01141: val_accuracy did not improve from 0.71000\n",
      "Epoch 1142/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.5089 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01142: val_accuracy did not improve from 0.71000\n",
      "Epoch 1143/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.5488 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01143: val_accuracy did not improve from 0.71000\n",
      "Epoch 1144/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01144: val_accuracy did not improve from 0.71000\n",
      "Epoch 1145/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5566 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01145: val_accuracy did not improve from 0.71000\n",
      "Epoch 1146/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5584 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01146: val_accuracy did not improve from 0.71000\n",
      "Epoch 1147/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5756 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01147: val_accuracy did not improve from 0.71000\n",
      "Epoch 1148/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5840 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01148: val_accuracy did not improve from 0.71000\n",
      "Epoch 1149/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5366 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01149: val_accuracy did not improve from 0.71000\n",
      "Epoch 1150/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5711 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01150: val_accuracy did not improve from 0.71000\n",
      "Epoch 1151/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5721 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01151: val_accuracy did not improve from 0.71000\n",
      "Epoch 1152/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5647 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01152: val_accuracy did not improve from 0.71000\n",
      "Epoch 1153/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6209 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01153: val_accuracy did not improve from 0.71000\n",
      "Epoch 1154/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.5716 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01154: val_accuracy did not improve from 0.71000\n",
      "Epoch 1155/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5848 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01155: val_accuracy did not improve from 0.71000\n",
      "Epoch 1156/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6022 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01156: val_accuracy did not improve from 0.71000\n",
      "Epoch 1157/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5540 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01157: val_accuracy did not improve from 0.71000\n",
      "Epoch 1158/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6156 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01158: val_accuracy did not improve from 0.71000\n",
      "Epoch 1159/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6522 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01159: val_accuracy did not improve from 0.71000\n",
      "Epoch 1160/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5640 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01160: val_accuracy did not improve from 0.71000\n",
      "Epoch 1161/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6196 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01161: val_accuracy did not improve from 0.71000\n",
      "Epoch 1162/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5872 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01162: val_accuracy did not improve from 0.71000\n",
      "Epoch 1163/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01163: val_accuracy did not improve from 0.71000\n",
      "Epoch 1164/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.5871 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01164: val_accuracy did not improve from 0.71000\n",
      "Epoch 1165/2000\n",
      "113/113 - 1s - loss: 0.5224 - accuracy: 0.9067 - val_loss: 3.3145 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01165: val_accuracy did not improve from 0.71000\n",
      "Epoch 1166/2000\n",
      "113/113 - 1s - loss: 0.7257 - accuracy: 0.8244 - val_loss: 2.3944 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01166: val_accuracy did not improve from 0.71000\n",
      "Epoch 1167/2000\n",
      "113/113 - 1s - loss: 0.1553 - accuracy: 0.9489 - val_loss: 2.6840 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01167: val_accuracy did not improve from 0.71000\n",
      "Epoch 1168/2000\n",
      "113/113 - 1s - loss: 0.0513 - accuracy: 0.9867 - val_loss: 2.3938 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01168: val_accuracy did not improve from 0.71000\n",
      "Epoch 1169/2000\n",
      "113/113 - 1s - loss: 0.0393 - accuracy: 0.9944 - val_loss: 2.6577 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01169: val_accuracy did not improve from 0.71000\n",
      "Epoch 1170/2000\n",
      "113/113 - 1s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.6504 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01170: val_accuracy did not improve from 0.71000\n",
      "Epoch 1171/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.7409 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01171: val_accuracy did not improve from 0.71000\n",
      "Epoch 1172/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.7163 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01172: val_accuracy did not improve from 0.71000\n",
      "Epoch 1173/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.7397 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01173: val_accuracy did not improve from 0.71000\n",
      "Epoch 1174/2000\n",
      "113/113 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.7285 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01174: val_accuracy did not improve from 0.71000\n",
      "Epoch 1175/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.8063 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01175: val_accuracy did not improve from 0.71000\n",
      "Epoch 1176/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7640 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01176: val_accuracy did not improve from 0.71000\n",
      "Epoch 1177/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.8113 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01177: val_accuracy did not improve from 0.71000\n",
      "Epoch 1178/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7730 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01178: val_accuracy did not improve from 0.71000\n",
      "Epoch 1179/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01179: val_accuracy did not improve from 0.71000\n",
      "Epoch 1180/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01180: val_accuracy did not improve from 0.71000\n",
      "Epoch 1181/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01181: val_accuracy did not improve from 0.71000\n",
      "Epoch 1182/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8304 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01182: val_accuracy did not improve from 0.71000\n",
      "Epoch 1183/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01183: val_accuracy did not improve from 0.71000\n",
      "Epoch 1184/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7841 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01184: val_accuracy did not improve from 0.71000\n",
      "Epoch 1185/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01185: val_accuracy did not improve from 0.71000\n",
      "Epoch 1186/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8048 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01186: val_accuracy did not improve from 0.71000\n",
      "Epoch 1187/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01187: val_accuracy did not improve from 0.71000\n",
      "Epoch 1188/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01188: val_accuracy did not improve from 0.71000\n",
      "Epoch 1189/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01189: val_accuracy did not improve from 0.71000\n",
      "Epoch 1190/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7736 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01190: val_accuracy did not improve from 0.71000\n",
      "Epoch 1191/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7511 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01191: val_accuracy did not improve from 0.71000\n",
      "Epoch 1192/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8024 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01192: val_accuracy did not improve from 0.71000\n",
      "Epoch 1193/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01193: val_accuracy did not improve from 0.71000\n",
      "Epoch 1194/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7804 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01194: val_accuracy did not improve from 0.71000\n",
      "Epoch 1195/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01195: val_accuracy did not improve from 0.71000\n",
      "Epoch 1196/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7698 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01196: val_accuracy did not improve from 0.71000\n",
      "Epoch 1197/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01197: val_accuracy did not improve from 0.71000\n",
      "Epoch 1198/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7729 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01198: val_accuracy did not improve from 0.71000\n",
      "Epoch 1199/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7841 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01199: val_accuracy did not improve from 0.71000\n",
      "Epoch 1200/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01200: val_accuracy did not improve from 0.71000\n",
      "Epoch 1201/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7421 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01201: val_accuracy did not improve from 0.71000\n",
      "Epoch 1202/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7543 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01202: val_accuracy did not improve from 0.71000\n",
      "Epoch 1203/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01203: val_accuracy did not improve from 0.71000\n",
      "Epoch 1204/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01204: val_accuracy did not improve from 0.71000\n",
      "Epoch 1205/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01205: val_accuracy did not improve from 0.71000\n",
      "Epoch 1206/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8016 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01206: val_accuracy did not improve from 0.71000\n",
      "Epoch 1207/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8049 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01207: val_accuracy did not improve from 0.71000\n",
      "Epoch 1208/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01208: val_accuracy did not improve from 0.71000\n",
      "Epoch 1209/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01209: val_accuracy did not improve from 0.71000\n",
      "Epoch 1210/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8045 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01210: val_accuracy did not improve from 0.71000\n",
      "Epoch 1211/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01211: val_accuracy did not improve from 0.71000\n",
      "Epoch 1212/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7734 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01212: val_accuracy did not improve from 0.71000\n",
      "Epoch 1213/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01213: val_accuracy did not improve from 0.71000\n",
      "Epoch 1214/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01214: val_accuracy did not improve from 0.71000\n",
      "Epoch 1215/2000\n",
      "113/113 - 1s - loss: 0.7332 - accuracy: 0.8622 - val_loss: 2.2575 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01215: val_accuracy did not improve from 0.71000\n",
      "Epoch 1216/2000\n",
      "113/113 - 1s - loss: 0.4975 - accuracy: 0.8500 - val_loss: 2.1810 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01216: val_accuracy did not improve from 0.71000\n",
      "Epoch 1217/2000\n",
      "113/113 - 1s - loss: 0.1168 - accuracy: 0.9633 - val_loss: 2.7218 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01217: val_accuracy did not improve from 0.71000\n",
      "Epoch 1218/2000\n",
      "113/113 - 1s - loss: 0.0788 - accuracy: 0.9711 - val_loss: 2.6416 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01218: val_accuracy did not improve from 0.71000\n",
      "Epoch 1219/2000\n",
      "113/113 - 1s - loss: 0.0514 - accuracy: 0.9911 - val_loss: 2.6522 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01219: val_accuracy did not improve from 0.71000\n",
      "Epoch 1220/2000\n",
      "113/113 - 1s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.6963 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01220: val_accuracy did not improve from 0.71000\n",
      "Epoch 1221/2000\n",
      "113/113 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.7260 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01221: val_accuracy did not improve from 0.71000\n",
      "Epoch 1222/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.6820 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01222: val_accuracy did not improve from 0.71000\n",
      "Epoch 1223/2000\n",
      "113/113 - 1s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6798 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01223: val_accuracy did not improve from 0.71000\n",
      "Epoch 1224/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.6942 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01224: val_accuracy did not improve from 0.71000\n",
      "Epoch 1225/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.6962 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01225: val_accuracy did not improve from 0.71000\n",
      "Epoch 1226/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.6964 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01226: val_accuracy did not improve from 0.71000\n",
      "Epoch 1227/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6946 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01227: val_accuracy did not improve from 0.71000\n",
      "Epoch 1228/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.6862 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01228: val_accuracy did not improve from 0.71000\n",
      "Epoch 1229/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.7096 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01229: val_accuracy did not improve from 0.71000\n",
      "Epoch 1230/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7062 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01230: val_accuracy did not improve from 0.71000\n",
      "Epoch 1231/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7065 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01231: val_accuracy did not improve from 0.71000\n",
      "Epoch 1232/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7158 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01232: val_accuracy did not improve from 0.71000\n",
      "Epoch 1233/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7085 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01233: val_accuracy did not improve from 0.71000\n",
      "Epoch 1234/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.6833 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01234: val_accuracy did not improve from 0.71000\n",
      "Epoch 1235/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7265 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01235: val_accuracy did not improve from 0.71000\n",
      "Epoch 1236/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7227 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01236: val_accuracy did not improve from 0.71000\n",
      "Epoch 1237/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7167 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01237: val_accuracy did not improve from 0.71000\n",
      "Epoch 1238/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01238: val_accuracy did not improve from 0.71000\n",
      "Epoch 1239/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7705 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01239: val_accuracy did not improve from 0.71000\n",
      "Epoch 1240/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7670 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01240: val_accuracy did not improve from 0.71000\n",
      "Epoch 1241/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7661 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01241: val_accuracy did not improve from 0.71000\n",
      "Epoch 1242/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01242: val_accuracy did not improve from 0.71000\n",
      "Epoch 1243/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7623 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01243: val_accuracy did not improve from 0.71000\n",
      "Epoch 1244/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01244: val_accuracy did not improve from 0.71000\n",
      "Epoch 1245/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01245: val_accuracy did not improve from 0.71000\n",
      "Epoch 1246/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7742 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01246: val_accuracy did not improve from 0.71000\n",
      "Epoch 1247/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01247: val_accuracy did not improve from 0.71000\n",
      "Epoch 1248/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01248: val_accuracy did not improve from 0.71000\n",
      "Epoch 1249/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01249: val_accuracy did not improve from 0.71000\n",
      "Epoch 1250/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7757 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01250: val_accuracy did not improve from 0.71000\n",
      "Epoch 1251/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01251: val_accuracy did not improve from 0.71000\n",
      "Epoch 1252/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01252: val_accuracy did not improve from 0.71000\n",
      "Epoch 1253/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7792 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01253: val_accuracy did not improve from 0.71000\n",
      "Epoch 1254/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01254: val_accuracy did not improve from 0.71000\n",
      "Epoch 1255/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8059 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01255: val_accuracy did not improve from 0.71000\n",
      "Epoch 1256/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01256: val_accuracy did not improve from 0.71000\n",
      "Epoch 1257/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01257: val_accuracy did not improve from 0.71000\n",
      "Epoch 1258/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01258: val_accuracy did not improve from 0.71000\n",
      "Epoch 1259/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01259: val_accuracy did not improve from 0.71000\n",
      "Epoch 1260/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8114 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01260: val_accuracy did not improve from 0.71000\n",
      "Epoch 1261/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8221 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01261: val_accuracy did not improve from 0.71000\n",
      "Epoch 1262/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01262: val_accuracy did not improve from 0.71000\n",
      "Epoch 1263/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8069 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01263: val_accuracy did not improve from 0.71000\n",
      "Epoch 1264/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8186 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01264: val_accuracy did not improve from 0.71000\n",
      "Epoch 1265/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8238 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01265: val_accuracy did not improve from 0.71000\n",
      "Epoch 1266/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01266: val_accuracy did not improve from 0.71000\n",
      "Epoch 1267/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7667 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01267: val_accuracy did not improve from 0.71000\n",
      "Epoch 1268/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01268: val_accuracy did not improve from 0.71000\n",
      "Epoch 1269/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8818 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01269: val_accuracy did not improve from 0.71000\n",
      "Epoch 1270/2000\n",
      "113/113 - 1s - loss: 0.7056 - accuracy: 0.8933 - val_loss: 3.2814 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 01270: val_accuracy did not improve from 0.71000\n",
      "Epoch 1271/2000\n",
      "113/113 - 1s - loss: 0.5122 - accuracy: 0.8589 - val_loss: 2.6050 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01271: val_accuracy did not improve from 0.71000\n",
      "Epoch 1272/2000\n",
      "113/113 - 1s - loss: 0.1247 - accuracy: 0.9600 - val_loss: 2.3486 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01272: val_accuracy did not improve from 0.71000\n",
      "Epoch 1273/2000\n",
      "113/113 - 1s - loss: 0.0572 - accuracy: 0.9833 - val_loss: 2.2051 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01273: val_accuracy did not improve from 0.71000\n",
      "Epoch 1274/2000\n",
      "113/113 - 1s - loss: 0.0294 - accuracy: 0.9978 - val_loss: 2.2084 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01274: val_accuracy did not improve from 0.71000\n",
      "Epoch 1275/2000\n",
      "113/113 - 1s - loss: 0.0233 - accuracy: 0.9989 - val_loss: 2.2883 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01275: val_accuracy did not improve from 0.71000\n",
      "Epoch 1276/2000\n",
      "113/113 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.2766 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01276: val_accuracy did not improve from 0.71000\n",
      "Epoch 1277/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01277: val_accuracy did not improve from 0.71000\n",
      "Epoch 1278/2000\n",
      "113/113 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.3253 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01278: val_accuracy did not improve from 0.71000\n",
      "Epoch 1279/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.3430 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01279: val_accuracy did not improve from 0.71000\n",
      "Epoch 1280/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.3773 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01280: val_accuracy did not improve from 0.71000\n",
      "Epoch 1281/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.3532 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01281: val_accuracy did not improve from 0.71000\n",
      "Epoch 1282/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.3856 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01282: val_accuracy did not improve from 0.71000\n",
      "Epoch 1283/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.3721 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01283: val_accuracy did not improve from 0.71000\n",
      "Epoch 1284/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.4119 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01284: val_accuracy did not improve from 0.71000\n",
      "Epoch 1285/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.4058 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01285: val_accuracy did not improve from 0.71000\n",
      "Epoch 1286/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.4495 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01286: val_accuracy did not improve from 0.71000\n",
      "Epoch 1287/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.4449 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01287: val_accuracy did not improve from 0.71000\n",
      "Epoch 1288/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.4816 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01288: val_accuracy did not improve from 0.71000\n",
      "Epoch 1289/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4664 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01289: val_accuracy did not improve from 0.71000\n",
      "Epoch 1290/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4919 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01290: val_accuracy did not improve from 0.71000\n",
      "Epoch 1291/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.4961 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01291: val_accuracy did not improve from 0.71000\n",
      "Epoch 1292/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.5040 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01292: val_accuracy did not improve from 0.71000\n",
      "Epoch 1293/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5117 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01293: val_accuracy did not improve from 0.71000\n",
      "Epoch 1294/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.5418 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01294: val_accuracy did not improve from 0.71000\n",
      "Epoch 1295/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5079 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01295: val_accuracy did not improve from 0.71000\n",
      "Epoch 1296/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.5763 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01296: val_accuracy did not improve from 0.71000\n",
      "Epoch 1297/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5339 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01297: val_accuracy did not improve from 0.71000\n",
      "Epoch 1298/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.5282 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01298: val_accuracy did not improve from 0.71000\n",
      "Epoch 1299/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5461 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01299: val_accuracy did not improve from 0.71000\n",
      "Epoch 1300/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5547 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01300: val_accuracy did not improve from 0.71000\n",
      "Epoch 1301/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01301: val_accuracy did not improve from 0.71000\n",
      "Epoch 1302/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.5838 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01302: val_accuracy did not improve from 0.71000\n",
      "Epoch 1303/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6349 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01303: val_accuracy did not improve from 0.71000\n",
      "Epoch 1304/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6378 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01304: val_accuracy did not improve from 0.71000\n",
      "Epoch 1305/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5796 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01305: val_accuracy did not improve from 0.71000\n",
      "Epoch 1306/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6305 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01306: val_accuracy did not improve from 0.71000\n",
      "Epoch 1307/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5667 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01307: val_accuracy did not improve from 0.71000\n",
      "Epoch 1308/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01308: val_accuracy did not improve from 0.71000\n",
      "Epoch 1309/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6145 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01309: val_accuracy did not improve from 0.71000\n",
      "Epoch 1310/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6349 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01310: val_accuracy did not improve from 0.71000\n",
      "Epoch 1311/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6307 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01311: val_accuracy did not improve from 0.71000\n",
      "Epoch 1312/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6754 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01312: val_accuracy did not improve from 0.71000\n",
      "Epoch 1313/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6587 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01313: val_accuracy did not improve from 0.71000\n",
      "Epoch 1314/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6616 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01314: val_accuracy did not improve from 0.71000\n",
      "Epoch 1315/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7016 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01315: val_accuracy did not improve from 0.71000\n",
      "Epoch 1316/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6722 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01316: val_accuracy did not improve from 0.71000\n",
      "Epoch 1317/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6746 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01317: val_accuracy did not improve from 0.71000\n",
      "Epoch 1318/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7222 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01318: val_accuracy did not improve from 0.71000\n",
      "Epoch 1319/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6990 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01319: val_accuracy did not improve from 0.71000\n",
      "Epoch 1320/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7235 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01320: val_accuracy did not improve from 0.71000\n",
      "Epoch 1321/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6757 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01321: val_accuracy did not improve from 0.71000\n",
      "Epoch 1322/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6419 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01322: val_accuracy did not improve from 0.71000\n",
      "Epoch 1323/2000\n",
      "113/113 - 1s - loss: 0.4191 - accuracy: 0.9200 - val_loss: 2.7487 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01323: val_accuracy did not improve from 0.71000\n",
      "Epoch 1324/2000\n",
      "113/113 - 1s - loss: 0.6703 - accuracy: 0.8233 - val_loss: 2.4227 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01324: val_accuracy did not improve from 0.71000\n",
      "Epoch 1325/2000\n",
      "113/113 - 1s - loss: 0.1555 - accuracy: 0.9522 - val_loss: 2.6319 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01325: val_accuracy did not improve from 0.71000\n",
      "Epoch 1326/2000\n",
      "113/113 - 1s - loss: 0.0525 - accuracy: 0.9889 - val_loss: 2.5386 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01326: val_accuracy did not improve from 0.71000\n",
      "Epoch 1327/2000\n",
      "113/113 - 1s - loss: 0.0336 - accuracy: 0.9978 - val_loss: 2.5420 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01327: val_accuracy did not improve from 0.71000\n",
      "Epoch 1328/2000\n",
      "113/113 - 1s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.5102 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01328: val_accuracy did not improve from 0.71000\n",
      "Epoch 1329/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 0.9989 - val_loss: 2.5884 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01329: val_accuracy did not improve from 0.71000\n",
      "Epoch 1330/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.4929 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01330: val_accuracy did not improve from 0.71000\n",
      "Epoch 1331/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.5118 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01331: val_accuracy did not improve from 0.71000\n",
      "Epoch 1332/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.5893 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01332: val_accuracy did not improve from 0.71000\n",
      "Epoch 1333/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.5860 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01333: val_accuracy did not improve from 0.71000\n",
      "Epoch 1334/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6096 - val_accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01334: val_accuracy did not improve from 0.71000\n",
      "Epoch 1335/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6465 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01335: val_accuracy did not improve from 0.71000\n",
      "Epoch 1336/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.6168 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01336: val_accuracy did not improve from 0.71000\n",
      "Epoch 1337/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6407 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01337: val_accuracy did not improve from 0.71000\n",
      "Epoch 1338/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5977 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01338: val_accuracy did not improve from 0.71000\n",
      "Epoch 1339/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6154 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01339: val_accuracy did not improve from 0.71000\n",
      "Epoch 1340/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6212 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01340: val_accuracy did not improve from 0.71000\n",
      "Epoch 1341/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6341 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01341: val_accuracy did not improve from 0.71000\n",
      "Epoch 1342/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6321 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01342: val_accuracy did not improve from 0.71000\n",
      "Epoch 1343/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6351 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01343: val_accuracy did not improve from 0.71000\n",
      "Epoch 1344/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6782 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01344: val_accuracy did not improve from 0.71000\n",
      "Epoch 1345/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6680 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01345: val_accuracy did not improve from 0.71000\n",
      "Epoch 1346/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6713 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01346: val_accuracy did not improve from 0.71000\n",
      "Epoch 1347/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6339 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01347: val_accuracy did not improve from 0.71000\n",
      "Epoch 1348/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6722 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01348: val_accuracy did not improve from 0.71000\n",
      "Epoch 1349/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6586 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01349: val_accuracy did not improve from 0.71000\n",
      "Epoch 1350/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6675 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01350: val_accuracy did not improve from 0.71000\n",
      "Epoch 1351/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6928 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01351: val_accuracy did not improve from 0.71000\n",
      "Epoch 1352/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6588 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01352: val_accuracy did not improve from 0.71000\n",
      "Epoch 1353/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6764 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01353: val_accuracy did not improve from 0.71000\n",
      "Epoch 1354/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6723 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01354: val_accuracy did not improve from 0.71000\n",
      "Epoch 1355/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7280 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01355: val_accuracy did not improve from 0.71000\n",
      "Epoch 1356/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6828 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01356: val_accuracy did not improve from 0.71000\n",
      "Epoch 1357/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7046 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01357: val_accuracy did not improve from 0.71000\n",
      "Epoch 1358/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7149 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01358: val_accuracy did not improve from 0.71000\n",
      "Epoch 1359/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6805 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01359: val_accuracy did not improve from 0.71000\n",
      "Epoch 1360/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7160 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01360: val_accuracy did not improve from 0.71000\n",
      "Epoch 1361/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7003 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01361: val_accuracy did not improve from 0.71000\n",
      "Epoch 1362/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01362: val_accuracy did not improve from 0.71000\n",
      "Epoch 1363/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6879 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01363: val_accuracy did not improve from 0.71000\n",
      "Epoch 1364/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6706 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01364: val_accuracy did not improve from 0.71000\n",
      "Epoch 1365/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7723 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01365: val_accuracy did not improve from 0.71000\n",
      "Epoch 1366/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7025 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01366: val_accuracy did not improve from 0.71000\n",
      "Epoch 1367/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7264 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01367: val_accuracy did not improve from 0.71000\n",
      "Epoch 1368/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7548 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01368: val_accuracy did not improve from 0.71000\n",
      "Epoch 1369/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7383 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01369: val_accuracy did not improve from 0.71000\n",
      "Epoch 1370/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8224 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01370: val_accuracy did not improve from 0.71000\n",
      "Epoch 1371/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7202 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01371: val_accuracy did not improve from 0.71000\n",
      "Epoch 1372/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8945 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01372: val_accuracy did not improve from 0.71000\n",
      "Epoch 1373/2000\n",
      "113/113 - 1s - loss: 0.7608 - accuracy: 0.8467 - val_loss: 2.3513 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01373: val_accuracy did not improve from 0.71000\n",
      "Epoch 1374/2000\n",
      "113/113 - 1s - loss: 0.2811 - accuracy: 0.9178 - val_loss: 2.7104 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01374: val_accuracy did not improve from 0.71000\n",
      "Epoch 1375/2000\n",
      "113/113 - 1s - loss: 0.0912 - accuracy: 0.9733 - val_loss: 2.4397 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01375: val_accuracy did not improve from 0.71000\n",
      "Epoch 1376/2000\n",
      "113/113 - 1s - loss: 0.0420 - accuracy: 0.9933 - val_loss: 2.7137 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01376: val_accuracy did not improve from 0.71000\n",
      "Epoch 1377/2000\n",
      "113/113 - 1s - loss: 0.0282 - accuracy: 0.9978 - val_loss: 2.6300 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01377: val_accuracy did not improve from 0.71000\n",
      "Epoch 1378/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.6437 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01378: val_accuracy did not improve from 0.71000\n",
      "Epoch 1379/2000\n",
      "113/113 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6032 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01379: val_accuracy did not improve from 0.71000\n",
      "Epoch 1380/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7175 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01380: val_accuracy did not improve from 0.71000\n",
      "Epoch 1381/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.6772 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01381: val_accuracy did not improve from 0.71000\n",
      "Epoch 1382/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7474 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01382: val_accuracy did not improve from 0.71000\n",
      "Epoch 1383/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.7516 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01383: val_accuracy did not improve from 0.71000\n",
      "Epoch 1384/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.7864 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01384: val_accuracy did not improve from 0.71000\n",
      "Epoch 1385/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01385: val_accuracy did not improve from 0.71000\n",
      "Epoch 1386/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01386: val_accuracy did not improve from 0.71000\n",
      "Epoch 1387/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7777 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01387: val_accuracy did not improve from 0.71000\n",
      "Epoch 1388/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7961 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01388: val_accuracy did not improve from 0.71000\n",
      "Epoch 1389/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8155 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01389: val_accuracy did not improve from 0.71000\n",
      "Epoch 1390/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.8189 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01390: val_accuracy did not improve from 0.71000\n",
      "Epoch 1391/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01391: val_accuracy did not improve from 0.71000\n",
      "Epoch 1392/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.8302 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01392: val_accuracy did not improve from 0.71000\n",
      "Epoch 1393/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8590 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01393: val_accuracy did not improve from 0.71000\n",
      "Epoch 1394/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01394: val_accuracy did not improve from 0.71000\n",
      "Epoch 1395/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8429 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01395: val_accuracy did not improve from 0.71000\n",
      "Epoch 1396/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.8426 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01396: val_accuracy did not improve from 0.71000\n",
      "Epoch 1397/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.8572 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01397: val_accuracy did not improve from 0.71000\n",
      "Epoch 1398/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8331 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01398: val_accuracy did not improve from 0.71000\n",
      "Epoch 1399/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.9005 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01399: val_accuracy did not improve from 0.71000\n",
      "Epoch 1400/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8732 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01400: val_accuracy did not improve from 0.71000\n",
      "Epoch 1401/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8636 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01401: val_accuracy did not improve from 0.71000\n",
      "Epoch 1402/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.9027 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01402: val_accuracy did not improve from 0.71000\n",
      "Epoch 1403/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.9594 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01403: val_accuracy did not improve from 0.71000\n",
      "Epoch 1404/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8723 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01404: val_accuracy did not improve from 0.71000\n",
      "Epoch 1405/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8871 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01405: val_accuracy did not improve from 0.71000\n",
      "Epoch 1406/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9074 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01406: val_accuracy did not improve from 0.71000\n",
      "Epoch 1407/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.9016 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01407: val_accuracy did not improve from 0.71000\n",
      "Epoch 1408/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8785 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01408: val_accuracy did not improve from 0.71000\n",
      "Epoch 1409/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.9016 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01409: val_accuracy did not improve from 0.71000\n",
      "Epoch 1410/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.9047 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01410: val_accuracy did not improve from 0.71000\n",
      "Epoch 1411/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8743 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01411: val_accuracy did not improve from 0.71000\n",
      "Epoch 1412/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8705 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01412: val_accuracy did not improve from 0.71000\n",
      "Epoch 1413/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01413: val_accuracy did not improve from 0.71000\n",
      "Epoch 1414/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.9157 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01414: val_accuracy did not improve from 0.71000\n",
      "Epoch 1415/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8361 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01415: val_accuracy did not improve from 0.71000\n",
      "Epoch 1416/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8778 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01416: val_accuracy did not improve from 0.71000\n",
      "Epoch 1417/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.9448 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01417: val_accuracy did not improve from 0.71000\n",
      "Epoch 1418/2000\n",
      "113/113 - 1s - loss: 0.5571 - accuracy: 0.8789 - val_loss: 2.1098 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01418: val_accuracy did not improve from 0.71000\n",
      "Epoch 1419/2000\n",
      "113/113 - 1s - loss: 0.3333 - accuracy: 0.8989 - val_loss: 2.7046 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01419: val_accuracy did not improve from 0.71000\n",
      "Epoch 1420/2000\n",
      "113/113 - 1s - loss: 0.0780 - accuracy: 0.9767 - val_loss: 2.5677 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01420: val_accuracy did not improve from 0.71000\n",
      "Epoch 1421/2000\n",
      "113/113 - 1s - loss: 0.0601 - accuracy: 0.9856 - val_loss: 2.6466 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01421: val_accuracy did not improve from 0.71000\n",
      "Epoch 1422/2000\n",
      "113/113 - 1s - loss: 0.0267 - accuracy: 0.9989 - val_loss: 2.6064 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01422: val_accuracy did not improve from 0.71000\n",
      "Epoch 1423/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 0.9989 - val_loss: 2.6666 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01423: val_accuracy did not improve from 0.71000\n",
      "Epoch 1424/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7150 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01424: val_accuracy did not improve from 0.71000\n",
      "Epoch 1425/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.7124 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01425: val_accuracy did not improve from 0.71000\n",
      "Epoch 1426/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7071 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01426: val_accuracy did not improve from 0.71000\n",
      "Epoch 1427/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7089 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01427: val_accuracy did not improve from 0.71000\n",
      "Epoch 1428/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7606 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01428: val_accuracy did not improve from 0.71000\n",
      "Epoch 1429/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.7719 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01429: val_accuracy did not improve from 0.71000\n",
      "Epoch 1430/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.7384 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01430: val_accuracy did not improve from 0.71000\n",
      "Epoch 1431/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.7526 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01431: val_accuracy did not improve from 0.71000\n",
      "Epoch 1432/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7415 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01432: val_accuracy did not improve from 0.71000\n",
      "Epoch 1433/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.7628 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01433: val_accuracy did not improve from 0.71000\n",
      "Epoch 1434/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7657 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01434: val_accuracy did not improve from 0.71000\n",
      "Epoch 1435/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7679 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01435: val_accuracy did not improve from 0.71000\n",
      "Epoch 1436/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7602 - val_accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01436: val_accuracy did not improve from 0.71000\n",
      "Epoch 1437/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7743 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01437: val_accuracy did not improve from 0.71000\n",
      "Epoch 1438/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7901 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01438: val_accuracy did not improve from 0.71000\n",
      "Epoch 1439/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8003 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01439: val_accuracy did not improve from 0.71000\n",
      "Epoch 1440/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7864 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01440: val_accuracy did not improve from 0.71000\n",
      "Epoch 1441/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01441: val_accuracy did not improve from 0.71000\n",
      "Epoch 1442/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01442: val_accuracy did not improve from 0.71000\n",
      "Epoch 1443/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01443: val_accuracy did not improve from 0.71000\n",
      "Epoch 1444/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01444: val_accuracy did not improve from 0.71000\n",
      "Epoch 1445/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01445: val_accuracy did not improve from 0.71000\n",
      "Epoch 1446/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8424 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01446: val_accuracy did not improve from 0.71000\n",
      "Epoch 1447/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8476 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01447: val_accuracy did not improve from 0.71000\n",
      "Epoch 1448/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01448: val_accuracy did not improve from 0.71000\n",
      "Epoch 1449/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8372 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01449: val_accuracy did not improve from 0.71000\n",
      "Epoch 1450/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01450: val_accuracy did not improve from 0.71000\n",
      "Epoch 1451/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8528 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01451: val_accuracy did not improve from 0.71000\n",
      "Epoch 1452/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8457 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01452: val_accuracy did not improve from 0.71000\n",
      "Epoch 1453/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8354 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01453: val_accuracy did not improve from 0.71000\n",
      "Epoch 1454/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8857 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01454: val_accuracy did not improve from 0.71000\n",
      "Epoch 1455/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8741 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01455: val_accuracy did not improve from 0.71000\n",
      "Epoch 1456/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01456: val_accuracy did not improve from 0.71000\n",
      "Epoch 1457/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.9202 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01457: val_accuracy did not improve from 0.71000\n",
      "Epoch 1458/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.9044 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01458: val_accuracy did not improve from 0.71000\n",
      "Epoch 1459/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8689 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01459: val_accuracy did not improve from 0.71000\n",
      "Epoch 1460/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.9196 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01460: val_accuracy did not improve from 0.71000\n",
      "Epoch 1461/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8872 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01461: val_accuracy did not improve from 0.71000\n",
      "Epoch 1462/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.9112 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01462: val_accuracy did not improve from 0.71000\n",
      "Epoch 1463/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8784 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01463: val_accuracy did not improve from 0.71000\n",
      "Epoch 1464/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01464: val_accuracy did not improve from 0.71000\n",
      "Epoch 1465/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.9344 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01465: val_accuracy did not improve from 0.71000\n",
      "Epoch 1466/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01466: val_accuracy did not improve from 0.71000\n",
      "Epoch 1467/2000\n",
      "113/113 - 1s - loss: 0.0763 - accuracy: 0.9867 - val_loss: 3.2996 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 01467: val_accuracy did not improve from 0.71000\n",
      "Epoch 1468/2000\n",
      "113/113 - 1s - loss: 0.7494 - accuracy: 0.8011 - val_loss: 2.3221 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01468: val_accuracy did not improve from 0.71000\n",
      "Epoch 1469/2000\n",
      "113/113 - 1s - loss: 0.2752 - accuracy: 0.9056 - val_loss: 2.1963 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01469: val_accuracy did not improve from 0.71000\n",
      "Epoch 1470/2000\n",
      "113/113 - 1s - loss: 0.0592 - accuracy: 0.9889 - val_loss: 2.5423 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01470: val_accuracy did not improve from 0.71000\n",
      "Epoch 1471/2000\n",
      "113/113 - 1s - loss: 0.0385 - accuracy: 0.9944 - val_loss: 2.5643 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01471: val_accuracy did not improve from 0.71000\n",
      "Epoch 1472/2000\n",
      "113/113 - 1s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.5811 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01472: val_accuracy did not improve from 0.71000\n",
      "Epoch 1473/2000\n",
      "113/113 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.6526 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01473: val_accuracy did not improve from 0.71000\n",
      "Epoch 1474/2000\n",
      "113/113 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01474: val_accuracy did not improve from 0.71000\n",
      "Epoch 1475/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01475: val_accuracy did not improve from 0.71000\n",
      "Epoch 1476/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01476: val_accuracy did not improve from 0.71000\n",
      "Epoch 1477/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.7645 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01477: val_accuracy did not improve from 0.71000\n",
      "Epoch 1478/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01478: val_accuracy did not improve from 0.71000\n",
      "Epoch 1479/2000\n",
      "113/113 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.8093 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01479: val_accuracy did not improve from 0.71000\n",
      "Epoch 1480/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01480: val_accuracy did not improve from 0.71000\n",
      "Epoch 1481/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01481: val_accuracy did not improve from 0.71000\n",
      "Epoch 1482/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8429 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01482: val_accuracy did not improve from 0.71000\n",
      "Epoch 1483/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8205 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01483: val_accuracy did not improve from 0.71000\n",
      "Epoch 1484/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8564 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01484: val_accuracy did not improve from 0.71000\n",
      "Epoch 1485/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8466 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01485: val_accuracy did not improve from 0.71000\n",
      "Epoch 1486/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.8548 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01486: val_accuracy did not improve from 0.71000\n",
      "Epoch 1487/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.8639 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01487: val_accuracy did not improve from 0.71000\n",
      "Epoch 1488/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.8401 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01488: val_accuracy did not improve from 0.71000\n",
      "Epoch 1489/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8780 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01489: val_accuracy did not improve from 0.71000\n",
      "Epoch 1490/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01490: val_accuracy did not improve from 0.71000\n",
      "Epoch 1491/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8739 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01491: val_accuracy did not improve from 0.71000\n",
      "Epoch 1492/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.8745 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01492: val_accuracy did not improve from 0.71000\n",
      "Epoch 1493/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8506 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01493: val_accuracy did not improve from 0.71000\n",
      "Epoch 1494/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8539 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01494: val_accuracy did not improve from 0.71000\n",
      "Epoch 1495/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8851 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01495: val_accuracy did not improve from 0.71000\n",
      "Epoch 1496/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8624 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01496: val_accuracy did not improve from 0.71000\n",
      "Epoch 1497/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8781 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01497: val_accuracy did not improve from 0.71000\n",
      "Epoch 1498/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8948 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01498: val_accuracy did not improve from 0.71000\n",
      "Epoch 1499/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.9120 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01499: val_accuracy did not improve from 0.71000\n",
      "Epoch 1500/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01500: val_accuracy did not improve from 0.71000\n",
      "Epoch 1501/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8996 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01501: val_accuracy did not improve from 0.71000\n",
      "Epoch 1502/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8904 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01502: val_accuracy did not improve from 0.71000\n",
      "Epoch 1503/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.9169 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01503: val_accuracy did not improve from 0.71000\n",
      "Epoch 1504/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.9303 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01504: val_accuracy did not improve from 0.71000\n",
      "Epoch 1505/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8913 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01505: val_accuracy did not improve from 0.71000\n",
      "Epoch 1506/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.9233 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01506: val_accuracy did not improve from 0.71000\n",
      "Epoch 1507/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.9140 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01507: val_accuracy did not improve from 0.71000\n",
      "Epoch 1508/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.9443 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01508: val_accuracy did not improve from 0.71000\n",
      "Epoch 1509/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.9491 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01509: val_accuracy did not improve from 0.71000\n",
      "Epoch 1510/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 3.0015 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01510: val_accuracy did not improve from 0.71000\n",
      "Epoch 1511/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.9538 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01511: val_accuracy did not improve from 0.71000\n",
      "Epoch 1512/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8722 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01512: val_accuracy did not improve from 0.71000\n",
      "Epoch 1513/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.9243 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01513: val_accuracy did not improve from 0.71000\n",
      "Epoch 1514/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 3.0332 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01514: val_accuracy did not improve from 0.71000\n",
      "Epoch 1515/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8844 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01515: val_accuracy did not improve from 0.71000\n",
      "Epoch 1516/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.9023 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01516: val_accuracy did not improve from 0.71000\n",
      "Epoch 1517/2000\n",
      "113/113 - 1s - loss: 0.9491 - accuracy: 0.8189 - val_loss: 2.6126 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01517: val_accuracy did not improve from 0.71000\n",
      "Epoch 1518/2000\n",
      "113/113 - 1s - loss: 0.3462 - accuracy: 0.8933 - val_loss: 2.7138 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01518: val_accuracy did not improve from 0.71000\n",
      "Epoch 1519/2000\n",
      "113/113 - 1s - loss: 0.1254 - accuracy: 0.9589 - val_loss: 2.5300 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01519: val_accuracy did not improve from 0.71000\n",
      "Epoch 1520/2000\n",
      "113/113 - 1s - loss: 0.0659 - accuracy: 0.9789 - val_loss: 2.6074 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01520: val_accuracy did not improve from 0.71000\n",
      "Epoch 1521/2000\n",
      "113/113 - 1s - loss: 0.0393 - accuracy: 0.9933 - val_loss: 2.7911 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01521: val_accuracy did not improve from 0.71000\n",
      "Epoch 1522/2000\n",
      "113/113 - 1s - loss: 0.0284 - accuracy: 0.9989 - val_loss: 2.6810 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01522: val_accuracy did not improve from 0.71000\n",
      "Epoch 1523/2000\n",
      "113/113 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.6974 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01523: val_accuracy did not improve from 0.71000\n",
      "Epoch 1524/2000\n",
      "113/113 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.7387 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01524: val_accuracy did not improve from 0.71000\n",
      "Epoch 1525/2000\n",
      "113/113 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.7893 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01525: val_accuracy did not improve from 0.71000\n",
      "Epoch 1526/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.7833 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01526: val_accuracy did not improve from 0.71000\n",
      "Epoch 1527/2000\n",
      "113/113 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.7818 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01527: val_accuracy did not improve from 0.71000\n",
      "Epoch 1528/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.8022 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01528: val_accuracy did not improve from 0.71000\n",
      "Epoch 1529/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01529: val_accuracy did not improve from 0.71000\n",
      "Epoch 1530/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.7975 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01530: val_accuracy did not improve from 0.71000\n",
      "Epoch 1531/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01531: val_accuracy did not improve from 0.71000\n",
      "Epoch 1532/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8500 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01532: val_accuracy did not improve from 0.71000\n",
      "Epoch 1533/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8382 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01533: val_accuracy did not improve from 0.71000\n",
      "Epoch 1534/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8338 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01534: val_accuracy did not improve from 0.71000\n",
      "Epoch 1535/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.8410 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01535: val_accuracy did not improve from 0.71000\n",
      "Epoch 1536/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.9194 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01536: val_accuracy did not improve from 0.71000\n",
      "Epoch 1537/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.8539 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01537: val_accuracy did not improve from 0.71000\n",
      "Epoch 1538/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.9121 - val_accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01538: val_accuracy did not improve from 0.71000\n",
      "Epoch 1539/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01539: val_accuracy did not improve from 0.71000\n",
      "Epoch 1540/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.9064 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01540: val_accuracy did not improve from 0.71000\n",
      "Epoch 1541/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8929 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01541: val_accuracy did not improve from 0.71000\n",
      "Epoch 1542/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9176 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01542: val_accuracy did not improve from 0.71000\n",
      "Epoch 1543/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9226 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01543: val_accuracy did not improve from 0.71000\n",
      "Epoch 1544/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.9303 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01544: val_accuracy did not improve from 0.71000\n",
      "Epoch 1545/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.9179 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01545: val_accuracy did not improve from 0.71000\n",
      "Epoch 1546/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.9169 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01546: val_accuracy did not improve from 0.71000\n",
      "Epoch 1547/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.9153 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01547: val_accuracy did not improve from 0.71000\n",
      "Epoch 1548/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.9080 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01548: val_accuracy did not improve from 0.71000\n",
      "Epoch 1549/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.9395 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01549: val_accuracy did not improve from 0.71000\n",
      "Epoch 1550/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.9262 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01550: val_accuracy did not improve from 0.71000\n",
      "Epoch 1551/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.9085 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01551: val_accuracy did not improve from 0.71000\n",
      "Epoch 1552/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.9571 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01552: val_accuracy did not improve from 0.71000\n",
      "Epoch 1553/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01553: val_accuracy did not improve from 0.71000\n",
      "Epoch 1554/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.9226 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01554: val_accuracy did not improve from 0.71000\n",
      "Epoch 1555/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.9456 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01555: val_accuracy did not improve from 0.71000\n",
      "Epoch 1556/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9516 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01556: val_accuracy did not improve from 0.71000\n",
      "Epoch 1557/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9252 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01557: val_accuracy did not improve from 0.71000\n",
      "Epoch 1558/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9504 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01558: val_accuracy did not improve from 0.71000\n",
      "Epoch 1559/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.9392 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01559: val_accuracy did not improve from 0.71000\n",
      "Epoch 1560/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.9878 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01560: val_accuracy did not improve from 0.71000\n",
      "Epoch 1561/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.9280 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01561: val_accuracy did not improve from 0.71000\n",
      "Epoch 1562/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.9743 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01562: val_accuracy did not improve from 0.71000\n",
      "Epoch 1563/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.9395 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01563: val_accuracy did not improve from 0.71000\n",
      "Epoch 1564/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.9011 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01564: val_accuracy did not improve from 0.71000\n",
      "Epoch 1565/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8557 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01565: val_accuracy did not improve from 0.71000\n",
      "Epoch 1566/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.9090 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01566: val_accuracy did not improve from 0.71000\n",
      "Epoch 1567/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8948 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01567: val_accuracy did not improve from 0.71000\n",
      "Epoch 1568/2000\n",
      "113/113 - 1s - loss: 1.1488 - accuracy: 0.8089 - val_loss: 1.9379 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01568: val_accuracy did not improve from 0.71000\n",
      "Epoch 1569/2000\n",
      "113/113 - 1s - loss: 0.5469 - accuracy: 0.8222 - val_loss: 2.0099 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01569: val_accuracy did not improve from 0.71000\n",
      "Epoch 1570/2000\n",
      "113/113 - 1s - loss: 0.1563 - accuracy: 0.9500 - val_loss: 2.4342 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01570: val_accuracy did not improve from 0.71000\n",
      "Epoch 1571/2000\n",
      "113/113 - 1s - loss: 0.0665 - accuracy: 0.9822 - val_loss: 2.4948 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01571: val_accuracy did not improve from 0.71000\n",
      "Epoch 1572/2000\n",
      "113/113 - 1s - loss: 0.0377 - accuracy: 0.9978 - val_loss: 2.3862 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01572: val_accuracy did not improve from 0.71000\n",
      "Epoch 1573/2000\n",
      "113/113 - 1s - loss: 0.0277 - accuracy: 0.9978 - val_loss: 2.4713 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01573: val_accuracy did not improve from 0.71000\n",
      "Epoch 1574/2000\n",
      "113/113 - 1s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.4753 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01574: val_accuracy did not improve from 0.71000\n",
      "Epoch 1575/2000\n",
      "113/113 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.4832 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01575: val_accuracy did not improve from 0.71000\n",
      "Epoch 1576/2000\n",
      "113/113 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.5436 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01576: val_accuracy did not improve from 0.71000\n",
      "Epoch 1577/2000\n",
      "113/113 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.5705 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01577: val_accuracy did not improve from 0.71000\n",
      "Epoch 1578/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6256 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01578: val_accuracy did not improve from 0.71000\n",
      "Epoch 1579/2000\n",
      "113/113 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.6339 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01579: val_accuracy did not improve from 0.71000\n",
      "Epoch 1580/2000\n",
      "113/113 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.6099 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01580: val_accuracy did not improve from 0.71000\n",
      "Epoch 1581/2000\n",
      "113/113 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.6439 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01581: val_accuracy did not improve from 0.71000\n",
      "Epoch 1582/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.6368 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01582: val_accuracy did not improve from 0.71000\n",
      "Epoch 1583/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6735 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01583: val_accuracy did not improve from 0.71000\n",
      "Epoch 1584/2000\n",
      "113/113 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6579 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01584: val_accuracy did not improve from 0.71000\n",
      "Epoch 1585/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6618 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01585: val_accuracy did not improve from 0.71000\n",
      "Epoch 1586/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6932 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01586: val_accuracy did not improve from 0.71000\n",
      "Epoch 1587/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.6955 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01587: val_accuracy did not improve from 0.71000\n",
      "Epoch 1588/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.7151 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01588: val_accuracy did not improve from 0.71000\n",
      "Epoch 1589/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7498 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01589: val_accuracy did not improve from 0.71000\n",
      "Epoch 1590/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7103 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01590: val_accuracy did not improve from 0.71000\n",
      "Epoch 1591/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7150 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01591: val_accuracy did not improve from 0.71000\n",
      "Epoch 1592/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7472 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01592: val_accuracy did not improve from 0.71000\n",
      "Epoch 1593/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7060 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01593: val_accuracy did not improve from 0.71000\n",
      "Epoch 1594/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7576 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01594: val_accuracy did not improve from 0.71000\n",
      "Epoch 1595/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7430 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01595: val_accuracy did not improve from 0.71000\n",
      "Epoch 1596/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7499 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01596: val_accuracy did not improve from 0.71000\n",
      "Epoch 1597/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7283 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01597: val_accuracy did not improve from 0.71000\n",
      "Epoch 1598/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7497 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01598: val_accuracy did not improve from 0.71000\n",
      "Epoch 1599/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01599: val_accuracy did not improve from 0.71000\n",
      "Epoch 1600/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7574 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01600: val_accuracy did not improve from 0.71000\n",
      "Epoch 1601/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7897 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01601: val_accuracy did not improve from 0.71000\n",
      "Epoch 1602/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7626 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01602: val_accuracy did not improve from 0.71000\n",
      "Epoch 1603/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01603: val_accuracy did not improve from 0.71000\n",
      "Epoch 1604/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7648 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01604: val_accuracy did not improve from 0.71000\n",
      "Epoch 1605/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01605: val_accuracy did not improve from 0.71000\n",
      "Epoch 1606/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01606: val_accuracy did not improve from 0.71000\n",
      "Epoch 1607/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7630 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01607: val_accuracy did not improve from 0.71000\n",
      "Epoch 1608/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8179 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01608: val_accuracy did not improve from 0.71000\n",
      "Epoch 1609/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7814 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01609: val_accuracy did not improve from 0.71000\n",
      "Epoch 1610/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01610: val_accuracy did not improve from 0.71000\n",
      "Epoch 1611/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8750 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01611: val_accuracy did not improve from 0.71000\n",
      "Epoch 1612/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8502 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01612: val_accuracy did not improve from 0.71000\n",
      "Epoch 1613/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01613: val_accuracy did not improve from 0.71000\n",
      "Epoch 1614/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01614: val_accuracy did not improve from 0.71000\n",
      "Epoch 1615/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01615: val_accuracy did not improve from 0.71000\n",
      "Epoch 1616/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01616: val_accuracy did not improve from 0.71000\n",
      "Epoch 1617/2000\n",
      "113/113 - 1s - loss: 0.7340 - accuracy: 0.8411 - val_loss: 2.2869 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01617: val_accuracy did not improve from 0.71000\n",
      "Epoch 1618/2000\n",
      "113/113 - 1s - loss: 0.2488 - accuracy: 0.9144 - val_loss: 2.6295 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01618: val_accuracy did not improve from 0.71000\n",
      "Epoch 1619/2000\n",
      "113/113 - 1s - loss: 0.0847 - accuracy: 0.9789 - val_loss: 2.3572 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01619: val_accuracy did not improve from 0.71000\n",
      "Epoch 1620/2000\n",
      "113/113 - 1s - loss: 0.0938 - accuracy: 0.9789 - val_loss: 2.6878 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01620: val_accuracy did not improve from 0.71000\n",
      "Epoch 1621/2000\n",
      "113/113 - 1s - loss: 0.0821 - accuracy: 0.9744 - val_loss: 2.4795 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01621: val_accuracy did not improve from 0.71000\n",
      "Epoch 1622/2000\n",
      "113/113 - 1s - loss: 0.0260 - accuracy: 0.9989 - val_loss: 2.3793 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01622: val_accuracy did not improve from 0.71000\n",
      "Epoch 1623/2000\n",
      "113/113 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.4526 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01623: val_accuracy did not improve from 0.71000\n",
      "Epoch 1624/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.4530 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01624: val_accuracy did not improve from 0.71000\n",
      "Epoch 1625/2000\n",
      "113/113 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.4826 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01625: val_accuracy did not improve from 0.71000\n",
      "Epoch 1626/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.4955 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01626: val_accuracy did not improve from 0.71000\n",
      "Epoch 1627/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.5228 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01627: val_accuracy did not improve from 0.71000\n",
      "Epoch 1628/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.5346 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01628: val_accuracy did not improve from 0.71000\n",
      "Epoch 1629/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.5595 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01629: val_accuracy did not improve from 0.71000\n",
      "Epoch 1630/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.5676 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01630: val_accuracy did not improve from 0.71000\n",
      "Epoch 1631/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01631: val_accuracy did not improve from 0.71000\n",
      "Epoch 1632/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5974 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01632: val_accuracy did not improve from 0.71000\n",
      "Epoch 1633/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6149 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01633: val_accuracy did not improve from 0.71000\n",
      "Epoch 1634/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6514 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01634: val_accuracy did not improve from 0.71000\n",
      "Epoch 1635/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6517 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01635: val_accuracy did not improve from 0.71000\n",
      "Epoch 1636/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6465 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01636: val_accuracy did not improve from 0.71000\n",
      "Epoch 1637/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6757 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01637: val_accuracy did not improve from 0.71000\n",
      "Epoch 1638/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6273 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01638: val_accuracy did not improve from 0.71000\n",
      "Epoch 1639/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6502 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01639: val_accuracy did not improve from 0.71000\n",
      "Epoch 1640/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7013 - val_accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01640: val_accuracy did not improve from 0.71000\n",
      "Epoch 1641/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6689 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01641: val_accuracy did not improve from 0.71000\n",
      "Epoch 1642/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6683 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01642: val_accuracy did not improve from 0.71000\n",
      "Epoch 1643/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6652 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01643: val_accuracy did not improve from 0.71000\n",
      "Epoch 1644/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7042 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01644: val_accuracy did not improve from 0.71000\n",
      "Epoch 1645/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6916 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01645: val_accuracy did not improve from 0.71000\n",
      "Epoch 1646/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6944 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01646: val_accuracy did not improve from 0.71000\n",
      "Epoch 1647/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6964 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01647: val_accuracy did not improve from 0.71000\n",
      "Epoch 1648/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6873 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01648: val_accuracy did not improve from 0.71000\n",
      "Epoch 1649/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7066 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01649: val_accuracy did not improve from 0.71000\n",
      "Epoch 1650/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7288 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01650: val_accuracy did not improve from 0.71000\n",
      "Epoch 1651/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7681 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01651: val_accuracy did not improve from 0.71000\n",
      "Epoch 1652/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01652: val_accuracy did not improve from 0.71000\n",
      "Epoch 1653/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7585 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01653: val_accuracy did not improve from 0.71000\n",
      "Epoch 1654/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7520 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01654: val_accuracy did not improve from 0.71000\n",
      "Epoch 1655/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7544 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01655: val_accuracy did not improve from 0.71000\n",
      "Epoch 1656/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7566 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01656: val_accuracy did not improve from 0.71000\n",
      "Epoch 1657/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7733 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01657: val_accuracy did not improve from 0.71000\n",
      "Epoch 1658/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01658: val_accuracy did not improve from 0.71000\n",
      "Epoch 1659/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8201 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01659: val_accuracy did not improve from 0.71000\n",
      "Epoch 1660/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7870 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01660: val_accuracy did not improve from 0.71000\n",
      "Epoch 1661/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8295 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01661: val_accuracy did not improve from 0.71000\n",
      "Epoch 1662/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8002 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01662: val_accuracy did not improve from 0.71000\n",
      "Epoch 1663/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7603 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01663: val_accuracy did not improve from 0.71000\n",
      "Epoch 1664/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8197 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01664: val_accuracy did not improve from 0.71000\n",
      "Epoch 1665/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8165 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01665: val_accuracy did not improve from 0.71000\n",
      "Epoch 1666/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01666: val_accuracy did not improve from 0.71000\n",
      "Epoch 1667/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01667: val_accuracy did not improve from 0.71000\n",
      "Epoch 1668/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8479 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01668: val_accuracy did not improve from 0.71000\n",
      "Epoch 1669/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.8399 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01669: val_accuracy did not improve from 0.71000\n",
      "Epoch 1670/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.8183 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01670: val_accuracy did not improve from 0.71000\n",
      "Epoch 1671/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8576 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01671: val_accuracy did not improve from 0.71000\n",
      "Epoch 1672/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01672: val_accuracy did not improve from 0.71000\n",
      "Epoch 1673/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.8951 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01673: val_accuracy did not improve from 0.71000\n",
      "Epoch 1674/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.7070 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01674: val_accuracy did not improve from 0.71000\n",
      "Epoch 1675/2000\n",
      "113/113 - 1s - loss: 0.5948 - accuracy: 0.8922 - val_loss: 2.7210 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01675: val_accuracy did not improve from 0.71000\n",
      "Epoch 1676/2000\n",
      "113/113 - 1s - loss: 0.5299 - accuracy: 0.8633 - val_loss: 2.1683 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01676: val_accuracy did not improve from 0.71000\n",
      "Epoch 1677/2000\n",
      "113/113 - 1s - loss: 0.1064 - accuracy: 0.9633 - val_loss: 2.0627 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01677: val_accuracy did not improve from 0.71000\n",
      "Epoch 1678/2000\n",
      "113/113 - 1s - loss: 0.0924 - accuracy: 0.9733 - val_loss: 2.4697 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01678: val_accuracy did not improve from 0.71000\n",
      "Epoch 1679/2000\n",
      "113/113 - 1s - loss: 0.0386 - accuracy: 0.9933 - val_loss: 2.4779 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01679: val_accuracy did not improve from 0.71000\n",
      "Epoch 1680/2000\n",
      "113/113 - 1s - loss: 0.0219 - accuracy: 0.9989 - val_loss: 2.3866 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01680: val_accuracy did not improve from 0.71000\n",
      "Epoch 1681/2000\n",
      "113/113 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.3887 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01681: val_accuracy did not improve from 0.71000\n",
      "Epoch 1682/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.3936 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01682: val_accuracy did not improve from 0.71000\n",
      "Epoch 1683/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.4068 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01683: val_accuracy did not improve from 0.71000\n",
      "Epoch 1684/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.4143 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01684: val_accuracy did not improve from 0.71000\n",
      "Epoch 1685/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.4150 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01685: val_accuracy did not improve from 0.71000\n",
      "Epoch 1686/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.4380 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01686: val_accuracy did not improve from 0.71000\n",
      "Epoch 1687/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.4408 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01687: val_accuracy did not improve from 0.71000\n",
      "Epoch 1688/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.4587 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01688: val_accuracy did not improve from 0.71000\n",
      "Epoch 1689/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.4760 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01689: val_accuracy did not improve from 0.71000\n",
      "Epoch 1690/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.4830 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01690: val_accuracy did not improve from 0.71000\n",
      "Epoch 1691/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.4947 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01691: val_accuracy did not improve from 0.71000\n",
      "Epoch 1692/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.4868 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01692: val_accuracy did not improve from 0.71000\n",
      "Epoch 1693/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.4974 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01693: val_accuracy did not improve from 0.71000\n",
      "Epoch 1694/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5234 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01694: val_accuracy did not improve from 0.71000\n",
      "Epoch 1695/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5078 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01695: val_accuracy did not improve from 0.71000\n",
      "Epoch 1696/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5348 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01696: val_accuracy did not improve from 0.71000\n",
      "Epoch 1697/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.5221 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01697: val_accuracy did not improve from 0.71000\n",
      "Epoch 1698/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5324 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01698: val_accuracy did not improve from 0.71000\n",
      "Epoch 1699/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5361 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01699: val_accuracy did not improve from 0.71000\n",
      "Epoch 1700/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.5252 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01700: val_accuracy did not improve from 0.71000\n",
      "Epoch 1701/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01701: val_accuracy did not improve from 0.71000\n",
      "Epoch 1702/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.5751 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01702: val_accuracy did not improve from 0.71000\n",
      "Epoch 1703/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.5666 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01703: val_accuracy did not improve from 0.71000\n",
      "Epoch 1704/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.5565 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01704: val_accuracy did not improve from 0.71000\n",
      "Epoch 1705/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01705: val_accuracy did not improve from 0.71000\n",
      "Epoch 1706/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.5856 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01706: val_accuracy did not improve from 0.71000\n",
      "Epoch 1707/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.5938 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01707: val_accuracy did not improve from 0.71000\n",
      "Epoch 1708/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5911 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01708: val_accuracy did not improve from 0.71000\n",
      "Epoch 1709/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6159 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01709: val_accuracy did not improve from 0.71000\n",
      "Epoch 1710/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5927 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01710: val_accuracy did not improve from 0.71000\n",
      "Epoch 1711/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6133 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01711: val_accuracy did not improve from 0.71000\n",
      "Epoch 1712/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01712: val_accuracy did not improve from 0.71000\n",
      "Epoch 1713/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6663 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01713: val_accuracy did not improve from 0.71000\n",
      "Epoch 1714/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6491 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01714: val_accuracy did not improve from 0.71000\n",
      "Epoch 1715/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6607 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01715: val_accuracy did not improve from 0.71000\n",
      "Epoch 1716/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6755 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01716: val_accuracy did not improve from 0.71000\n",
      "Epoch 1717/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6639 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01717: val_accuracy did not improve from 0.71000\n",
      "Epoch 1718/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6381 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01718: val_accuracy did not improve from 0.71000\n",
      "Epoch 1719/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6515 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01719: val_accuracy did not improve from 0.71000\n",
      "Epoch 1720/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6701 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01720: val_accuracy did not improve from 0.71000\n",
      "Epoch 1721/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6739 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01721: val_accuracy did not improve from 0.71000\n",
      "Epoch 1722/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.7056 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01722: val_accuracy did not improve from 0.71000\n",
      "Epoch 1723/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6841 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01723: val_accuracy did not improve from 0.71000\n",
      "Epoch 1724/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6912 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01724: val_accuracy did not improve from 0.71000\n",
      "Epoch 1725/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.6773 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01725: val_accuracy did not improve from 0.71000\n",
      "Epoch 1726/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.7042 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01726: val_accuracy did not improve from 0.71000\n",
      "Epoch 1727/2000\n",
      "113/113 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6988 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01727: val_accuracy did not improve from 0.71000\n",
      "Epoch 1728/2000\n",
      "113/113 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.7304 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01728: val_accuracy did not improve from 0.71000\n",
      "Epoch 1729/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 0.9989 - val_loss: 3.5645 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01729: val_accuracy did not improve from 0.71000\n",
      "Epoch 1730/2000\n",
      "113/113 - 1s - loss: 0.7088 - accuracy: 0.8378 - val_loss: 2.6518 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01730: val_accuracy did not improve from 0.71000\n",
      "Epoch 1731/2000\n",
      "113/113 - 1s - loss: 0.2322 - accuracy: 0.9344 - val_loss: 2.7832 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 01731: val_accuracy did not improve from 0.71000\n",
      "Epoch 1732/2000\n",
      "113/113 - 1s - loss: 0.1103 - accuracy: 0.9667 - val_loss: 2.4589 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01732: val_accuracy did not improve from 0.71000\n",
      "Epoch 1733/2000\n",
      "113/113 - 1s - loss: 0.0269 - accuracy: 0.9956 - val_loss: 2.3589 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01733: val_accuracy did not improve from 0.71000\n",
      "Epoch 1734/2000\n",
      "113/113 - 1s - loss: 0.0217 - accuracy: 0.9978 - val_loss: 2.3968 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01734: val_accuracy did not improve from 0.71000\n",
      "Epoch 1735/2000\n",
      "113/113 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.3662 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01735: val_accuracy did not improve from 0.71000\n",
      "Epoch 1736/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.3729 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01736: val_accuracy did not improve from 0.71000\n",
      "Epoch 1737/2000\n",
      "113/113 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.4073 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01737: val_accuracy did not improve from 0.71000\n",
      "Epoch 1738/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.4115 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01738: val_accuracy did not improve from 0.71000\n",
      "Epoch 1739/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.4203 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01739: val_accuracy did not improve from 0.71000\n",
      "Epoch 1740/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.4808 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01740: val_accuracy did not improve from 0.71000\n",
      "Epoch 1741/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.4704 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01741: val_accuracy did not improve from 0.71000\n",
      "Epoch 1742/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.4682 - val_accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01742: val_accuracy did not improve from 0.71000\n",
      "Epoch 1743/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.4884 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01743: val_accuracy did not improve from 0.71000\n",
      "Epoch 1744/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5025 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01744: val_accuracy did not improve from 0.71000\n",
      "Epoch 1745/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.4945 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01745: val_accuracy did not improve from 0.71000\n",
      "Epoch 1746/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.5024 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01746: val_accuracy did not improve from 0.71000\n",
      "Epoch 1747/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.4813 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01747: val_accuracy did not improve from 0.71000\n",
      "Epoch 1748/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.4847 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01748: val_accuracy did not improve from 0.71000\n",
      "Epoch 1749/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.4952 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01749: val_accuracy did not improve from 0.71000\n",
      "Epoch 1750/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.4920 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01750: val_accuracy did not improve from 0.71000\n",
      "Epoch 1751/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.5224 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01751: val_accuracy did not improve from 0.71000\n",
      "Epoch 1752/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.5096 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01752: val_accuracy did not improve from 0.71000\n",
      "Epoch 1753/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.5300 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01753: val_accuracy did not improve from 0.71000\n",
      "Epoch 1754/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01754: val_accuracy did not improve from 0.71000\n",
      "Epoch 1755/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5621 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01755: val_accuracy did not improve from 0.71000\n",
      "Epoch 1756/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.5814 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01756: val_accuracy did not improve from 0.71000\n",
      "Epoch 1757/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5876 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01757: val_accuracy did not improve from 0.71000\n",
      "Epoch 1758/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5871 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01758: val_accuracy did not improve from 0.71000\n",
      "Epoch 1759/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01759: val_accuracy did not improve from 0.71000\n",
      "Epoch 1760/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6086 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01760: val_accuracy did not improve from 0.71000\n",
      "Epoch 1761/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6300 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01761: val_accuracy did not improve from 0.71000\n",
      "Epoch 1762/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6289 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01762: val_accuracy did not improve from 0.71000\n",
      "Epoch 1763/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6421 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01763: val_accuracy did not improve from 0.71000\n",
      "Epoch 1764/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6079 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01764: val_accuracy did not improve from 0.71000\n",
      "Epoch 1765/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6495 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01765: val_accuracy did not improve from 0.71000\n",
      "Epoch 1766/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6678 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01766: val_accuracy did not improve from 0.71000\n",
      "Epoch 1767/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6159 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01767: val_accuracy did not improve from 0.71000\n",
      "Epoch 1768/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6458 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01768: val_accuracy did not improve from 0.71000\n",
      "Epoch 1769/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6452 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01769: val_accuracy did not improve from 0.71000\n",
      "Epoch 1770/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6687 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01770: val_accuracy did not improve from 0.71000\n",
      "Epoch 1771/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6710 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01771: val_accuracy did not improve from 0.71000\n",
      "Epoch 1772/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01772: val_accuracy did not improve from 0.71000\n",
      "Epoch 1773/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6598 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01773: val_accuracy did not improve from 0.71000\n",
      "Epoch 1774/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6334 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01774: val_accuracy did not improve from 0.71000\n",
      "Epoch 1775/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.7123 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01775: val_accuracy did not improve from 0.71000\n",
      "Epoch 1776/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.6880 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01776: val_accuracy did not improve from 0.71000\n",
      "Epoch 1777/2000\n",
      "113/113 - 1s - loss: 0.1709 - accuracy: 0.9667 - val_loss: 3.1525 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01777: val_accuracy did not improve from 0.71000\n",
      "Epoch 1778/2000\n",
      "113/113 - 1s - loss: 0.7083 - accuracy: 0.8133 - val_loss: 2.2045 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 01778: val_accuracy did not improve from 0.71000\n",
      "Epoch 1779/2000\n",
      "113/113 - 1s - loss: 0.1295 - accuracy: 0.9589 - val_loss: 2.7615 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01779: val_accuracy did not improve from 0.71000\n",
      "Epoch 1780/2000\n",
      "113/113 - 1s - loss: 0.0493 - accuracy: 0.9900 - val_loss: 2.4330 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01780: val_accuracy did not improve from 0.71000\n",
      "Epoch 1781/2000\n",
      "113/113 - 1s - loss: 0.0407 - accuracy: 0.9956 - val_loss: 2.6514 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01781: val_accuracy did not improve from 0.71000\n",
      "Epoch 1782/2000\n",
      "113/113 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.6084 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01782: val_accuracy did not improve from 0.71000\n",
      "Epoch 1783/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6177 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01783: val_accuracy did not improve from 0.71000\n",
      "Epoch 1784/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6123 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01784: val_accuracy did not improve from 0.71000\n",
      "Epoch 1785/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6103 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01785: val_accuracy did not improve from 0.71000\n",
      "Epoch 1786/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6075 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01786: val_accuracy did not improve from 0.71000\n",
      "Epoch 1787/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6027 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01787: val_accuracy did not improve from 0.71000\n",
      "Epoch 1788/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6244 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01788: val_accuracy did not improve from 0.71000\n",
      "Epoch 1789/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01789: val_accuracy did not improve from 0.71000\n",
      "Epoch 1790/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01790: val_accuracy did not improve from 0.71000\n",
      "Epoch 1791/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6259 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01791: val_accuracy did not improve from 0.71000\n",
      "Epoch 1792/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6298 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01792: val_accuracy did not improve from 0.71000\n",
      "Epoch 1793/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6294 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01793: val_accuracy did not improve from 0.71000\n",
      "Epoch 1794/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6236 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01794: val_accuracy did not improve from 0.71000\n",
      "Epoch 1795/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6238 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01795: val_accuracy did not improve from 0.71000\n",
      "Epoch 1796/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6333 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01796: val_accuracy did not improve from 0.71000\n",
      "Epoch 1797/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01797: val_accuracy did not improve from 0.71000\n",
      "Epoch 1798/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6513 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01798: val_accuracy did not improve from 0.71000\n",
      "Epoch 1799/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6566 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01799: val_accuracy did not improve from 0.71000\n",
      "Epoch 1800/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6503 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01800: val_accuracy did not improve from 0.71000\n",
      "Epoch 1801/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6576 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01801: val_accuracy did not improve from 0.71000\n",
      "Epoch 1802/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.6586 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01802: val_accuracy did not improve from 0.71000\n",
      "Epoch 1803/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6689 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01803: val_accuracy did not improve from 0.71000\n",
      "Epoch 1804/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6705 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01804: val_accuracy did not improve from 0.71000\n",
      "Epoch 1805/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6576 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01805: val_accuracy did not improve from 0.71000\n",
      "Epoch 1806/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6587 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01806: val_accuracy did not improve from 0.71000\n",
      "Epoch 1807/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6762 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01807: val_accuracy did not improve from 0.71000\n",
      "Epoch 1808/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6836 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01808: val_accuracy did not improve from 0.71000\n",
      "Epoch 1809/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7161 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01809: val_accuracy did not improve from 0.71000\n",
      "Epoch 1810/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6697 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01810: val_accuracy did not improve from 0.71000\n",
      "Epoch 1811/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6863 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01811: val_accuracy did not improve from 0.71000\n",
      "Epoch 1812/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6818 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01812: val_accuracy did not improve from 0.71000\n",
      "Epoch 1813/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7073 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01813: val_accuracy did not improve from 0.71000\n",
      "Epoch 1814/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7506 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01814: val_accuracy did not improve from 0.71000\n",
      "Epoch 1815/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7219 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01815: val_accuracy did not improve from 0.71000\n",
      "Epoch 1816/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7083 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01816: val_accuracy did not improve from 0.71000\n",
      "Epoch 1817/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01817: val_accuracy did not improve from 0.71000\n",
      "Epoch 1818/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7071 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01818: val_accuracy did not improve from 0.71000\n",
      "Epoch 1819/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7656 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01819: val_accuracy did not improve from 0.71000\n",
      "Epoch 1820/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7236 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01820: val_accuracy did not improve from 0.71000\n",
      "Epoch 1821/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.7224 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01821: val_accuracy did not improve from 0.71000\n",
      "Epoch 1822/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.7437 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01822: val_accuracy did not improve from 0.71000\n",
      "Epoch 1823/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6913 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01823: val_accuracy did not improve from 0.71000\n",
      "Epoch 1824/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7322 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01824: val_accuracy did not improve from 0.71000\n",
      "Epoch 1825/2000\n",
      "113/113 - 1s - loss: 0.7448 - accuracy: 0.8300 - val_loss: 2.6487 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01825: val_accuracy did not improve from 0.71000\n",
      "Epoch 1826/2000\n",
      "113/113 - 1s - loss: 0.1788 - accuracy: 0.9411 - val_loss: 2.9386 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01826: val_accuracy did not improve from 0.71000\n",
      "Epoch 1827/2000\n",
      "113/113 - 1s - loss: 0.0582 - accuracy: 0.9811 - val_loss: 2.5650 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01827: val_accuracy did not improve from 0.71000\n",
      "Epoch 1828/2000\n",
      "113/113 - 1s - loss: 0.0245 - accuracy: 0.9989 - val_loss: 2.7605 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01828: val_accuracy did not improve from 0.71000\n",
      "Epoch 1829/2000\n",
      "113/113 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6523 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01829: val_accuracy did not improve from 0.71000\n",
      "Epoch 1830/2000\n",
      "113/113 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.6646 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01830: val_accuracy did not improve from 0.71000\n",
      "Epoch 1831/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6879 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01831: val_accuracy did not improve from 0.71000\n",
      "Epoch 1832/2000\n",
      "113/113 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01832: val_accuracy did not improve from 0.71000\n",
      "Epoch 1833/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6887 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01833: val_accuracy did not improve from 0.71000\n",
      "Epoch 1834/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01834: val_accuracy did not improve from 0.71000\n",
      "Epoch 1835/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.7127 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01835: val_accuracy did not improve from 0.71000\n",
      "Epoch 1836/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7212 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01836: val_accuracy did not improve from 0.71000\n",
      "Epoch 1837/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7129 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01837: val_accuracy did not improve from 0.71000\n",
      "Epoch 1838/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7273 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01838: val_accuracy did not improve from 0.71000\n",
      "Epoch 1839/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7289 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01839: val_accuracy did not improve from 0.71000\n",
      "Epoch 1840/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7226 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01840: val_accuracy did not improve from 0.71000\n",
      "Epoch 1841/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7408 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01841: val_accuracy did not improve from 0.71000\n",
      "Epoch 1842/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7240 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01842: val_accuracy did not improve from 0.71000\n",
      "Epoch 1843/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7488 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01843: val_accuracy did not improve from 0.71000\n",
      "Epoch 1844/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7587 - val_accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01844: val_accuracy did not improve from 0.71000\n",
      "Epoch 1845/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7499 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01845: val_accuracy did not improve from 0.71000\n",
      "Epoch 1846/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7376 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01846: val_accuracy did not improve from 0.71000\n",
      "Epoch 1847/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7522 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01847: val_accuracy did not improve from 0.71000\n",
      "Epoch 1848/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7824 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01848: val_accuracy did not improve from 0.71000\n",
      "Epoch 1849/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01849: val_accuracy did not improve from 0.71000\n",
      "Epoch 1850/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01850: val_accuracy did not improve from 0.71000\n",
      "Epoch 1851/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7566 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01851: val_accuracy did not improve from 0.71000\n",
      "Epoch 1852/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01852: val_accuracy did not improve from 0.71000\n",
      "Epoch 1853/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01853: val_accuracy did not improve from 0.71000\n",
      "Epoch 1854/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7557 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01854: val_accuracy did not improve from 0.71000\n",
      "Epoch 1855/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01855: val_accuracy did not improve from 0.71000\n",
      "Epoch 1856/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7607 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01856: val_accuracy did not improve from 0.71000\n",
      "Epoch 1857/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7634 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01857: val_accuracy did not improve from 0.71000\n",
      "Epoch 1858/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7799 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01858: val_accuracy did not improve from 0.71000\n",
      "Epoch 1859/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01859: val_accuracy did not improve from 0.71000\n",
      "Epoch 1860/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7749 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01860: val_accuracy did not improve from 0.71000\n",
      "Epoch 1861/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01861: val_accuracy did not improve from 0.71000\n",
      "Epoch 1862/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01862: val_accuracy did not improve from 0.71000\n",
      "Epoch 1863/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01863: val_accuracy did not improve from 0.71000\n",
      "Epoch 1864/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7718 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01864: val_accuracy did not improve from 0.71000\n",
      "Epoch 1865/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.7954 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01865: val_accuracy did not improve from 0.71000\n",
      "Epoch 1866/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8010 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01866: val_accuracy did not improve from 0.71000\n",
      "Epoch 1867/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.7458 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01867: val_accuracy did not improve from 0.71000\n",
      "Epoch 1868/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01868: val_accuracy did not improve from 0.71000\n",
      "Epoch 1869/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01869: val_accuracy did not improve from 0.71000\n",
      "Epoch 1870/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01870: val_accuracy did not improve from 0.71000\n",
      "Epoch 1871/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.7748 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 01871: val_accuracy did not improve from 0.71000\n",
      "Epoch 1872/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.7512 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01872: val_accuracy did not improve from 0.71000\n",
      "Epoch 1873/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01873: val_accuracy did not improve from 0.71000\n",
      "Epoch 1874/2000\n",
      "113/113 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01874: val_accuracy did not improve from 0.71000\n",
      "Epoch 1875/2000\n",
      "113/113 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.7630 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01875: val_accuracy did not improve from 0.71000\n",
      "Epoch 1876/2000\n",
      "113/113 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.8430 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01876: val_accuracy did not improve from 0.71000\n",
      "Epoch 1877/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.8774 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01877: val_accuracy did not improve from 0.71000\n",
      "Epoch 1878/2000\n",
      "113/113 - 1s - loss: 0.8372 - accuracy: 0.8278 - val_loss: 2.6442 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01878: val_accuracy did not improve from 0.71000\n",
      "Epoch 1879/2000\n",
      "113/113 - 1s - loss: 0.2839 - accuracy: 0.9078 - val_loss: 2.7696 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01879: val_accuracy did not improve from 0.71000\n",
      "Epoch 1880/2000\n",
      "113/113 - 1s - loss: 0.1235 - accuracy: 0.9644 - val_loss: 2.3582 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01880: val_accuracy did not improve from 0.71000\n",
      "Epoch 1881/2000\n",
      "113/113 - 1s - loss: 0.0745 - accuracy: 0.9800 - val_loss: 2.5197 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 01881: val_accuracy did not improve from 0.71000\n",
      "Epoch 1882/2000\n",
      "113/113 - 1s - loss: 0.0406 - accuracy: 0.9933 - val_loss: 2.7881 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01882: val_accuracy did not improve from 0.71000\n",
      "Epoch 1883/2000\n",
      "113/113 - 1s - loss: 0.0349 - accuracy: 0.9944 - val_loss: 2.5263 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 01883: val_accuracy did not improve from 0.71000\n",
      "Epoch 1884/2000\n",
      "113/113 - 1s - loss: 0.0236 - accuracy: 0.9989 - val_loss: 2.5929 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01884: val_accuracy did not improve from 0.71000\n",
      "Epoch 1885/2000\n",
      "113/113 - 1s - loss: 0.0317 - accuracy: 0.9967 - val_loss: 2.5276 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01885: val_accuracy did not improve from 0.71000\n",
      "Epoch 1886/2000\n",
      "113/113 - 1s - loss: 0.0224 - accuracy: 0.9978 - val_loss: 2.6733 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01886: val_accuracy did not improve from 0.71000\n",
      "Epoch 1887/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.6556 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01887: val_accuracy did not improve from 0.71000\n",
      "Epoch 1888/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6887 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01888: val_accuracy did not improve from 0.71000\n",
      "Epoch 1889/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7070 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01889: val_accuracy did not improve from 0.71000\n",
      "Epoch 1890/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7030 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01890: val_accuracy did not improve from 0.71000\n",
      "Epoch 1891/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7036 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01891: val_accuracy did not improve from 0.71000\n",
      "Epoch 1892/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7163 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01892: val_accuracy did not improve from 0.71000\n",
      "Epoch 1893/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01893: val_accuracy did not improve from 0.71000\n",
      "Epoch 1894/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01894: val_accuracy did not improve from 0.71000\n",
      "Epoch 1895/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7313 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01895: val_accuracy did not improve from 0.71000\n",
      "Epoch 1896/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7216 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01896: val_accuracy did not improve from 0.71000\n",
      "Epoch 1897/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7063 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01897: val_accuracy did not improve from 0.71000\n",
      "Epoch 1898/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7176 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01898: val_accuracy did not improve from 0.71000\n",
      "Epoch 1899/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7170 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01899: val_accuracy did not improve from 0.71000\n",
      "Epoch 1900/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7308 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01900: val_accuracy did not improve from 0.71000\n",
      "Epoch 1901/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7095 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01901: val_accuracy did not improve from 0.71000\n",
      "Epoch 1902/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7365 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01902: val_accuracy did not improve from 0.71000\n",
      "Epoch 1903/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7336 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01903: val_accuracy did not improve from 0.71000\n",
      "Epoch 1904/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7287 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01904: val_accuracy did not improve from 0.71000\n",
      "Epoch 1905/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7381 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01905: val_accuracy did not improve from 0.71000\n",
      "Epoch 1906/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7701 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01906: val_accuracy did not improve from 0.71000\n",
      "Epoch 1907/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7509 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01907: val_accuracy did not improve from 0.71000\n",
      "Epoch 1908/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7656 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01908: val_accuracy did not improve from 0.71000\n",
      "Epoch 1909/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7754 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01909: val_accuracy did not improve from 0.71000\n",
      "Epoch 1910/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7512 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01910: val_accuracy did not improve from 0.71000\n",
      "Epoch 1911/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01911: val_accuracy did not improve from 0.71000\n",
      "Epoch 1912/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7521 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01912: val_accuracy did not improve from 0.71000\n",
      "Epoch 1913/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7710 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01913: val_accuracy did not improve from 0.71000\n",
      "Epoch 1914/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7777 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01914: val_accuracy did not improve from 0.71000\n",
      "Epoch 1915/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7827 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01915: val_accuracy did not improve from 0.71000\n",
      "Epoch 1916/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7578 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01916: val_accuracy did not improve from 0.71000\n",
      "Epoch 1917/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7513 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01917: val_accuracy did not improve from 0.71000\n",
      "Epoch 1918/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01918: val_accuracy did not improve from 0.71000\n",
      "Epoch 1919/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8087 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01919: val_accuracy did not improve from 0.71000\n",
      "Epoch 1920/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01920: val_accuracy did not improve from 0.71000\n",
      "Epoch 1921/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8114 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01921: val_accuracy did not improve from 0.71000\n",
      "Epoch 1922/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8131 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01922: val_accuracy did not improve from 0.71000\n",
      "Epoch 1923/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01923: val_accuracy did not improve from 0.71000\n",
      "Epoch 1924/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7852 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01924: val_accuracy did not improve from 0.71000\n",
      "Epoch 1925/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7064 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 01925: val_accuracy did not improve from 0.71000\n",
      "Epoch 1926/2000\n",
      "113/113 - 1s - loss: 0.2848 - accuracy: 0.9544 - val_loss: 2.4792 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01926: val_accuracy did not improve from 0.71000\n",
      "Epoch 1927/2000\n",
      "113/113 - 1s - loss: 0.7563 - accuracy: 0.8222 - val_loss: 2.4380 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01927: val_accuracy did not improve from 0.71000\n",
      "Epoch 1928/2000\n",
      "113/113 - 1s - loss: 0.1475 - accuracy: 0.9422 - val_loss: 2.3618 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 01928: val_accuracy did not improve from 0.71000\n",
      "Epoch 1929/2000\n",
      "113/113 - 1s - loss: 0.0870 - accuracy: 0.9778 - val_loss: 2.4056 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01929: val_accuracy did not improve from 0.71000\n",
      "Epoch 1930/2000\n",
      "113/113 - 1s - loss: 0.0589 - accuracy: 0.9844 - val_loss: 2.3379 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01930: val_accuracy did not improve from 0.71000\n",
      "Epoch 1931/2000\n",
      "113/113 - 1s - loss: 0.0452 - accuracy: 0.9889 - val_loss: 2.6337 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 01931: val_accuracy did not improve from 0.71000\n",
      "Epoch 1932/2000\n",
      "113/113 - 1s - loss: 0.0334 - accuracy: 0.9967 - val_loss: 2.5917 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01932: val_accuracy did not improve from 0.71000\n",
      "Epoch 1933/2000\n",
      "113/113 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.6421 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01933: val_accuracy did not improve from 0.71000\n",
      "Epoch 1934/2000\n",
      "113/113 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.6650 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01934: val_accuracy did not improve from 0.71000\n",
      "Epoch 1935/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6573 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01935: val_accuracy did not improve from 0.71000\n",
      "Epoch 1936/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6883 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01936: val_accuracy did not improve from 0.71000\n",
      "Epoch 1937/2000\n",
      "113/113 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.7115 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01937: val_accuracy did not improve from 0.71000\n",
      "Epoch 1938/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.7048 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01938: val_accuracy did not improve from 0.71000\n",
      "Epoch 1939/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6993 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01939: val_accuracy did not improve from 0.71000\n",
      "Epoch 1940/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01940: val_accuracy did not improve from 0.71000\n",
      "Epoch 1941/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7232 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01941: val_accuracy did not improve from 0.71000\n",
      "Epoch 1942/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01942: val_accuracy did not improve from 0.71000\n",
      "Epoch 1943/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7334 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01943: val_accuracy did not improve from 0.71000\n",
      "Epoch 1944/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7670 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01944: val_accuracy did not improve from 0.71000\n",
      "Epoch 1945/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01945: val_accuracy did not improve from 0.71000\n",
      "Epoch 1946/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7316 - val_accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01946: val_accuracy did not improve from 0.71000\n",
      "Epoch 1947/2000\n",
      "113/113 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7420 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01947: val_accuracy did not improve from 0.71000\n",
      "Epoch 1948/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7925 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01948: val_accuracy did not improve from 0.71000\n",
      "Epoch 1949/2000\n",
      "113/113 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01949: val_accuracy did not improve from 0.71000\n",
      "Epoch 1950/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01950: val_accuracy did not improve from 0.71000\n",
      "Epoch 1951/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01951: val_accuracy did not improve from 0.71000\n",
      "Epoch 1952/2000\n",
      "113/113 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7743 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01952: val_accuracy did not improve from 0.71000\n",
      "Epoch 1953/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7795 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01953: val_accuracy did not improve from 0.71000\n",
      "Epoch 1954/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01954: val_accuracy did not improve from 0.71000\n",
      "Epoch 1955/2000\n",
      "113/113 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01955: val_accuracy did not improve from 0.71000\n",
      "Epoch 1956/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8288 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01956: val_accuracy did not improve from 0.71000\n",
      "Epoch 1957/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8128 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01957: val_accuracy did not improve from 0.71000\n",
      "Epoch 1958/2000\n",
      "113/113 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.8452 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01958: val_accuracy did not improve from 0.71000\n",
      "Epoch 1959/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01959: val_accuracy did not improve from 0.71000\n",
      "Epoch 1960/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01960: val_accuracy did not improve from 0.71000\n",
      "Epoch 1961/2000\n",
      "113/113 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8010 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01961: val_accuracy did not improve from 0.71000\n",
      "Epoch 1962/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8087 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01962: val_accuracy did not improve from 0.71000\n",
      "Epoch 1963/2000\n",
      "113/113 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01963: val_accuracy did not improve from 0.71000\n",
      "Epoch 1964/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8151 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01964: val_accuracy did not improve from 0.71000\n",
      "Epoch 1965/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8192 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01965: val_accuracy did not improve from 0.71000\n",
      "Epoch 1966/2000\n",
      "113/113 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.8262 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01966: val_accuracy did not improve from 0.71000\n",
      "Epoch 1967/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8346 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01967: val_accuracy did not improve from 0.71000\n",
      "Epoch 1968/2000\n",
      "113/113 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.8241 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01968: val_accuracy did not improve from 0.71000\n",
      "Epoch 1969/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8407 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01969: val_accuracy did not improve from 0.71000\n",
      "Epoch 1970/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8331 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01970: val_accuracy did not improve from 0.71000\n",
      "Epoch 1971/2000\n",
      "113/113 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01971: val_accuracy did not improve from 0.71000\n",
      "Epoch 1972/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.8625 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01972: val_accuracy did not improve from 0.71000\n",
      "Epoch 1973/2000\n",
      "113/113 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.8500 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01973: val_accuracy did not improve from 0.71000\n",
      "Epoch 1974/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8823 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01974: val_accuracy did not improve from 0.71000\n",
      "Epoch 1975/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8432 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01975: val_accuracy did not improve from 0.71000\n",
      "Epoch 1976/2000\n",
      "113/113 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.8617 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 01976: val_accuracy did not improve from 0.71000\n",
      "Epoch 1977/2000\n",
      "113/113 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01977: val_accuracy did not improve from 0.71000\n",
      "Epoch 1978/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.9062 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01978: val_accuracy did not improve from 0.71000\n",
      "Epoch 1979/2000\n",
      "113/113 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.8059 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01979: val_accuracy did not improve from 0.71000\n",
      "Epoch 1980/2000\n",
      "113/113 - 1s - loss: 0.1400 - accuracy: 0.9733 - val_loss: 3.9697 - val_accuracy: 0.5400\n",
      "\n",
      "Epoch 01980: val_accuracy did not improve from 0.71000\n",
      "Epoch 1981/2000\n",
      "113/113 - 1s - loss: 1.0955 - accuracy: 0.7744 - val_loss: 2.2135 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01981: val_accuracy did not improve from 0.71000\n",
      "Epoch 1982/2000\n",
      "113/113 - 1s - loss: 0.1798 - accuracy: 0.9456 - val_loss: 2.2735 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 01982: val_accuracy did not improve from 0.71000\n",
      "Epoch 1983/2000\n",
      "113/113 - 1s - loss: 0.0944 - accuracy: 0.9667 - val_loss: 2.4973 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 01983: val_accuracy did not improve from 0.71000\n",
      "Epoch 1984/2000\n",
      "113/113 - 1s - loss: 0.0276 - accuracy: 0.9978 - val_loss: 2.5347 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01984: val_accuracy did not improve from 0.71000\n",
      "Epoch 1985/2000\n",
      "113/113 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.6021 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 01985: val_accuracy did not improve from 0.71000\n",
      "Epoch 1986/2000\n",
      "113/113 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.6348 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 01986: val_accuracy did not improve from 0.71000\n",
      "Epoch 1987/2000\n",
      "113/113 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01987: val_accuracy did not improve from 0.71000\n",
      "Epoch 1988/2000\n",
      "113/113 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6077 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01988: val_accuracy did not improve from 0.71000\n",
      "Epoch 1989/2000\n",
      "113/113 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.6113 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01989: val_accuracy did not improve from 0.71000\n",
      "Epoch 1990/2000\n",
      "113/113 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6260 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01990: val_accuracy did not improve from 0.71000\n",
      "Epoch 1991/2000\n",
      "113/113 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6353 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01991: val_accuracy did not improve from 0.71000\n",
      "Epoch 1992/2000\n",
      "113/113 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6461 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01992: val_accuracy did not improve from 0.71000\n",
      "Epoch 1993/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6159 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01993: val_accuracy did not improve from 0.71000\n",
      "Epoch 1994/2000\n",
      "113/113 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6331 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01994: val_accuracy did not improve from 0.71000\n",
      "Epoch 1995/2000\n",
      "113/113 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6619 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01995: val_accuracy did not improve from 0.71000\n",
      "Epoch 1996/2000\n",
      "113/113 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.6710 - val_accuracy: 0.6300\n",
      "\n",
      "Epoch 01996: val_accuracy did not improve from 0.71000\n",
      "Epoch 1997/2000\n",
      "113/113 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.6710 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01997: val_accuracy did not improve from 0.71000\n",
      "Epoch 1998/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6802 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01998: val_accuracy did not improve from 0.71000\n",
      "Epoch 1999/2000\n",
      "113/113 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6731 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 01999: val_accuracy did not improve from 0.71000\n",
      "Epoch 2000/2000\n",
      "113/113 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6922 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 02000: val_accuracy did not improve from 0.71000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1635e98a0a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "csv_filename = os.path.join(checkpoint_path,\n",
    "                            \"training_log.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "n_epoch=2000\n",
    "\n",
    "\n",
    "dense_model.fit(train_data, \n",
    "                train_targets, \n",
    "                epochs=n_epoch,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_data, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x163654bfc40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAD8CAYAAADQSqd1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAADEOElEQVR4nOydd3hURReH37nb0nsIaRB67713BJQmCCiKAnbsqGCvn713saCIIigKioD03nuHhCSEhFTSk+13vj82EkLaJixFzOuzj+TeuTOzye65c8+c8ztCSkkNNdRQQw2XF+VKT6CGGmqo4b9IjfGtoYYaargC1BjfGmqooYYrQI3xraGGGmq4AtQY3xpqqKGGK0CN8a2hhhpquALUGN8aaqihBhcghHhYCHFICHFYCPFIZe1rjG8NNdRQw0UihGgJ3AV0BtoANwghGlZ0TY3xraGGGmq4eJoB26WUhVJKG7AeuLGiC7SXZVpOEhQUJKOioq70NGqooYZ/Abt3786QUgZfTB/X9fOUZzPtzo13wHwYMJ13aJaUclbRvw8B/xNCBAJGYBiwq6L+rirjGxUVxa5dFc63hhpqqAEAIcSpi+3jbKadHX/XcaqtJjTaJKXsWNY5KeVRIcSbwAqgANgHVGjVa9wONdRQw38WCahO/ldpX1J+I6XsIKXsDWQBJypqf1WtfGuooYYaLicSiVU653aoDCFELSllmhCiDg5/b9eK2tcY3xpqqOE/jTOrWidZWOTztQLTpJTZFTWuMb411FDDfxaJxO4iWV0pZa+qtK8xvjXUUMN/GpUro2leY3xrqKGG/ywSsF8h41sT7VDDVYeUksyULGqqrNRwOVCRTr1cTY3x/ZdzLRqo9+/5kpsj7+X1iR9e6anUcI0jAauUTr1cTY3x/Zdit9l5oMtTDHO/hd0r91/p6biUQ5uOodpVDm85fqWnUsM1jkRid/LlamqM77+UnIxcYvbGYrfa2fT7jis9HZfy9E8PM/TOATy34DEAzEbzNbnCr+EqQILdyZerqTG+/1ICavsz6aXxdBrSlgkzRl3p6biUhm3r8dise2nauRFLv17FcO/beKzP8zUGuAaX48hwc+7lamqiHf7F3PJUhaJJ1wTb/9qDlJLDW46j2lU0Ws2VnlIN1xQCO+KKjFxjfGu4qrn77dvQ6jT0GN25xvDW4HIcG25XxvhetNtBCOEmhNghhNhfpOD+UtHxekKI7UKIGCHEfCGE/uKne21yOjaNu69/j2cnzyI3K/9KT+eqIrxhKM/Ov5++N2xHLZh3padTwzWGI85XOPVyNa7w+ZqB/lLKNkBbYIgQoivwJvC+lLIhDoWfqS4Y65pk9aI9xO+LZfucVdze8EGM+cYrPaWri8IFUDAb8l5DWo9d6dnUcI2hSuHUy9VctPGVDv5ZrumKXhLoD/xadPx7YNTFjnWt0m9EO7zdNQgBpgITBTmFV3pKVxfapoAA4QaakCs9mxquIa7kytclPl8hhAbYDTQEPgVOAtlF5TQAEoHwcq69G7gboE4d50SNrzXqNgxh7v43+e2DJdRrWZeg8MArPaUKkdYjSNNyhPs4hDaiwranjpxm25I9DLytN4Gh/tUaTxi6IH3fAGkC4VutPmqooSwkAvsVCvpyifGVUtqBtkIIP+B3oGkVrp0FzALo2LHjfzaWyN3TjYnPjL3S03AKmTUV1EykZTsicH6FbZ8c9DI56bnsWLaHd9e+VKVxjm6P5oN7vmT4XREMG/Ot46BwA/cbqjv1K86e/adIS89jYL/maDWu+9KfLoxj+9l1dA8aSJh7pMv6/S9wKVwKzuDSaAcpZbYQYi3QDfATQmiLVr8RQJIrx6rhCqKpB2ouaBthV81oFEO5TYPCA8nLLCA4IpAfXl5AeKMw+t/c06lhfnz1V2IPnOKXd08wdAyOBz/FudWz0WShsNBCYICXU+0vB2eSs5nxwq8IBEaTldE3tHNZ3z/GvUmqJZsT+Yd5utk7Luv3WkcisMgrE0XjimiH4KIVL0IId2AQcBRYC/yzlLsdWHyxY9VQzF+zVvJgt6c5vOU43z3/M08MeInk2NTLMrYI+A67/0+szdnEyoRuZJnKT29+d91LvL/hZeq2iOCn137nnSmfceZkilPjDL/vOnwCvWjZ9zqUoCWIwF8Qhh6VXldYaObmKbMYd8cXbNwS7fT7utSkpOYAAgn4eru5rF+18FceD1jL40FHqetR32X9/hdwJFkoTr0qQwjxaFHE1yEhxDwhRIV/ZFesfEOB74v8vgqwQEq5RAhxBPhZCPEqsBf4xgVj/ecxFpj4esZc/vxiBVKVfPbIbE7ui8NuV/n1vT958JM72bPqAN88/RPD7h5Is86NqNeqDkK47tFKCD2F6LGqeUipkmXei4+uJW/d8SlJJ5J5dv6j1I6qBYCbh4EmnRqSlZqDEODmacAn0NupcboMa8/C9NlVnl9evpn8fDNIiI5NpVf3RlXuozLM9kyOZ76Hr6EldX0mVNo+7lQGM19cCEjum9qX/n2auW4ylu0oAmrrzNxc63bX9fsfwRWbaUKIcOAhoLmU0iiEWABMAL4r75qLNr5SygNAqecnKWUs0Pli+6+hJKt+2MCyb9YghECr13DDvYNY8d06Tu6Lp/fYbgB89shsTh1JJHp3LFqDlptnjua2529y6Tx89E1p4HsXRtsZIr3HcOpQIht/3YrNamflD+u57bmS43W9oQPfR3+Ch487nj4eLpmDqkqEoNSNJaSWD09NH0ZsfDoTbuzkkrEuJDb7WxLz/yQpfwm1PPrirq1dYXur1bH3rAhBcKCPS+civKcjhR6h74GieLq072sdKQV26TLfuxZwF0JYAQ/gTGWNa7jCpCWks2beZnqO7kxE47AK2x7adAyr2YqHjzvfR3+MX7AvQ6cMKNFm2N2D+HrmXOxWO6pNdfoxvyoIIWjkf++5nyObutGsa2OSY1PpdWPZdQODIxxRHCZ7IXrFDUVU/0MfG5/O/dPn4uVh4JtPJ+Pr417i/IA+zRjgytXlBQS6dyY+dy7u2lD0TvihGzeszRsvjcFotNC9S0PXTkYJQXjPRCjOPVHUUBLVBStfKWWSEOIdIAEwAiuklCsquqbG+F4FvHzTe0TvieWvL1fyQ+ynFbZdN38zAA3aROEXXHbY1Y0PDePGh4ZxZOtxDmw4yvV3D6z23ArzjHh4u1faTqfX0axrY2wWG0oFu/jr0payKGku9T2b8lDj58tt9+F9s1j900Ye+uwuBk7sXer8/kOJ2GwquXkm4hMyaNOy9A6/Km3EZM9CI/TU952CuAhjfyG1PHozqO4WNMKAw+NWOe3b1HXZ+Ocjs6eBeTXS8x4U78cuyRjXKo4NN6fNYJAQYtd5P88qitZCCOEPjATqAdnAL0KIW6WUc8vrrEbVrIpIaaQ4fNk1hNQNQqPVEFwnqNK2tz43hvCGtbnthcrdCM27NWHCjFF4+1dvx//9e79klN8kPrxvVqVts9Jy+OWdPziy9QS/vvdnue2O5R5AIokrOFGhStny2Wsx5plY8kXZi4fB/ZvTp0djhg9tQ8tmZYaQk1q4mticb4nO/oJ04+ZK34NqXIqa1ge1wLntCa3i4bThvaRYdgISzJsAkNKONG9Dqpnnflbzv0Et+KlGGe4CqrjhliGl7Hje6/wvxkAgTkqZLqW0Ar8B3Ssau2blWwWkeTsyawooARC0DKG4JozpqR8f5uS+eOq1qjzJ5Lbnx3Hb8+NcMm5F7Px7H0tnrQJg14rKxdp9g7xp178lx3eeZMDE8ou43hhxO8tTFtLOrytCCP74bDmnjiQy+dWb8fIr9lfe++7tLJ+9hqmvTSxxvclk5ZGZP3M2K593/zeOOkWuDKvVTvTJVBrUr4VB7/hYe+nqFz1QKnjqnFh15n8KajLkfwae/55seOH3IdK4EOF5FwAy900wzgPFC4I3g2k55BdVBdHWA0O3Kzjbqw+7a+J8E4CuQggPHG6HAcCuii6oMb5VQFr3ABLULFBTQHGN706r09Kkk4v9gBfJlkXFAu3TPpxcaXtFUXjj7+cqbVfLLZRJUQ8AkBidzBfT56Da7fiH+DLx6d6g5iB0jRk5bQgjpw0BwG6389KYd4jZG8ft70/mZFwadlWyZfvJc8b3+dcWsXNPPK1bRPDea+MB8NY3on+dtQgUtM5sRHndD3lvgMekytteZtTsx8C0FHxeRPEoGV0hDN0RBsciS0ormBYC5iIRWgnaKMf/hQKasp8S/qu4KsNNSrldCPErsAew4YjwqvCRscb4VgHhMRFpTwRtfdA0uNLTuSRIKXn5pnfZt+YQzbo0ovuoTnS9oaNT15rsRg7m7CJMRlHbLwyNpuJH8sBQP3wCvcnJyKVVz2BkxnUg7eD3LsJt8Ll26afPsmPZXuxWO9HrDtO7R2NHlljf4g21tPQ8VFUlPSOvxBi6KmxCKe7Xg/v1Tre/rJj+BlQwLgaPCkLb1GyQhYAAt0EOt4iuBQSvA6EgnExS+S+huijaQUr5AvCCs+1rjG8VEIoPwvd/l2WsnIxc9q05RMfr2uDpe/nChwpzC9m8aAdSlYQ2CGHCjNFOX/vjqc85lLUHc4YN6xNhfLH37QoNsLuXO3PjPsVisuLunorMsDtO2NNKtAupG8zAW3tzYtdJht83mLrNSutJ/O+50azdeIw+PZo4Pd9/C1KaQOhA2kBXcVac0AQjvZ8Cy26E94zzjl/deiFXCoewzr9Y26GG6iOlZFP6cby0BqKs/rx/z5fUbR7BjqV7STxxhmZdG/POmhcv23w8fT0Z98RIdq/Yz7gnRlbpWq3Qotol0goJR5MwF1oqjZTQ6rRodVogCvw/AXsyuJfUuBBC8Pg391fYT+0QX24e26VK8/0HqWaDPRWhu0oNt7Q4DC9anCloo3hOAs+rz3VyNSIRWK9QenGN8b1C5J7NwzvAi3Wph3nh4C9IKRm7oR7b/9rDrr/3EVKUIXYldqfvfH0id74+sfKGF3BL3XtpKFux8bt9jPmug1MhaucjDH2qPObFIqUJmX4dyEKk9wwUz1svqr+Ff+zm18W7uW9KH3q7aBUuFB/w/wZsR8B9vEv6rMGBlLgyyaJK1BjfK8BXM37gl3f/pNvwjgz6cgT/2NeW/Zuz8v1V1K5Xi9eWPcPRrSfoeF2bKzvZKqBT9PSo348en/W7qH6kLQZMK8F9BKKMDaLCQjNGk7WUaE5enomPvlxF7RBfptza07mUamkGWYCjjG1iledqsdr4/sfNeHm5MWFMZ779YRP5BWa+nrPJZcYXHLKaGKq3sq+hIoRLkiyqQ02c7xVg7+pDSFVyaNMxetZqym3HWhBxbxryjIk/8+fy9aH3qRUZhNVq4562T/Dn539f6SlfVmTmncj8D5FZD5U6l5tnZNzkLxk/+Ut27I4rce6vFQdYs/4YPy/cQfTJkiJDFquNBx7/kVG3fFLinFB8Ef7fILynI7xKj1cZq9cdZcGi3cz+cTP7D51mwpjO+Pt5cMu4GkP5b0DiWPk683I1Ncb3CvDE7PsZNKkPz/86HYDVb64kI/4s3z03v8Rqbc6LC0g9lc6cFxdcqaleNqQ9AzXvI6RlD2giAS1oS8Y9pyWkc3+7JzCt3Iu02oiNTy9xvk3LSBRF4OvjQdgFwu1JZ7I5diKF7JxCNm4tqXQmDF0QnlMQStU1JxrUCwZAq1EID/XntgndWPTTAwwZ0LLKfdVwZbCjOPVyNTVuhytAvVZ1eWL2NFTVsXkyfsZo5r32GxNmjirR7panbmT2c/MY93jVNr7KIjkulYDafhjcy9ferQwpJaiZoAQ49UifFJNM4olk1szbxA13D6JVr/K1FmTuC44U2YKvoNYuhP0kaBuXaLNtyR7OJp5FC/RuE8mo60vu/DdrEsqy3x5FEQJFKTm/upGB9OvdhKQz2Qwb1Mr5N10JjRvW5vcfp6HRCNzdqlYjVlqPIDNvBaU2IvDXahn/Gi4OyaWpz+YMNcb3CmAsMHFvuydIP32Wd9a8QLcbOiCA7iNLKnANmdKfIVP6O93v6eNJzH9rMf1v6UX7Aa04kpPIvPjNBG618/cjfxIcGch3xz9CUZy/i0spwbwGFG9k4QIwLQG3GxF+r1V43cGNR5l53StYzVakhH1rDjI/6avyL9A2BPM60ESgKAZQmpdq0mtMF1bN3YBPkDePvzAWvZuudDfl6ErsP3SatRuO4+Ghx9Oj+jegsvDyrGZ/5o0gjWBPAHt8me/ZWaQtBpl5h0NkJ3AuDmntGirDUTr+ypjBGuN7BUiNTyf9dAZ2m8reNYdY/u0aMhLPsn7BFj7Y9GqV+5sVvYptGdEYnjhFzJaTbPx1G4tz5vDC/gWcKszAPVjBza6SdiqD3z74i74TehAUFuBc5+a/kdlP4siQ8gVUsFaYNQnA2TOZCCEQigKqpE2fFhW2F16PgPuICjOw/EP8+GhL9eKsT8SkIJEYjRbSMvLwdqGYebVxHwuWPQ73irZk5S0pVcBCJXrcjnb2U0jTalDPOpIsrCeQwgBqBuh7uFTL+drj0hTHdIYa43sFqNs8gvEzRnH6WBLX3z2QbX/uIjM5C//aflXuK99m4puTa5BA85Z6lO0KTTo7UpU7BTUkIeEsPSKb0fDJ5qyau4FvnvqRtfM28enON50b4NyXX4DvM2DegPAoDsfat/YQnz/2HUOnDmDUA0PPHe99UzdMBWbcvd1pP7BVCd2GMocRArRVzxpMz8gjK6eQ/DwTr76zhG6dG/DEQ0NKtRs+tC1pGXmE1/Y756c9n8ysAnx83F1aV60yhCYQEfBlqeNS2pAZI8Aeh/T9CMV9ULl9yJzHHdlvuk6gaw+aMKTiDxmOOnfC92VwH3Wp3sK/HonrMtyqiriaVI46duwod+2qfFV1rWEsMBGzJ46mXRqi05d+lK4IKSVP7J3Lnsw4Xm97M00JwTvA65xrIc9qxEvrhhCCR/s8z4mdMbTp25LXlj7t/BiWvSA8EbrGpc492O1pjm2PRuemY2nhT1Wa+8WSnVPIhClfotolUXUCOR7jiGJYsegxtBqF+IQMIiMC0OtKrzF++2AJCz/4izvfvJUUjZZZ322gUYMQZn14+ZMTDuXsIceaSdfAfmiEBqlmItN6ABLcx6P4ll94VM24AWzRoAlHCV6DVPOROc+DeTmgRfi+iHC/8bK9l8uJEGK3lNK53PdyiGjpK6ctqLw0FcDTLZZd9HjnU7PyvQpw93SrcDOqIoQQvNP+tnLPe+uKfX+vL3uG4ztjaNalamV1hL78lNaR064j4Wgig2/vW6U+XYHZbMNuU0FAy+bhGE1WundpiEGv5bV3/2LN+mM0bxrKR2/dUuraua8uJC8znx9e+oWQ8b2QUhITm4aqylKbdZeSFFMS38V9cO7nHkEDEUoA0vt5sO5CeJWf2adKGwmawehkHcL8HnYcNP5cZHgB7yfAzfn08P8iUoortvKtMb7/Idw8DJX6XqvKwFv7MPDW6mem7TuYwOvvLaNXt0Y8cLfzm4vgKBf05ktjOZOSzZCBLdFqi9NEExIzsdlVkpKzy7z25qdG89sHf3HLMzfScmAbggK96dm1YaWGd9feeLKyCxnQp9lFG2lp2YPBnocQClKq+OqK/fCK583AzcVtzVuQppUIz6kIrUPbIin/T47lfA+Al48NXwBdW0ABxRfhPrLG31sJjg23mvTi/wx5Wfls/HUb7Qa2IrReyJWejkvJMu0jy7yXSK8x6DSV1yr7+dcdpKTm8MuiXdw7pU8JA+oM7dvWpT2ltXpfnDmC5asO0btHaVcJwE3TR3DT9BHnfp7+wOAy251PfEIGT730G0KA3a4yZGDlsbxqwU9Q+APCZwbC0PfccWnZjcycjC/wTMOPMGkaUdstHKkWgOlP0LVF6Io34WTWPYAFaT+FCPgWAA+tY3NSoKDXOAy30HeEkJ2AFiGq5sL6b+LSGm5Vosb4XgFen/gh+9YewjfIh3mnS2+4/FuxSwvbU6YgpUq+JZbWwa+U2W71+qN8+Pkqrr+uNePHdCY2PoOe3RpW2fBWRO0QX+6Y6Jwvz1ncDDqEACTOR0vkvwMyH5n3bgnje75Ajq/OEz+9w5DKvP+B8Q8QGqi1GyGKvqK6pmA95NhUKyLQvTO9wxejUdwwaIqroNSEmTmPY8OtJtrhP4OnrydCKHj4XBtfkmzTAQ6dfYXaHoPRKf5Y1SzcteWHjC34bSc5uUYW/rGbeyb3YcH395bZLjfPSFZaLhFRQZVqA18Oaof4MvuzyRQUmGncsOJqxefwuA0KfwKPO0ocFvpOEPANIB3/PnfCH1BAeHJ+AqoImAfqWYSm5JOSh660vGYNVaNGUvI/xBPfTePghiM07lgytCozPQ/fAE80lzHcyRlyM/P44J5ZBEcGcs87k9i35hCvTnifdv1b8uz8xziR/Qm5lqPkWo4ysM5mTLZkvPXli8pMndSLj75YzfCh5YsGpaTmcOudX2G12IjKyeW7rf8r4b9MSsxk+cqD9OrVxHlD6ALCQ8sXI5dSMvfUZ8QVnGByvYeJ9KiP8Lwd3AaAtnRWXQmj+88x7+ng1he0DUoU/BRCC5pry0V1NeCqDDchRBNg/nmH6gPPSyk/KO+aiza+QohIYA4QgmMVP0tK+aEQIqBoMlFAPDBOSpl1seNdC+gNOjoMKml4fvx0NT99voamrSN596eyV4LVRZWOR9zKSrXnZxdQkFNISF1HHGxiUibzFu5An5jO1j93oigKfcf3YNk3q8nLzGfjwu0Y803U8R5PtukAIZ4D0Gt80WscVZVjs78n3biJFkHP4KWLOjdO5w71mPvVnRXOJT0jD7tdBSRJZ7JQ7SqaIrdERmoOdw99F7tdZeGvO1n61+PV/M24ljxbDnuytqCisjljNeMjw5HpQxxZbN6PIM6rC3eqIAYvrS+BhpIxx0IoUIZRruHSobqmjNBxoC2AcFRVTQJ+r+gaV6x8bcB0KeUeIYQ3sFsIsRK4A1gtpXxDCDETmAnMqKCf/zSH98QjVZWYo2dc2m+GOZW3jz2NEIInm75BgL7sCsm5mXnc3uhBzIUWnlvwGN2Gd+TND5Zz8HAibhYrOr0O/2Af6jQNY/yMUSSeSKbTkLZ4eLvjwQBqew4o0V+BNYljWW8DEJP1GW1rvVWlebdsHs5dE7uzaclubv7ojnOGFyAlsfge7mu4ejaVvDQ+dAjoTlxBND2CBoK0OgwvskR1jj1ZW/jp1JcIIXi2+fv46vxRjUsh9znQ90Tx//DKvYn/GFKCVXX5k+YA4KSU8lRFjS7a+Eopk4Hkon/nCSGOAuE4atj3LWr2PbCOf4HxTYxL55t3ltF9YAsGje7g8v7zcowgJd5+JUVUHnxxNF++voSIekHYbfYSxuZiOF0Yi13aQEJiYVy5xjcvMx9zoQUpJaePJ9FteEfatIzg0NEkmnVqwHsrnz732N+wbT0+312+MbXYs9icNAYQgEJtz9IZZ5UhhOCWiT25ZWLPUudatK/LndOHkpCQwdTHrqty365EqrlgXIDUtoa8l7nFEIeo/RXCUM/RIGAOWA+Dx5hz1xTY8gHHE4lNtToO5r4MMg/My1AtkyD3JdC1Rvi8UhMudglxuB2cNr5BQojzs8BmXVA+/h8mAPMq68ylPl8hRBTQDtgOhBQZZoAUHG6Jsq65G7gboE6dykunX2o+fWkR+7bHsn3tUfrd0Bat7uKMoJSS9OQcgmr7cObUWR4c8zFSwocLplG3UfGvRAjYuyWavVuiCQnzZ/hER3nv4wdOY7XYaNmxXrXGb+XbkS6BfRAoNPcpP1kivGEoM394kKSYlHNVg++8vTc3juiAn69HlQyARc1BxYpAS9OAx6jtWbX43coQQjD6jtJGuSykmglqPkJb+rMl7SkgrQhtZLXnIvNec0QnUBQGgYo0rz9XTVjo28EFSSo9ggbipnHHXxdIoMFRsQS3YWCc69hwK/wTbMccmWte94MmrNrzq6FyqqDtkFFZhpsQQg+MAJ6qrDOXGV8hhBewEHhESpl7/pdVSimFEGXmMRfdOWaBI73YVfOpLnHbjyGlDoOQaLSl74h5OUY+eWkRQSE+TH1iaKUKYe/MWMD6ZQfoMagFA0a2P1e1IjE+o4TxNbjpUDQKql3FN8ChgxBzOIknb5+FQPD8J7fRvkfJzDSLxYbdase9DFWtuBMpPHvnt4SE+/PGd3eid+LxvPfYbqWOBfhXvXinly6KtsFvUGhNoo7PxZW9+fr7DfyyaDdTbuvJ+Bud84VKWwyycD4Y+kP2/SBtSJ9XEYoB9L2QpiVQ+LPDuCEg4HuEvn2l/ZaJpg6gAcUPPG4B60GE5+QKL1GEQqeAXiWP+T6P9HkGUMB2EGlZ7ag6rNTGbld579MVpKXn8fT0YfhXopNRg/NcglCzocAeKWVqZQ1dYnyFI5p7IfCjlPK3osOpQohQKWWyECIUSCu/h6uHOhG+5Gw+RvN+Lctc7a1atJstqw6jKIJeQ1rRtE3Fq/UThxKx21SiDyUx450J3PbgQOx2Sdf+JdOJ/YO8mbXkUXIyC2jYwhGmpUrp+HSI0rXcsjPzuef69zEZLbzx3V00a1uH6D2x2Kx2mnVpxLbVR8g6m09eTiGnY9Np0Kzy1VN+dgEJx5Jo2rkhiqKQk5HLz28uonXv5nQbXrWU9tqe5YvBVIXfluzFZLay+K+9zhvfrIfBHg2mZUWFJyXkv4FU80HfFSybADuO1aoBVMf3REo7suALx2rYa5pTSQrC8z4w9ANNBKIKZerL7EsUPWXpWiNqbTx3/Hj0GVasPoyqSlasOcz4Gztf1Dg1nI/L04tvxgmXA7gm2kEA3wBHpZTvnXfqD+B24I2i/y++2LFcgV01sy35doy2JDrX/gofQ0kpv1f/nEnMvniiWkZyNjmLwAtCi1p3ro9Wq8HH34PI+rUqHe/pDyaybMEOrhvTEUVRGDOld7ltg0P9CA71O/dz45YRvPbtVCxmG+26NSzRNjUxC5PR4aONOZyETtp5pNdzCOCVP2cycFR7dm06QVidAHZuOM7PP6wjcHwgwxp2oI5nab+vlJK720wnJyOXIQ8PJvK+Fhx4dzubP93I7x8t5beM2VUuiOkMUtrA+KtDh9atH6oqWbfpOP5+HgQFeGE2WRECunSs73ynuuZgj3MYMfeRYE9GFv4I5APS8Yhv+tuhS6xvAYYiv7FlI+QXJb3omoDb0PJGOIcQAnTV0+Vwlqi6QYSH+ZOZVUCn9s65nzKzCjh4OJHOHetVWeT9v4arargJITyBQcA9zrR3xcq3B3AbcFAIsa/o2NM4jO4CIcRU4BQwzgVjXTQFtlPkWY6jYie1cF0p46t309O0c0OmNn+U5LhU7n//DkbcP4T5s9ayaM4Wpk4fwsJdLzi0ap3wg9ZrXJv7nx1RabvyaNE+qszjjVtFcOsDA8lMz2PQjR2IO3DK8RESYDXbCA71490f7yX2WDKPTPgMq81GoV2w5oYjLOj1aKn+pJTkns1HtUv+bhBP1tGTuA/UovtcEBQRiMHdtV9gaT0Iwg8sm5C5RcLsQYtZud7Iu5/8jZTw5ktj0Wo1aKRCu9bO7wcI3zfB6yHQhBfHyrpdD5btYOiLULyAd0tfqKnvyCyTKmidFx+S0uxQEsPm2CBzcUUKD3c9330+pUrXPPjET6Rl5NGxXRSvv3Btqpq5Ake0g2s2t6WUBUCgs+1dEe2wCcq9dQwo5/gVw1vXkHDvURRY44n0LlvxyWq2khybgpRwdHs0I+4fwq/fbCQ/18iCr9cz8BJEQVQVIQQ33VksaNOsSyNeXfIUVrOVTkOKN3hCwv3x9nEnKysfGaWUueoFUBSFDza+woENR9jaKpNt2dEE+PrwWeyn+AT5uCz6AkCa/kZmP+HYZfR+rugNaUB44elhd+i2CwgN8eG7L6aQm2ukSSPnEymEUOCCTTShCQb3Gyq+TlsHgjcDEqFUwa9q3uhwcSAdLojzxpG2GOTZiY7SS4G/FBn+S48qJXa7nX0HEjh87Awtml78pp3VakerVa6p6IuaMkKXESEUWgW9UGEbg7uBF397kj2rDjBh5ihOxaTSuHUECTFp3PZQsS/Tblc5efQMderXws3j8jzaSWkHir8ABfkmVi/eQ4v2UbTtV1roxdPbjTlrZmCyWDljz6KeZ/mukobt6tGwXT1uUG3syYyjuW8EPjp3cjPz+OvLlbQb0IqoFtWPDDiHml30ZlSHEEzQ7yC8EZpa9OxWiw/fvBkvTwOhReLyoSG+Fz+mk1Rr1aprDYoPYCsV2YB5syOEzF6AtB5EGEpvapaFVLPAnlpCXKcqfPDGBMbd/gWFRgvf/7SZt16+qVr9/MOmrdE8979F1KsbxKyPbr+sovOXmitVOv4/Z3ydpesNHeh6g2OF+/jgt0lJzKRuwxB6XVecJvrpy4tZtWgP4VFBfL744Us+J2neisyaCpq6ELQYIfR8/uofrF96AI1GYeHOF8pcoWq0Gjy1GhoR6tQ4ekVL16Dix+53p37OjmV7cfM0MDf2U354+Vfqt6nL4El9q/dG3McihMHh59VGlTrdrIlz87xaEJpaiFqbyj7pPhyMS8B2ELIfQgb/jVAqLuEkpakoM64Q6T0DxfPWCtuXRUiwD9cNaMGW7SdLFRoti207Y3n/0xUMHdSqTEGibbtikRLiT2WQn2/Cz/faKPZZI6xzlRNRP5j0lBwiG5RcNaYVpb2eTcu9LPOQ5o2Ao2YXajpowvEP8kZRBJ4+biiXaDUSEOqPogh8Ar1Z8M4fLPp4KYqi0LZvC2rVKV2SpzKE0ID7KArzjLjr5TX1GHshQgkA9+HIvKMgTWBPwYoXEoleKafwprSALMCRGZdY7bGfnn49AEaTpVKR+G/mbCAlLZc587aUaXwnTehGXp6Jtq0irxnD+w81YupXMS98chuJcRlE1C9paKa/fhOrF++lQ6+yNWPLIj+7gKVfraJFj6a06F6++ExZCM87kPbToGuJKCo0Ofmx6+g2oDmR9YIvmRF74OMpDJjYi3otI9m//ghCUfAJ8sY7sPqhVT+/+TvfPj2PDoNb8/qyZ10428uLmj0TTEvB5yUUj3KqRniMc4SzKaFkqcG8eeReVFQea/wKoe6l3ThC8YGAbx2Zce4XFye9bOVB3vpwOY0ahPDlB7eV+xmxWO0A5Yo61Qr24aWnR17UXK5GpBTYaozv1YtGqymREJF2JpvM9FyatqnD2Knlh46VxZePz2HVD+sRisKirO/QVyEMSGhqIfw/PvezlJJDu+IJjQwola5cXew2O58+/C15WQU8+uU9eHi7o9FoaNnD4XvsPqITPyd+ibuXW5XmfiE7lu1DSsnBjUer3YcqVWLyj1DLEIqf3ulN5lJIKXn+wAL2Z8XzWttbaOlXsV9bShXMK0GpBaY/ABsYf4FyjK8QbgjvJwBIyz2AXToMXZLxVJnGF0DoO4O+M2ruy8jCX8D7KRTP0uWQKmPH7jiklESfTMVisWEoJ9mmc4d6nE7Komnj2rz90XLSM/J5evqwa26VWxY1bodLiN1m57sPVmCz2pkyfQg6fdXfdvLpTF6eNge/YC+O7T2NKiUPvjCKgaOqlhkV1rA2ikbBO9AbzUWmLv/+3SbmfLQSjUZh7vqnysx0qyoHNhzh7+/WIVVJ274tuP7u0skSvkGVV6iojIc/u5MfX13IgIm9Km9cDqtS/2BFyu8oKDzS5GXCyjFklZFtLWBl8gFUJL+d3l7K+OZZc9iQ/jeNvVvSyLs5GH9H5r4ESPCcBpb1CO8nnRqrsXdLBoQMx6KaaevXtfILjL8DZjDOh2oY37sn90FRBF061sdg0JGXZ+LwsSSaNQ1j5Zoj1IkIoHOHetx/Zz9uHNGBtPRcHn9mwbmEjnGjr22FtRqf7yVm18YT/PnjVgCatqlDn2Gtq9zHxuUHSDiZRmJ8BgCKIsjNLig91t54tmyPYcKYztQKLm2kJswYRZdh7QmJCr5ogfCCfBNSSmw2e5H84sVTv3VdfAK8MOabaNW7udPXqaoNCj8H1YzwfghHintppLQjc54kslYsT835sEzNBWcx2Y1IqWLGwrvHn+HuBk/SxLvy0j4X4qfzZERER/ZmxTOuTulohIWJ37Mvezur0/7k7TazUcQ/NzmB8LgR4T3N6bEUoTA0dKzzk/N+Dow/IbyeOHdIWvYizZsRHjcjNBWv+ENDfHnuyeHnfn545jxOJ2VRu5YPyak5APz0zd3UCvImNMQXX283QkP9yMoqdDqh499OjfG9hEQ1ro1Wp0FVJQ2aVW8nved1rVi1aA+1wvy4aWof0lKy6X9D2xJtpJTMeOFX7HaV5JQcXn9xTKl+hBDUb1265lh1mHBPP0IjA4lqFIKXi6pi+Ab58FPCFwBl+geltDjSb8+Lgz2w4Qgzr3uZ8HoFfLwsAYOuafkxtbZYMC0HbEjj7wjvh1GlyryEL0k2JXJH1EMEGZwTDR8WOha9omdl6iIEkGXJqOrbBRzv8+mWox3vzRaNlLVKpBaHukeyP3sHfroAFDTgdr2jooQSgNBc2sgMxeNG8ChOkpBSRWZOAqxI21GE/6dV6s9ktiKlRCgCIUCn0+LuVvxePTwMzPliagU9XFvUxPm6iIJ8E2lJWUQ1rn3OcOTnGvEP8mLepmcAquVyAAirE8isvx4r81z04SQ8vd0IqxNI/brBnIxPp/lFBLXn5RhZ+fsuWneqf07noSx0em2V3B7Ssh80wYhKVLLK25SRajYyYwio+UViNI5QvB1L92CzqiSeNJCRrCM8vILYVG0U6DuCLR5RlL6bbk5md9YW7NLG1rNrGR42wan3o1V0DAkdQ4hbOAW2vFJiNVVFZj0Ali2g74EIKK6tl2vJQkHBYjcDRb+fKyZ4LhwqZ/Yk0DYk42weq9cfo0eXBkSEVxzCBvDBGzeza088Pbs1JDOrAD9fD7y9nKxHVw5S2sm1HMdLVw+N8u8rjVUT53uR2O0q997wPjlZhdxyf38m3NOP/dtP8uxds/H0duPrZdOrtDqUUvLifd+zZ3M0j785jj7Dyi55s3H5Ad6e8QuKIvhyyaN8/v6tZGUXEhxU/UiAz15ZzKYVh9BoFH7b/WKlymnOII2LkTnPgVAgeE2lsaYAedn53Bp1P6YCMy8vnkHnQW6gFoVAWQ9CkfEd9dAwEo4l0aBtBGGdRiE05WeHCaFDBHxf4liQIQRvrQ851iyC9JXrZVxIO38nfKfOYD8N2Ir+X4xJNTrStqXVqW6ktCDz3gPFC+F5f4lyQBeLEAKCFjmMr6YBzz/+I8dOpPDbH7uZ/13lFVBqBXkzbLAjVt2nilodx04ks2X7SQb0aUbdOsXujkNnXyUpbzFe+vr0DP+1Sn1eaaQEm+vF1J3imklTsdtVcrIKUFWV5ISzgGNFClBYYOZsasWxuDlZBfz+/SZOxTgUruw2lR3rj2Ozqaxbsr/Ma6wWGx+/uAirxYbNZsdssqLVai7K8AIEhfqiKAJff0+XhY9JNRuQIO0gzU5ds/vv/RTmGlHtKr++twS0zcDrEXCfAO7FGVNBYQG8vGgGt784EaUCw1vu3KQk25qJRHIoZ3fxcXsqsvBHh+6ui8lMjeXA1g2oarGvXPh/gfB6GOH/RYm24yKnclPkZB5r4qSwuWkJFP4I+bMcehJVQKrZyMKfkbbT5bYRwh2hbYgQguAgbzSKICDg0qctP/r0fL6ft4VJ937Dhs3Hzx0vtCYisWO0uf7vdDlQpXDq5WqumZWvXq/l9dl3cnBnHKdj03nryflMuKcvC2atQygCL9/iu/zRfQns2nic68d3IaCWY1Ps3ad+Ye/mGOZ9sZYFW59Dq9Nw/7Mj2LzqMJMeGVzmmCajlYJ8E0IIOvZsTJ0GVV+1lcXkR6+j5+CWRES5LnZXeEwE4Q3aSKf9lN1HdSIoIpDcjFxufXaMQ0zIyzl/oNF6hqSCJdT2GISXvuKNG62io0/wUA7l7KZ/SPHmkMy6G2wxoJ2HCFri1LjOYDWlcu+ITzGbFcZMOsKkxxwrRqGtC173AaAaV0DeS+A+FoP3o3QN7Fdpv9KyD5n9EGgbAgKEHrRV27SS2Y+BZQcoAUjv58GyziFvWc7f7LknbuBYdAoN6xV/9gqNFrZsj6FNy8iLXgicT60gb+KLFjYHjyTRu0cTpJTI5Pvw82lOi/DrnerHZLJitdkv2t3hCmp8vi6iRfso8nOMzPtiLUiJX4AnZpMVCezbGsOAkQ7/6FOTv8ZqsRFz5AwvfX47AIG1fFA0Ar+A4pXb8IndaNO1AbHHkomICirlL/b2defZD2/lwM5YbpjQxak5ZiSd5eDGY3S9oT3uXqUf+zJSc8jLMdKklQs0FM4jZm8Cmcl16TzMOR+xXaq8fnwxngva8n6bCdR296vSeHvSHiXHcpTTeQvpF/l3pe1vjJjEjRGTSh5U/HCUUa/a2JWh2vOxmBWQgvyccp6ICmc5sggLvgHv0ipwZSGNC0BNAUsaBK1CaIIdadSVzadgDlgPIbxnFGlECEfp+JwHARWp5pSI77bbVbbviqVe3SBCa/vRslnJfYHnX1vMvgMJBPh5suB71xVjnfXhJOb/tpOMzHxuHe+IClm36Tivv7cOKeGbTwLxqaSSfXZOIbfe/TVmk5X3XhtPqxaVXHAZkDXG1zU0ahmBp5cBm01l8I0dSTp1FqvFRpd+xZqroXUCSIzLoG7D4tXCA8+PZPDoDtQ5L5nCZLTw8E2fIqUk9ugZpjxeWt+1Vad6fPj8byz5aRsvfX57qWoTF/Jwj2fJTsuh05C2vPhbydjQrIw87hr8NsaEM3Qf2pbnfnzQJSvflPg0h9avEDz06Z0Mvr1vpdeczEtlRcoBbKrKX2f2MLVB1UoBeegiybNE466teHNv1pM/sPiTZUz53y2MebRkhITw/xIs+0Bffon589mduYXtmeu4IWw8dTwalNvO4NmAd+f04cTBU/QdfUeZbYTXA8jcl8HdeSVU4XEr0rIX9J0QmnCn/nbSngJ5bwIqUglE+L4F7juR2paQNQlsJ0DfibUbjrF6w1HunNSbVeuOsOD3nWgUhUU/TSuROBETm8buvfGoqsSuuib88B8MBh2Tbu5e4phS9B4FIJzYuEpJzcFstiGBmLj0q8L41my4uYiAYG9+3PA04Nic+Gdlez4fLphGalIW4VFBxJ1IISTcHw9PA83alQwBE0KgKAK7XaItJ0oi+2w+hflmkBBz5EylxlfRKCAEynkxvsYCE24eBoyFFszpmdhz8tiycAsnnxxOw7YXF2uplvgCOkKMAM6a09mQvpw2fp2p71U6zTnKK5jmPhEkGTPpU8v5eN9/aBP8Bnm+J/DSN6yw3d+z12AxWVn69arSxle4gcH5zbR5CV9ilRbMp0082uTlCts2aH0DDSoI9xaGvsig3uzK3ISbbSet/SqPbhC65ojgZU7PFwAl4Fz0gjB0dcRHG3o4KsIF/gYyB4Q/r7z9Lna7itFooXHD2iAdspEXFDghLT0XnVaDKiX3TulbtblUg1Ytwvnfc6Px9XEnMqLyTdwmjWpzzx29ycjMZ9igqsdkuxopXRfnK4TwA74GWuLI35gipdxaXvtrzvhC+aFS/6A36IisX4sfP13F/Fnr8Q/yYvbKJ0pFFRjcdHy2+GESTqaVa1Qj6gVz3zPDSYrPYPgtlRuKj7b8j8NbjtPxurYA/PbhX3zx2Pe07d+St1Y+z90vjuGLB78iKCyAsAbOa9iez8aF2zi2I4beN3VlxqBX0Bl0vPrnTFS7SvuBDoszL+ELovOPsO3sWt5s822pPvSKlq+6OiXIXyaK0OJrqNxoP/DJnSx8fwmTX3EuvKwiWvl2ZE/2Vjr4d6+8sRPsz97BgtPfAPBAo+eI8qz4RlIdhNBD0N+AxXGzKXFOA8Jh0Nq3qcOuvfH06NKIEcPa0LhhCA3qBePmVjJduFvnBjxwT38UIRjY99JW2Pjh5618O3cTzZuG8ek7EyttL21xyIKvGDP0eoSh7yWdm/MI7K6LdvgQWC6lHFtUSLPC3Oxr0vg6Q36ukd9mb8JqsZGZnodql5QV0RUS7k9IuH/pE+cxdJzzNbX8Q/zoObrYP7z9rz0OjYMNRwAYdfcAhk/ti6JUT7Q6Oz2H1275ACnh5P54rGYrNosNm8VGpyHtHOLe0kqkRwNiC46Xqy1wueg3vgf9xpdW0aoOt9d7kNvkNBQXhXZ5a334p4ieRxWiOF579y9WrTvKw/cNYOSwyuUc8wotTPv4N2yqymcP3oi/d+nv7Nuv3ITJbCMxKRO7XaVfr7JjqYUQjBja1um5Xgz7DiYgpeREtHNRDjLnWbDuRJqWIkL2XdrJVQFX+HyFEL5Ab+AOR5/SAlgquuaaMr5r/tzHojmbuOW+AaUKVF7IiYOJWK02FI1g9KQe50rE//DxSnZtPMEjr9xIvcugKzvtoynMeWkBfccVr9aqk3Z8bEc07931BV1u6IBfLV+y03PpM647AbX9cPNyo92AVkjrUeRZhw9zeNC39Ax6Hz99xTeWylBVtcpxyCZ7IZ/FvI5JNXJ/g6fx01f+uOosrjK8AA29m/NE09fRCl1xiXcnWLfxOHa7yt+rDztlfHdFJxJzJgMpYdvRBIZ2Lm1YhRB8/s1alq44SFRkIF9/ckdV3orL2LbzJGazjd49GjP9gev46Zft9OnppDqfvgtYdzvE568SqqjtECSE2HXez7OKqq8D1APSgdlCiDbAbuDhotJCZXJNGd8Pnv0Vq8XOyw/+wJw1MwgqpwKCVLNo1foY/a6vz9mM4nI8hQVm5n2+Bilh/pfrmPnezQCkp+Twx9wtdOnXjJYdolw65zpNw3l2nnO76RUx7/XfiTuYQNzBBH7PnI3ZaCUw1J+hU4o3yqTFyD8Vn4TMJ9Ct6lq85/P6bR+x9qdN3PPOpFL+2nyzmZeXrSHIy5PHB/Q6tzEDEFcQzRnjKSSSI7l76R501VWbOkeIW/kZhuUx/cHB/PX3Qe6Z0qfyxkCnJpG0qFsbu6rSvUVUue2SzmRht6ukVFM/eu+BBGbP3cxNozrQq3uxDKrdrpKdU0hgJbHCh4+d4fn/LUYI0GoVenRtxOMPXVeqncmWyqGMV/E1NKeh373nnuAU74eQnreWil6x2ewsXXGQWsHedO1U/kbpJUFSym9eARlSyvLKeGuB9sCDUsrtQogPgZnAc+V1dk0Z34bNwzm6LwFFERTkmco3vplT0diieXh6M5TABeeOu3vo6dq/OQd2xDJoTHGdtg+f/409m6JZ/MNmug9swcRpA5yqXHw5ueHewRzafIwuw9rj5eeFl1/pNkLfHvw/coh1u8DntmXRTqSUrJu/uZTxXXzgKMuORCOEYGCThrSPLI56aODVlAZezTDZjbTyrVpJ+n8D1w1oyXUDnN9M8nY38PX0yqMqnp5+PUtXHqTrBZWczyRn8/hzCwjw9+TdV8eVKxv5/qcrOHU6k5Nxabz54XL8fD348oPbeObl39h/KJFbburCXbeXL5H6jwaElOBZgYJeXO5c0ozrSTduJNxrBB664htYWZmVS/4+wKdfrQUk334y2amNO1fiomiHRCBRSvlPVs2vOIxvuVwTxtdqs6NRFN7+4W7+XriLgFo+1G1YkTiLcsH/HQgheP6T20q1btg8jP1bT2K12Fm/9AA5mQW8PvvOEm2yz+aTfTafpfO3s3TBDqZMH8KNd1yc1kBV6HRdWxamld44u5B/NjqktCGtR0DbxKlY1LJ4/Nv7WPb1aia/enOpcx0iw9EoCj5ueuoHlfwy6RUD9zV8qtQ1UkqeHPQyBzce5dmfHy3hG68BAgO8uG18N6JPpvLgEz/Rp2djxo7syKZt0aSk5pKenseJmNRyw7cG9WvBt3M3Ub9eMEeOncFsthIXn8Hx6FSkKjlYlBFaHvXqBjFiWFuycwpp2qh8l1wt916cypmLp64eBm3lT1dBRStujaLgcZlqIf6DdNGGm5QyRQhxWgjRREp5HEfx4CMVXSNkFdbcl5qOHTvKXbt2Vd4Q+PbdZaxatIch0/rw6eY91PL1ZMFzk3Av565/PlLNActW0Hd3VA2orL2UpCRm8cGzCzm4M46pTwzlxjt6lhDvuWPgW1gtNoQQmE1WohrXvix13aqLmv0omFaCriVK4M+XZAy7qqIIUenG4dtTPmXTb9t56LO7ePO2j5FS0nd8d565CHeMRbVgtOfjqytp+Of/tpOv52xk7MgO3DPZObfA1cbMF35l685YhIBVfzxOVlYBz776O4EBXrz01Eh0lehE5+QaeeP9pQQFePPI/QM5cDiRNeuPMf7GjhWK8xw+doZHZv6MlJIH7u5fYW04KatWHio+IQMvTwNBVaiOIoTYXYEbwCk8GoXJRu87l7V5YPirFY4nhGiLI9RMD8QCk6WUWeW1/9eufH/7bhN2m8qiv/eieqik5RSQmpVHVO3KH1mE4gtuQ5weSwhBaGQAb3x3J8ZCC8kJZ7mx44v4B3nz8cIHMBktWMw2QNKtfzMy0vKYdF6V49+X7OXXRbu4d0qfEr62K4r9DGAHewqPfv4HW47E8/Kk67iuk3ObJ3a7nS2LdxHROJR6LcvW5NU4sRGnqiorv1+PlJIV363j3vduZ/vSPdz2gvPJDRdiU628euRR8m253Bx5N50Ci59A/ly2H4vFxtIVB/51xjcn18iW7TF079KQ3fsT6NKxHlqNQnCQN19+MKnyDorw9XHn9ReK5U7bta5Du9aV6yqH1fbFzaDFZLbSpGHFYZBVjdSJqhNUpfauxFUZblLKfYDTNwOXGF8hxLfADUCalLJl0bEAYD4QBcQD4yq6C1SVifcPYMXvu7n91n6sPHWaBmGB1A25uJ37yhBC4OFpYN+2k1gtNjJSckiMS6dJq0he/GwSp+PSGXpTJ/QXrL6//n4D+QVmvp6z8aoxvsLvQzD+gV3Xn/UH/gTgrx1HnDa+v7zzJ3Nf/gWE4KeEz/EJKL1ikVKSbtyAXhOAn6FVGb2Aoijc+eZE1v68mdtfHk/zro258WHnNALKw6QaybflIKXktDGOThQb34fuHcA3czYy7sZ/X4WGp1/+jePRKUSE+bNyUdnyppcSfz9Pfv3hfux2FQ/3y+seuFRI+e9PL/4O+ASYc96xmcBqKeUbQoiZRT/PcNF43Hxff26+z7GT35dLnyljt6vMfm85eTlGJt7fnyN7ThES7kejIr3d9j0alZuIMf7GTiz8YzcTxjgfD3wxZJp2sy9tJsEePWgV9GKZbYSmNnjdjRaYMb4fq/ZE88DInpX2nZORy45le7GYLA4JAlH+KudMwRIOZjjK7fQK/x1PXdmrq3GPj2Tc464rzuil9eG2ug+wLWMXzb378OGxpcTkpfJsqxvp3KEenTsUZw3abHb2H0qkYf1a+LpIkP5S4abXIoRAX01N6vORtjiHqL3b9VWqJmJwwdhXG/9qYR0p5QYhRNQFh0cCfYv+/T2wDhca38vN4d3xLPlpG6qUNG0dyXMf3+r0tZNu7l4qJ74sbDY7dlVe9Ac8PmcuJnsyp/MW0izgSbRKxUUQx/dty/i+bZ3q++lhrxF3KIG6zSN4bsF0whvWxtu/7BAlgQabGU4s9aJO3xSat6t+yaB/+O2jpaz5cQP3fziF5l3Lf4o4kasyLy6dH2O/QUVil3bu3f4V0xoPZmBocZzpe5+sYOW6owT4eTilh3sleeW50ew7kEDrlhefGCOz7nboFpuWIYL+cMHsSpNviSPNuI4wz+tx015d0UHnc6W2vS6lnm+IlDK56N8pQJnhB0KIu4UQu4QQu9LT0y/hdMrmt+82cv+oDzm0K67CdnUa1MLd04BGUWjW9uKNyIVk5xQy5rbPGT7uI447mTFUHvV8J+GhjaSu981ohDvr0paxKPEHzHYTUppR879GmlZUq2+9QYcA9G46ugxrT0Tj8oVzQj2HcvLLm1j9bBhP9voIY4Gpmu8I9mRtZeHp7/nqpe84vvMks5+dV2F7m6ri+E5JoryCEQiSjJm8dLCk2HdegRkpJYXGCpORrgo83PV079IQrwrCvJzeQNdEAFrQuP6zDGBV89h0ZizHMt9jb9rjl2QMVyARqKri1MvVXJZnCCmlFEKU+akoyhCZBY5oh8sxn/P55p3lqHaV7z9cwds/lK9l4BfoxY8bnkKqktjjKdw38kM69W7MlOmllc6qQ+KZLIxGC6qUHDmeTJNG1dN1APB3a0ffSIfAS2JhHH+emYdE4q8PppdHEuS/j0SBoL+qXMDy1b+eYuPCbRzdFs3O5XvpNKT8HW8hBAF+9RDiAFqdBo2meh/gAlseP8R/CkjavRvOwQczGHbXwAqvmRDVnTB3P8I9AmnsE8rP8Vt4/9gSetYqmT0245GhrN14jHbVlPCUUnI860OMtiRaBD6LXlN2bHlFxOYfJ6Ewlm6B/TBo3M71u3NPPD7ebjRtXHmmpd2uMu3xH4k+mcrrL4wp4VopC+H/ZZFW8qXZgziTvxRVWgCJUk4x1auFKxXvdSmNb6oQIlRKmSyECAXSLuFY1WLJvG1oNAKtVssNTojiKIoCCvzy9XriT6RwKjqFm+/tf1El2/cfPM3zry2mZfMwbrmpM5lZhQwZ2KLa/V2IJteA/YQWpZGFCI8ohFaDLBL6VqUnVU1k9vTxYMeyvWz6bTvLvl2D8vNgHu/Uh4F1yhadmfjsWFp0b0pk03D0btX7EhoUd/z0AeRYM7lxxBheu6Ny37RGKPSrXbwXMCGqOzfV7YrmgvRjL08Dw4c4J1lZFrmWI8Tn/oCUdnwNzanvO7lK15vsRj6N+R8SSaYl/Zym8doNx3jjg2VICfdN7UundlEVJh/k5Bo5Hp2ClJKNW6LPGd+Ff+xm/abjPHTvQBqelxgkhB50VVerk1KSkpZLUIDXuZA2Ka0gLSWKqga6dUSDBxrFjTbBb1Z5nMvGFdxwu5Ruhz+Af/QcbwcWX8KxqsXCbzdgtdjx8HKjz9Cyv4CnolM5uLOkS2LY+C74BnjSZ1gb3C4yKHzpyoNk5xSyedtJRg/vwGMPDMa9mkbqQkyFZqa1fIboO0x03zyOBl5NEW6DIPAvnr6tH8M87mfjwm1V7rd5tyYoioI11I1jORn8b+factsqikK7Aa04pZpIzy83zb1CtIqWZ5q9x8stPqNjQOWGtzwuNLyuwENXF4MmECE0BLhVPYJCK7QYFDcUBH6688rAF21i2u0qn329ljsf+h6jqXzXSIC/J3dO6kXnDvW5ZZwjOcVmV/noi9XsP5TI199vqPLcyuL7eVu49c6vuOcRx966VPOQ6X2RaV2Q5uKSSV76BgyO2sbAuutx01Zc3v6KI518uRhXhZrNw7G5FiSESAReAN4AFgghpgKngOoHbl4i7nj0OuZ8tJLxd/ctdS4jNYedG07w+at/oCiC6a/fRK8hjnCptl0b8PPmZ10yh3GjO3IyNo12beq4fLfdYrJgKjADkuykYj0AozGYvWsSkBI2L95JrzFVK0A59tEb6DehB7NP7+e7E/u4vVnF1TFmbd7JZxu3o9dq2PTo3Ri0Vf/YaRUtXk4kxFyIXdpQ0LisHNOF6BQv+kb8DaiAwpzY9cTmp/FI0+vx01e80QmOEkrPNH+XTEsGEe5R547369UEH2831m48xsq1R5xKgJ04risTz/uWaTUKPbs2ZPvuuErTnfMLzOTlmwgtJyX/H05Ep2JXJQmJmQ7/sj0F1BxABet+MBRnJV6q37mr+VeHmkkpS+eXOrh6FVOAPsPalFmVWFVV7h/1EWajBbvNjmLQYrXYLskcGtSrVaZClZRWZP7nINwRnndW64PsE+DNG38/S+z+UwyZWiyw4+njwf0fTmH3yv3c/mL598TYnEymrlpIXW8/vhp4IzpFw6wnf+Dv2Wt44JM7eXx8Xx7v3LfSeWQZjUgpMdvs2FSVspw0cTlzic+dQxP/xwjzcj4BpiIO5+zh69h3CXEL54mmr6ERl8bL5vjbaDhVkMGX0atQpSTc3Z+7GlXsl/4HT603ntqScdJCCDq2i6Jd6zp069SAqDqB1Xoi+t/zN1bapqDQzC1TZ1FotPDsEzfQrXMDlq88SP2o4FKpyo9OG0RkhD9dOzVACIHUNgTv6WA7BR7lmYGrFwmo6r/Y+F5pbKqN08ZYwt2j0CuueWRX7Y4KEJ37NGXwmI507d+MQ5uPkZeZT9cbOrjkri6tR5E5z4ChN4r3IyVPmpZDwdeOf+tagKF6AuGtezende/Svr2R04YwclrFRu6vuGOcys0mKT+XE1kZtAgMYfGny7EYLSx8f4nTOryP9O1B/cAAmofWQo8gLSGdWnVK5vzHZH+GVc0lOvszlxnfI7n7kEhSTUkU2PLx0fm5pN/yqGXwIcjNm3RTHu0CLq4CyT9oNAo9u1VcHeViKSgwU2i0IKUkPiGDmNg05i/cAcCvP9xf4oksOMib+6YWFxMVQiA8K/dzSymJzv6UXPMxWgY9f/WEnkng37zyvZLEHE7i4wVfo/aIp1FUFA81fuGi+1QUhY9+fYATB0/TbUALDG464g+fZsbgVxACnvh2Gn3GXVy1BCnNDsNrOwS2w0jPOxHKefGy2oaABKEBbd1y+7mUjKjfjCVxx6jr408Tf4exnPLqzSz9elWVKk+46bSMa98KKSX3tH2chGNJ3P7iOG5+qnhV1sD3LuJy59DQ9y6XzX9QyCjybbnU82xSqeE9vjOGk/tPMfDWXtXeGHTX6vm99+NYVTsGTeUaI1cLtYJ9eGHGCOITMhg7qgPLVx0CIdDpNJXqRDiL0ZbIyeyvkajE5/5I04CLl1F1FVcqzvdfb3yfu+c7sjNNuO31J+SN7Gr3k302n4fHfYrNaue9efcREOzN799v5qs3l/L67DvR6jTn/G46J8R7KkLaU5F5b4DtmOOAvq+jWu35bSx7cPgRPUG5ON3dKs+vSBSlro8/f4+eUuLcmEdvKCUfWZV+Tx9LQrWrHN95ssS5+n6Tqe9XtUiByvDTBzC53iOVtivIKeCxPi8AkjMxydz5hvMJNP+QmpfPq8vX0iY8lDu7F6f3J2Xn8tqKdXSuG8HtXZyrHH2xWKw25v2yg4AAT6cjOXp1b0Sv7o4V9qjr29G0cSi1grxdlkZs0IbgpWtAgS2OWu6XT+3PKWqMb/WIrB9Mfm4hjZvU4d4G1fc5HTtwmuyz+Ugc2Wzh9YKIO57iKNO99ig33dmHj7e9RkFOIS17Vr82lpQWZMb1IAtxrGx9EP4flHZj2E85zss8kCa4TLGSq37cwNt3fErH69rwvyVPu7RvU4GZ2vVqkZWSw7gnq5ZObLOr/PL7Tjw9DAwf2qbE7ysnI5fs9FzqNqteJVypUVDDvVCS8/ENrvqmniolb6xcz8pjMaw5Ecvwlk0J8XE8xXy+aTurj59k7YlYRrRqhr/HpU9hXr7yEHPnbwUhaNwgpMox40IImlUQW1xoTUSreFcpplkj9PSKWIiq2hHiakpoEf/uDbcryWvfTCUlMZOwuoFVLmdzPu27N6T7wBZYLTa6DmiOwaCl99BWpCVl03+EI5GgXitXPP6rIK2ABgwDED7PIETpL6TwegiUINC1dEr20lWs+3kzql1l57J92O32apU0Ko8Tu06SlpCBqkpi9sRVmB4spWT+W4tIO5XBnW/eyqadscyeuxmAunUCaVOUYluQU8AdjR/CYrLw2Ff3MWBi1VdVT/y1gtN3NKd9YDBj7xlebrv1MXEOuctGJcXMX1/hMLwSqBfoj79n8d9zQOMG/LbvME1rB+PjVv148KpQN9IR2qXTKgQFlp36HZ9wlmnT5+LpaeDrj2/Hx9u5m0JqwVr2pk1HEXr6Ri5Hr/Fzel5S2iFzlKOOoO87KO4XJ6DkMmpWvtVDq9MQUa9qj+V//rSV3ZuisZit5OcYee7jWwkO9WPGOyX9mI+/4froOCHcIHAB2A47RE3KETIXihd43e3y8Stj6usTsVls9BrT1aWGF6B59yZ0GtKWnIw8eo2tOLzt5P54fnjpF1RVEt4olGZD2yMBjSKodd7q1JhvwuZuJvQ12Oq5jH6yR5XruMWdzcKmqsQU5vHR+q3c17Mz+gvC4XacSuShX5cA8Pm4EbQIDSE6PYN2EWGk5OYhJXjodfxx960lFgH9Gtfn4NMPOaVrfD4n0jI4nJzKsBZNyg3Ny80zUlBgJrS2X4njbVpFsuD7e9HrtXh6lP352n8wAbPFhtVq52RculOSkgAFtgQkEhULVjWnlPFVTauh4FuE14MIwwV/Y1kItmjHvy2b4GowvhJkTbRD9dizOZr/PfIjrTrV44VPJ1X6AS/IM/HF//5EVSWK4vhCrF92gLFTyi+fcjHYVIfAukYUGzKhawI6J4sOXmbqtazDG3+XW3aqBEmFmfjo3PHWObdq0ht0vPjbk5W2s9rtpLtJ3AM8KTxbQNMujWjeNIz5s+9Bq1VKrNKCwgO58ec+7PPYQJbmNEnGU0R6VC3S4LNxI/hqy06WHDrON1t3Ee7nw9i2JeNi3XRapHRUwHPX67jx6x9Jzy9gTJuWvHLDIDrsP0LXqMgyn76c0TU+H7PNxrhv52FXVT7dsJ2RrZvxQO+uJV0tuUZunjoLq8XGi0+PpEeXkhmG/n4VV1se0Lc5e/Yn4OvrXm7li7Ko6z0BKVU8NN54WLcjFU+E5jwt3txnQT2LzH0eEVxSP0Qo3kifV8GyDeF1NRUacI3xFULEA3mAHbBVJvT+rze+v8zdTGG+me3rjlGYb8bT263C9u6eehq2CCf6UCIR9YOxWex0d2E67/kkFsbzwYkXMGjceKrZ23hpL5/74FKzOuUgrxz8CS+d4Ocez+Olq/j3XhYWm41Cqw0/95LXPrrwL9bHxNPmf4OYe9NI3IpWbwH+ZRuUwR2HciJ6N/76QELcyhf6KY/6QQE80rcHK47FYLXbaRxcWti7dVhtFkyegETSrHYtcoxmVCmJO5vJmexc7ujqus00IQQ6jQaLzc7p7By+3LSDka2aUSfA71ybvDwjFosNpKOwZlXx8jTw0tOV+93jc34kx3KEZgGPk5Ol5YXXFhMUFMALd32NtMeBdj4iaGHxBW43QOEP4FZ234rHWPAYW+X5XlJc63boJ6XMcKbhv974nvaXWLy12IPcKjW84Agj+2D+/ah2FY226o/Viz5dxr7VB7nv/cmE1K3Y3RFfGI0GO1N8d6E/OwQZOAehLVsDwdVY1Xy2J0/GphbQJfQb3LXFGyhmoxm9m54f/7eQ+W8uYuKzY5gwY3S5feVZjXx64m/qe4Uwrm43AGLzz9AiIAFFSDamr2RoWLGvVEqJ2Wg5ZzTLotBiZchns8ksMPLRTTfQv3Fx1dozuXnYVZXUvPwK+/iHcPe6vN76q0rbVUSIjxcbHrkLq10tdTMASMzOYfHBIwxu5ogI+HnyeBbuO8yPO/dx83fz+e62MbSLqLrhLwu9RsOSeyax9PBx3lu7mboBfuc28P4hIjyA558cTlJyFiMrKOdTGYWFZo4cT6ZV8/AShTctVht20jia+Q4SOwZNEPvW9+BYdAqak6kYJ+nw0Aq4QK5U8XkGfJ6p9nyuCNegpORlYfSwDuR3CaLP+OIVfnpyNn/8uIXt646yZdXhUjJ7QohqGd68rHw+f+Q7tizexQ8v/1Jp+07+vegf2JQ6ukK0MhNMq6o8prNIKUktWMNZoyM4Ptu0n3xrLCZbMumFm861+/X9PxnudSvPDn+dv75cianAzJ9fVCwvOf/UFhYn7uLD40s5VeC4qY+O7IBOEWiFgqRYKlJVVaZ1nslI30msmru+3D6zjUYyC42oSPYllpTQ/OSm4Tzavwdf31J5dpYr8dTryzS8AE/9sYLZ2/Zw10+LAGgYHEjfRvUQigABJmvJDEhVWsk2HcCuVk9GM8THi8ndOnDgqQdZcu+kc37f9PwCLDbHWL17NObmsV2c1n+22VVmfv0Xt781j5TMPAAefXo+T730Gy+8Xiy98spbfzJo5HvMmx+NmzYEgUKgWyd6dm1IcKAXjRvWRhf0LcL/U36KeZDeH3zFr/sOVet9XnH+SbJw5uWQT9h13uvCTRkJrBBC7C7jXCn+9SvfMT1bM6anQxzbYrayc8MJvnt/OcmnM7HbVQwGHfc9O4Lrxlx8iXIPH3catosiZm883YZX3p9B48bgiJnInCywn0a6DYYqFhZ0ltTCVexLfwqQdA/9kQC3DgS5dcOq5hHiWZzlvfWPXUgJ+9YcYsYPDzLvtd+59bmKHwNb+9UtEn7xJNjgjZSSQJHIA/UfINmSS9fAvufaWkxWTu6LR6qSncv3MfDWsuukhfn68NKwARxNTefO7h1Knbure/XL/CQWxvNb4hza+XelV/DgavdzPs1rB7Pn9BkaBRcri3WJiuTjscORSLrVK7lhtT/9aVILV+Ojb0b3sB9L9SelxGKzY9BV/BU8/7Py+/7DPLtkFSHeXvw97Q50VdwQPZGYxrr9J7GrKst3HuOO6zpRUGBGqpK8fDNz52/l8LEz7D+UCMCWbXFMnvgXqrSgUdzBgwsE53vz+aYvySgo5PON20v5yStDSiugIIRrN3arShWSLDIq8eP2lFImCSFqASuFEMeklOUqGv3rje/5fPziIjYsP4hqU1EUgWp3fHB1etf8cTUaDZ9sf6NKLgshtAi/d1Hzv4KMoUh9H0TALJfMp8TczgtXU4QOjeJGx9qflGr3wMdTmfPiAgbe2pseozrTe0y3SvvuHNSQFQOexaBo0Soa1PxvIP9D6gs9DWptcsgT4jAobh4Gpn9zH7uW72PK/24p1Vf82SxOZWXTq0EUY6r4ZXWWJck/c7LgKCcLjtEjaOC56Id8ay7fxL0HwJR6j+Ktcz5OdeagPtzaqS21fUpqMPRuGFVme6MtGSntmGyllVSllEx+ez6H4lN4YdJghnd1Ttpxf1IKqpSk5uVjtFqrbHwbhAXRIqo2KZl59G3jcPO899p4tu44SYtmYdz98A+oqkr3zg1ACCZN6IYQmhKfrQuZ1rsrX27eybTeVRNnktajyLPjQfGCoCUIpfLCt5cMF0U7SCmTiv6fJoT4HegM/DeMr6qqICUe3m4888EtuHsaKMw30bpz/covdhIhBFJKFn28jKCIAHqO7lL5RQDmtYAEy/ZKm1YVu7SgVTzpXPtLdIovXvoG5bat17IOL/z6OBaThXvaPc6Zk6m8tfJ5mnWpWD/AU3ue71XNwBGvbAZpAwFzYtfz6YkVjIzowNOTbmTwpL6l+sg1mRj11Y9IJA/16cbUbqUXEWa7jUkrfiEpP5fvB4+lgW+xHKEqJbsTkqgfFECgZ9mKYapUi3x4ghY+7UqEnX0U/TKp5iQA9mZvo3fwdRW+5/MRQhDp7+d0+/a13uVMwVJqefQrdc5qs3Movkh792BsucY3LS+f5/5aRaPgQKb378lDfbuj12joUCccH7eqb3AadFq+mV4yfLJWsA8jr2+HzWanflQQcacyuHFEBzq2i3Kqz1s6tuGWjtXQQ7buBVRQ88EWC/orZ3zLLvNQxT6E8AQUKWVe0b8HAy9XdM01ZXwffHE0nfs0o1nbOtQK87tk4yz9ajVfzfgBgM92vUnd5pVXQRA+LyHzP0a4l7+xVV12pz5EpnEH/m7t6RL6tVPXJMelcfpoEnabnZ3L9lRqfM9HeD8M2jqgbX5Oj2J58n6kyc7qbzcwblI7GrYtDvfKSDrLk4NeQeeug+FhYNBiU9Uy+47OymBv2hlsUmX5qWimtS42vh+u28J32/bgrtUyf8QIIhrULvUEEltwnJj8o2iFhuY+bcscQyO05Z6rDvnWXKLzD9PUpw3uGsdNwU0bUq6wul6n5cVJg9l4MJYHR5WvTzx/z0E2xMSzOTaB0W1a0CAogKev61uluRVYE8g2H6C2x0A0SvkGW6vV8PXHd5xLLQeH3zop/088dXUJcOtw7lhi3mLcdWEEu1dN3yS1cB0mWwqR3mMQbiPBeghEIOguT9p1mbhOqzcE+L3od6cFfpJSLq/ogmvK+NptKtvWHuX4wdPc+cTQi8p4q4iQKEeUg0arwauc4pEXInSNEP4fXZL5mO3pSOyY7c7XwKvTNJxRDw0j/lACwXWC2bViPx0HO7eCEcKtlHzgjOYjeeXuD8lfksojXz7Lb2dnnxOo2bl8HylxaQhF8MLj1+PRNpyBTcpenTcNqMXgOo1IyM9mZP2SadzZhQ5pSu3Ph7j32fW0H9S6VAp0qFsEHlpPTHYj9b1Klgya1ugZjuTuo6VP+yq5HCrjk5hXyTCnEOXZiAcaVR4jXWixsjU9icB6PoQGlh9+2KtBFN9s3UWkvy8RflUPU5TSzuakcdhUG2e9d9A6uOyFmJQSm11Fpy2pexyfM5cTWZ+AgL4RS3HThpCQ9wvHzr4LAnqHL8JDV/7CQ1qPIQvnIzzGUiA92Js2/Zyhq+szAeH7WpXfk+s5t5l2UUgpY4EqPQJcU8Z39R972PT3QRRF0GNQC1q0jyq3rbyIja8uw9oz68C77Fi6h9cnfshdb91Gk47lP+pDkZhO1p2o6NlhBnddA9oGv+6SzYaOIZ+QXLCC2h7O6ceC4zH67rduY8vinbw28UOQknfWvkjTztWTL2zjX5fhLbryy9LFGDz0KOfVa+s+shMrvluHm5cbQ0d2w83DwN/frSX1VDpjH7uBrX/sJqxhbZp1aYRWUfik34gyx5gxqA/NQ2ux7KdYkmx24g+dLtXGU+vNSy0+RSJLZbr56vzpFljaDXA+UkoO5ezGQ+tFgyLjfTAjhV1pSYxt2BJvfenQNyklqpQ4G6z/1+Hj/HnoKEgI9/VhQofWZSZitI0IZd/MB53qs2wEf83twL4tdblhjJ3WU0u3kFIy5Z35HIhL5uXbr+P6LsUuEJ3GH4SjCrVSlIlp0ASdO6appCq2zH4E7LFI8zp0Ab8g0CCFHTdNmbV0rxw16cUXT6uO9dDqNHh5u1Gnfvl6oTFHzvDEbV8SEOzNxwsfxKMaNdjCG4Yy68m52Cw2vpz+Pe+tr9C94/D52mIBFY1NIdUSR57vFHwMTSu+zgnctaHU97298oZlXevtBlIiAYMTMbUVcdvzY2nXvyWRTcLQnreL7xvkw/sbXzn3c9yhBD66/yuklMTsi2P3igMgJXNOfkpgqH+5/XvodYxv35oevz3Jsm9WU791FAW5hXj6lDQCQghEJYZQlZJss5EAt5LX7s3exryEL5FSZXqT/xFkCOOmpT9hlyqHzqbybq9hJdrbpQ2zakJFpZ1/+ZuXUkp+23+YHJOZ7lGRaISC2W7jjZUbOJKSxv+GF0dlFFqspOblUy+w/N9FeWPY7SraIleMEAonDzQCLBzZHQJlGF+Lzc6BuGSQsH5/bAnjG+k9Cm99Awya4HNpxKGeg/HU1UWv+GHQlF8eSNpTQfgAGtC1xqANok/EX9jUPLz0rtuDcQlle8AuOdeU8a3XJJSFO19wfPkqWNXu2xaD1WIjPTmHxLh0GresnhpWrxu7sOHXrQy8zYnUZMMA0P6CRIPJmomfvk6FG2OXi3b9W/H+xlfQu+mc8l1XhKIoZQq3X0hAbT/0bnrMRguh9UIQgNBo0DqpHRvROAwpJe/d9Tn+tf344eSnVX6KuWX5z+xITeThNt15uF2xKLxO0RXFhQs0QotGKPjq3cixmAj1KO1iMttN5FgdGWZJxlPljrc/KYWXlzlq3fkP68/OJ++n5/uzyDOZSc7JO9fOrqpc/8X3ZOQX8mi/7kwpY1OyLCxWG1OnfceZlGzefGnsuQ2zp6ffwO9L9nL7LWX7Zw06Lc9NHMTGQ3E8UIb/2c/QqtQxL119DmW8jF2aaRX0ItoyVsAy607HYkPTCOH3AQBu2mDg8sqjVkqNmLrrcMbPO2h0B47uTaBWmB8Nm1c/K+npnx7h6Z8ecaqt0AQjghaiAGVHvpZPQu6vnCn4i2YBT+JrqL6cZXk0au/cSiQm/yh/Js2jZ/AgOgVUTT1MSslrt3zI/vWHefbnR5kb/xnmQjP+IX70HN2FoIgAfIOc92umncpAtatkp+U65UJKPHGGlT9soP/NPajbPJL96clIKdmWcprzVQZa+XZkWsNncNO4U8vNkRW4YvQUYnMzaRtUWmbRQ+vFrXXvJ7bgGENrlx8vXcvbE0UI7FKlMN3I488sYMaQbmTqrYxsVfw3takq6XkFqFISnX7W6d/H2cwCzqRko6qSnXvjzxnf7l0a0r1I90FVJVt3niQ81I+oOsUp1KN6tGRUD+fD/jKMWzhTsNTxvgp6Eu5dhptIeAEKaPyv+lpuroh2qN64V0rGvQw6duwod+3adaWncVUhpWRZfBtAJdCtq9PRDJeCt489RaIxHoPixlttZlfp2vzsAm4MmoxUJf1v6clTcy9OWCUjPZtX3vyB5r2bcs+IQZW2v7PVYyQcOU1og9p8f+JjNibF82fcUe5r1YV6vpcnzCmz0IjVZufBB+eSmp5LSLAPC76/t1S7bfGn2ZWQxK2d2pabcVcWP/26nRPRKTx4zwACA0qv0hf8vpOv52wE4Jfv76t2wVazPYNNSeNQpYUeYfPK3HSTaoEjnEzXHlGJb7i6CCF2VyZeUxmGOpEy7IlHnGob/9DjFz3e+VxzK99rDSEEtT0Gklq4hnCv6lWQqC751lyWpyyknmdjOgT0oGtgPxYl/VCt8u1efp6MfmgYe1Yd4KbpZW+oVYU/00+yrJWF5dkH6JvVlib+weRbzfxwdB+tgkLoGRZVon3dZuEkRSdTp2k4AL3Co+gVHlW640tIQJGQ+oC+zZj363YG9C37KaZrVCRdo6ruArplrJMx5xeJQRPEgDprKmwjFE8wVP1z8l+ixvj+C2gf4sjKMuYbObjxKE27NESnv/Q1wpal/MrmjNVszlhNU5/W9AoeXCJdV0rJ3Fd+JSk6mfs/nIxPgHcFvcF9791R4ufjO2P4euZcrpvcr9w05PJoWJR8YdBoCXJ3qJ29u2cTPxzdixCCXROm4WsoXjU+Pe8REo+fIaKxa8RvKmJXQhLTFvxBq7AQZt08GuW8x26r3U5YxxC+GHoHTWtffBHJtRuOsfdAArff0r3Uajc1LZeNW07Qu0djagX7MHZkRyLC/AkL9cPXx53snELuffQHzGYbn707sZQu8MWgSitHzr6JRKV54Ew0l6kSS3W4Um6HGuP7L+Lx/i8RfyiBrsM78tz8x6rVR0FuIdG7Y2nRo0mlBryeZ2O2ZKzBXx+Am6b0I2r8oQTmvfE7qk0lqkUkE2YWJ5BIKclOy8E32KdcP/xnj37HkS3HObL1RJWNb6/wKDbddA/uWt258K/6PgEoQuCjN+B2gQC5RqMpc0Nxy5lTPLN1BTc2aMGDbatfFNVss/HnoWM0DQnmj4NHyTaa2BKbQEZ+AbW8i43iZxu38+3W3QBsfuxuvAzVjzApLDTzylt/IgGL1c7MR4eWOD/jhV85nZjJ0pUH+fbTySiKOOf/BTgenUJmpsO/vOdAAte70PimFW4gMX8RAEHuXQj1dD6b8LIicVl6cVW55KpmQoghQojjQogYIcTMSz3elcaqWlic9CMrUxaVUlNzlmzzQTYmjSU664uSx9NzUO0qWSnZZV5nLDAx+7l5rJizrty+H+v9PM9c/xpvTiqt+3AhHQN68kqrz3i62XtoROn7dEhULQJC/FA0Cq0uiHL44rHvmBBxDy+Ofrvc/gfe2htFo9BzTOW6AFbVzv1rFzPyzzkk5eVwz+rfGbJ4Nkcyi7UTbmvWjqUj72DNmLswaJxbV3y4bwtxuVl8sG+zU+3L45P123h52Rpu+W4+N7VrSZuw2kzq0o5gr5IaxO46XVEMMmVW3DiWms49Py/ir8PHKx1Tr9fQuLmCwE7D+qWjCPz9PFAUUa4Ocrs2dejdozFdOtanTw/Xivt765sipYKUAl99C9IKN7Iz5V6yTHtdOo5LkE6+XMwlXfkKRwbBp8AgIBHYKYT4Q0p55FKOWx0KbWZi8lJo7huBVql+4sPurM1sSF+OlFbM5r8YVudzlDIMV0VEZ31GnuUYeZZjNPCbiiIcK9S3V73A9r/20Hd82Su0Pz/7mwVv/+EogNilEZFNwku1ycvKR1UluWdznZpLRQLwHt7uzDn5CapdLRHXC7B92V5Uu8qRbeUbkeH3Dmb4vc6pjh0+m8aqhBjsUmVBzEFWno5BlZL5Jw7QpXbxirahX9mxp2mmHNamHKZPSHNqu/udOz61RUdO5pxlZH3nxG3Kw8fdgMAhgt4wOJAFU8su5tqzQV0+Xr8VvU6LyWrF44Knj9dWrGN7fCKbY09xfYuKDeKRrJcYce8fxB4J5ZvZbgzo06xEBYs3XhzD8ZjUcgto6nVann3i0uwjnMg/zeocRwx7k+ACYs8+jUXNwmhLpnfE4kquvrxcq26HzkBMUeodQoifgZHAVWd879z2JQmFGQwObc3zraqvtB/uHoXEjkDFattLoS0RL11Ulfqo6zOBbPN+Ag1dMdlSzu0mhzWozeiHhpV7Xb1WdRxlbrwM+NUqO332nTUvsuvv/fS+yXkVKqO9kAPZO2nk3ZwAfckVlqIopdwKeVn5pManoyiCDk6mLFdGU/9g2gaHklyQx8j6zSmwWtiSnMBdLYulJ/MsZg5mpNAhJLzUyvfxPT8Qk5fCb6d3ML/XI+eOD67biMF1HVl9JquNswWFhFcjlffObh1pFxFKpL8f7rry3TkHklLOjRV7NouACwSCBjdtxPb4RHrWj6p0zBzLESR2gsMysdnt5OebSxhfg0FH6yqUCHIlvrp/EkQEXlofann0JzF/IcHufdmTOh2DJpDmgTOuuJwkcM1muIUD5+eAJgIltmSLRIfvBqhTx7kifpeCTEs+qlRJNzm3IiyPSI96PNPkeQ5mPIWfYQCe2qq/p1oefegR9gsbk0aRlrSeTiGfE+jeudLrOg1px9z4z0g8kYxqL07biTt4itdv+4hWvZrzwEdTGHF/1fxvP8R/wvG8Q3hqvXm55aeVttcZdLh7uWEuNFdYobg8pJR8vmk70WlneW5IPwI8PXDTapnaoiM/HttHttnEs537l7pu3NKfiM3NYmBkAz7tV7KMjb/eC0Uo+OvLfgS3qSrDPv+etPz8c/KR5bV7YtNSUgvz+bDPcIKLNvuEEHSsU7mhG96qKYdT0gjwcKd9ZOnNv1s7tWVCh9ZonYhXbxf8NvE5Czge04gXZrQmMqJ0yFxunpHok2m0aRlxLvPtclDfqwkzm72NRmjx1wdSy+0lWgU9z6m8+ZzKnQNCIdRrCAFuV1BU5x+uUeNbKVLKWcAscMT5Xql5fNH5TrZmRHNd6MWv1ALdm9I38veL6sOiZiKL8h6NtmTsqpEjZ99Eo7jTNGB6ua6MlXPWM+elX3D3dGNe4hfo9Dp+/3gZcQcSOHU4kYnP3EhAbefTVlfMWcdxEQctQa84t2Pt5mHg26MfkH76LA3bVa2YJTiqCX++cQc2VaV+UAAP9nGk7T6xaRm5FjMZpkKWjrwDgA1JcTy0/k96hUWRbTahSkmBjOWzmNcZWnsM9bwcxv+tdhM5nJNIc9/SrhhwpNmm5uWjSsnRlNIavP+wPz2ZpfHHsUvJH7FHmdqiamGfnno9r1xfsQZHRYb3VGY2Ty5aTuvw2jw9uA8tg2fS8jzPzaat0aSfzWf4kNZotRrueXgOGZkFDOzbjBmPDC23X1cgpeRk9tfkWY/TPPApggwlNRyE0BDo1glF6NFpfPHWXZ6SWhUh5LXrdkgCzt9ijig6dtUR5VWLKK+LD/1xFX6GVrQOehWrmkO41w0k5S8hqeBPQBDs3pNgj+KU2BzzEcz2dILde5ORlIlUVYz5RmxWOzq9Do1GQWfQ0bZfC/xD/Jyeg91m550pn4FW0n5aIx5986kK2x/fGcOH939F77FdmTBjNH7B5SuH7U9K5q1VGxnbtiWj25T0t4b6ehPq601yTh7d6hV/fAbXacSvMYcYXq9YD2Pe8f1km00siTvGilFT2JZ6msPmTzmeV0CuNYuZzd4CwKDR0T6g/BuBh17HZ+NHsPNUElO6dSi3XdOAYBr4BpJhLKBvRNVvLGVRaLLgptehKJXvuv+wYy/7kpI5lJzK5K7tCfMtdpHEJ2Tw0pt/AhKNIhgxrC0FhRaklOTmVa+cUVUotJ0mOvszJHY8tHVoEvBQqTbe+kYMqrsN4OrJfLtGS8fvBBoJIerhMLoTgNLlDf4jSCk5dCSJiHD/Skt7A4R5Fa9U/AytEWhRhA5vffGjfKE1ia3JtyEQtAh8jimv3UJ4w1Aad2qAu6cbGWcyWfbNGlRVJaxh7Sp94DVaDW37tWDf2sP0azkIT23FcbxzXlpA9O5YonfHctP0EWVW+5h1cDu/xBxCn6YlJi2Tg2dSShlfd52Ov++/A7uUJVaB7/Qaxls9h5aIm53Wuiun8rIZENmARv5BNPIPYt6pzmzLXEs7v8qrdJxPs7BgOtQNw0tXOvwrJvssD6//k9ZBofw14vZzovqzDu0gLieTmR37logrvhApJe+v3UxsRhYvXT/gnBj8n9uO8NKcFTSKCOLHmRMrNcDXt2xyLqQt5LwQNpuq8u7GzVhVO1qhUCvY8bf67N2JbNsVS4c2dav0u6gObpoQPLRhFNrOEORe/p7CVWN0i7gmV75SSpsQ4gHgb0ADfCulPHwpx7yamf3TZubO24pOp2HJgofROSkkA+Clr8fgulsAgTgvROl89S6BwN3TjVEPFhtt/1q+1G9Tl7gDp8qtO/ftMz+x9KtV3PrCTahWla7DOxBaPwQhBG+tfAGb1VYqmqEsrr97EIc3H6frDR3KLbP01u6N2KRKPTd/tIrC0OZl+4SFEGjL+JIqFxxrGVT7nAviH26uezfj69xZZihXeWxMimfqqoW4a7WsG3M3/m7Fcc3JBXk8v20lhzPTOJ6VwbQ2XYnw8iUm5yzv7N6IKiUR3n74W9w5mpLOHV3bc+dPv2G1qyyYMoEwXx+i088ye9sebKpK89rB3F9UdmfrkXgkcOJ0On/vPk6b+qGEBZb/xNAuIoztj99X6viR5DTWnTqF2k7L1I4d6NrJIdrk7+/JnHlb+eLb9Tz3xA0EBnixeOlexozoQNPGpbUqLgaNYqB3xBIk9ipH+FxRXGh8iyK8dgFJUsoKQ0ku+W9ISrkUWHqpx/k3sG9/AnZVYjfbOBmXVuUPf1k7w+66MLqH/YTZfpYgt9IrPY1Ww2c73yQrLYe9qw6Qm5lXKhPt94+WYiow883MH7GYrXw14weEovDWyudo2bOZU4YXoPuITizK+r7CNrc2bcuik0eY3r0XN9S7eDnN8qiK4QU4ke2oymyy20g3FpQwvrcs/5nTeTnoFIWeYVGEejh+f6Ge3vi7uZNpMlLHw5enlqxAlZJco4nMAiMSya6EJEa08iHS35dwPx/O5OTRvX7xKvTBUT1RhOBsbiEv/7ASvU7DmrfvLVPftyIa1wqiWe1gUvPyGdmtWCQnP99ModHheohLyOCTWWtIy8jj6PFk5n51V5XGcAaHnOe/y/C6eOX7MHAUqDRk5l/0W/r3M/7Gzhw6ega9TkPtkNKrG6vVTuKZLOpGBjrl//sHH33lAfIzr3uFxONnaNyhAe9vfIWP7v+K9b9s4bGv7mPy/27hz8//xjfImxM7T2K12lCEys7l+2jZ06E/YLIXYpf2Sl0PlfFi14G82LXkhlNeVj5fTP+eiEahTJg5+oo8lk5s0oalccc5mpXG8ax0GvsXq3556fRoFIUeoXX4dtDY844b2HzTvVhVO0h4z2szaXkFDG/dFJ1Wg8VuZ0BRxQ53nY7l999RSoEtNMCHVycP5Y15a9h38kxVKumWwE2nZcGU0rHFIbV8eO6JG4hLyGDc6E4kncli1dqjtGtz5SKLrjpcZHyFEBHA9cD/gEpTUGuM72WkR9eGzJ99D+7uerzKEHB/9KmfOXYihesGtuCJh4a4dOx/3AAanQYpJUtmrUSqkkWfLOPtVS9w40PDsFqsHNsRw/a/9nD6WBIjpjnmkGU5y+tHn8AubTzU6HnqelZ/l/rQ2VRisjO4vl5TdEXJLH99uZLVczeiaBS6Du9IvZZlGwaTvZAzxtPU9WyI5oKnAIvNxs6EJFqFhZRZXPJQRgqTVy2kkW8g319307mx/8FNq+NQZgpmu52vD+9k+HkljH4aMoE96WfoElI6lEyrKOf80iumTcZktWFVVQY2Kft3VN6NZfpNfejYJIJmdUKqvOr9h3m79zN/90FmDu5TQpinT88m9MFxg356+vU8eM8AfLyrp2h2LSKcF1MPEkKcL7s4qyha6x8+AJ4EnFqh1Bjfy0xwUPl/l8QzWdjsduJPOa/j6ixv/P0s+9cdof3AVgghmPzqzaz5aSOTXiiuZqvT62jVsxmtepZU2zprTiN7kwWNpyQlMqnaxjfHbGLsXz9ilyrPblnJQ227cXerLrTs2RRFo+AX7ENI3fLFtt89/hyZlnQ6BfTkpsgpHM7ZS7h7FIGGYGYs/pvVJ04S4efL0vtKV/X4K/44GcYCss1GTuflUL9IRnL+8f1E55zl4bY9eKJ9b34+sZ/H25cUx/fWG+gTXnlkg06j4eGFf7H2RCx3dGnHjEHO61XotBoGtq96TPT5vLFiAyabjXdWb+TXqWXvawshKjS8Ukp+X7IXu11lzIgOVXoC+w+QUZ6kpBDiBiBNSrlbCNHXmc5qjO9VxNuv3MTGLdEMG1y6ekBl2KWNr2PfJcmYwNDaY+gWVDIJwSfAm143Fue33DxzNDfPHE22pYBUYzYh7n7YrDbemfoZ2Wm5PDX3oXPi5imrckl80o6UEv82EVB+9ZgKUYQ4Vz7Hqlr4eP+2IuPbjEXZ36PRKmg0jpX5F5t2cCYnjxmDep0Tnymw5SGR5Fiz+SPpJzZnrEYjtLzW+ktyzWakhAKLpcyxJzRuzZbkBJoFBBPl44hzjs/N4rltq1ClxNfgzoNtunHneRlzFZFvNpNtNBHhV9J9tOf0GVQp2RafWL1f0kUwtl1Lft9/uHql3IvYsTuOL75dB0DtWr706l69mn7/KlzjdugBjBBCDAPcAB8hxFwp5a3lXVBjfK8iGjUIoVGD6hUXTDYmciz3ICp2Fpz+llpuYecKQJZHqimH8RvfxyZVPuxwB9pDRjb+ug1Vlaybv4WRRW4HnUGHIhQkoNdXXxrQW29g+ajJLIg+wC/RB5nSvHgRoTcUp+QeSUnj803bUaWkQVAAd3R1ZEE91PgFjucepENAd/5O+SeJxfHNeXf0MFYcjaZbvbJdFnV9/Fk8/LYSxwLdPPDRG8ixmGgV6Pi9H81M49mtKxgU2Yh7W5etj5tvtjDw428psFh5a+R1DD1Pg+HjsTewcP9hpnQtP1b4UvHckH48N6T8AqFSShb+sZv0jDwmT+yJm1vpNOjz9yLCQl1X4bki7NJCWsEafA0tKqyGfElw0YablPIp4CmAopXv4xUZXqgxvtcMoe4RRHk2JLbgOAqKU9lomeZ87NLh8Eo0ZjKwbTNCG4SQl1lQQpOhy7D2vLH8Wdy83IhqcXFfjkhvX6a378X09uWXIYr098XbzUCuyUzbiFBi8lKYE7uBEREd6FPLcUMYGTaRBl5NiXCPQiO0+LlrGde+9BPDilPRzDm6h0fa9aBlYAi3/r2AlMI85gweR33fADbddC9Gm/VcdMMHezezO+0Me9LOcEfz9rhpSxuofLOZAosVVUpiMjJLnOtUN4JOdctOM/6nyvGFPl0pJaezcgj19UanufgU4GVHTpBrMjG2bcsSY0WfTOXL2RuQqqRWsA9jRpS+QdSNDGTBd/c6nnKciEWvKkbrGbanTEWreNM1dDbpaVY++v4zwltsoXHLDAbV3Xz59R6uxTjfGi4fGqHl4cYvklgYhxAK4e6VB9U38w3n6ZajyTTnc31YO7SKhq8Pvl+ijSqt7El9lIKoU3QI+fhSTb8EPm5urH/4LuyqikGrZdKWTziWe4YtGcdZNeA5ALSKlrZ+lVdueHLTMrItJtJNhbzR4zoOZKRgVe1MXvkrX/QfRbOAWiW0f8c2asnGM/H0CKtbrixlbR9v3r9xGCfSM7iji3MrXJuqctM38ziels7n40fSp2GxD/mNleuZu3M/rcNCmDd5QqV9xSec5eEZP+Hr68EX792Kx3lVpw+cSWHm4r8BxybiyNbF/vtawT64GbQYTdYKn7D8fC9N2R+ANOMGjLYUhEgj23yQDz5PZNsuDcqmnjz18R+XbNwKcbHxlVKuA9ZV1q7G+F5jRHhULeV1aFi7Cs/nW2PJMG5GxcaZ/KU09r//YqZXAovNRr7ZUkrZKzknj6+37qJ/4/r0qF+XzoENOZ6bTDv/yt/bmfxcYnMz6R5alzMFueeSMobXa0rLwBAGRjZg6akTnMrL5s1d6/lu8E0lrh9UpxFHbnu03P7PmgoptFoZ2LQhA5tWvvFosdtZdvgEIT5eHE9NRwXWnDhZwvgeTk7DpqrsS0ohNiOT+kEV15TbtSeO/AIzhYUWjsek8svOQxSYLLw6eQj+7u4IAaqU1PYpWdnCz9eDX+fch8Vqx9vL+dpwriTI0B9b/i/oFB/8De1o11phx+44GtT3oFfEwsu+6hVUKdrBpdQY3/8oFpOFwjxjhfoLAF66BgS79yTfdopwr+tdN77NxnWffUdaXgFvjLyO4S2L/dMvLVvNuph4ft59gENPP8QDTYYwqX4fvLXFBiPPYmb5qRN0rR1JpLcfACablesWfYtVVbm/dVc0QpBtMaFXNPQNr4dO0fBZ/1FMXbWQdYlxVdbwTSnIY8BvX2OTKt8OHEuPsNJPF/lmM556/bmQso/XbeX7HXsRwEN9u3EgKZV7epRUqHuobzdu/2EhqpQs2HuQmZVESQzs15wde+IICvAiX9hYuz8GKWH13hh8PAw0lwHc1K8NXcqoA2cw6DAYLn0JqvJYuzaZj75w6JI0eDebCWM6M3RQK7w8DWg0l7y2Q2muYWGdGq5CTIVm7mj8EDnpOTw979ESURAXoggtHWpX7G6w2HM4a9pBkHs3dErpqrllkW+xkpZXgJSS/YnJJYxvu4gwNpw8ReNaQeeMmI+uZHjUE5uWsTbxJD56N3ZOmAY4VntW1bGMKbRaGNuoFT8d30+4lw+Nzkua+GbgmHLLzf++/wizt+3mkX7d8fY18NWhHUxt0YkutSM5ayrEVpQFkZCXTQ9KGt9nl6zkl72H8NTrWHLvJMJ8ffDQ6xACtELh9i7tS2j9Wux2bp79M9HpZ2kdVtuRndaq7KKa5+Pn68FbLztW7DkFJkL8vTGarXRqEskdb//M2dxCZv+1g9FdS5eDt9nsrFp3lLqRgTRr4lyG5ey/dzBvzT4eGdOLYZ0rn19FhNTWAyoaRXPOvVHdKsouo8b41nC5yM/KJycjFynhxK6YCo2vM+xIuZN8ayx+htZ0DZ2NlHYS8xfjpqlFsEfZFWwDPNx5a9QQ9iUmc3+vkuPf07Mzo9o0P1fttyzctVoEAsN5G1QeOj2LbriNo1lpDItqgkGjZfO40qXZpZRsSU4g2N2zRCYbOPyv2UYTb63aSEGwmdP5ORw+m8bmcfeiCEH/iPo09gtibKPShm19TBwABRYrG0/GM759a+7p2Zk24bWJCvQvJbKempvPsdQM7KpKhzphPDmwd6k+K8PX041FL00+9/OIbi2Yu3o3I3u0KLP9j79sZ+78bYDkl+/vK+XfVaVaKjV79t+7yDea+Xb5josyviezvybd90Oe/7Azrfw+vqS+5SpRY3xrKAu7zc437y7HbLRy98zrMZQRHlRVgsIDmf7NfcTsiWP8k6Ocn4tqZk/aI1jsmXQI+Rg3rUOCU0p7UZ0rx6rzdN7vHMl8HYCeYb/gpa9fZn/Xt2hSbqmc8xW7yuKNHkMYUa8ZrYNLrt6aBgTTNKD8RA2A308e4ektjk2pNTfeSZiXD8kFeexJS2Jc+5b8uPMAt3ZqS7Q9g++P7qF/pCNF+PYVv5BhLCTNWMCj7UvfVN4bPYzHfluKv6c7g4oy3BQhSmg5nE+Enw9Tu3XkSEoqt3Uq7Xvff+g0W3ec5MYRHahVQXLO+Tw4qicPjiq/ZLu3pwEhQKNoSomrf3FiJd/GrmV8ne5Mb16sCXPP9V2Zt3Yv995QeYFRKSVfz9lI0pksHrl/UAkDm164CZAUyP1Xj+Glxu1QQzns23aSpT9vR0pJs7Z1GDiqfOV/o72QXGs2IW6Vl0cfOLE3AydWbaWVWrias8btSFRSClYS5TsRgM6hX3PWuI1gd8eX3qBxZGEIFDSK679kUkruXbOIrckJfNRn+LkyQOdz1lTItLWL8Te480GfG0pELthUO4KiwrVFy54Rf84hz2JmSN3G7JkxjX3pybzx9zpaBNTi2c6O2Nk63n5kmU2Eu/sw/felNAgK4L6eXc65LzrVjWDjo3c7/T6EEDzWv0e55x9/9hesVhtxpzJ486Xql7Y6n9HD29Ogfi1CQ3xLpbivTDkAwOrUgzTOrc8rc1fSv21D3rjzeiYOcK7iRGx8OvN/24ndrrJrbzx+vp588s4t+Pl60CLoOWKyvyDc69LUjas2Nca3hrKIalwbvZsOm8VGk9Zlx4/aVBt2aeN/Rx7DaC9gdMTt9AyquFqCs0hpBvM6EkwnOJz1DQoKHtpIQjyKg/kNmgDCvIpry4V49qO77id0ig/u2rKLN14MJruNdYmxSGDRycNlGt+l8cfZnXYGRcDu1CS6n7c5diIrgwA3Dx7v0IsIr7I3HFefjqHQauVE9llO5+XQ0C+QH4eMJy4ni9WHTvLp4W1oFIXrmjaiQXBxyt/q4yfJN1sY3qppKfnLqlI3MoC4Uxk0bli9xJuyEELQpmXZsdpPtxjN7Ni1TIzqxXc/HsBmV1m1JxopJTZVRasolYoehdb2IzjIm7S0XIwmK2ZLLoeOJNGzWyO89Q1oV6v8atZXBFkT7VBDOQTW8mHepmdAyjI1cuMKTvBJ9Kt4aLwotBcgkaSbzrhsfJnzApiWUhvJYQQS6Bn+KxqltDDQ+ZSltHYyI5M9p5MY2rwJXobqZ8q5a3U81bEPq0/H8nC7sleOfcPr8YW7J74GN1oFFd8Acswmvj2yGxXJusQ4Rjdw+Eb/GD6Jveln6B/hcJFMbNKWfenJNPYPokGRDoRBo6VpQDD5URa+2LSDEG8vQs+rJHHgTAqP/eZQT9VpFIZVUn24Mj5/7zbSM/IIrX1pM802px9na/pxbq/fl086TQXAd7Qv7y1cz9DOTdl0KI7HvviDeqGB/PjULRUmgni46/np67vIyzfx6tt/odUqdGwXdUnnf9HUrHxrKI+KQnBO5h9DlSqF9nzGRNxOgS2f3sHOlWN3DseyQCvcaeBzMwEeXSo1vBdyJDmNNSdO8s223djsKtvjE3lndNXrid2/4A82xsTz1qgh3N2qC3e3Kn+jUK8F76BMJFComvDGMWcfvYFhUU3YlpLAzU1an2sf6ObB0LqNz63sant688N148rqmo51wtkzY1qJlWCeycy66DjUoiiKC2OXq8L+pGQe/vUv2keG8e7ooZdUYtOq2nh8zw9IKcm0FPBaW4csZfO6IXz9mOP9vz5vDaqUxCWfJSsvl1p+FdcA/Ee8562Xx5JjPkJ03qvUEePwNZS9CXilqfH51lAtugf2J9mYSLAhhO6BA1z+RRW+L4OhL0Lfliaayn3JZTH5x4XkmsxoFIewjo9b1Yw3gNVuZ/XxkwAsPnCk3AoY/3Aw5zQ5FiM21c5HO9bzv94jAIdh+KTfiBJtvz28i1d2rKF/ZAO+GTjGqflcuPp7cdlqVhyNQaMIFky5mca1SkZRJGRmc+ucBfi4ufHz5PHnxILKYsGegyTn5rHsyAmeHtyHIK+LS/NVVVmmOll6dj7/b++8w6Mqsz/+eadPMkkmlTRCAqH3XhUUEGyIqNiwIeuq+HNXXdviruuurnUt69rYta4iujYQkSaoCNJ7DxASUiC9T6bd9/fHHVLIJJk0EmA+zzMPM/e+994zM+TMe897zvf8sieVeHM4GbZ8+lu962LMnjqcnOKTWMKXsKP4My60fINJ51soZHvOQ1S4jpNv28iEzsta9D7aDL/z9dMcAnQWbklsvaqz0xHCBObLkFKSZ/sVky4Giz6xSeeIt4ZwMCePK/v1ZFr/3nW0D7KKS7j23U/RaTR8OecmIr04G71Wy7xLxrP8wGF+f1H9i1SnGBfZC4rNOJ1O1qZkQwNri8vTUpCorYR85XBRPkattqrAIzwgAI0QBJtMdI+sK/u29mgaBRU2imyV7M3O8VoAcYqbhw1i2/EshiXEVfV6ay7/+uYX3lu+mRsvGsSgbnGEBpkZ1kO99t2vfUlmXjG9u8Tw7X13EmHy3nyhU2gQD91sZk/+ARQpKHem+ex8Q42DsbmyCDU2XEnZbkj8ztdPx+Z46RfsK3geAUzovLwqo8EXFtw+k7SCIpIjw70uQm1Nz6LM7kAAb/+yiQMnc3l00oUMiKu9WHfryCHcOtK3VXeTVs+f+l3DG2s3cO+k+ps5Ajw1ahL/2LaWq7tVV7wtTzvEo+uWcWViL/42pnYYZ+OJ49y24n8AfHfVbXQLCefRyRcyuVcy3WsUhtTk0j49+OHAYawBZgZ3bvgOok9MFN/fe7tP77MxVmw9BMCSjfv5et0epJR88vjNdI0Jx2xUC0ACjIZ6He8pYgIvpdRxGJ3GQpjJey9AbwyIfIZeYQ9iaML/lzOJwB92OOuoqHTwuzcXYbM7eW3uVYQHt74CVEdCkapOrkQiZdOWh406XZ3b8JpM7NmN1SlH0Gu0fLZtF063wnMrf+I3Y4bzxs8bmDN2OFN7N11X9rK+PX1a9NK6BM+MvISoGrnFH+zbRpG9kv8e3EFSSBiz+1Y7nPzKiqpUtWK7HVDDGfWpmYFaVPLeLN9CGq3Jn2ZN5v3lmxjQNZYPV2wBBEZPT763fncNu45kMaRHXbv37M/ku2W7uOaqoSR3jSK9opiYoHuwGnz7fy6lwqHC17G78+kT/miH61hcE7/zPcvYfjiTPceykRLW7k5l+ti6FU8A//jfj6zYdognb7mEMX0Sz6yRrUiX4Bsx6iIJ0MVj0jVcxNBUAgx6Xpmh6kZIKfl+/yGuHtiHp5evIaOohKeXrfHJ+UopybQdI9QQSaDOtzLnFftT+MM336PTaFgx946q+OrvB49lw/fpSGDx0f21nO/ULj2oHOMiUG9gSFQsS1IPcP9P3zIsKo7PLr2x2Y7G6XZTaXcSFNB6ojfDe3ZmeE81zDCuXxJBZiNxEWr2REl5JW8sXk9ClJWn77gUXY2F3Sf/voi8/DL2Hczixj8N5em9X2HU6Fk0/mEs+sbtK7LvJLXkI6SUBBt7kxhct79ch6GdnG87KFmcGwxKjqN3QieSosMY18+72paiSD5ZvZ3conL+u3LrGbawdRFCQ0zgJYQYmyZGU5MC2xZ25z5JmeNIvWNevPpS9vzxd1w3uD/XD+mPQaslNiSIw7mNt1Zak/Mdrx56kr/vfwiX4vLJppyycpCq5GO5w1m1fWR0Z/45/krGxnSp0/BTIwQzkvsyxZNfvOzYIaSUbD6ZQaW74euuOnCY3y78ht1ZJ2ptd7rczPjLh1z88Dus9IQKWpt+idF06VSdqfD9pgMcyshlzc4jHMnKqz22TxwajWBg/85k2gqQUmJXHFS41Zm+lJJNB9JJPVFbz9jtVlj9034yUgPRa4IQQkOocVCbvJ9WQ/r4aGX8M99mEmgy8N4frm9wjEYjmD1lOCu2HmL21BENjj0f2JrzO5xKMSWOQ4yN+7TR8XeNHcHn2/awM/ME93+xxGtvtpoUOHJRkFS6bbilC50P/72vH9IfrUYQGxJMlzBrrX1Xdu1dq5EmqOI9X2zfg16rYfqAPggheGjIOCpcDi6K74bZi/h6TR5ZtIxyh5P88opafdZKK+ycLCgFJNsPZzJ5aA8KSyvYc+wEI3olVIUKWpOLByfzzfo9JAzIY7PrS+KcN2PRq7Hfvzw2jaLiCqwhAdgVF2adgaTAKKJM6qz52w37eG7hapCw6K93EGlV7zS+XrKd+e//hAQW/GcR4eEBaET7qag1SiupmgkhTMDPgBHVr34hpXyyoWNaNPMVQlwnhNgrhFCEEMNO2/e4EOKwEOKgEGJKS65zNnPf9HEs/tvsqlu/4xWp/Jy7jEp3RTtbVs2erce4c+pLvPvS9216HauxP6AhzOTbohlAz04R6DQaekc3Huq4MvZGpsXeyNzkeRi1Jlamp/DPHespd3rv6wZqFsWNQwdyYbdE1melcby0uMFrrD54hGeW/8i8H1by57WrqHS5SAoJ473J13JLb3VFf+neg0z+13ss3LqrzvETuqtFHFN61Q6jhAUH8KdbJnP12P785jI1f/nW5z/lkX9/x1P/XdHoe28OXWPC+ejPV2HqsYetRb+wOmdJ1T4hBKHWQIQQmLR6bkocx+jI6vQ+h0vV85CAW6n2XiajDoR6d6DT6Tq24z1F68x87cDFUsqBwCBgqhCiwZXelv6c7gFmAO/U3CiE6APcAPQFYoFVQogeUkp3C693VuOWLl479BcUFI5XHOPmLnUVt840lTYHf77rfWwVDr5492du+90l6PRtI2g9rNObOJQCjNr6F99O55/XXkFmUQnxoY1XeRm1JiZEqWXOORVlzF2zGAWJ3e3i4aEN61i8t28rL279GY0QbLj+XoIN3vNwOwVbcGsUKqwOFqbuJNYaxD0Dav+NvfrjetILi3n1x/XcMHQANqeTZ5b/iFmv54XpU3lh+tSqdvM1uXJUH64cVR3WcbjUpqWVDt9CKI1xNDsfk0FHbHj1ZxmkC8aqD6PImU84iTy3cDXjB3RjdB+1HNuluDhecZS4gMRaralmjO1PqMVMTFgQ0WHVoj+XTxlAfFwoEeFBbdKGqC1ojfJiKaUEyjwv9Z5Hgy67Rc5XSrkf8LbAcBWwUEppB1KFEIeBEcCvLbnemcTlVtBqRItWafNLypn90ucAvPeHmYQGmTFrA7C5KwjRW5t1zpzKbBamz6erpRdXxDYc9vCF7OMFODx/3D36x7eZ4wU1btwUxwug1WhIOC0c4AsWvYEgg5FSh50e1saveWp2rEiJ4iWbw+Zy8u89m0kKDuXL2TdzzfKPcSruqjzfmlwzoC//WruB8cmJACzfl8Li3fsRCC7olsiFnu2N8f7DN7AtJYMJA7v5NL4hNh5I5/dvLgLgsyduISFKtVuvMfBEn1dwKg4efWcZa/cc46tfdrPx9fsRQvDhsX+yr2QHnQOS+H2Pp6rOp9EIJg6uuwgqhGBQf+/FGh2VJoQdIoQQW2q8ni+lnF91HrUNx1YgGXhDSrmxoZO1Vcw3DthQ43WGZ1sdhBB3AXcBJCR0jC9t88HjzH39K+IjQvh03qxG421lzkoq3Y46uZJbUzLIKSoFYFuKGsd7rPeL5Niz6BLQeAsab6zJ+Y4j5Qc4XHKA727exPNf/oXgMO9yg3lZBSx+YxkjLh1Mv3HedVgTu3di+q1jyUjN5f6nZjTLpo5IgN7AFYm9WJZ2iEhz4zOwewaMJNIcSKQ5kAUHdzKpc3Itrd8P9m3l9Z3r0QjBiumz+fnauyi02+gWUjd/dVtmFk63m293H+DZaVMYEBeNTqPFoNXQq5PvPz6x4cHEhjd/gbMmhaXV6XFlNnutfRqhwag1MbBbHOv2HiM5tjpXudhZiCIVSpxFrWJHh6Npi2l5Usp6k5w9d/aDhBBW4GshRD8p5Z76xjfqfIUQqwBv0lTzpJSLfDC4QTy/HPMBhg0b1k5JH7XZsD8NRZFk5BWTW1RGfKS13rEF9jKuXfsyDsXFK0NvY3h49SxlbN8kRvRK8DxPBCBQZyFJ13BpbEMMCR3D+ozVVOxxk/7LcXas3sOF1472Ova1u+ezcek2vnxlCR8WvMIPOd8y0DqCXsHVmgZCCOY8fJnX489m3IrChwe2AfD2nk21VM28sflEBk9uWIUiJRLJB/u2ssnTIQOgW0g4UoJBq8NqNBNiNBFm8l59NjYpgZ9SUukdHYlGCLpGhLH54XsQQtSrdFbpdKHTaryGI2pSWGHjlTXr6B/biesG1+3WXB+XDO2Jy60QZDbSp4v36rQ7pgznilG9CbVUv6/ZSQ+wvehX+of4Xlhx1tH6DTSLhBBrgKmooVmvNLrgJqWcJKXs5+XRkOPNBGrWT8Z7tp0V3HjRYCYOTubuK0Y36HiLHBVkVhTgUFyA5FhZTq39gSYDr907ndfunU6AycBb367nkkfns2pbSrNt6x7Uh8q5saTdraDTaRk6eUC9Y7sNSkSr0xLXPYb/ZbzH+vzV/PvoS82+ti+kFn/CxuzfNJhOdibQajRM7pyM1WDirr7DGx2/K/8ECtLTyUEQG1j7LuZgUS5aIXAp7gYd5K6sE/xyNA2jXsehnHx+TU2vskcjBAu27ORPS1ZRWGGrOmbr8UyGv/gm41/7NyWVlQ3a+e/1m/li+x6eWrqaEyWlXsdk5hXz064juNzV4RONRnDFqD5YLWaOZtefthcZYqmV72s1hHFR1OVEGFtP1rIjcarCzZdHg+cRItIz40UIYQYmAwcaOqatwg6LgQVCiJdRF9y6A5va6FqtTkRIIM//pmHB512Fady7+V0MGh33dZ9ChdvOtHjvswO3orDlUAYfrtiCw+Xmg+WbmDSkO1JKfszZh0VnqjVjboy/fPUwKz/6iQuvHU1gSP231Lc9dT2Tbx1PZOcIfixcwqHSPcSbE6v2f/DJOn785SB/uH8K/Xp7jQo1CbdSyf6C5wDJwdzfMST221atbJJSsiblKGa9ntFJDYeo9uSfZG3WMQBybOWNnntWr0GcrCijS5CVoVFxdLfWDie4FU/PN6FW+dXHvG9XcChHdW4GrZaj+YVVtmYWlfD3FT+iSElogLlKSH1nxgkUKSmttJNZVEJwdP1FDMMS4vhw43YigwKxmuu2WXI4Xdz4zMe43Ao3Xjy4VleL1TsOM++97wHJY1deyORxfQgwN1/a81xBKK0y9Y0BPvTEfTXA51LKJQ0d0CLnK4S4GngdiAS+E0LskFJOkVLuFUJ8DuwDXMDcszXToajMRmZeMX26dKpyJBm5RewoVGc0TsVFt+Boulk6YdR6T6t5Y9E6Fq7ZgUYjiA0L4q7L1TDBquzd/G3Pl0gk7466mx7BvqmGxSR14tYnvcsd1kQIQVyy2mbnkuirGR1+MYE6NT7sdiu8/8k6AD5asJ4X/nZdvefxFY0wEq6PpsCZRYw8Cu7joGu9OP7qQ0d58OulIOHj266jf2z9Qu0hBrVdjpT4FPO16I08OXJivfvvGzianqERdLdGYNHXr0h2UfeuHMrJZ3B8DOO7J3HdoGoZxfDAACItgeSUljMsofrHbuaQfhwrKCTeGkyvTg2n1F3coxsbHrobk17nVVdXoi4aArVmvgCVDidCgN3h5rW3V7P2p0O89HTj/4/OaVqpgEJKuQtoknpQS7Mdvga+rmffM8AzLTl/e+N0ubnmqQ+psDu46/JR3DFlBFsOHee+179Go4MZt48gwmLh0W0f45AuXh16O8O8zGBLbXYkEo3Q8PVf70Cv1bJhfxrzPl+GGObCoNdi0LR9vUuQvjrF6GjFfrqOkuTsNTBjmu95tw0hhGBE1N+RBbNBlwTa1u1iYdbrqnJLjbqGP6/OQVZWXT0Hm8tJsrXloi4211G6Ba8iJvBKoO75imyV5JdX8ODF47j3glGYvCzSmvQ6Vt43m0qnq5aYvMVo5K+X1+08sjMzm98uXETPqAjevXlGVbgjqAFJTqNexyeP38yhjNw6WRKXDu+FUa/jzbdXU+Iqw+E8K+dDrY5f26EDkJVfjMVkJDhQve1zuRXKKx1IIKdITeE7UVCKEALphsusw9CFSv5zZDUgOFqWw7DwbmqPMKFq1wI8eO14+iZG0z8xumq28sueVNwn9WjXh/LyvdeQaIk6o+/1k7S3Cb4yj8RrIhnVt+WpTKcQhuHQaVeD4YYT5T+Qa/uFriGzSS/5DK0w0j30XtQ7ttpIKflixx5cboUKp4tx3bowe9SwBoV6ThFnaVipqylsOTkXmyuLHNsaxsV9UWtfmd3BJf96n0qXk6cum8TVA+vPUNBpND538Vi69xBFFTY2p2Uw68PPKa60M/+G6XRuJOe5S6fQWmXEpxBCTQ8b9GwMm7cfY8wI9XtPzynkxc9/ZFy/JK6fMMgn284p/M63fVm94zCPzFdjlJ8/cQtJHsm9+Q9cx760E0wbrd4+XjqiFza7k+BAE326qDO7h3tfycnKYq6KH0ZqWQ53/Pomeo2OT8feT4QpGLNBz/Qx1cI7NruTKcN6kl1QSr/EaIbHedeGaEsGWofzY+73DAhpfDGqKUilCEQgao55XdzSwfacB5FISh0HKXEcBAShpiFEBtTV6f3laBpPL/8RRZFVt9MD46IZmtA8YXeACqeDx9cvx6DV8fToybWaa9ZHoK4Lla4cAvV1OzHbnE5sTicSSXphUa19eWXlvLJmPUM7xzJjUNM6Odw0bCA7MrKJCgrkx5RU3FJh5YHDzB49tEnnOZ3wMAtTJ1b/f3xz8XrW7T3G+n1pTBvdF7Ox+rsr9aSlBZmbLoB/tuCf+bYzWw8dR5GAlHyzfi8PXKNWRA3oGsOArtXtybUaDdeNH1jr2Ks6VzuwvUXHcUsFt9vJkbKTdXJ/HU4X0598n6JyG/NumlTl1M80V8ffyrS4m9F6mW36giIVHEolJm11WpJS8RmU/AW0cRDxPcJLaakGPRZ9V8qcRwk3jaHUkYJAW297+eggi1p/DwSbjJTa7QyKb77jBViRnsLyNDXjZEpCdyYlNJ5zPSz6Dcqdx7B4cb6RlkDemDmNw7n53DisdvbJm2s38tXOvXy9ax8Tuic1qb1QlzArn82+AYfLxdz/fcvJkjKm9mm6tGZjTBzcnVXbUhicHIfJUO0SjmbnM+u5BQgEnzx+E4nRYa1+7Q6B3/m2L7+5bBQrt6ZQYXdw+UjvBQmnszUlg9yiMi4Z2hONRiClZFJMf3YVpROgM3iN/1bYnRSW2ZBScuh4LnhP0W0y0tM7rCk01/FKKfnHwXlk2tK5vvMcRkdchFLyAlT8Rx3gzgJZDmrmTS2EEIyN+x8upQyD1kqydQ4g6u0L1z0qgpX33YGUEG4JwOl2Y9a3TC9gaFQ8ATo9Oo2WARG+xaU1Qk+QoX7Hd2Fy3co1t3RBzCrGT8wg6+DQBmO1DWHQ6biwWyJ/X/ETr//0K89Oqy2V4nC7mfvZYjKKSnj7hqvqCAQ1xuShPZg4uHudVkNpJwsB9ftOyyk8N52vv3tx+2O1mFnx/F0+j0/PKeK+179CILDZnWw9nMGyTQd5eOYE/jjh6jrjv1m3h/dXbObuK0bz4l1XsOfYCW6d1LLbRwCbw8msZxeQnV/COw9cS/+kmMYPaiEu6STTlg5IDpbuZnTEReBY59lrhOBnEBprneOk6zAoBQj9cAxadb9W07g2bE2R88aKEE4ns6yEmUsXYNLp+PLym7EazXQOCmHbTf/n0/FZxSV8sX0PE3t2o29M03Jd8+25FJGO0eRm9qSIBrv+Nsai3ftRpGTZvpQ6zjclJ4/1qem4FYUlew4w98KGO3d4w1uPtwsHdGXOparIT32yqWc77dnJwq/n20yMeq268AZYzEZWbzuMIiVLN+33Ov6Nxes4nlPEG4vWMX5AN+ZOG9sqotmZucVk5BXjcLvZsD+txefzBb3GwC1d5jIsdBzT4lRZRBHyPJiuQoT+B03AtDrHSHcWMm8GsmAOVH53RuwEWJedRl5lORllJWzPyWry8Y98s4w3127kzgVek3oaJMLYiRFh40kI6Ma4yLrZDE1h3pQJjOwSz9+uqHsek15XFQ93K603jdNqNMyeOoLZU0egbeKP3lmFlL49WpnzYua799gJnvhgGSN7JfDYDRe3yjk7hQaxcN4tFJfb6J8Ug8ut8M36PbWS2mtyy6RhfLhiM7dNbt0yzW6x4dx88WCOnSxkxjjfy01bytCwMQwNG1P1Wuh7Iawv1n+AVKsA1SqF+iUeW5spCd35LvUAATo9o2PUnOODJbv5OvO/BOut3NJlbq0UvNNJjgxnR2Y2ic0Q99EIDTck/MbrPreisD0ji+TICKzm2j/CvxxJwy0VxidXzzYHx8fy0a3ec7GtZjNmvQ6XotCzkTxhgOWbD5JXUsbMCYOqZuPZBSWs3n6YiYO711IpOx9or5mvkG3g0ZvLsGHD5JYtWxof2ET++N5Slm0+iBDw40v3NGvGuXF/Gs8tXM20MX25Y0rHEUYvcOSyq2gzA60jCTVU559KKfklbyXFzkKmRF+NXtP+lUzSsROUHDBOalblmyKdpBS+gUYYSbb+FiGaNxt7dOedVCqqnvLU6Gu4NObaBq4pSc0roHOYFUMLwgankFKSW1bO/HWb+N/2vYQGmFlz/51Vn8fmtAzmLPgaBLw1cxpjujasSXGKk6VlFNsqG03BO5SRy20vLEQiefi6CVxzgbpAeN1fPyItp5Ck6DAURXKisJQ3759xRsJYzUUIsbUhoRtfsIR1lv2n/N6nsRsW/qHF16vJOXwvUc3M8QMJtZgx6fX844ufaM4PzttLfiUtp4i3vq2rirkv7QRvLV7PiQLvtfatSanNzrLNB8grVktm3znyAouyFjD/yAu1xmXYUlmU+TFrcpawIf/HNrfLF4RhIMI0uVHHe6jgdVYcG8XhwvdqbT9RvpLUko85Uvwuebb1zbYj2aIuqAoEPYK89947hUYIukWGN8vxKlJS7qg9y3/wq6VMeO0/rElJRZGSksraCmNVCnqSetX0imyVrDuahsNdXSTRKcjiU+5zqMWMViNAQnxE9Yw/LDgAjVAXjY9k51Ne6eCd7zY0cKZzB6H49mhtzouww6BucYzu04Wlmw7w7YZ9PHjNeLYcOs6899VQxCv3TGvUIcyaNJT0T3/gypF1E+jnvv41JRWV7DiaxTu/r38W1Ro8+u/v2JaSQUx4MF//5XYCtEY0CIJP0we26sPRafTY3XbyHCc9gjEd87c2z7aRfNsGEkNmYdSGk1ryEW5p41DRK3QKHE+QQc0aCTL0QCAQaAjUN38BaE7Xh7C5KzBpzW32mShSMn3+x6Tk5vPctEu4aoD6/2Zn5gncUqLTaHjskvEMT4ir9X9vQGw0n95+PQqSfvUs8M1871NOlJQxpXcyL06/tEl2RVotfPv0ndjsTmLDq9MgX7t3OvvTT2IxGbjp2U9QFMmMeprCnmv4sx3amAv6d2XjgXQu6JeEViP4btN+7E4Xa3cfxeFy1zvLODVLnji4e5V4tNPt5vmFa7A5nDxx0yQ6R1o5eDyHrjEtL2NtDFXgXZ2RZZevIFn/PZ0sFq7s8kqtcUH6EOYkPcRbh59jXe4q4s2JdA3sRaAusFZubn24FRsaYaz31v5kZSZfZ/yXviFDuCDykma/H0U62XzibiRubK5MBkW9QGzglRwv+x+gxakUVb8nQzITE35CINBq6orK+IoQggBd23ZZqHA4ScnNRwLrU9OrnO9r117O59v2cNOwAfSO9l7V2Cem4WrHcocD6RHiaQ6hFjPWQBNlNjsWT/GEyaBjcLKqN/HDC3ejSInV0vzP+KzBk9vfHpwXzre0olLtgyVh19FsLnzoTa69YADhwQHkl1Tw0Yot/Obyuuk5x3OLuOW5BRj1Ohb88WbCg9U/2E0HjvPdxv1IJKN6JfDvB65l44F0hvWI52h2PrHhIbWS1VuT5+dczq/70xjSPZ4C5wI0KFi1pQjq/iGGGiLQaDRIqZBTeYKF6fMxasw82fefGLX1x72zypaxI/cRgvTJjIv7n9ey3++yPmd/6U4OlO5iVPgEn2LKiuKCwjng2oGwvoEwjkWgxayLwebKJsjQC4B+EX8i1DQQrTASZqqdjqfT+F6k0J5YjAaenXYJ64+m88BF1ZV7/WOjGxQE8oVPb7ueDceOM6V38wsu/vje96zYepAbLxpMdGgQ3eMiGNlbjS+fKq8/X/BXuLUlQr1ZlagC6VLC/vQc3B7VpxVbD3l1vjsOZ1LpdGF3ujmQnsNYT65jr86RBJmN2F0uBnaL4/0VW3h/+WbMBh0VdifxESF8+eRtrSqneIoAk6FqBh6szEIjDAToOxOgrysJGaw3c1/XGzHr+7C54FckkkrFRqVS0aDzzbP9AkhKnYdxyQr0ou7q96DQUewu3kKypQ86H5okStdhyL8WpLrQJW2LVecrNFwQ9xWV7hwC9Wo2ghCC+KCrfPk4OjTTB/Rh+oDW6URxsrQMq9mEUacjIczarNZKNdl0IB0p1fbxZZV2BIKlz8whLPjs+HFrVfzOt+0IMhtZ8MebScspRCsEizfs486pIzhZWMrCNTv4zeUjvR43cXB3Xv1qLYVlNg5n5VU53/DgQJY/p6YQCSFIPVGAW1EotTkASVZBCVJCG/jeWmg1RpJCbql3/4asWyl3pRNlvpBJnZ5FK7TEmbsQom+4Uql76FwU6SDcPAq9xnva0ZDQ0Qy2jvL9B8axxZNupgNtV4SluqBFqzERqOkYLaSaSpGtksW79lNir2Rc10QGxTcvO6Dc4SBAr/f6eX69cy9PLFlFpCWQFffd0SpZF8/NuZwv1+6iS1QoH67cgsmgr6XpcL7QnkUW54XztTtdfLF2F0FmI3MuHVnlRHvER3JBf++aAgBmo55Smx0BbD6YwW2XVGs41Pwjeez6i0iODadnfBT7j59kVK8uXiuGzjQuWQ5S4lRKMWpNTI25pmpfkaOAd448T4AukLu6PlJrJmzWxTAo6gVvp6xFzc9AutJBliH09cz0TFeAYzNoQhFBj3sNZbQE6UpDFtwEwoII/xyhabzb8SkUKZn37Qr2n8jllWsuJym8riLY6TjcReg1ITzyzTLWHjmGIiXz121m/YO/xWJsWhnxhxu38eyKnxiZ2JkPb6lesK10unApbnZnnUSipqhVOJwYzC3/7Ib37MzwnmqzmSnDexIeHHheOl+kbBUxdSFEZ+AjoBPqXHq+lPK1ho45p52vlJKlmw7w675jrNx2CI3QMLR7PEN7xPt0vBCCF39zBau2p/Cby+ov2QwNCqjaf+GA+p35mWZU9Afk2tYRHTi51nYpFX7J+ZCTlRlohJZjFYfp2UjKVUNIVzoy7wpAQujrCOOEOmOExoKw/qPZ12gUx6+gFAMl4NwLxjGNHnKK44XFLN59ALei8Pn23Tw6qeE28wcKXuNo8btEmscRGjCtKkXLqNOh0zTdMf50+BgS2JKeWaXRkVNaxuVvf4Td5eb/Ro1EXwbdwkIJbqJj94UzsVDcoWmdma8LeEhKuU0IEQRsFUKslFLuq++Ac9r57jqazdOfrFIzFiQYDdqqltm+Mn5gN8bX07p7x+50Fn65metnDGfwAO+3zbnFZWzYl8aFA7oRcoYXMsz6WBL01VVRLsXFf9P+hXTtIEyzj0BtHBGmPiQFNr5wYyuzkbItld6juqM3nDZDkjaqqteU4tZ9E75iupS04o8pVVz01HanKS4qzhrMmK4JHMrJY1q/Xo2Oz7dtABQK7dt5+orXmT6gD1JKenaK9Cqi3hhPTJnA6z/9ymV9e1TdTRwvKsbhcgOSH/cdRVckSS8uoMxmP+8WxNqa1gg7SCmzgWzP81IhxH7Uju3np/MNDw6oiru+du/VDE6OxeDjH4fd4eLBdxaTnV/Cq/dO9+q0n315KSdOlpB6LJfPPrjb63nufvVLMvOKWfTrXv7zYPu2bEmrOMye4m1E6AqIDnQyNvg44+PfxFCPolhNHrroL6TtPc6oKwfzxAe9QT8IoVPvIIS+J4S+hXQdQ+qH4C3g4lDsPl2nuVS4izlQmQkomEo/p0fo3EaPOYVOo+HfN9YVQ6qPAZF/42jx+8RZpqHXahvtJ9cYa1KOotEIhnSuXjQdEh/L/00YTVGFjat69eIl50+M6NXZ73hbG7Xvkq+jI4QQNUtw53u6r9dCCJGI2lJoY0MnO6edb3yklcV/nY3D5a6VUA5qLfuLn//IkOQ4Zp2mLvbDthQe/c93VTm+q7YdYvbUuiXFY0cl8+WibYwdXb8erEGnRYj6q5XOJPHmRGLNCZS6QugT8TCRpiTMOnWBKKPiGKWuInoFDfS66FOcV4LiVijM3Iks/ghEAERtqB6rjYXCe6H0eWTYxwhDtebxF8ffZ23eCsZGTGJm5zvb5L0ZtREYteHY3XmEmprUSqvJBBmSGRhZf4esPNuv7Mh5lMiACxkY+XSD5zpeWMwrq9ehSElMcBB/mHgBoIa85oyurmRt6+Kd8xrfZ755jZUXCyEswJfA76WUJQ2NbX+P0MZE1NPd971lm/hp11HW7j7KZSN610qxWbU9BSnVHrVdo8O4ZGgPnlmwimWbD/LETZOYMrwnAPf/dhL3zL4Ivb7+ON87v7+W7UcyGdGz+bOjEwWlBJoNVd0EjucW8fcFPzC0R3yV5J83Dpbu4aNjr9MraAC3JM7FqDXxUM+6zqDAkcurh54EYGbn2YwIH19nzIurnmTT0u1cMHUNsAtOXzBT8jxPnMiyNyH0raoCjX0l29GiEGz/BlmZgDDVjkEDSOch0IQgtM1rUa7TBDCh8zIU6Wj3XOC0kk9xKAVkln1Dv/A/1atVDBAVFEisNZjMohLGJCXgcBdS4cogxNCvTVIV/dSltbIdhNo94EvgEynlV42NP+edb32MH9CNb9btITkuos6t3D1XjqbMZq/V0+qbdXtwK5LPf95Z5XyBBh0vqAnr4wc0v0faz7uP8vD8JZgNOhb9dTYhgSY+WL6ZTQfS2XzoODPG9icsOIB82yaK7HvoEnw9Oo36g7MudyVlrhK2FP7C9QlzWnTbH9stmun/dylSTgT7JaDvX9s56IeDaQpULlG1fZ3bwaDeUczqMpecgmcZZtiDLHoAIr5D6KoFY2TlcmTRH0DoIGIVQtv0BaAyRypZZUuJtVyGxdC+2rPdQuZQ7kwjKuCiBh0vqI1Al917Oy5FQadRWJ1+MS5ZQXfrvXSzts1dgp/atFK2gwDeBfZLKV/25Zjz1vmO65fEhtfvRyNEnRlGQlQor99XOwb4wIwL+XbDPuZO830VvSGOlB3g64yPGBk+ngsip5CVX8zu1BNMGNitVogiNbsApKTS4aK4vJKQQBOTh/Zg6ab99E7oRIjFhFMpY/OJ36pFFO6T9A1/HIBJ0dPIsWfTJ3hwg443zBDJ73s8RYmziN7BA+sdByCEAUx1NWWFEBB4J9K+EkQw6KpDMV0tPUnS3YIs2gpCD6fnDrtPqv/KSmTBrWB9FaFvWvXW1pz7KXceI7tiGePjv23Ssa2N1TSAC+MX+TxeIwQGrRaXYscly5ESKt05lJTaWLlmH0MHJZKYcJ5nJLQVrdQ6HhgL3ALsFkLs8Gz7o5RyaX0HnLfOF2iSQPRNE4dw08TWabEOsCRrIcdtqWRlHmdcxCXc9PdPsDvdXDqiF3+eVX1bfv2EQThdbhI6WasW/Ub17sKv/7y/+mTSgE4TjEuWEqirDm8kBHTjsd6N5+sCxAcktvg9CX0viNoG1P1BE6aJEPEdaCwIzWlFHgE3grRD2UvgTkFWvI8I+XuTrm3RJVLhzPDaY01KyaYTd1FYuZVBUf8gOvCipr61M4JOE8DI6Pcpduwl3jKdP/3tezZtPUqA2cC3n93f+Al8wK0oOF1Km5W/n22oRRYt975Syl88p/OZFn0DQogXgSsBB3AEuENKWeTZ9zhwJ+AG7pdSLm/Jtc5GpJS8u2wTu49m8/iNE2uJVI+NmESmLY2hoepMWuNxVqfXZpgMOuZcVn9cF0ArDIzvvIRKV06VAlh70ZDGrtB5j3sLoYfAOUjnVnDsQJh9zzw4xeBOr1DuPEa5M42M0kXEWa6sssUtbeRXbgAk2eVLO6zzBQg1DSTUpN59hIUGoNFoCAlumcCNS3Gh0+iwO11c+9ePOFlYyqv3XsWYPolex0vpRhbcDM59iNB3EMZWajTYUTlLVc1WAo9LKV1CiOeBx4FHhRB9gBuAvkAssEoI0UNK6W7gXOccJwvLeGfJBtyKQtDiX3j69mr5v2Fh4xgWVt31YsEfZ7Ev/STj+iY261p6TRB6w9nbgUAIgQh9u9nHa4QOKV3syH0EdeatIc5yJaDOKHuFPkiubS3drd5TAtuD/67ayq6jWTw88yKirJY6+x+YewlTJvaja2Lj3Snq47Nj77Fk5yYm9xjFpKgZnCwsRZGSrYcy6nW+KPng3AkoyMrl57zzbY2Zb3NokZiplHKFlNLlebkBOFU6dhWwUEppl1KmAoeBjtP+4QwRHhJA50grACu3prDzSP09xKLDgrh4ULLPecg1UaSLwsrtuJTyJh+bZUvnmX0P8d9jbzRLZL4jodNYUO/8JIbTQhtdrXcwMuY9LPXcGTjcRRTZd5+xzyC3uIx/fr2W1TsO8/7yTV7H6LQaBvSNxxLY/IXShUvS2b8ymTf/nUdMWBAPzLiQy0f0ZlYDITShjYLAuWAYgwg8xxf9ZBMerUxrKknPBr73PI8DjtfYl+HZVgchxF1CiC1CiC25ubmtaE77o9dqeeLmiZj0OrQaQXFFZZtcZ3fek2w8cSe/Zs1q8rG/5q8mx57FtsJfKXTmVW2XUqHSlUNzblakcx9KzgSUwrvrHC+VAqRtCbKGTq+UlUgpUcreRjnRF6XkBXWcdLE//yV+ybyWEsfBRq8boI9nVMwH6DUh7Mr7EzZXtk/2KtLJzxnT2JB9O0eK/t2k99pcrBYzSdFhaIRgXN+2y85IMvdBoEEnjUgJN148mKdum0JoUMPpeJqg+9CEvY/QdW4z2zoGqraDL4/WptFplhBiFeBNgHSelHKRZ8w81NrmT5pqgKdCZD6oPdyaenxHZ0j3eJ6ZfSkOl5sLPII+ilRYdXIxinQzOXo62ho5sw6niz99uJzSCjvP3nmZTyXJdncuUirYlYIm2zcybAJ7ireRENAVq15dUXcp5axOn4RLlmLRd+fC+KZ17pW2RaBkgT0H3JlQI9YrC2aD6wjo+yLCF6KUfwSlz4BhDLgzACdULEBWvI9Tm0hqWQYgOVr0AYOinm302nZXDk5PiXNB5VbiLFc0bq90e7IMFCpPZV60MXqtls+euAW3ItFp267DyDO3XM3qfocZ0DWmQ4g9dUg6qpi6lLLBntdCiNuBK4CJsvqeLROo+ZMZ79l2XnLRoNoVcPtLdrDihOrQos3xDLJWL6htO5zJz7uOoEj4YXuKTx2JB0Y+R1bZd0SaxyKlA5l/A7gOI8LeRRiGN3hsfEAiT/b9Z61tFa5MXLIMgDLnEcodGezK+yNBhu70DZ+HEJoqARhviIDrkI51oOsL2tNFjE45Gs8Pjn0NIMGxEazzofxfgADnNnSuY3QKuITCym10DprR6OcAEGEeQ6eAi1Gkk04B9Xeqtjtc5OaWEBcbilZjYlTMBxTZdxNvme7TdVoDIQQ6bds6RLNBz+Uje7fpNc5q5FnaRkgIMRV4BBgvpUclW2UxsEAI8TLqglt3wHtg6zwkyhRb5biijbWjMX27dCIuwkpFpYNRvdUZY25xGVaLuarN9+kYtWFVur7SlQGuA4AbaVuJrFwB0oEI/iNC+BY7DNJ3JzHoZnJsP9Ej9HccL/uCQvt2iuy7SQyexVdZS9hauJ7hwRZmJr6AQVtbglHokiF8MWmlC0lJG4dZH8fomI/QasyIsPfBsUGd6QIieB6y9J9guhyNaRyYxiHdJ5BlbyIMFzDUXLcariZ2Vx4ajRG9JggpHYiiuxkojiPC5iMaqHS76/4Pycgq5OaZo5g9axxWY3+sxsZ/6Pycg3TUmW8j/AswAis9zmSDlPJuKeVeIcTnqIo+LmDu+Zbp0BCRxmj+1u8tQNbppxYUYOKLP99a9frT1dt5+cufSYiy8sWfb2285FQbB4F3gXMP6HtCyVPqdsNwMDd+Cw7qjKxPxGP04TEAAuzxZJR+SaA+kQB9PLuK1N/RlPIcMkq/pqt1dp1zpBZ/xMHCV5G4cDlslDlTCTH2UXV2TVNQyj9FVn6LCP4jmtDaM2+hjUaE/LVRO/NsG9ly4h40wsD4zt9hUE6qou24oHI5WO71epyUkszsIhRFcuRojk+fSXshpROQanGLj3z8w1a++HkXD8+8iCCzkdU7Upg5fiCx4b5rHJ9XnI1i6lLKehVlpJTPAPWrj5wjfPzDVhat38uj11/EsB6NL05IKVmQ/jbHylO4PfF3xAV0aXD8rtQspFRIzynE6XI3mg0hhEAE/V69lvsEUhgBN+ibP6uzGvsxqcvaqtczO9/Oiuy36W4qINzsXedY4kYILVIqxFguI9hQXZItpYTSpwAFd8nf2askEWocTEJw08RjypxHAVBwYnfnYdD3AOPF4E4D05X1HieE4B/PzGTT1lRmXFl71V/VmAinxJVDsX03cZYrW9SssyVI9wmPTrILwr9C6HzTin5z8XoqHS7eXLyOjLxiyirs7D12kn8/eF3jB5+HCKV94g7+MpcW8s+vf8HlVnhj0Tref/iGRseXuArZUvALCgq/5K3k+oQ5DY5/8NrxhFoCGN2nS5PT0IQ2GqLU4gIhWu+rHhE+kRHhExuM+3YNuZ1AfRcC9YkEGWr/RgshkKapULmSLJeRzIpvySpbQqfAizFqG25xVJPOlhk43cWYdNFVzl3UmEVL534QejUMchpxMVZGDE0iLLRaeEmpWAQlTyCFns02cEkodabQN3yezzb5yonKTNac/I7h4ReQbKknJus6CNIBwIHUbfzmjaVEhlj45PGbCDB5nwnbHE6GdY9n19Fsbp00jIU/bmdv2kl6JTQ/V/icRnLWFlmc91x7wQC+27ifGy/yTcaw0lVJiD4Up3QyJqL+BaFTRIZYeOT65ldk+dqup6Bym2dh6zoMWt9uTxsKgQihJTqw/rVajfVVAPRlqxAV2wjQd663X1x9aDVGuod6L5qQji3IgjvUF+Gf1WpvZLc7ue3u93C63Nx24xhunumZvStZgERIBwYRhAtnnXzh1uKTtLdIrzjCruLNPDugnvQ2w1gIuBlwsGlXPHZnBtkFJRw7WUifLt7V3/7xv5/YfPA4Gq2Gi4ckc/GQZE4UlBIf4XvIIavse1KK3iI55C7ignwLVZ2tCGS7FVn4nW8LeeT6i5rkHBdlfUyhMx+BhjhzYtsZ1gQU6WRT9hwkbkqdRxgU2XhKV2sRY5lEZMCvaIWx6odCrdvRNFiq3CiyDDWzQiJdqcjKHxDmyxC6brgVicOpLkGUlFXnXovA2SAsoOvKSF1Pyp3phBoH1T6t6zCI0GYpr9Uk2dKb4xWpJAbWrwUthA4R/CgA08bY2Hk0h7jwYHp1jqo1bsuh4/zhnSX0T4qmW2w4CIFRr0MjBFqNpqrQx1cOFLxMpTubA4Uvn/POFzhrF9z8NJE+IYPZV7KDpMAeaFriXFoBKSX7S3ai1+gxaMNxuPMJ1DUcgy6q3IVGGAg2em+3I6UCrr1qh2KNdy3l06mpvyudB5EFM1UnGPFtlQiPlG6o/B60nWsJtdeLYTzC+hIIPbL0JXClICsXIyJXEmA28MZLN5FyNIfJ49zI8o/APAOhsUCgmjViRBVor/XebEuRxY+qymyRqxEaq0/vzxtTo65n86oQ8vQmnF3c6HUN36GEWsy8fPc0r/uWbNhPSUUlv+5L48lbJjOmTyLdYsObJBxVk6SQ2zhc9BZJwbc2PvhcwO98zw/GRUxmeOgFbdpSBzziKCV/AvdxRMhLXkXK95Zs58PU15DA3ORXCTfoCWpAyjHPtoEtJ+8DJGNiPqnjgFMK3yKj5AP66sqJMHRGRH7v/UQN4dwG0g2yVC3GMHicb8V/ofRlQELkqkZF14UQ4BFtlxVfgCsVtNU/LD2So+neLQx5cigSBVwpiJC/NXhO6VbDEkgHyHLA2vT35+HHHUf4YWsqAhjXN6nePoG+cOvkoRzJzmNYj85EhFiICKmrE9EUkkJmkRTS9GrJsxJ/zPf8omab9jbDdQBsiwE32L4By2/rDNEJnSfLRmLUBhFsaLjbhiLtHuUENcPgdA4XvY3EzWGXJEJXfwpXqeMwFc7jRAWMrxtaMF2pirqIUNDXyEQQntmx0KgzzyYgrK+C6zDoTndwGlVbWCkDHzpoiMBbQRhAl4jQeq2W94mj2fk88+kqHC4XQWYjvRKiGj+oAbrGhPPfR29q0TnOZ/zZDn5aF1030PUAJRuMakxaqfgMKpchgh5H6HvQK3gAc7vPQy8MxJobdrxSqSBCOcagsPvQ6ft4LUhICrmNzLJFdA0cg6hxyyqVYmTR70GYcQX9mXVZalZID+t9dLXeXuscQmNBhDxX59zCfB3oEkETXSMUYUeW/xehS0CYLqnXdiF0oK8bJhFChzSMVMMZovEFKSEMENjyW/FNB9KxO1zodVpe/u00OoWevWp0Zz+y1cIOQoj3UKt9c6SU/Rob73e+5yhCmBARX6m96CoWIu0/qmLlgCx9CRGmNl1NCuzh0/lk2T+g4jMiEYioDV7H9Ap7kF5hD9bdUbkKHJsBgTBurZo9N2VBTQgBhtrCeLL8Yyh7BYmo05rIZ+yrAQUqF1XFe9uaS0f0ZuOB44QHBzCgW2yj493SQUbp11j0SYSbzztxwLZF0pox3w9QC88+8mWw3/meI0jnHmTxU6BLRgQ/jtB4ujU7t0CpJ3tB2wvch8B0edMvoIkGhHr738TbfoxjQBMFwoTONJaxsZ9R7jpOlPnCJp1GSqkueDk2IqyvIHRdVMcrjHDq/TaV4Keh4jNE0B+ad3wzCAk08co93hfPvJFa9AGHi98GCRM6L8ekazhn92h2PjlFZYzslcDJwjLu/MdnGPQ63v/D9Vgt7VMw0qFppaiDlPJnT9t4n/A733MEWfoPcO0E106k+xgi/FN1hyZGjZNKt7qgpB/QrK64InAOGEeBNr5Jpa4AQhuDiFpd9dpisNarq1sTtSK9RoGILKGwfCkfFSYRXvQvZnX/DyJiKWiCm515oDFfCeb6q+E6AkZtpCoAI3RoG9HnyC0qY9azCwB45IaL0ApBfkkFQsDu1GwiQyw88PYiesZH8co90/wdkjlLxdT9dCDM13ieaKjZSkro4hGRPyIi1yAMA5v9xyaEQOj7IzShjQ/2AaXoEZSTw9VwiBek+wQyZxQyZwTSleYxIpgtzgmkOQPZWeEgy5amxntbkPLVUckuX8n2nEfZlH0PBm2YusgpXVS4MrC788iz/YpS1cegGkXKKu1vl1thwsBuDO/ZmXH9ujK8ZwIvffEjJwvL+Hn3UTYfPF7n+PMSKX17QMQp7XHP466WXNY/8z1H0JivQBrHgv1XMI6rta85zklKN/sLXqTSlUP/iCfR+1j15tu5nVD5jfq8fAHCOKHuIOd+takmEpy7QdcFIQQDOj3K+rLnCDNEEm06Xa7y3KDEfoCduY+hSDsALllaFR+3ObPYfOJuXLKChKCZ9Al/pNaxnUKDeO8PMzlZWMaF/bui0YhanbgnDEhmW0omGiH8C32gOlW3z3GHPCnlsNa6tN/5nkMITSiYL2uVcxXZd5Fe+j+kVAgrG0JiK+Z9CqFHBt4P9hUIy9yq7VJKFNxohU79AQmYqebUmqplJWPMnXmq3xsALMv+ktU533FZzLVMiGqd990R0GtDEDXuYBIs1yGFgpQuogLG486rBCQupczr8b0TOtE7wXvq3KxJQxjRqzNmo77JlW/nLP4iCz8dCYu+G0ZtOA53EWHmhgXZm4Mm6D4Iuq/q9f6Sncw/8iIKbuYkPUR/6zBE8BMNnmNt3grsio21uSvOCee7Kf9nDpXu4YrYGxgfvxS3tBGgi6ujzzE29lMK7TuJCZxatc3hdPHMgh+odLp4ctbkeoV3AHrE+0V2atF6qWafAhNQwxMZwJNSynfrG+93vn68klL0Jop0Mjjq5VpykL4g7T8iC+8HwzBE6Ls+xZl/OPktCqrewt7i7fS3Nn53d3XcLfxw8lsui2lcKtGt2HBLOwattdGx7YHNXcGC9HcAiUZouKlL/V2WLYZudRYsNx5IZ8XWQ0gkq3ckccWoPvUc7acWajC9dU4l5Y1NGe93vn7qIKXCsZKPAThW/CFRAeMaOeK0423fApXgWK+W4YrGy12nRM8gMzWNQK2FKTG+tQwaFjaOYWGN2+ZwF/NTxuW4lXKGRb9FRD0axO2JUWMi2hTHicpMegQ1XXu5b5doQgKN2B0uBic3v/ru/EOC9Fe4+ekgCKGhW8hdZJd/Tzfrb5p+vOUepPskGMepYjU+0D2oT/3Sii3E7s7DLSuQQInjQId0vhqh4ZFez+FUHM0qP7dazBj1egpKbfy06wg3XVx/a3g/NZA0ZcGtVfE7Xz+1kFLili56ht1Pz7D7m3UOoUtGhH/cKrZI25eglCICb2m2IHyQoRt9wh6nwnmchKCZLbarrdAITbN1P5xuN1n5JUgk+9M6dmukDod/wc1Pe+KWLtLLU/k68yPSK45wc8I9DA+/4IxdXzp2IEvmgXESmqAH1I3O7VDi6eWmDQXz9GafPyH43G6hY9TreG3uVWw+kM4tk1otG+r8wO98/bQnH6a+zp7ibbhRE/d3F29tE+drd+exPmsWUroZHftfzLpoAGT52+BKUXV3LXMRwoC0LQUcgBa0DQv/+IExfRIZ0yexvc04y2g9YZ2m4q9w8wNAoTMfiUKgNoiBISOYFtekhVvfr1O5E7s7F4e7gILKrVXbRcAsEGFgmqE6XqUIbB8DChgnIgz+GKafNkACiuLbo5Xxz3z9AHBn0gNsK/yVfiFDiTLFtNl1zNpoAnWJmLSRdAqYULVdGMchOtVQSxMhag8z5zZEwPVtZo8fP/6wg592xWoI5+JO3vt1pVccIaPiGMPCLsCgaZqozulsOnkXLqUcsy4GXQNthoQQiLB689NrcaDgNU6UL2dAxF8JM/vjnX6aQpPKi1uVFoUdhBB/E0LsEkLsEEKsEELEerYLIcQ/hRCHPfv994xnKZVuG/889Fe+zPiQpVmft/h8Bk0oQmgwNiKL6CtSujla/G8qXOkcLm6bVDU/5zBSzWv35dHatHTm+6KU8k8AQoj7gT8DdwOXAt09j5HAW55//ZxlaIUWnUaPS3Fi0TVTM7cGY+IWUuZIwWoc0ArWqS3quwTdyImKVedPw0c/rUsrVbg1lRY5XyllSY2XgcCpd3EV8JGUUgIbhBBWIUSMlDK7Jdfzc+bRawz8sfdL5NtzSAysv7mm7+ezEGoa3AqWVdM3Yh59mdeq5/RzHnG2xnyFEM8AtwLFwEWezXFATbHQDM+2Os7Xo4l5F0BCgj+dqCMSrLcSrLe2txl+/LQ+UrZJJoMvNBrzFUKsEkLs8fK4CkBKOU9K2Rn4BLiv4bPVRUo5X0o5TEo5LDLSr7bkx4+fM4zvYuqtSqMzXynlJB/P9QmwFHgSyAQ619gX79nmx48fPx0IiXS72+XKLc12qBkEvAo44Hm+GLjVk/UwCij2x3v9+PHT4TglKenLo5Vpacz3OSFET9T+n2momQ6gzoAvAw4DFcAdLbyOHz9+/LQNZ6OkpJTymnq2S2Cut31+/Pjx01GQgGylWa0QYirwGqAF/iOlfK6h8X5tBz9+/Jy/SI+Yui+PBhBqr6c3UGsc+gA3CiEabCfiLy/248fPeU0rLbiNAA5LKY8CCCEWoq6D7avvgA7lfLdu3ZonhEhrp8tHAHntdG1v+O1pmI5kT0eyBc4fe7q09ASlFC5fJb+I8HG4SQixpcbr+VLK+Z7n3mobGqzq7VDOV0rZbom+QogtUsoOo8rit6dhOpI9HckW8NvTFKSUUxsf1Tb4Y75+/Pjx03KaXNvgd75+/Pjx03I2A92FEElCCANwA2q9Q710qLBDOzO/8SFnFL89DdOR7OlItoDfnjOOlNIlhLgPWI6aavaelHJvQ8cI2U6KPn78+PFzPuMPO/jx48dPO+B3vn78+PHTDpz3zrcjtUISQrwohDjgud7XQghrjX2Pe2w5KISY0ta2eK55nRBirxBCEUIMO23fGbfHc92pnmseFkI8dqauW+P67wkhcoQQe2psCxNCrBRCpHj+DT2D9nQWQqwRQuzzfFe/a0+bhBAmIcQmIcROjz1PebYnCSE2er63zzyLUuc3Usrz+gEE13h+P/C25/llwPeAAEYBG8+ALZcAOs/z54HnPc/7ADsBI5AEHAG0Z8Ce3kBP4EdgWI3t7WWP1nOtroDBY0OfM/z/5UJgCLCnxrYXgMc8zx879b2dIXtigCGe50HAIc/30y42ef5eLJ7nemCj5+/nc+AGz/a3gXvO5PfWER/n/cxX+tAKSUq5AbAKIdqup7pqywoppcvzcgNqruApWxZKKe1SylRUtbgRbWmLx579UsqDXna1iz3UKOGUUjqAUyWcZwwp5c9AwWmbrwI+9Dz/EJh+Bu3JllJu8zwvBfajVlu1i02ev5cyz0u95yGBi4EvzrQ9HZnz3vmC2gpJCHEcuBm1CSjU3wrpTDEbdebdEWw5nfayp6N9DqfoJKv1qk8AndrDCCFEIjAYdbbZbjYJIbRCiB1ADrAS9W6lqMbEoqN8b+3KeeF827oVUmva4hkzD3B57GlTfLHHj+9I9b76jOdvCiEswJfA70+7mzvjNkkp3VLKQah3biOAXmfq2mcT50WRhexArZAas0UIcTtwBTDR80dDW9niiz310F5tojpqe6qTp7pze0JTOWfy4kIIParj/URK+VVHsAlASlkkhFgDjEYN2+k8s9+O8r21K+fFzLchOlIrJI8Y8yPANCllRY1di4EbhBBGIUQS0B3Y1Ja2NEJ72dPkEs4zxGLgNs/z24BFZ+rCQggBvAvsl1K+3N42CSEiT2XpCCHMwGTUOPQa4NozbU+Hpr1X/Nr7gTpj2APsAr4F4jzbBao48hFgNzVW+9vQlsOoMc0dnsfbNfbN89hyELj0DH02V6PG5+zASWB5e9rjue5lqCv6R4B57fD/5VMgG3B6Pps7gXDgByAFWAWEnUF7xqGGFHbV+H9zWXvZBAwAtnvs2QP82bO9K+oP9GHgf4DxTH93He3hLy/248ePn3bgvA87+PHjx0974He+fvz48dMO+J2vHz9+/LQDfufrx48fP+2A3/n68ePHTzvgd75+/Pjx0w74na8fP378tAP/DxxpiFgaMxdRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden=dense_model.layers[1](train_data).numpy()\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "dr=TSNE()\n",
    "embed_attentions=dr.fit_transform(hidden)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "scatter=ax.scatter(embed_attentions[:,0], embed_attentions[:,1],\n",
    "                   c=cluster_labels_train,\n",
    "                   s=3\n",
    "                  )\n",
    "\n",
    "plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processed in excel by combining training and validation accuracy columns from individual training_log.csv\"\n",
    "import pandas as pd\n",
    "SynthDataFolder=\"SynthData_10dim_clusternoise\"\n",
    "df=pd.read_csv(os.path.join(\"SynthData_10dim_clusternoise_results.csv\"),\n",
    "               index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>LLDLwFW_valacc</th>\n",
       "      <th>LLDLwoFW_valacc</th>\n",
       "      <th>DenseModel_valacc</th>\n",
       "      <th>LLDLwFW_trainacc</th>\n",
       "      <th>LLDLwoFW_trainacc</th>\n",
       "      <th>DenseModel_trainacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.682222</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.517778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.471111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.534444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.501111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  LLDLwFW_valacc  LLDLwoFW_valacc  DenseModel_valacc  \\\n",
       "0      0            0.69             0.48               0.48   \n",
       "1      1            0.70             0.49               0.52   \n",
       "2      2            0.75             0.50               0.45   \n",
       "3      3            0.76             0.53               0.48   \n",
       "4      4            0.76             0.63               0.47   \n",
       "\n",
       "   LLDLwFW_trainacc  LLDLwoFW_trainacc  DenseModel_trainacc  \n",
       "0          0.682222           0.486667             0.472222  \n",
       "1          0.757778           0.502222             0.517778  \n",
       "2          0.813333           0.535556             0.471111  \n",
       "3          0.821111           0.550000             0.534444  \n",
       "4          0.850000           0.577778             0.501111  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots()\n",
    "df['logEpoch']=np.log10(df['Epoch']+1)\n",
    "# sns.lineplot('Step', 'AttentionModelwFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'AttentionModelwoFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'DenseModel_val', data=att_model_df, ax=ax)\n",
    "\n",
    "def get_mov_ave(y, window_size=3, percentiles=(10,90)):\n",
    "    assert window_size%2 ==1\n",
    "    w=int(window_size/2)\n",
    "    out=[]\n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    l,u=percentiles[0],percentiles[1]\n",
    "    for i in range(w, len(y)-w):\n",
    "        out.append(np.average(y[i-w:i+w+1]))\n",
    "        lower.append(np.percentile(y[i-w:i+w+1],l))\n",
    "        upper.append(np.percentile(y[i-w:i+w+1],u))\n",
    "\n",
    "    while w>0:\n",
    "        w=w-1\n",
    "        win_size=w*2+1\n",
    "        out.insert(0, np.average(y[:win_size]))\n",
    "        lower.insert(0, np.percentile(y[:win_size], l))\n",
    "        upper.insert(0, np.percentile(y[:win_size], u))\n",
    "        out.append(np.average(y[len(y)-win_size:]))\n",
    "        lower.append(np.percentile(y[len(y)-win_size:], l))\n",
    "        upper.append(np.percentile(y[len(y)-win_size:], u))\n",
    "    return out, lower, upper\n",
    "\n",
    "def get_min_max(mov_ave, y):\n",
    "    assert len(mov_ave)==len(y)\n",
    "    mins=np.min(np.vstack([mov_ave, y]), axis=0)\n",
    "    maxs=np.max(np.vstack([mov_ave,y]), axis=0)\n",
    "    return mins, maxs\n",
    "\n",
    "colors1=[\"b\",\"g\",\"r\"]\n",
    "colors2=[\"powderblue\",\"palegreen\",\"lightsalmon\"]\n",
    "for idx, i in enumerate([\"LLDLwFW_valacc\",\n",
    "          \"LLDLwoFW_valacc\", \n",
    "          \"DenseModel_valacc\"\n",
    "         ]):\n",
    "    x_plot=df['Epoch']+1\n",
    "    y_plot=df[i]\n",
    "    mov_ave, lower, upper=get_mov_ave(y_plot, window_size=15)\n",
    "    plt.plot(x_plot, mov_ave, c=colors1[idx])\n",
    "    #mins,maxs=get_min_max(mov_ave, get_mov_ave(y_plot, window_size=3))\n",
    "    plt.fill_between(x_plot,lower, upper, color=colors2[idx], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim([0.45, 0.95])\n",
    "ax.legend([\"Locality-adaptive Deep Learner\", \"Locality-adaptive Deep Learner\\nw/o Feature Weights\", \"Dense Model\"], \n",
    "          bbox_to_anchor=(1,1))\n",
    "ax.set_title(\"10-D Synthetic Data with cluster-specific noise\")\n",
    "plt.grid()\n",
    "# savefile=os.path.join(SynthDataFolder, \"SynthData_10dim_LocallyAdaptiveDeepLearner\")\n",
    "# plt.savefig(savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "n_estimators_list=[200,500,1000]\n",
    "n_repeats=10\n",
    "random_seeds=range(n_repeats)\n",
    "min_samples_list=list(range(1,11))\n",
    "RF_results=[]\n",
    "\n",
    "for n_estimator in n_estimators_list:\n",
    "    for min_samples in min_samples_list:\n",
    "        for i in range(n_repeats):\n",
    "            np.random.seed(random_seeds[i])\n",
    "            clf=ExtraTreesClassifier(n_estimators=n_estimator, \n",
    "                                     min_samples_leaf=min_samples,\n",
    "                                     bootstrap=True, \n",
    "                                     oob_score=True, \n",
    "                                     class_weight=\"balanced_subsample\")\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_score=clf.score(X_train, y_train)\n",
    "            test_score=clf.score(X_test, y_test)\n",
    "            RF_results.append([n_estimator, min_samples, \"train_accuracy\", train_score])\n",
    "            RF_results.append([n_estimator, min_samples, \"test_accuracy\", test_score])\n",
    "        \n",
    "RF_results=pd.DataFrame(RF_results, columns=[\"n_estimator\", \"min_samples_leaf\", \"metric\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_ave_LUbounds(df, x_col_name, percentiles=(10,90)):\n",
    "    l,u=percentiles[0], percentiles[1]\n",
    "    x_plot=np.unique(df[x_col_name])\n",
    "    ave=[]\n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    if percentiles=='std':\n",
    "        for x in x_plot:\n",
    "            out=df[df[x_col_name]==x]['score']\n",
    "            mean, std=np.mean(out), np.std(out)\n",
    "            ave.append(mean)\n",
    "            lower.append(mean-std)\n",
    "            upper.append(mean+std)\n",
    "        return x_plot, ave, lower, upper\n",
    "    for x in x_plot:\n",
    "        out=df[df[x_col_name]==x]['score']\n",
    "        ave.append(np.mean(out))\n",
    "        lower.append(np.percentile(out, l))\n",
    "        upper.append(np.percentile(out, u))\n",
    "    return x_plot, ave, lower, upper\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "colors1=[\"b\",\"g\",\"r\"]\n",
    "colors2=[\"powderblue\",\"palegreen\",\"lightsalmon\"]\n",
    "for idx, n_estimator in enumerate(n_estimators_list):\n",
    "    out_df=RF_results.query(\"n_estimator == @n_estimator & metric == 'test_accuracy' \")\n",
    "    x_plot, ave, lower, upper=get_ave_LUbounds(out_df, x_col_name='min_samples_leaf',\n",
    "                                               percentiles='std'\n",
    "                                              )\n",
    "    ax.plot(x_plot, ave, c=colors1[idx])\n",
    "    ax.fill_between(x_plot, lower, upper, color=colors2[idx], alpha=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Minimum samples in leaf nodes\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "# ax.set_ylim([0.45, 0.95])\n",
    "ax.legend([\"No. of trees=\"+str(i) for i in n_estimators_list], \n",
    "          loc=(\"lower right\"))\n",
    "ax.set_title(\"10-D Synthetic Data with cluster-specific noise\")\n",
    "\n",
    "plt.grid()\n",
    "# savefile=os.path.join(SynthDataFolder, \"SynthData_10dim_RF\")\n",
    "# plt.savefig(savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "n_estimators_list=[200,500,1000]\n",
    "n_repeats=3\n",
    "random_seeds=range(n_repeats)\n",
    "gamma_list=[0.00001,0.00003,0.0001,0.0003, 0.001, 0.003, 0.01,0.03, 0.1,0.3]\n",
    "xgb_results=[]\n",
    "scale_pos_weight= (len(y_train)-np.sum(y_train))/np.sum(y_train) #Ratio of number of negatives to number of positives\n",
    "\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    for gamma in gamma_list:\n",
    "        for i in range(n_repeats):\n",
    "            xgb_clf=XGBClassifier(n_estimators=n_estimators,\n",
    "                                  gamma=gamma,\n",
    "                                  max_depth=20,\n",
    "                                  scale_pos_weight=scale_pos_weight,\n",
    "                                  use_label_encoder=False, \n",
    "                                  eval_metric='logloss',\n",
    "                                  seed=random_seeds[i]\n",
    "                                 )\n",
    "            xgb_clf.fit(X_train, y_train)\n",
    "            train_score=xgb_clf.score(X_train, y_train)\n",
    "            test_score=xgb_clf.score(X_test, y_test)\n",
    "            xgb_results.append([n_estimators, gamma, \"train_accuracy\", train_score])\n",
    "            xgb_results.append([n_estimators, gamma, \"test_accuracy\", test_score])\n",
    "            del xgb_clf\n",
    "xgb_results=pd.DataFrame(xgb_results, columns=[\"n_estimator\", \"gamma\", \"metric\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_ave_LUbounds(df, x_col_name, percentiles=(10,90)):\n",
    "    l,u=percentiles[0], percentiles[1]\n",
    "    x_plot=np.unique(df[x_col_name])\n",
    "    ave=[]\n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    if percentiles=='std':\n",
    "        for x in x_plot:\n",
    "            out=df[df[x_col_name]==x]['score']\n",
    "            mean, std=np.mean(out), np.std(out)\n",
    "            ave.append(mean)\n",
    "            lower.append(mean-std)\n",
    "            upper.append(mean+std)\n",
    "        return x_plot, ave, lower, upper\n",
    "    for x in x_plot:\n",
    "        out=df[df[x_col_name]==x]['score']\n",
    "        ave.append(np.mean(out))\n",
    "        lower.append(np.percentile(out, l))\n",
    "        upper.append(np.percentile(out, u))\n",
    "    return x_plot, ave, lower, upper\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "colors1=[\"b\",\"g\",\"r\"]\n",
    "colors2=[\"powderblue\",\"palegreen\",\"lightsalmon\"]\n",
    "for idx, n_estimator in enumerate(n_estimators_list):\n",
    "    out_df=xgb_results.query(\"n_estimator == @n_estimator & metric == 'test_accuracy' \")\n",
    "    x_plot, ave, lower, upper=get_ave_LUbounds(out_df, x_col_name='gamma',\n",
    "                                               percentiles='std'\n",
    "                                              )\n",
    "    ax.plot(x_plot, ave, c=colors1[idx])\n",
    "    ax.fill_between(x_plot, lower, upper, color=colors2[idx], alpha=0.3)\n",
    "\n",
    "ax.set_xlabel(\"Gamma\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "# ax.set_ylim([0.45, 0.95])\n",
    "ax.legend([\"No. of trees=\"+str(i) for i in n_estimators_list], \n",
    "          loc=(\"lower right\"))\n",
    "ax.set_title(\"10-D Synthetic Data with cluster-specific noise\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylim((0.45,0.95))\n",
    "plt.grid()\n",
    "# savefile=os.path.join(SynthDataFolder, \"SynthData_10dim_RF\")\n",
    "# plt.savefig(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>gamma</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimator    gamma         metric  score\n",
       "1            200  0.00001  test_accuracy   0.77\n",
       "3            200  0.00001  test_accuracy   0.77\n",
       "5            200  0.00001  test_accuracy   0.77\n",
       "7            200  0.00003  test_accuracy   0.77\n",
       "9            200  0.00003  test_accuracy   0.77\n",
       "..           ...      ...            ...    ...\n",
       "171         1000  0.10000  test_accuracy   0.78\n",
       "173         1000  0.10000  test_accuracy   0.78\n",
       "175         1000  0.30000  test_accuracy   0.74\n",
       "177         1000  0.30000  test_accuracy   0.74\n",
       "179         1000  0.30000  test_accuracy   0.74\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results[xgb_results['metric']==\"test_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Similarity Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just create tensorflow function and call it _on_epoch end\n",
    "    Args:\n",
    "      variant_tensor: The variant-dtype Tensor associated with the Dataset. This\n",
    "        Tensor will be a captured input to functions which use the Dataset, and\n",
    "        is used by saving code to identify the corresponding _VariantTracker.\n",
    "      resource_creator: A zero-argument function which creates a new\n",
    "        variant-dtype Tensor. This function will be included in SavedModels and\n",
    "        run to re-create the Dataset's variant Tensor on restore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnaryDataset(DatasetV2):\n",
    "  \"\"\"Abstract class representing a dataset with one input.\"\"\"\n",
    "\n",
    "  def __init__(self, input_dataset, variant_tensor):\n",
    "    self._input_dataset = input_dataset\n",
    "    super(UnaryDataset, self).__init__(variant_tensor)\n",
    "\n",
    "  def _inputs(self):\n",
    "    return [self._input_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sh_ds._variant_tensor_attr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(<unprintable>, shape=(), dtype=variant)\n"
     ]
    }
   ],
   "source": [
    "print(Sh_ds._variant_tensor_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.data.ops.dataset_ops import UnaryDataset\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "class SimilarityBatchingDataset():\n",
    "    def __init__(self, \n",
    "                 numpy_dataset,\n",
    "                 numpy_targets,                 \n",
    "                 attentions,\n",
    "                 n_batch=8,\n",
    "                 clusterer_kwargs={\"n_clusters\":None,\n",
    "                                   \"affinity\":\"cosine\", \n",
    "                                   \"linkage\":\"average\"\n",
    "                                  },\n",
    "                 use_inter_op_parallelism=True,\n",
    "                 preserve_cardinality=False,\n",
    "                 use_legacy_function=False,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        self.numpy_dataset=numpy_dataset\n",
    "        self.numpy_targets=numpy_targets\n",
    "        self.attentions=attentions\n",
    "        self.n_batch=n_batch\n",
    "        self.clusterer_kwargs=clusterer_kwargs\n",
    "        self._use_inter_op_parallelism=use_inter_op_parallelism\n",
    "        self._preserve_cardinality=preserve_cardinality\n",
    "        self._use_legacy_function=use_legacy_function\n",
    "    \n",
    "    \n",
    "\n",
    "    def _partitions(self):\n",
    "        #Set n_clusters if not initialized\n",
    "        if self.clusterer_kwargs.get(\"n_clusters\") is None:\n",
    "            self.clusterer_kwargs[\"n_clusters\"]=20\n",
    "        \n",
    "        clusterer=AgglomerativeClustering(**self.clusterer_kwargs)\n",
    "        clusterer.fit(self.attentions)\n",
    "        cl_labels=clusterer.labels_\n",
    "        unique,counts=np.unique(cl_labels, return_counts=True)\n",
    "        print(f\"Fitted {len(unique)} clusters with distribution {np.sort(counts)[::-1]}\")\n",
    "        #Remember to shuffle partitions\n",
    "        partitions=[np.where(cl_labels==i)[0] for i in np.unique(cl_labels)]\n",
    "        m=len(partitions)\n",
    "        rand_order=np.random.choice(range(m), size=m, replace=False)\n",
    "        partitions=[partitions[i] for i in rand_order]\n",
    "        \n",
    "        return partitions\n",
    "\n",
    "    def get_rearranged_tensor(self):\n",
    "        arr=np.empty_like(self.numpy_dataset)\n",
    "        arr_targets=np.empty_like(self.numpy_targets)\n",
    "        self.partitions=self._partitions()\n",
    "        ptr=0\n",
    "        for p in self.partitions:\n",
    "            arr[ptr:ptr+len(p)]=self.numpy_dataset[p,:]\n",
    "            arr_targets[ptr:ptr+len(p)]=self.numpy_targets[p,:]\n",
    "            ptr+=len(p)\n",
    "        return arr, arr_targets\n",
    "    \n",
    "#     def get_similarity_batched_dataset(self):\n",
    "#         arr=np.empty_like(self.numpy_dataset)\n",
    "#         self.partitions=self._partitions()\n",
    "#         ptr=0\n",
    "#         for p in self.partitions:\n",
    "#             arr[ptr:ptr+len(p)]=self.numpy_dataset[p,:]\n",
    "#             ptr+=len(p)\n",
    "#         ds=tf.data.Dataset.from_tensor_slices(arr)\n",
    "#         return ds.batch(n_batch)\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 20 clusters with distribution [232 104  93  80  76  66  59  51  41  36  30  16   5   4   2   1   1   1\n",
      "   1   1]\n"
     ]
    }
   ],
   "source": [
    "attentions=LSwFW_model.layers[1](train_tensor).numpy()\n",
    "simbatched=SimilarityBatchingDataset(\n",
    "    train_data,\n",
    "    train_targets,\n",
    "    attentions,\n",
    ")\n",
    "rearranged_train_data, rearranged_train_targets=simbatched.get_rearranged_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.001>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSwFW_model.optimizer.lr.assign(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted 20 clusters with distribution [132 120 118 108  89  66  63  51  44  33  24  16  14   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0555 - accuracy: 0.9889 - val_loss: 0.9279 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88000, saving model to 210210_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_simBatched\n",
      "Fitted 20 clusters with distribution [153 132 126 110  86  66  62  52  34  24  18  15   7   4   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0450 - accuracy: 0.9911 - val_loss: 0.9368 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88000 to 0.89000, saving model to 210210_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_simBatched\n",
      "Fitted 20 clusters with distribution [153 132 126 111  93  89  61  51  34  12  11   7   4   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0397 - accuracy: 0.9911 - val_loss: 0.9473 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [158 132 125 111 100  89  51  51  34  14   8   7   4   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0380 - accuracy: 0.9933 - val_loss: 0.9621 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 111  91  89  86  62  50  34  34  12  12   8   7   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0361 - accuracy: 0.9944 - val_loss: 0.9706 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 112  91  89  86  61  50  34  34  12  12   8   7   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0356 - accuracy: 0.9933 - val_loss: 0.9779 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 125 112  89  89  61  50  34  14   8   7   4   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0338 - accuracy: 0.9956 - val_loss: 0.9862 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 124 111  89  89  62  50  34  14   9   7   4   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0341 - accuracy: 0.9956 - val_loss: 0.9872 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 125 111  92  84  62  50  34  12  11   7   4   4   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0333 - accuracy: 0.9956 - val_loss: 0.9923 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 125 111  92  84  62  50  34  12  11   7   4   4   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0331 - accuracy: 0.9967 - val_loss: 0.9998 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [159 132 124 112  89  85  61  50  34  12   8   8   7   4   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0328 - accuracy: 0.9967 - val_loss: 1.0037 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 132 112 112  89  85  60  50  33  23  12  11   8   7   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0320 - accuracy: 0.9967 - val_loss: 1.0075 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [157 132 124 112  89  87  61  50  34  12   8   8   7   4   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0318 - accuracy: 0.9967 - val_loss: 1.0123 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 132 112 112  89  87  60  50  33  23  12   8   8   7   4   3   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0314 - accuracy: 0.9978 - val_loss: 1.0203 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 132 112 112  89  87  60  50  33  23  12   8   8   7   4   3   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0312 - accuracy: 0.9978 - val_loss: 1.0244 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 132 112 112  89  87  60  50  33  23  12   8   8   7   4   3   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0308 - accuracy: 0.9978 - val_loss: 1.0267 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [148 132 112 112  89  89  58  50  34  20  12  12  10   7   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0303 - accuracy: 0.9978 - val_loss: 1.0366 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [157 132 112 103  89  89  58  50  34  20  12  12  10   7   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0304 - accuracy: 0.9978 - val_loss: 1.0442 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [148 132 112 112  89  89  58  50  34  20  12  12  10   7   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0299 - accuracy: 0.9978 - val_loss: 1.0449 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [148 132 112 112  89  89  58  50  34  20  12  12  10   7   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0297 - accuracy: 0.9978 - val_loss: 1.0545 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [148 132 112 112  89  88  58  50  34  20  12  12  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0293 - accuracy: 0.9978 - val_loss: 1.0528 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [148 132 112 112  89  88  58  50  34  20  12  12  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0289 - accuracy: 0.9978 - val_loss: 1.0608 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [150 132 112 112  80  73  69  60  34  20  12  12  11   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0290 - accuracy: 0.9967 - val_loss: 1.0617 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [150 132 112 112  86  73  69  60  34  20  12   8   8   7   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0286 - accuracy: 0.9978 - val_loss: 1.0604 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [150 132 116 112  86  73  69  56  34  20  12   8   8   7   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0288 - accuracy: 0.9978 - val_loss: 1.0618 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [150 132 116 112  86  73  69  56  34  20  12   8   8   7   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0286 - accuracy: 0.9978 - val_loss: 1.0635 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [152 132 116 112  83  73  69  56  34  20  12  12   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0268 - accuracy: 0.9989 - val_loss: 1.0696 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [152 132 116 112  83  73  69  56  34  20  12  12   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0267 - accuracy: 0.9989 - val_loss: 1.0766 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [147 132 116 112  91  89  56  50  34  20  12  12   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0268 - accuracy: 0.9989 - val_loss: 1.0741 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [147 132 112 111  91  89  61  50  34  20  12  12   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0285 - accuracy: 0.9978 - val_loss: 1.0812 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [147 132 112 111  97  89  61  50  34  20  14   8   7   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0259 - accuracy: 0.9989 - val_loss: 1.0827 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [132 128 112 108  97  89  61  50  34  24  20  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0257 - accuracy: 0.9989 - val_loss: 1.0872 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [132 128 112 108  97  89  61  50  34  24  20  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0255 - accuracy: 0.9989 - val_loss: 1.0898 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [132 128 112 108  97  89  61  50  34  24  20  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0254 - accuracy: 0.9989 - val_loss: 1.0946 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [132 128 112 108 102  89  56  50  34  24  20  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0252 - accuracy: 0.9989 - val_loss: 1.0974 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 129 112 108 102  89  56  50  34  24  20  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0250 - accuracy: 0.9989 - val_loss: 1.0998 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 129 112 108 107  89  56  50  34  20  19  14   8   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0249 - accuracy: 0.9989 - val_loss: 1.1036 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [130 129 112 107 103  89  56  50  34  20  19  12  12   8   7   5   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0247 - accuracy: 0.9989 - val_loss: 1.1059 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 112 107 103  89  56  50  34  20  19  12  12   8   7   5   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0245 - accuracy: 0.9989 - val_loss: 1.1091 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 111 103 101  89  59  50  34  28  19  12  12   7   5   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0244 - accuracy: 0.9989 - val_loss: 1.1143 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 111 109 101  89  59  50  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0243 - accuracy: 0.9989 - val_loss: 1.1182 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 111 109 101  89  59  50  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0241 - accuracy: 0.9989 - val_loss: 1.1200 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 111 109 101  89  59  50  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0241 - accuracy: 0.9989 - val_loss: 1.1244 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [136 131 110 109 101  82  59  50  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0242 - accuracy: 0.9989 - val_loss: 1.1289 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 110 109 101  82  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0239 - accuracy: 0.9989 - val_loss: 1.1318 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 110 109 101  82  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0237 - accuracy: 0.9989 - val_loss: 1.1354 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 110 109 101  82  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0234 - accuracy: 0.9989 - val_loss: 1.1393 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 110 109 101  82  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0235 - accuracy: 0.9989 - val_loss: 1.1415 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 110 109 101  82  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0281 - accuracy: 0.9978 - val_loss: 1.1243 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 110 103  89  57  51  34  28  12   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1256 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 109 109 101  83  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0235 - accuracy: 0.9989 - val_loss: 1.1363 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 109 109 101  83  59  51  34  28  19  14   7   5   4   4   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0231 - accuracy: 0.9989 - val_loss: 1.1393 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 109 109 105  83  59  51  34  28  19  12   7   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0230 - accuracy: 0.9989 - val_loss: 1.1450 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 120 109 105  83  53  51  34  28  12   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0229 - accuracy: 0.9989 - val_loss: 1.1480 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [134 131 110 109 105  83  59  51  34  28  19  12   7   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0229 - accuracy: 0.9989 - val_loss: 1.1538 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 114 109 105  83  59  51  34  28  12   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0227 - accuracy: 0.9989 - val_loss: 1.1581 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 114 109 105  83  59  51  34  28  12   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0227 - accuracy: 0.9989 - val_loss: 1.1582 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 117 114 105  95  59  51  34  12   8   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0227 - accuracy: 0.9989 - val_loss: 1.1636 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 117 114 105  95  59  51  34  12   8   7   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0225 - accuracy: 0.9989 - val_loss: 1.1661 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [146 131 114 109 109  83  59  51  34  20  12   8   8   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0226 - accuracy: 0.9989 - val_loss: 1.1708 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [145 132 114 109  97  95  59  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0223 - accuracy: 0.9989 - val_loss: 1.1727 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [145 132 114 109  97  95  59  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0222 - accuracy: 0.9989 - val_loss: 1.1774 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 132 114 109 104  95  59  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0222 - accuracy: 0.9989 - val_loss: 1.1793 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [145 132 114 109  97  95  59  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1811 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 132 114 109 104  95  59  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0220 - accuracy: 0.9989 - val_loss: 1.1832 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 132 120 109 104  95  53  51  33  20  12   8   8   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 120 104 102  95  53  51  33  28  12   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0218 - accuracy: 0.9989 - val_loss: 1.1919 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 120 104 102  95  53  51  33  28  12   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0220 - accuracy: 0.9989 - val_loss: 1.1946 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 124 120 102  95  53  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0217 - accuracy: 0.9989 - val_loss: 1.1977 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 102  98  53  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 102  98  53  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0216 - accuracy: 0.9989 - val_loss: 1.2074 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 102  98  53  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.2056 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0213 - accuracy: 0.9989 - val_loss: 1.2124 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.2161 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0211 - accuracy: 0.9989 - val_loss: 1.2218 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0208 - accuracy: 0.9989 - val_loss: 1.2293 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.2311 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2315 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 132 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 131 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 131 121 120 103  98  52  51  33  12   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 131 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 131 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 121 103  98  52  51  33  11   8   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.2635 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.2700 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 121 119 103  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 121 119 104  98  52  51  33  11  10   8   5   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 120 119 103  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 120 119 103  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.2805 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 130 120 119 103  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 104  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2838 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 104  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2862 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 104  98  52  51  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0199 - accuracy: 0.9989 - val_loss: 1.2875 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 103  98  52  52  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 103  98  52  52  33  11  10   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2925 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 120 119 105  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2981 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [149 130 120 112 105  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [149 130 120 112 105  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2998 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [149 130 120 112 105  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.3001 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 121 120 103  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [142 130 121 120 103  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.3058 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 121 120 103  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.3071 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 121 120 103  98  52  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0216 - accuracy: 0.9989 - val_loss: 1.3211 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 121 111 103  98  61  52  33  11   8   8   6   4   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0240 - accuracy: 0.9978 - val_loss: 1.3158 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 111 107 103  95  54  51  33  27  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.3002 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [145 128 111 103  98  87  61  58  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.3024 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 111 104  98  94  61  52  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0178 - accuracy: 0.9989 - val_loss: 1.3055 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 111 104  98  94  61  52  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.3021 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 111 104  98  94  61  52  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.3045 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [144 128 120 104  98  94  52  52  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 120 104  98  94  52  52  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.3087 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 120 105  98  94  52  51  33  28  11   8   8   6   4   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3049 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 120  98  94  81  52  51  33  28  28  11   8   8   6   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 120  98  94  81  52  51  33  28  28  11   8   8   6   3   3   2\n",
      "   1   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.3071 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 120  98  94  81  52  51  33  28  28  11   8   8   6   3   3   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.3108 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 112 108  98  94  60  51  33  28  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.3087 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 112 108  98  94  60  51  33  28  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.3095 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 112 104  98  94  60  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.3120 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.3124 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.3135 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.3151 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 131 116 104  98  94  56  51  33  28  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.3148 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  94  56  51  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.3158 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  94  56  51  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  94  56  51  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  94  56  51  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  94  56  51  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 103  98  94  56  52  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 103  98  94  56  52  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3142 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 103  98  94  56  52  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.3154 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 103  98  94  56  52  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.3158 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 103  98  94  56  52  33  21  11   8   8   6   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  33  21  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  33  21  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3171 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  33  21  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3202 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  33  21  11   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  32  21  11   8   8   6   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  32  21  11   8   8   6   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3180 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  32  21  11   8   8   6   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  32  21  11   8   8   6   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  32  21  11   8   8   6   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 107  98  94  56  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3201 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3211 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  97  56  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3202 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 116 104  98  97  56  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3214 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  11   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3211 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3236 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3236 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [141 138 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3237 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3237 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 107  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 104  98  97  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3256 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 116 104  98  97  56  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 104  98  97  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 104  98  97  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 108  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 116 108  98  94  56  52  31  21  12   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 120 108  98  94  52  52  31  21  12   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [151 128 116 108  98  94  56  52  31  21  12   8   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3213 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 115 108 101  98  56  52  31  21  14  12   8   8   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 115 108 101  98  56  52  31  21  14  12   8   8   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 115 108 101  98  56  52  31  21  14  12   8   8   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 114 113 106  93  52  40  31  28  14  12   8   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 109 109 106  93  56  52  31  21  14  12   8   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 109 109 106  93  56  52  31  21  14  12   8   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 109 109 106  93  56  52  31  21  14  12   8   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [131 128 114 107 106  93  52  40  31  26  21  14  12   8   7   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 114 107  99  93  52  40  31  26  21  14  12   8   7   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.3190 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [129 128 114 105  99  93  52  47  39  31  28   8   8   6   3   3   2   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 129 123 115  99  93  52  38  31  28  14   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 129 123 115  99  93  52  38  31  28  14   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3074 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 115  99  91  70  66  52  38  31  26  14   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3037 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 115  99  91  70  66  52  38  31  26  14   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3046 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 116 115  99  93  52  38  35  31  14  12   8   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 115  99  93  83  61  52  32  31  21  14  12   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3004 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 125 123 109  99  93  55  52  31  21  14   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.2973 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 125 123 109  99  93  55  52  31  21  14   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.2997 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 124 123  99  93  83  55  52  31  26  21  18   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.2929 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 125 123 109  99  93  55  52  31  21  14   8   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.2976 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 124 123  99  93  83  55  52  31  26  21  18   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.2891 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 124 123  99  93  83  55  52  31  26  21  18   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 124 123  99  93  83  52  38  32  32  31  18   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.2925 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 118 115  99  93  52  38  32  31  14  10   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 118 115  99  93  52  38  32  31  14  10   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 118 114 100  93  52  38  32  31  14  10   8   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2874 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [143 123 118 100  93  83  55  52  31  31  23  14  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2770 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 118 114 100  93  91  55  52  47  31  23  14  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.2825 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 118 105 100  93  83  55  52  47  35  31  23  10   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2734 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 118 100  93  83  55  52  35  31  23  14  10   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 121 109 105 101  93  53  52  49  31  23  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2831 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 121 109 105 101  93  53  52  49  31  23  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.2744 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 121 100  93  80  53  52  37  31  23  14  10   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 121 100  93  80  53  52  37  31  23  14  10   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 120 100  93  80  53  52  37  31  23  14  10   7   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 120 114 101  93  91  52  52  49  31  15  14  10   8   8   7   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.2665 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 120 110 100  93  91  52  52  49  31  23  14  10   8   7   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 120 110 106  99  93  52  52  49  31  15  10   8   8   7   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [128 120 106  99  93  86  52  52  47  35  31  15  10   8   7   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0111 - accuracy: 0.9978 - val_loss: 1.2796 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [175 117 100  99  98  82  52  38  38  31  31  11   8   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0710 - accuracy: 0.9911 - val_loss: 1.7743 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 119 118 103  93  88  51  51  31  26  14   7   6   4   4   4   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.1148 - accuracy: 0.9722 - val_loss: 1.1030 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [138 128 111 106  97  95  50  41  36  31  17  15   9   8   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0688 - accuracy: 0.9822 - val_loss: 1.1153 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [135 131 117 105  99  93  57  48  31  23  18  10   9   9   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0359 - accuracy: 0.9922 - val_loss: 1.0555 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 107 103  98  93  49  44  31  25  22  11  11  10  10   8   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0145 - accuracy: 0.9989 - val_loss: 1.0303 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 107 105  98  98  49  45  31  25  22  10   9   9   8   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0249 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 106 102  97  49  45  31  25  22  11  10   9   5   4   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0274 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0337 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0661 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0703 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 109 106  97  97  51  45  31  25  22  11   9   9   5   4   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 105 103  97  97  51  45  31  26  22  11  11   9   9   5   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0804 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0858 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 128 106 103  97  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 103  98  97  51  45  31  26  18  11  11   9   9   7   5   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 105 105  97  51  45  31  25  18  11  10   9   7   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0964 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 105 105  97  51  45  31  25  18  11  10   9   7   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 105 105  97  51  45  31  25  18  11  10   9   7   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 105 105  97  51  45  31  25  18  11  10   9   7   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1013 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 106 105 105  97  51  45  31  25  18  11  10   9   7   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 105 105 103  97  51  45  31  25  18  11  10   9   8   7   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1080 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 105 105 103  97  51  45  31  25  18  11  10   9   8   7   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1105 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 105 105 103  97  51  45  31  25  18  11  10   9   8   7   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1114 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 105 105 103  97  51  45  31  25  18  11  10   9   8   7   3   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1137 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [140 127 105 105 103  97  51  45  31  25  18  11  10   9   8   7   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [134 131 107 103 102  97  51  45  31  25  18  11  11  10   8   7   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [134 131 107 106 102  97  51  45  31  25  18  11  11  10   7   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [134 131 107 106 102  97  51  45  31  25  18  11  11  10   7   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1212 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [134 131 108 107 102  97  55  51  31  22  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 108 107 102  97  92  52  51  31  22  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1238 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 108 107 102  97  92  52  51  31  22  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 108 107 102  97  92  52  51  31  22  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 107 106 102  97  89  51  45  31  25  18  11  11  10   7   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 107 106 102  97  89  51  45  31  25  18  11  11  10   7   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 107 106 102  97  89  51  45  31  25  18  11  11  10   7   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1317 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 106 105  97  91  51  45  31  25  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 113 106 105  97  89  51  45  31  25  18  11  10   7   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 103  97  91  51  45  31  25  18  11  10   8   7   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 103  97  91  51  45  31  25  18  11  10   8   7   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 109 105 103  97  91  51  45  31  26  18  11  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1390 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 109 105 103  97  91  51  45  31  26  18  11  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 109 105 104  97  91  51  45  31  26  18  11  10   8   6   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1424 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 103  97  89  51  45  31  26  18  11  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 105  97  89  51  38  32  31  18  10  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 105  97  89  51  38  32  31  18  10  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 105  97  89  51  38  32  31  18  10  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1495 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 105  97  89  51  38  32  31  18  10  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 109 105 105  97  89  51  38  32  31  18  10  10   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 105 105 105  97  86  51  38  32  31  18  10  10  10   8   7   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1530 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 105 105 105  97  86  55  51  31  18  15  10  10  10   8   7   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 107 105 105  97  90  55  51  31  18  15  10  10   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 107 105 105  97  90  55  51  31  18  15  10  10   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 107 105 105  97  90  55  51  31  18  15  10  10   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 107 105 105  97  90  55  51  31  18  15  10  10   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1617 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 107 105 105  97  90  55  51  31  18  15  10  10   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1622 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 113 105 102  97  90  55  51  31  18  15   9   8   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 113 105 102  97  90  55  51  31  18  15   9   8   8   7   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116 106 102  97  86  55  51  31  20  15   9   8   8   6   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.1740 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116 106 102  97  86  55  51  31  20  15   9   8   8   6   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 114 105 102  97  90  55  51  31  18  15   9   8   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 113 105 103  97  90  55  51  31  18  15   9   8   8   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 113 103 100  97  89  55  51  31  18  15  10   9   8   7   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1718 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115 103 100  97  85  55  51  31  20  15  10   9   8   7   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115 103 100  97  85  55  51  31  20  15  10   9   8   7   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1760 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 100  99  97  93  55  51  31  20  15  10   9   8   7   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 100  99  97  93  55  50  31  20  15  10   9   8   7   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 101  99  97  93  55  50  31  20  15  10   9   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 101  99  97  93  50  37  33  31  20  10   9   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1805 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 101  99  97  93  50  37  33  31  20  10   9   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 101  99  97  93  50  37  33  31  20  10   9   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 101  99  97  93  50  37  33  31  20  10   9   8   6   6   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 106  99  97  93  51  37  33  32  23   9   8   6   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 106 103  97  89  51  37  33  32  23   9   8   6   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 110  99  97  92  49  44  32  26  25   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 110  99  97  92  49  44  32  26  25   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111 110  99  97  92  49  44  32  26  25   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 110  99  97  92  49  44  32  26  25   9   9   5   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1903 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 107  99  97  92  49  44  32  26  25   9   9   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 107  99  97  92  49  44  32  26  25   9   9   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 110  99  97  94  49  44  32  26  20   9   9   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 112 110  99  97  94  49  44  32  26  20   9   9   8   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1941 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 110  99  97  94  49  44  32  26  25   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1973 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 110  99  97  94  49  44  32  26  25   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 102  97  91  51  44  31  26  20   9   9   7   6   6   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 102  97  91  51  44  31  26  20   9   9   7   6   6   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 111 105 102  97  91  51  44  31  26  20   9   9   7   6   6   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2037 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 113 111 103 102  97  49  44  31  26   9   9   9   6   3   3   2   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2035 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 113 110 102  97  95  51  44  31  26   9   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 113 104 100  97  95  51  44  31  26  10   9   9   9   6   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2045 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 113 113  99  97  95  51  44  31  26   9   9   9   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2074 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 109 108  99  97  95  51  44  31  26  10   9   9   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2091 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 116 109  99  97  95  51  44  31  26   9   9   8   6   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2080 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 116 109  99  97  95  51  44  31  26   9   9   8   6   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 116 112  99  97  95  51  44  31  23  11   9   9   6   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 112 108 103  98  91  49  44  31  23  11  10  10   9   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 112 108 103  98  91  49  44  31  23  11  10  10   9   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 112 108 103  98  91  49  44  31  23  11  10  10   9   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2128 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 112 110  98  94  82  50  44  31  23  14  13   9   9   8   6   5   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 112 110  98  94  82  50  44  31  23  14  13   9   9   8   6   5   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2113 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  98  94  82  50  44  31  23  13  10   9   8   6   5   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2142 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  98  94  82  50  44  31  23  13  10   9   8   6   5   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  98  94  82  50  44  31  23  13  10   9   8   6   5   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  98  94  82  50  44  31  23  13  10   9   8   6   5   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2156 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2167 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2163 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2186 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2213 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  99  98  88  50  44  31  23  10   9   8   6   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [185 117 115  98  98  88  50  44  31  23  10   9   8   7   5   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2180 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 117 115  98  92  88  50  44  31  23  13  13  10   9   7   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2194 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 117  98  92  88  50  44  31  23  13  10   9   8   7   5   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115 115 105  98  88  50  44  31  28  10   9   8   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115 115 105  98  88  50  44  31  28  10   9   8   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2234 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 114  98  92  88  50  45  31  28  13  10   9   8   7   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 114  98  92  88  50  44  31  29  13  10   9   8   7   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2263 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 119 118  98  92  88  50  50  31  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 119 118  98  92  88  51  50  30  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 118  98  92  88  51  51  30  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2265 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 118  98  92  88  51  51  30  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2251 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 118  98  92  88  51  51  30  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2247 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 118  98  92  88  51  51  30  23  13  10   9   7   3   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2249 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 112  98  92  88  51  51  30  23  13  11   9   9   4   3   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 118 112  98  92  88  51  51  30  23  13  11   9   9   4   3   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116 112  98  91  88  51  51  30  23  15  10   9   7   6   4   3   3\n",
      "   3   2]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 117 112  98  91  88  51  50  30  23  15  10   9   7   6   4   3   3\n",
      "   3   2]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2258 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 117 112  98  91  88  51  50  30  23  15  10   9   7   6   4   3   3\n",
      "   3   2]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2284 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 117 112  98  91  88  51  50  30  23  15  10   9   7   6   4   3   3\n",
      "   3   2]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2340 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 121 112  98  91  88  51  50  30  23  15  10   9   9   3   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2333 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115  98  91  88  62  59  51  50  30  23  15  10   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115  98  91  88  62  59  51  50  30  23  15  10   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2314 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115  98  91  88  62  59  51  50  30  23  15  10   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115  98  91  88  62  59  51  50  30  23  15  10   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 115  98  91  88  62  59  51  50  30  23  15  10   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2305 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 105  98  96  91  62  60  51  50  30  23  15  10  10   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 105  98  96  91  62  60  51  50  30  23  15  10  10   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 105  98  96  91  62  60  51  50  30  23  15  10  10   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111  98  91  87  62  60  51  50  30  23  15  14   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2298 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111  98  91  87  62  60  51  50  30  23  15  14   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111  98  92  87  62  59  51  50  30  23  15  14   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 111  98  92  87  62  59  51  50  30  23  15  14   9   9   3   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2337 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178  98  88  87  63  62  60  53  51  50  30  23  15  14   9   9   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2412 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178  98  88  87  63  62  60  53  51  50  30  23  15  14   9   9   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178  98  88  87  63  62  60  53  51  50  30  23  15  14   9   9   3   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116  98  88  87  62  60  51  50  30  23  15  14   9   8   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2420 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116  98  88  87  59  59  51  51  30  22  15  15   9   8   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116  98  88  87  59  59  51  51  30  22  15  15   9   8   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2446 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 116  98  88  87  60  59  51  50  30  22  15  15   9   8   5   3   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 0.9989 - val_loss: 1.1598 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [178 106 102  93  91  60  59  51  50  30  15  14  11  10   9   8   5   3\n",
      "   3   2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.1093 - accuracy: 0.9867 - val_loss: 1.1305 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [177 130 103 101  66  61  60  53  51  30  16  10  10   9   8   6   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0703 - accuracy: 0.9822 - val_loss: 1.4773 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 130 103  87  66  65  62  60  32  29  28  23   9   8   8   6   3   3\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0929 - accuracy: 0.9733 - val_loss: 1.0366 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 132 106 100  66  55  53  51  44  32  22  21  12   8   7   7   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0467 - accuracy: 0.9856 - val_loss: 1.1042 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [177 125 118 106  66  51  51  49  46  31  23  22   8   7   5   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0209 - accuracy: 0.9956 - val_loss: 1.0026 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 122 104  98  92  53  52  50  46  30  22  22   8   6   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.9680 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [177 129 103  98  86  53  50  49  46  30  23  22   8   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0171 - accuracy: 0.9967 - val_loss: 0.9707 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 134 103 100  84  53  50  50  42  32  23  22   8   6   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.9570 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 134 103  98  86  53  50  49  42  32  23  22   9   8   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.9610 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106 100  89  52  50  50  43  32  24  23   8   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.9600 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106 100  89  52  50  50  43  32  24  23   8   6   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.9594 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106  98  91  50  50  49  43  32  23  22   9   8   5   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.9644 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106  98  91  50  50  49  43  32  23  22   9   8   5   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.9637 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106  98  91  50  50  49  43  32  23  22   9   8   5   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.9732 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 127 106  98  91  50  50  49  43  32  23  22   9   8   5   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.9729 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 129 106  98  94  50  50  49  43  32  23  14   8   8   8   5   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.9829 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "Fitted 20 clusters with distribution [176 129 106  98  94  50  50  49  43  32  23  14   8   8   8   5   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.9824 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89000 to 0.90000, saving model to 210210_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_simBatched\n",
      "Fitted 20 clusters with distribution [176 129 106  98  94  50  50  49  43  32  23  14   8   8   8   5   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 106 100  92  50  50  49  39  32  23  22   8   8   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 105  98  94  53  50  50  39  32  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 105  98  94  53  50  50  39  32  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 105  98  93  53  50  50  43  30  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 105  98  93  53  50  50  43  30  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 105  98  93  53  50  50  43  30  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 105  98  93  53  50  50  43  30  23  16   8   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0335 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  74  55  54  50  50  43  30  23  23   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0368 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  74  55  54  50  50  43  30  23  23   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  74  55  54  50  50  43  30  23  23   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  74  55  54  50  50  43  30  23  23   8   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0472 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  74  55  54  51  50  43  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0501 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  55  54  52  51  42  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0505 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  54  54  52  51  43  30  24  22   8   8   3   2   2\n",
      "   1   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0518 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  54  54  52  51  43  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0528 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  54  54  52  51  43  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  55  54  52  51  42  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0556 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  55  54  52  51  42  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  55  54  52  51  42  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 105  98  93  73  55  54  52  51  42  30  24  22   8   8   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0763 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0712 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0768 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 102  98  93  54  52  51  42  30  24  21   8   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0792 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0792 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0862 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0868 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 102  98  93  54  52  52  46  30  24  21   8   8   4   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 108  98  93  52  50  48  46  30  24  22   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0930 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 108  98  93  52  50  48  46  30  24  22   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0923 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 108  98  93  52  50  48  46  30  24  14   8   8   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0960 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0984 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0983 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1007 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1035 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  49  46  30  24  21   8   8   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1062 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 101  98  93  56  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 106  98  93  52  51  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 102  98  93  55  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 102  98  93  55  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 102  98  93  55  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 124 102  98  93  55  52  50  42  30  24  21   8   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  50  42  30  24  21   9   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  50  42  30  24  21   9   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1172 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  50  42  30  24  21   9   8   5   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  51  42  30  24  24   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1192 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  51  42  30  24  24   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1209 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 102  98  93  55  52  51  42  30  24  24   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 104  98  93  55  52  51  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 123 104  98  93  55  52  51  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1221 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1215 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1235 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1263 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  55  51  50  42  30  24  22   9   8   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1198 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 104  98  93  52  50  42  37  34  30  22   9   8   8   4   3   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1330 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1328 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1308 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1322 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1324 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 104  66  52  50  41  36  33  30  22  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 124 103  66  52  50  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1328 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 124 103  52  50  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 124 103  52  50  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 124 103  52  50  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1350 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 124 103  52  50  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1370 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1365 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 124 103  52  50  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1366 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  51  51  43  41  36  33  30  23  11   9   8   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  52  51  43  41  36  33  30  23  11   9   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1396 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 123 103  51  51  43  41  36  33  30  23  11   9   8   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1405 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 128 103  52  51  43  41  36  33  30  23  11   8   6   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1399 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 128 103  52  51  43  41  36  33  30  23  11   8   6   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 128 103  51  51  43  41  36  33  30  23  12   8   6   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1479 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 128 103  51  51  43  41  36  33  30  23  12   8   6   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1468 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  36  33  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 102  51  50  46  45  36  34  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 102  51  50  46  45  36  34  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1495 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 102  51  50  46  45  36  34  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 102  51  50  46  45  36  34  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1499 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 102  51  50  46  45  36  34  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1528 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 123 102  51  50  46  43  36  34  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1453 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  37  32  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 119 103  51  50  46  45  37  32  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1583 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 122 103  51  50  45  42  37  32  30  23  12   8   6   4   4   4\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 122 103  93  50  43  37  32  30  23  12   8   6   4   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1536 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 122 103  93  50  43  37  32  30  23  12   8   6   4   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 126 103  51  50  43  42  37  32  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 126 103  51  50  43  42  37  32  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1580 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 126 103  51  50  43  42  37  32  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 122 103  93  50  43  37  32  30  23  12   8   6   4   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 126 103  51  50  43  42  37  32  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 126 103  51  50  43  42  37  32  30  23  12   8   6   4   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1627 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1616 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 103  93  50  44  37  32  30  22  12   8   6   4   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121  98  94  50  44  37  32  30  22  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121  98  94  50  44  37  32  30  22  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 106  92  50  44  37  32  30  16  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 106  92  50  44  37  32  30  16  12   8   8   6   4   4   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 106  92  50  44  37  32  30  16  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 106  92  50  44  37  32  30  16  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 121 106  92  50  44  37  32  30  16  12   8   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  92  51  43  37  32  30  16  12  10   8   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  92  51  43  37  32  30  16  12  10   8   8   4   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1792 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  92  50  43  37  32  30  16  12  10   8   8   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  92  50  43  37  32  30  16  12  10   8   8   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  92  50  43  37  32  30  16  12  10   8   8   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1763 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 118 106  57  52  50  44  37  36  30   8   8   8   6   4   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 120 106  55  52  50  44  37  36  30   8   8   8   6   4   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 120 106  55  52  50  44  37  36  30   8   8   8   6   4   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1778 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 148 120 106  55  52  50  44  37  36  30   8   8   8   6   4   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1864 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 120 106  52  51  44  43  37  36  30  16   8   8   8   6   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1827 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 117 106  52  50  44  43  37  36  30  16  10   8   8   8   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 116 106  52  50  45  43  37  36  30  16  10   9   8   6   4   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 117 108  52  50  44  43  37  30  30  16  12  10   9   8   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 117 108  52  50  44  43  37  30  30  16  12  10   9   8   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 120 108  52  50  44  43  37  30  30  16  12   9   8   6   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 0.9978 - val_loss: 1.1239 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 118 110  52  50  44  42  37  30  28  16  12  10   9   8   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0244 - accuracy: 0.9978 - val_loss: 1.1221 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 118 113  66  52  50  45  42  32  26  18   8   8   6   6   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0479 - accuracy: 0.9922 - val_loss: 1.3588 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 128 108 104  67  53  51  51  46  30  26  22  13   8   5   4   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.1176 - accuracy: 0.9733 - val_loss: 1.0054 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 148 113 112 107  52  51  49  31  16   9   8   8   7   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0727 - accuracy: 0.9800 - val_loss: 1.2311 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 119 107  51  51  47  41  39  31  31  17   9   8   8   6   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0526 - accuracy: 0.9878 - val_loss: 1.1700 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 124 109  83  66  51  42  35  31  16  12   8   6   4   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0276 - accuracy: 0.9922 - val_loss: 1.0726 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 116 115 103  66  51  39  31  31  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 121 114  96  66  51  41  31  30  12   9   8   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 128 120 116  96  66  51  38  33  31  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 131 120 116  93  66  51  38  33  31  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 131 120 116  93  66  51  38  33  31  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 131 129 111  98  66  51  34  34  31  12   8   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1015 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 131 129 111  94  66  51  38  34  31  12   8   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1116 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 131 130 111  94  66  51  39  32  31  12   8   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 131 130 111  94  66  51  39  32  31  12   8   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 118 115 101  93  51  39  31  15  12   9   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 118 115 101  93  51  39  31  15  12   9   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1348 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 118 115 101  93  51  39  31  15  12   9   5   3   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  20  12   9   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1409 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  20  12   9   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 121 116  97  66  51  39  31  31  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  14  12   9   7   5   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1535 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  14  12   9   7   5   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1564 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  14  12   9   7   5   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  14  12   9   7   5   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 116 100  93  66  51  49  39  31  14  12   9   7   5   3   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1711 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 121 115 115 100  93  51  39  31  15  12   9   6   5   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1729 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 120 117 101  95  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 101  94  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1799 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 100  79  66  51  49  39  31  17  15  12   9   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 100  79  66  51  49  39  31  17  15  12   9   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 100  79  66  51  49  39  31  17  15  12   9   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 100  79  66  51  49  39  31  17  15  12   9   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 101  94  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 101  94  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 101  94  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1983 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 101  94  66  51  49  39  31  15  12   9   5   4   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 117 100  79  66  51  49  39  31  17  15  12   9   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2039 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 116 100  94  66  51  49  39  31  17  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 116 100  94  66  51  49  39  31  17  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2197 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2247 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115 113 100  94  51  39  31  15  12   9   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2295 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2315 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 113 100  94  66  51  49  39  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2395 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 113 103 100  66  51  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2423 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 113 103 100  66  51  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2428 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 113 103 100  66  51  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 113 103 100  66  51  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2461 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 120 113 103 100  66  51  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2508 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 118 115 100  98  88  52  51  31  15  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2522 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 113 103 100  66  52  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2587 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 113 103 100  66  52  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 113 103 100  66  52  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2588 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 113 103 100  66  52  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 116 103 100  66  52  49  35  31  15  12   6   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2602 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 113 103 100  66  52  49  35  31  15  12   9   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2621 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 116 103 100  66  52  49  35  31  15  12   6   5   4   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2637 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 116 101  87  66  52  49  35  31  15  15  12   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2647 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 119 116 101  87  66  52  49  35  31  15  15  12   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115 102  87  66  51  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2682 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115 102  87  66  51  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2719 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2757 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2771 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2781 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2801 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2825 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 102  87  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2854 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 101  88  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 101  88  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2859 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 101  88  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 114 101  88  66  52  49  35  31  15  15  12   6   6   5   5   4\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2920 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 116 114  87  66  51  40  32  31  15  12   6   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2923 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 116 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 116 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 116 114  88  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2964 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 116 114  88  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3000 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 116 114  88  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3027 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 129 116 114  88  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 116 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3034 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 116 113  87  66  51  41  31  31  15  12   7   6   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 113  87  66  51  41  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 113  87  66  51  41  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3057 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 113  87  66  51  41  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3078 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3099 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 114  87  66  51  40  31  31  15  12   7   6   5   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 115  87  66  51  40  31  31  15  12   7   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 115  87  66  51  40  31  31  15  12   7   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 107  87  66  51  40  31  31  15  12   9   7   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3159 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 107  87  66  51  40  31  31  15  12   9   7   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 107  87  66  51  40  31  31  15  12   9   7   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3162 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 115 107  87  66  51  40  31  31  15  12   9   7   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3213 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3407 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3342 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 118 115  97  85  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3384 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 116 115  97  87  66  51  49  40  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 115 113  97  87  66  51  47  45  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 115 113  97  87  66  51  47  45  31  15  15  12   6   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 119 109  97  87  66  51  47  45  31  15  14  12   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3444 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 119 111  97  87  66  51  47  43  31  15  14  12   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3464 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 119 111  97  87  66  51  47  43  31  15  14  12   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 119 111  97  87  66  51  47  43  31  15  14  12   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3479 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 110  87  51  46  43  31  30  14  12   9   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3495 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 110  87  51  46  43  31  30  14  12   9   9   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3495 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3498 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3563 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3572 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 111  87  51  46  43  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3569 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 109  87  51  46  45  31  30  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3588 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 111  87  55  51  46  31  17  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3605 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 111  87  55  51  46  31  17  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3641 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 111  87  55  51  46  31  17  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 111  87  55  51  46  31  17  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 111  87  55  51  46  31  17  14  12   8   6   5   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 108  87  55  51  46  31  17  14  13  12   8   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3673 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 108  87  55  51  46  31  17  14  13  12   8   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3660 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 106  87  55  51  46  31  17  16  13  12   8   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 106  87  55  51  46  31  17  16  13  12   8   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 106  87  55  51  46  31  17  16  13  12   8   6   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3766 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 111  93  51  50  46  31  17  16  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3735 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 111  93  51  50  46  31  17  16  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3763 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  92  55  51  46  31  16  14  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  92  55  51  46  31  16  14  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  92  55  51  46  31  16  14  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  92  55  51  46  31  16  14  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3821 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  92  55  51  46  31  16  14  12   8   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3889 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3926 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3897 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111 101  53  46  31  31  29  22   8   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3931 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 111  85  53  46  31  31  29  22  16   8   6   5   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 115  85  53  46  31  31  29  22  15   6   5   5   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3993 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 116 115  85  53  46  31  31  29  22  15   6   5   5   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4050 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4151 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 114  85  53  53  31  31  29  22  15   6   5   4   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 113  85  53  53  51  30  17  15  12   6   5   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 118 115  85  53  51  46  31  16  15  12   6   6   5   5   4   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4186 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 115  90  53  51  46  31  16  15  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4109 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 115  90  53  51  46  31  16  15  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 106  90  53  51  46  31  22  16  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4217 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 106  90  53  51  46  31  22  16  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4282 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 106  90  53  51  46  31  22  16  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4286 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 106  90  53  51  46  31  22  16  12   6   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4240 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 106  85  53  53  51  30  22  17  12   6   5   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4276 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 106  85  53  53  51  31  22  17  12   6   5   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 106  85  53  53  51  30  22  17  12   6   5   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4304 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4299 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4334 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4256 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 115  90  53  51  46  30  16  15  12   6   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4450 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 117 106  90  53  51  46  31  22  17  12   7   6   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4440 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 115 102  90  53  53  51  30  17  15  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4378 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4423 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4500 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 106 104  90  53  53  51  30  22  17  12  11   6   5   5   4   3\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4586 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 106  90  53  51  46  31  22  16  12  11   6   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 109 106  90  53  51  46  31  22  17  12  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4469 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 109 106  90  53  51  46  31  22  17  12  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4537 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 111 106  90  53  51  46  31  22  16  12  11   6   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4440 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 109 106  90  53  51  46  31  22  17  12  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4442 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 108 106  89  53  51  46  30  22  17  12  11   7   6   5   5   4\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 109 106  90  53  51  46  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4471 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 109 106  90  53  51  46  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 108 106  90  53  51  47  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 108 106  90  53  51  47  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4489 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 106  90  53  51  43  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 106  90  53  51  43  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 106  90  53  51  43  31  22  16  13  11   7   6   5   4   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4615 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 103  90  53  51  50  31  20  16  13  11   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4548 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 103  90  53  51  50  31  20  16  13  11   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 103  90  53  51  50  31  20  16  13  11   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4598 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 103  90  53  51  50  31  20  16  13  11   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 112 103  90  53  51  50  31  20  16  13  11   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4846 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 103  90  53  51  46  31  20  16  13   7   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4754 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 120 103  90  53  51  46  31  20  16  13   7   6   6   5   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4349 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 123 103  90  53  51  43  30  20  16  13   7   6   6   5   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 123 103  98  94  90  53  51  30  20  16  13   7   6   6   5   4   3\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4624 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 119 103  92  53  52  46  30  26  20   7   6   6   5   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4534 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 149 118 103  92  53  53  52  30  26  20   6   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0292 - accuracy: 0.9956 - val_loss: 1.2493 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 149 119 104 104  53  53  30  30  24  22  12   6   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0799 - accuracy: 0.9811 - val_loss: 1.5199 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 120 116  75  67  61  31  27  27  24  16  12   7   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.1706 - accuracy: 0.9644 - val_loss: 1.4143 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [226 126 113  88  68  65  51  50  31  22  14  10   9   8   6   4   4   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0794 - accuracy: 0.9744 - val_loss: 1.1504 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 128 119 115  90  66  50  49  28  18  14  12   9   8   5   4   3   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0421 - accuracy: 0.9889 - val_loss: 1.0553 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 132 126 117  83  66  51  49  30  19  11  10  10   6   5   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.9684 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [228 125 119 117  67  53  51  49  30  15  13  10   8   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0101 - accuracy: 0.9989 - val_loss: 0.9703 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 134 126 111  85  66  51  49  30  25  13  10   8   5   4   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.9732 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 135 124 113  87  66  51  49  30  25  11   9   8   5   4   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [228 127 124 120  66  53  53  49  30  15  10   9   4   2   2   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.9988 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 124 120 103  66  53  49  30  15  13   9   4   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 135 127 124 103  66  53  49  30  10   9   4   4   2   2   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 124 120 103  66  53  49  30  15  13   9   4   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 127 124 120 103  66  53  49  30  15  10   9   4   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0296 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 122 121 103  66  53  49  30  15  10   9   8   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0402 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 122 121 103  66  53  49  30  15  10   9   8   4   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 124 121 101  66  57  53  49  30  15  14  11   9   8   4   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 124 117 101  66  57  53  51  30  15  14  12   9   8   4   2   2   2\n",
      "   2   2]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0534 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 124 121 101  66  57  53  49  30  15  14  11   9   8   4   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 149 124 119  66  54  49  30  18  15  11   9   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 149 124 119  66  54  49  30  18  15  11   9   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0767 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 149 124 119  66  54  49  30  18  15  11   9   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0772 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 149 124 119  66  54  49  30  18  15  11   9   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [229 149 124 119  66  54  49  30  18  15  11   9   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 122 119  85  66  51  49  30  18  15  11  10   8   8   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 122 119  85  66  51  49  30  18  15  11  10   8   8   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 132 124 119  85  66  51  49  30  16  15  11   8   8   2   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 132 124 119  84  66  51  49  30  16  15  11   8   8   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 132 124 119  82  66  51  49  30  16  15  11   8   8   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 131 124 119  80  66  54  49  30  16  15  11   8   8   3   2   2   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 119  82  66  54  49  30  16  15  11   8   8   3   2   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1046 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 121  82  66  54  49  30  16  15  10   8   8   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 121  82  66  54  49  30  16  15  10   8   8   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1290 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 112  82  66  54  35  31  30  16  11   8   8   7   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1165 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 119  82  66  54  35  31  30  16  10   8   8   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1214 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 129 124 119  82  66  54  35  31  30  16  10   8   8   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 124 120 119  82  66  54  35  31  30  16  10   9   9   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1288 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 120 117  89  66  54  35  31  30  13  10   9   9   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1299 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 120 117  89  66  54  35  31  30  13  10   9   9   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1352 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 120 117  89  66  54  35  31  30  13  10   9   9   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 120 117  89  66  54  35  31  30  13  10   9   9   8   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1360 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 130 124 117  89  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1386 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1437 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1455 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1532 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1644 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1622 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1662 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  96  65  54  35  31  30  13  10   8   6   3   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124 123 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 117 111  96  65  54  35  31  30  15  10  10   9   8   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 117 111  96  65  54  35  31  30  15  10  10   9   8   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 117 111  96  65  54  35  31  30  15  10  10   9   8   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 117 111  96  65  54  35  31  30  15  10  10   9   8   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 117 111  96  65  54  35  31  30  15  10  10   9   8   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1783 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 117 115  96  65  54  35  31  30  13  11  10   8   6   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1778 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 117 115  96  65  54  35  31  30  13  11  10   8   6   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1811 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 119 115  96  65  54  49  30  15  13  11  10   8   6   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1807 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 119  98  65  54  49  30  15  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1857 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 119  98  65  54  49  30  15  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 119  98  65  54  49  30  15  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1842 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 119  98  65  54  49  30  15  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1863 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 119  98  65  54  49  30  15  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1887 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1925 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 122 117  98  65  54  35  31  30  13  10   8   6   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 117 108  98  65  54  35  31  30  15  13  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 117 108  98  65  54  35  31  30  15  13  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1987 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 110 108  98  65  54  35  31  30  20  15  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 110 108  98  65  54  35  31  30  20  15  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 110 108  98  65  54  35  31  30  20  15  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 110 108  98  65  54  35  31  30  20  15  10   8   6   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 123 110  93  65  54  35  31  30  20  10   8   6   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 123 110  93  65  54  35  31  30  20  10   8   6   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 123 110  93  65  54  35  31  30  20  10   8   6   5   3   2   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2057 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 110 109  93  65  54  35  31  31  20  15  10   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2096 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2105 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2158 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 114 109  93  65  54  35  31  31  15  14  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 115 109  93  65  54  35  31  31  15  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 115 109  93  65  54  35  31  31  15  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2151 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 115 109  93  65  54  35  31  31  15  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 125 115 109  93  65  54  35  31  31  15  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2210 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 115 109  90  65  54  35  31  31  16  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2221 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 115 109  90  65  54  35  31  31  16  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [177 125 115 109  90  65  54  35  31  31  16  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2245 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2240 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2268 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 126 115 109  90  65  54  35  31  31  16  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2285 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 126 115 109  90  65  54  35  31  31  16  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2269 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [176 125 125 115  90  65  54  35  31  31  13  12   8   6   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2284 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2463 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 112  90  65  54  35  31  31  15  11  10   9   8   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 126 115 110  91  65  54  35  31  31  15  13  12   8   6   5   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2517 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2528 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2553 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 115 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2498 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 116 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 116 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 116 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2554 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 118 116 110  91  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2555 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2610 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2600 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 116  86  65  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2636 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  35  31  31  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2704 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115  86  66  54  49  31  17  15  13  12   9   8   8   5   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 130 118 116  86  66  54  49  31  17  13  12   8   8   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2754 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 130 118 116  86  66  54  49  31  17  13  12   8   8   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 130 118 116  86  66  54  49  31  17  13  12   8   8   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 130 118 116  86  66  54  49  31  17  13  12   8   8   5   5   4   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 126 116  91  66  54  49  31  17  13  11   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2732 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2774 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 116 111 106  66  54  49  31  17  13  11   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2822 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 116 111 106  66  54  49  31  17  13  11   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2805 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2824 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2892 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2997 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2876 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2880 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  49  31  17  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2980 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 116 110 109  65  54  49  31  17  11  10   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2998 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 116 110 109  65  54  49  31  17  11  10   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2916 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 116 110 109  65  54  49  31  17  11  10   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 117 110 109  65  54  53  31  23  10   8   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2898 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 110 109  65  54  34  31  30  11  10   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2939 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 110 109  65  54  34  31  30  11  10   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 122 118 118 107  66  54  34  31  30  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2986 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 122 118 118 107  66  54  34  31  30  11   8   8   5   5   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  34  31  30  11   8   8   5   5   4   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3027 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  51  31  21   8   8   5   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2938 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  51  26  21   9   8   8   5   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 118 116 104  66  54  51  26  21   9   8   8   5   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3070 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3006 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 128 118 116 104  65  54  51  30  21   8   8   5   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3200 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 118 116 115 104  65  54  51  30  21  15   8   8   7   5   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 121 119 114 103  65  54  48  30  26  15   8   5   5   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 126 120 118  94  66  54  48  30  21  13   8   8   5   4   3   3   2\n",
      "   2   1]\n",
      "29/29 - 1s - loss: 0.0483 - accuracy: 0.9911 - val_loss: 1.5963 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [173 116 114 106  94  71  67  54  30  22  16   8   8   7   5   4   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.1321 - accuracy: 0.9700 - val_loss: 1.5930 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 128 122 106  82  67  62  47  30  22  16  10   9   7   6   6   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.1288 - accuracy: 0.9711 - val_loss: 1.1125 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [188 173 121 115  52  51  48  42  31  26  26   6   5   5   3   2   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0703 - accuracy: 0.9778 - val_loss: 1.1515 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [175 124  99  97  91  66  52  50  45  31  22  19  10   6   4   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.9281 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [173 125 117  99  94  94  50  45  31  27  15   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.7385 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 107  93  68  67  64  53  53  31  30  11   7   6   5   4   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.7745 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 113  93  68  67  66  52  48  31  28  11   7   6   5   4   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.8240 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 120 109  91  68  67  51  31  28  11   7   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.8622 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 113 109  93  68  67  53  31  28  11   7   6   5   4   4   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.8615 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 109  93  68  52  51  31  28  23  11   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.8744 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113  93  90  68  52  50  32  31  29  23  11   6   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.8834 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 110  93  68  52  50  31  28  23  11   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.8989 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 123 117 110 100  92  50  47  31  23  11   6   4   4   2   2   1   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.9115 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 110 100  93  50  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.9236 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 110 100  93  50  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.9504 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 110 100  93  50  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.9536 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 110 100  93  50  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.9640 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 110 100  93  50  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.9804 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 109 100  93  51  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.9904 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 113 109 100  93  51  48  31  23  11   9   6   4   4   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.9960 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 109  98  93  51  48  30  23  11   6   4   4   3   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.9969 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 109  98  93  51  48  30  23  11   6   4   4   3   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 0.9989 - val_loss: 1.0074 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 109  98  93  51  48  30  23  11   6   4   4   3   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 0.9989 - val_loss: 1.0087 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 115 109  98  93  53  48  30  23  11   7   6   4   4   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 0.9989 - val_loss: 1.0171 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 122 117 109  98  93  51  48  30  23  11   6   4   4   3   2   2   1\n",
      "   1   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 1.0165 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 115 109  98  93  53  48  30  23  11   7   6   4   4   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.0440 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 117 115 109  98  93  53  48  30  23  11   7   6   4   4   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 0.9989 - val_loss: 1.0184 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 117 115 109  66  53  48  30  23  11   7   6   4   4   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 1.0528 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 118 115 113  66  51  48  30  22  10   7   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.0473 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 116 115 113  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.0128 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 116 115 113  66  53  48  30  23  11   6   6   4   3   2   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 0.9989 - val_loss: 1.0469 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 125 117 114 113  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 0.9989 - val_loss: 1.0601 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 116 115 114  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 0.9989 - val_loss: 1.0270 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 116 115 114  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 0.9989 - val_loss: 1.0728 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 116 115 114  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 0.9989 - val_loss: 1.0397 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 116 115 114  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 0.9989 - val_loss: 1.0584 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 116 115 114  66  53  48  30  23  10   6   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 0.9989 - val_loss: 1.0523 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  48  30  23  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  48  30  23  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 0.9989 - val_loss: 1.0470 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  48  30  23  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  48  30  23  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 1.0870 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 114 100  66  50  48  30  22  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 0.9989 - val_loss: 1.0770 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  48  30  23  21  10   6   4   3   3   2   1\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0823 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  46  30  23  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  46  30  23  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  46  30  23  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0897 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  46  30  23  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 116  94  66  53  46  30  23  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "Fitted 20 clusters with distribution [174 124 120 117  94  66  53  35  33  30  21  10   6   5   3   3   2   2\n",
      "   1   1]\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "#For a trained LSwFW_model (n_epochs=200; shuffling) \n",
    "checkpoint_path=os.path.join(\"210210_TrainingLocalitySensitivewFW\",\n",
    "                                      \"LocalitySensitivewFW_label\" )\n",
    "LSwFW_model.load_weights(checkpoint_path)\n",
    "\n",
    "simbatched_checkpoint_path=os.path.join(\"210210_TrainingLocalitySensitivewFW\",\n",
    "                                      \"LocalitySensitivewFW_simBatched\" )\n",
    "try:\n",
    "    os.mkdir(simbatched_checkpoint_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Set callbacks\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=simbatched_checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                     \n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "csv_filename = os.path.join(simbatched_checkpoint_path,\n",
    "                            \"training_log_simBatched_lr0_001.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "#Assign learning rate\n",
    "LSwFW_model.optimizer.lr.assign(0.001)\n",
    "\n",
    "n_epoch=1000\n",
    "for i in range(n_epoch):\n",
    "\n",
    "    #Set training tensors\n",
    "    attentions=LSwFW_model.layers[1](train_tensor).numpy()\n",
    "    simbatched=SimilarityBatchingDataset(\n",
    "        train_tensor,\n",
    "        train_targets,\n",
    "        attentions,\n",
    "    )\n",
    "    rearranged_train_tensor, rearranged_train_targets=simbatched.get_rearranged_tensor()\n",
    "    \n",
    "    #Fit model\n",
    "    LSwFW_model.fit(rearranged_train_tensor, \n",
    "                rearranged_train_targets,\n",
    "                epochs=1,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_tensor, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0545 - accuracy: 0.9867 - val_loss: 0.9221 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89000, saving model to 210210_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_simBatched\n",
      "29/29 - 1s - loss: 0.0433 - accuracy: 0.9933 - val_loss: 0.9312 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0396 - accuracy: 0.9933 - val_loss: 0.9443 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0388 - accuracy: 0.9933 - val_loss: 0.9630 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0372 - accuracy: 0.9933 - val_loss: 0.9682 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0357 - accuracy: 0.9956 - val_loss: 0.9714 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0341 - accuracy: 0.9944 - val_loss: 0.9867 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0335 - accuracy: 0.9956 - val_loss: 0.9884 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0337 - accuracy: 0.9967 - val_loss: 0.9938 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0328 - accuracy: 0.9967 - val_loss: 0.9989 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0326 - accuracy: 0.9967 - val_loss: 1.0052 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0324 - accuracy: 0.9967 - val_loss: 1.0044 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0319 - accuracy: 0.9967 - val_loss: 1.0076 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0317 - accuracy: 0.9967 - val_loss: 1.0144 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0312 - accuracy: 0.9967 - val_loss: 1.0232 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0306 - accuracy: 0.9967 - val_loss: 1.0275 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0302 - accuracy: 0.9978 - val_loss: 1.0315 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0299 - accuracy: 0.9967 - val_loss: 1.0312 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0310 - accuracy: 0.9956 - val_loss: 1.0366 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0313 - accuracy: 0.9967 - val_loss: 1.0342 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0294 - accuracy: 0.9989 - val_loss: 1.0437 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0290 - accuracy: 0.9978 - val_loss: 1.0508 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0296 - accuracy: 0.9967 - val_loss: 1.0502 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0313 - accuracy: 0.9967 - val_loss: 1.0508 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0279 - accuracy: 0.9989 - val_loss: 1.0668 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0275 - accuracy: 0.9989 - val_loss: 1.0691 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0269 - accuracy: 0.9989 - val_loss: 1.0761 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0266 - accuracy: 0.9989 - val_loss: 1.0803 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0264 - accuracy: 0.9989 - val_loss: 1.0818 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0261 - accuracy: 0.9989 - val_loss: 1.0816 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0272 - accuracy: 0.9967 - val_loss: 1.0825 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0257 - accuracy: 0.9989 - val_loss: 1.0843 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0255 - accuracy: 0.9989 - val_loss: 1.0860 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0252 - accuracy: 0.9989 - val_loss: 1.0883 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0252 - accuracy: 0.9989 - val_loss: 1.0928 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0250 - accuracy: 0.9989 - val_loss: 1.0947 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0247 - accuracy: 0.9989 - val_loss: 1.0983 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0246 - accuracy: 0.9989 - val_loss: 1.1032 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0246 - accuracy: 0.9989 - val_loss: 1.1093 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0244 - accuracy: 0.9989 - val_loss: 1.1134 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0244 - accuracy: 0.9989 - val_loss: 1.1175 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0245 - accuracy: 0.9989 - val_loss: 1.1187 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0241 - accuracy: 0.9989 - val_loss: 1.1226 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0241 - accuracy: 0.9989 - val_loss: 1.1248 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0242 - accuracy: 0.9989 - val_loss: 1.1315 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0238 - accuracy: 0.9989 - val_loss: 1.1337 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0235 - accuracy: 0.9989 - val_loss: 1.1381 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0236 - accuracy: 0.9989 - val_loss: 1.1414 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0234 - accuracy: 0.9989 - val_loss: 1.1437 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0235 - accuracy: 0.9989 - val_loss: 1.1456 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0233 - accuracy: 0.9989 - val_loss: 1.1485 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0230 - accuracy: 0.9989 - val_loss: 1.1520 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0229 - accuracy: 0.9989 - val_loss: 1.1550 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0230 - accuracy: 0.9989 - val_loss: 1.1584 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0228 - accuracy: 0.9989 - val_loss: 1.1632 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0228 - accuracy: 0.9989 - val_loss: 1.1664 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0225 - accuracy: 0.9989 - val_loss: 1.1681 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0227 - accuracy: 0.9989 - val_loss: 1.1696 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0225 - accuracy: 0.9989 - val_loss: 1.1744 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0225 - accuracy: 0.9989 - val_loss: 1.1793 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0222 - accuracy: 0.9989 - val_loss: 1.1843 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0222 - accuracy: 0.9989 - val_loss: 1.1886 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0220 - accuracy: 0.9989 - val_loss: 1.1906 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0221 - accuracy: 0.9989 - val_loss: 1.1933 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0220 - accuracy: 0.9989 - val_loss: 1.1992 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0218 - accuracy: 0.9989 - val_loss: 1.2040 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0216 - accuracy: 0.9989 - val_loss: 1.2057 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0217 - accuracy: 0.9989 - val_loss: 1.2086 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0215 - accuracy: 0.9989 - val_loss: 1.2111 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.2122 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0214 - accuracy: 0.9989 - val_loss: 1.2189 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0212 - accuracy: 0.9989 - val_loss: 1.2236 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0304 - accuracy: 0.9967 - val_loss: 1.1965 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0214 - accuracy: 0.9989 - val_loss: 1.2209 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.2255 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.2288 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0207 - accuracy: 0.9989 - val_loss: 1.2315 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0206 - accuracy: 0.9989 - val_loss: 1.2346 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2361 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2374 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.2400 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.2429 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.2454 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.2476 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2503 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2528 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.2530 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.2554 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.2621 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.2632 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2644 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2693 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0193 - accuracy: 0.9989 - val_loss: 1.2643 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0208 - accuracy: 0.9989 - val_loss: 1.2711 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2770 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2765 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2808 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2810 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2804 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2843 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2869 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2900 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2921 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2949 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3016 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.3014 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.3027 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.3045 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.3154 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.3160 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.3175 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3183 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.3195 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.3142 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.3214 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3281 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.3332 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3327 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3348 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3343 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3368 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3378 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3415 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3400 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3388 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3408 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3358 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3383 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3365 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3362 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3341 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3426 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.3409 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3272 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3255 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0129 - accuracy: 0.9978 - val_loss: 1.3052 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0117 - accuracy: 0.9989 - val_loss: 1.3585 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0120 - accuracy: 0.9989 - val_loss: 1.2880 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0188 - accuracy: 0.9978 - val_loss: 1.3304 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0137 - accuracy: 0.9978 - val_loss: 1.3050 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0269 - accuracy: 0.9967 - val_loss: 1.2673 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0607 - accuracy: 0.9922 - val_loss: 1.1645 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0871 - accuracy: 0.9856 - val_loss: 1.2803 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0940 - accuracy: 0.9800 - val_loss: 1.0396 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0321 - accuracy: 0.9922 - val_loss: 0.9926 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0166 - accuracy: 0.9978 - val_loss: 1.0339 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0139 - accuracy: 0.9989 - val_loss: 1.0612 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0128 - accuracy: 0.9989 - val_loss: 1.0740 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0123 - accuracy: 0.9989 - val_loss: 1.1104 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0127 - accuracy: 0.9989 - val_loss: 1.1129 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1238 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1413 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.1468 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1507 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1595 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.1648 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.1680 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1721 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1748 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1779 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1846 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1880 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1907 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1929 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1942 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1964 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1999 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.2020 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2038 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2065 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2082 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2115 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2103 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2136 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2136 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2194 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2215 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2289 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2275 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2334 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2400 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2474 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2418 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2488 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2415 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2485 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2502 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2533 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2533 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2542 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2557 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2530 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0737 - accuracy: 0.9922 - val_loss: 1.1973 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.1186 - accuracy: 0.9778 - val_loss: 1.1898 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0380 - accuracy: 0.9889 - val_loss: 1.1558 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0333 - accuracy: 0.9889 - val_loss: 1.0655 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0271 - accuracy: 0.9933 - val_loss: 1.1078 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0128 - accuracy: 0.9989 - val_loss: 1.0678 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1057 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1185 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1680 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1988 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2180 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2277 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2337 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2408 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2442 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2484 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2632 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2717 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2835 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2897 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2912 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2931 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2967 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2997 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2969 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3024 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3000 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3044 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3087 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3102 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3136 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3137 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3157 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3151 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3180 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3182 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3226 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3217 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3242 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3295 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3290 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3289 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3311 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3293 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3306 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3338 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3333 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3328 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3326 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3367 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3375 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3373 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3392 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3413 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3404 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.3369 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3429 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3453 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3522 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3523 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3183 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3561 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0268 - accuracy: 0.9967 - val_loss: 1.3195 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0892 - accuracy: 0.9856 - val_loss: 1.1774 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0320 - accuracy: 0.9900 - val_loss: 1.1586 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0317 - accuracy: 0.9944 - val_loss: 1.1599 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0150 - accuracy: 0.9967 - val_loss: 1.0493 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0213 - accuracy: 0.9956 - val_loss: 1.1728 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0211 - accuracy: 0.9956 - val_loss: 1.1347 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0074 - accuracy: 0.9989 - val_loss: 1.0709 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0373 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0416 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0598 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0625 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89000 to 0.90000, saving model to 210210_TrainingLocalitySensitivewFW\\LocalitySensitivewFW_simBatched\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0673 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0897 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0986 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1003 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1081 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1114 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1101 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1244 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1284 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1360 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1390 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1404 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1447 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1448 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1529 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1535 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1517 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1560 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1553 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1595 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1580 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1608 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1585 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1660 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1563 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1644 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1621 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1601 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1650 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1703 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1670 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1716 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1711 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1705 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1711 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1731 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1688 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1721 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0576 - accuracy: 0.9933 - val_loss: 1.5750 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.1635 - accuracy: 0.9722 - val_loss: 1.4347 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0742 - accuracy: 0.9789 - val_loss: 0.9580 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0299 - accuracy: 0.9922 - val_loss: 0.9859 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0132 - accuracy: 0.9989 - val_loss: 1.0244 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0109 - accuracy: 0.9989 - val_loss: 1.0291 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0108 - accuracy: 0.9989 - val_loss: 1.0419 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 0.9989 - val_loss: 1.0584 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0093 - accuracy: 0.9989 - val_loss: 1.0667 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0091 - accuracy: 0.9989 - val_loss: 1.0742 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0089 - accuracy: 0.9989 - val_loss: 1.0889 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 0.9989 - val_loss: 1.0954 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0087 - accuracy: 0.9989 - val_loss: 1.1069 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0084 - accuracy: 0.9989 - val_loss: 1.1222 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0083 - accuracy: 0.9989 - val_loss: 1.1268 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0082 - accuracy: 0.9989 - val_loss: 1.1353 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0081 - accuracy: 0.9989 - val_loss: 1.1450 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 0.9989 - val_loss: 1.1427 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0080 - accuracy: 0.9989 - val_loss: 1.1593 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.1708 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.1840 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0076 - accuracy: 0.9989 - val_loss: 1.1880 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 1.1925 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 0.9989 - val_loss: 1.2043 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0071 - accuracy: 0.9989 - val_loss: 1.2096 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 1.2057 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 0.9989 - val_loss: 1.2251 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0067 - accuracy: 0.9989 - val_loss: 1.2505 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0075 - accuracy: 0.9989 - val_loss: 1.2062 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 1.2222 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 0.9989 - val_loss: 1.2247 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 1.2329 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.2396 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.2517 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2588 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2781 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2852 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2607 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0291 - accuracy: 0.9944 - val_loss: 1.1970 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0524 - accuracy: 0.9900 - val_loss: 1.2041 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0171 - accuracy: 0.9967 - val_loss: 1.1555 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.1348 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0114 - accuracy: 0.9967 - val_loss: 1.1429 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0113 - accuracy: 0.9967 - val_loss: 1.1764 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0222 - accuracy: 0.9944 - val_loss: 1.1309 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.1327 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0085 - accuracy: 0.9989 - val_loss: 1.1477 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.1641 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0072 - accuracy: 0.9989 - val_loss: 1.1692 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 0.9989 - val_loss: 1.1804 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0068 - accuracy: 0.9989 - val_loss: 1.1878 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0065 - accuracy: 0.9989 - val_loss: 1.1902 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0064 - accuracy: 0.9989 - val_loss: 1.1956 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.2042 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.2061 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.2157 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0058 - accuracy: 0.9989 - val_loss: 1.2260 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2363 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2414 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.2452 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2561 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2621 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2646 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2736 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2810 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2953 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3077 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3227 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3283 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3325 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3356 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3396 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3536 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3565 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3624 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3617 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3623 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3624 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3632 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3625 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3638 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3678 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3667 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3682 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3748 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3732 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3769 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3756 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3741 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3788 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3785 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3765 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.3796 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3752 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3793 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3819 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3790 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3788 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3755 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3757 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3728 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3768 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3772 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3764 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3740 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3802 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3722 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3762 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3735 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3744 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3720 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3755 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3760 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3771 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3791 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3644 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3717 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3710 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3660 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3754 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3691 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3768 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3636 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3742 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3745 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3736 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3767 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3733 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3765 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3861 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3832 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3780 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3841 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3824 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3806 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3788 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3846 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3856 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3638 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3721 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3581 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3808 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3542 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3627 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3609 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3671 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3661 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3740 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3632 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3655 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3344 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0606 - accuracy: 0.9911 - val_loss: 1.7479 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.2369 - accuracy: 0.9644 - val_loss: 1.3855 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0951 - accuracy: 0.9778 - val_loss: 1.3393 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0418 - accuracy: 0.9911 - val_loss: 1.1088 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0197 - accuracy: 0.9944 - val_loss: 1.1070 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0123 - accuracy: 0.9989 - val_loss: 1.1795 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0094 - accuracy: 0.9989 - val_loss: 1.1520 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0070 - accuracy: 0.9989 - val_loss: 1.1511 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0051 - accuracy: 0.9989 - val_loss: 1.1380 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1436 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1515 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1594 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1665 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1646 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1684 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1733 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1812 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1807 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1903 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1889 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1916 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1934 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1949 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1979 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2001 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2018 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2083 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2092 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2135 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2131 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2138 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2150 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2152 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2180 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2178 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2203 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2290 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2297 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2321 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2331 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2388 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2398 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2437 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2446 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2477 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2542 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2634 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2629 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2610 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2774 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2695 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2667 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2587 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2612 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2638 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2651 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2661 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2721 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2732 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2734 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2778 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2701 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2744 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2825 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2826 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2895 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2908 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2876 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2991 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2913 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2991 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2958 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3030 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2962 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3026 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3148 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3149 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3120 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3193 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3171 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3174 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3136 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3212 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3263 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3199 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3453 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3361 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3419 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3340 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3428 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3396 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3484 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3445 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3559 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3648 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3544 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3601 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3518 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3672 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0097 - accuracy: 0.9989 - val_loss: 1.6434 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.1400 - accuracy: 0.9767 - val_loss: 1.9156 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.1575 - accuracy: 0.9689 - val_loss: 1.2012 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.1175 - accuracy: 0.9733 - val_loss: 1.1712 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0400 - accuracy: 0.9867 - val_loss: 1.3480 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0338 - accuracy: 0.9911 - val_loss: 1.1475 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0248 - accuracy: 0.9956 - val_loss: 1.1375 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0166 - accuracy: 0.9978 - val_loss: 1.1138 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0132 - accuracy: 0.9978 - val_loss: 1.1110 - val_accuracy: 0.8200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0090 - accuracy: 0.9978 - val_loss: 1.0618 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.0666 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.0922 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0061 - accuracy: 0.9989 - val_loss: 1.0957 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "29/29 - 1s - loss: 0.0050 - accuracy: 0.9989 - val_loss: 1.1017 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "#For a trained LSwFW_model (n_epochs=200; shuffling) \n",
    "checkpoint_path=os.path.join(\"210210_TrainingLocalitySensitivewFW\",\n",
    "                                      \"LocalitySensitivewFW_label\" )\n",
    "LSwFW_model.load_weights(checkpoint_path)\n",
    "\n",
    "simbatched_checkpoint_path=os.path.join(\"210210_TrainingLocalitySensitivewFW\",\n",
    "                                      \"LocalitySensitivewFW_simBatched\" )\n",
    "try:\n",
    "    os.mkdir(simbatched_checkpoint_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Set callbacks\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=simbatched_checkpoint_path,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                     \n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "csv_filename = os.path.join(simbatched_checkpoint_path,\n",
    "                            \"training_log_NosimBatched_lr_0_001.csv\"\n",
    "                            )\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(filename=csv_filename, append=True)\n",
    "\n",
    "#Assign learning rate\n",
    "LSwFW_model.optimizer.lr.assign(0.001)\n",
    "\n",
    "n_epoch=1000\n",
    "for i in range(n_epoch):\n",
    "    #No rearranging of tensors\n",
    "    #Fit model\n",
    "    LSwFW_model.fit(train_tensor, \n",
    "                train_targets,\n",
    "                epochs=1,\n",
    "                batch_size=n_batch,\n",
    "                validation_data=(test_tensor, test_targets),\n",
    "                shuffle=True,\n",
    "                verbose=2, \n",
    "                callbacks=[csvlogger_callback,\n",
    "                           cp_callback\n",
    "                          ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processed in excel by combining training and validation accuracy columns from individual training_log.csv\"\n",
    "import pandas as pd\n",
    "SynthDataFolder=\"SynthData_10dim_clusternoise_AddBN\"\n",
    "df=pd.read_csv(os.path.join(\"SynthData10dim_results.csv\"),\n",
    "               index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cavio\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots()\n",
    "df['logEpoch']=np.log10(df['Epoch'])\n",
    "# sns.lineplot('Step', 'AttentionModelwFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'AttentionModelwoFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'DenseModel_val', data=att_model_df, ax=ax)\n",
    "\n",
    "def get_mov_ave(y, window_size=3, percentiles=(10,90)):\n",
    "    assert window_size%2 ==1\n",
    "    w=int(window_size/2)\n",
    "    out=[]\n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    l,u=percentiles[0],percentiles[1]\n",
    "    for i in range(w, len(y)-w):\n",
    "        out.append(np.average(y[i-w:i+w+1]))\n",
    "        lower.append(np.percentile(y[i-w:i+w+1],l))\n",
    "        upper.append(np.percentile(y[i-w:i+w+1],u))\n",
    "\n",
    "    while w>0:\n",
    "        w=w-1\n",
    "        win_size=w*2+1\n",
    "        out.insert(0, np.average(y[:win_size]))\n",
    "        lower.insert(0, np.percentile(y[:win_size], l))\n",
    "        upper.insert(0, np.percentile(y[:win_size], u))\n",
    "        out.append(np.average(y[len(y)-win_size:]))\n",
    "        lower.append(np.percentile(y[len(y)-win_size:], l))\n",
    "        upper.append(np.percentile(y[len(y)-win_size:], u))\n",
    "    return out, lower, upper\n",
    "\n",
    "def get_min_max(mov_ave, y):\n",
    "    assert len(mov_ave)==len(y)\n",
    "    mins=np.min(np.vstack([mov_ave, y]), axis=0)\n",
    "    maxs=np.max(np.vstack([mov_ave,y]), axis=0)\n",
    "    return mins, maxs\n",
    "\n",
    "colors1=[\"b\",\"g\",\"r\",\"y\",\"k\"]\n",
    "colors2=[\"powderblue\",\"palegreen\",\"lightsalmon\",\"bisque\",\"lightslategray\"]\n",
    "for idx, i in enumerate([\"LLDLwFW_valacc\",\n",
    "#           \"LLDLwoFW_valacc\", \n",
    "#           \"DenseModel_valacc\"\n",
    "                         \"LLDLwFW_simBatched_valacc\",\n",
    "                         \"LLDLwFW_NosimBatched_valacc\",\n",
    "                         \"LLDLwFW_simBatched_lr_0_001_valacc\",\n",
    "                         \"LLDLwFW_NosimBatched_lr_0_001_valacc\"\n",
    "         ]):\n",
    "    x_plot=df['Epoch']\n",
    "    y_plot=df[i]\n",
    "    mov_ave, lower, upper=get_mov_ave(y_plot, window_size=15)\n",
    "    plt.plot(x_plot, mov_ave, c=colors1[idx])\n",
    "    #mins,maxs=get_min_max(mov_ave, get_mov_ave(y_plot, window_size=3))\n",
    "    plt.fill_between(x_plot,lower, upper, color=colors2[idx], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim([0.45, 0.95])\n",
    "ax.legend([\"Locality-adaptive Deep Learner\", \n",
    "           \"Similarity Batching\",\n",
    "           \"No Similarity Batching\",\n",
    "           \"Similarity Batching_lowLR\",\n",
    "           \"No Similarity Batching_lowLR\"\n",
    "          ], \n",
    "          bbox_to_anchor=(1,1))\n",
    "ax.set_title(\"10-D Synthetic Data with cluster-specific noise\")\n",
    "plt.grid()\n",
    "# savefile=os.path.join(SynthDataFolder, \"SynthData_10dim_LocallyAdaptiveDeepLearner\")\n",
    "# plt.savefig(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try turning learning rate down to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try on unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cavio\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAEWCAYAAABseTM4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABoF0lEQVR4nO3dd3xUxdrA8d9zdtMTQg8QSoAQSAggElEQBQuKDQsWFEVsXLDX14JylXst14KKWEBF7OJVsWBvoNeCAgpKBwHpPT3ZbJn3j3M22YRUIJCQ5+tnZffsKTNnN7vPzjxnRowxKKWUUkopm3WwC6CUUkopVZdocKSUUkopFUKDI6WUUkqpEBocKaWUUkqF0OBIKaWUUiqEBkdKKaWUUiE0OFLFRGSQiGzYj/u7S0Re2F/7q4tEJFdEOlXy/FoROXE/HGe/7Ke+E5HFIjLIuS8i8pKI7BaRX0TkGBFZfoDL85yI3HMgj6mUqn0aHFVBRK4VkXki4hGR6eU8f4KILBORfBH5VkQ6VLKvUSLid75Qc0VkjfPhnlJFGe5y1s0VkQ0iMmM/VA0RMSKSvJ/2tUdgZYx5wBhz5V7sa7aIFIpIjohki8h8EblDRCJqsI/9VrfKGGNijTF/OcecLiL/ru1j7i0RuVdEXjvY5dgXxpjuxpjZzsMBwGCgrTGmrzHme2NM1wNcnjHGmH8dyGMqpWqfBkdV2wT8G5hW9gkRaQ68B9wDNAXmAVUFLj8ZY2KBeOBEoACYLyLp5a0sIpcClwAnOttlAF/vXVXqlWuNMXFAa+AWYDjwiYjIwS1WwyUi7oNdhjI6AGuNMXkHuyBKqUOLBkdVMMa8Z4x5H9hZztPnAIuNMf81xhQC9wK9RKRbNfbrN8asNsZcDcxxti3PEcDnxpjVznZbjDFTAUTkPBGZH7qyiNwsIh8496eLyNMi8rHTCjNXRDo7z33nbLLQaZG6IGQft4jINhHZLCKXhSyPEJFHReRvEdnqdClEiUgM8CnQJqRVrE3ZlgoRGSAiP4pIpoisF5FR1ThPeU5LwVCgH3Cas6++IvKTs6/NIjJZRMIrqpuINBGRWSKy3emGmSUibcs7pohcJiIfhTxeKSL/DXm8XkQOc+4bEUkWkdHACOD/nGN+FLLLw0RkkYhkicgMEYmsqL4icpWILHVeryUicng565RqoSrbaicit4vIRmcfy53WzSHAXcAFTvkWOuvGi8iLzjncKCL/FhGX89woEflBRB4XkZ2U8x511vnLOdYaERlRZtvJTr2XicgJIdtVeNzKzoM43YsicgXwAtDPqc995ZyHdiLynvOa7xSRyRWc83tF5G0RecU53mIRyQh5PlXs1sxM57mh5b0WItLceV9lisguEfleRCznuTYi8q5TljUicn1F7wGl1MGnwdG+6Q4sDD5wfsGudpbXxHvAMRU89zMwUkRuE5GM0C8Q4EOgo4ikhiy7BHgl5PFw4D6gCbAKuN8p67HO872crqFgi1cr7FatROAK4GkRaeI89xCQAhwGJDvrjHfqfQqwydlXrDFmU2glxO5u/BR4Cmjh7OP3yk5KKGPM39gtc8Hz5AduAppjB00nAFdXUjcLeAm7taE9dotduV+W2MHqMSJiiUgbINw5BmLnF8UCi8qUbyrwOvCwc8wzQp4+HxgCdAR6AqPKO6iInIcdgIwEGmEHhOUF5RUSka7AtcARTsvbyditK58BDwAznPL1cjaZDviwX8/ewElAaFfokcBfQALOeyfkWDHAJOAU51j9Kf2aHon999Ac+Cfwnog0req41TkPxpgXgTE4LbHGmH+WKZsLmAWsA5Kw36tvVXzmGOo83xj772qys58w4CPgC6AlcB3wunOey7oF2ID9/k7ADkaNEyB9hP1ZkYj9Xr1RRE6upDxKqYNIg6N9EwtklVmWBcTVcD+bsLvl9mCMeQ37A/lk7C/tbSJyu/OcB7sb72IAEemO/UUwK2QXM40xvxhjfNhf3odVURYvMMEY4zXGfALkAl1FRIDRwE3GmF3GmBzsL9vh1azjRcBXxpg3nX3vNMb8Xs1tg4rPkzFmvjHmZ2OMzxizFpgCDKxoQ+d47xpj8p2y31/R+k4OUQ72uToW+BzYJHaL4EDge2NMoAblnmSM2WSM2YX9JXlYBetdiR1c/Wpsq4wx62pwHLCDxgggTUTCjDFrg62OZYlIAnAqcKPTQrcNeJzSr+kmY8xTznkuKGc3ASBdRKKMMZuNMYtDntsGPOG83jOA5cBp1Tju/jgPfYE2wG3OMQqNMf+rZP3/GWM+Mcb4gVeBYPB4FPbf+UPGmCJjzDfYf18XlrMPL3Y3cAenzt8be/LKI4AWxpgJzj7+Ap6n+n87SqkDTIOjfZOL/cs2VCMgR+wrZ4JdTIvL2TZUIrCroieNMa8bY07E/lU7BvhXyK/Ol4GLnODlEuBtJ2gK2hJyPx/7g74yO51Aquw2LYBo7PyoTBHJBD5zlldHO+xWhH1RfJ5EJMXpwtgiItnYgVrzijYUkWgRmSIi65z1vwMal2mJCzUHGIQdHM0BZmMHRgOdxzVR3ddgn8+RMWYVcCN2y8s2EXnLaf0qTwcgDNgc8ppOwW4hCVofvCN2N2rwPX2X02J4AfZ7crPY3behXcobTemZrddhByxVHXd/vFfaAevKvJcrU/Y1ihQ7x6oNsL5MMLwO+71Y1iPYrbNfOF2NdzjLO2B3OWeG1Pcu7NYlpVQdpMHRvllMyS/MYDdDZ+w8pO9Dupiq6mY7G/i+qoM5v0b/i92lk+4s+xkowu5uugj7V29t2IHdFdXdGNPYucU7SeIAppJtwf6S7by3BxeRdkAfSs7Ts8AyoIsxphH2l01lydq3AF2BI531g11vFW0TDI6Oce7PoergqKpzUJXqnqM87EA1qFWpQhjzhjFmAPaXsgH+U0H51gMeoHnIa9qozPu1eBtjX5kVfE8/4Cz73BgzGLvFZBl2i0hQohO0B7XHbv2r6rj79F4J2Ud72fck8k1Au2DukKM9sLHsisaYHGPMLcaYTtjddDc7eVbrgTUhdW1sjIkzxpy6j2VTStUSDY6qICJusRNoXYBLRCJDPnBnYncpDHPWGQ8sMsYsq8Z+XSLSUUSewv4Svq+C9UaJyGkiEufkwJyCndM0N2S1V7BzJLxVdB2UtRWocIyeUM4v5+eBx0WkpVO2xJAWrK1AMxGJr2AXrwMnisj5zjltJk5Sc2WcFp+BwAfAL8AnzlNxQDaQ67RWjK2ibnHYwV2mk/fyTyo3BzgOiDLGbMAOyoYAzYDfKtim2uezAi8At4pIH7ElS/lDQ/wOnCoiTUWkFXZLEWDnHInI8WIPe1CIXedgq8dWICn4RW+M2YydS/OYiDRy3l+dnfNdJRFJEJEznR8FHuyW1NAWlpbA9SIS5uQRpQKfVOO41T0PlfkF2Aw8JCIxzt/t0TXcB9h/Z/nYifZhYo+xdAbl5C+JyOlOWQW7e92PfT5+wW5Nvl3sCxhcIpIuIkfsRXmUUgeABkdVuxv7C+YO7NyeAmcZxpjtwDDs/JXd2AmoVeUR9BORXOwv9tnY3XBHGGP+qGD9bOxWkb+BTOBhYGyZIOhV7Jakmo5hcy/wstPUf3411r8du9vgZ6dr6ivs1hicgPBN4C9nf6W6coydUH0qdgvOLuwv+F5UbLKI5GB/oT8BvAsMCeneuBW7pSwHO2grO4RC2bo9AURht4D9jN0lWCFjzArsL/vvncfZ2InJPzh5KeV5ETvXJ1NE3q9s/xUc87/Y76U3nHq9T/m5aK9iJ/euxQ4yQusegZ04vwO7q6glcKfzXPCKu50issC5PxI74XwJ9nv4HexWoOqwgJuxW1d2YbeqhQapc4EuTlnuB841xgQTqys8bg3OQ4Wc1+gM7ITvv7ETpS+odKPy91Pk7OcUpx7PACMr+AHUBftvIhf4CXjGGPOtU5bTsXPN1jj7eQH7wgelVB0kpVMCVH0kIlHYya+HG2NWHuzyKCX2MA1XOt17SilVr2jL0aFhLPCrBkZKKaXUvqtrI96qGhKRtdhJxWcd3JIopZRShwbtVlNKKaWUCqHdakoppZRSIepdt1rz5s1NUlLSXm2bl5dHTEzM/i3QQaJ1qZsOlbocKvUArUvQ/Pnzdxhjqjtoq1INWr0LjpKSkpg3b95ebTt79mwGDRq0fwt0kGhd6qZDpS6HSj1A6xIkIjWdgkWpBku71ZRSSimlQmhwpJRSSikVQoMjpZRSSqkQ9S7nSCml1P4xf/78lm63+wXs6Yf0x7JqKALAnz6f78o+ffpsK28FDY6UUqqBcrvdL7Rq1Sq1RYsWuy3L0kHvVIMQCARk+/btaVu2bHkBGFreOvpLQSmlGq70Fi1aZGtgpBoSy7JMixYtsrBbTMtf5wCWRymlVN1iaWCkGiLnfV9hDKTBkVJKKaVUCA2OlFJKHTTR0dG9a3vfa9euDRsyZEgngB9//DFqxowZ8bVxvEmTJjUbOXJk+73Zdvny5eHPPfdc0+Dj7777LnrUqFHt9rVMs2bNiouLizssNTU1LSkpKT0jI6Prm2++WSv1D5WYmNhj8+bN9TavWYMjpZRSh7SkpCTvZ5999hfAvHnzoj/++ONaDw5qauXKlREzZswoDo6OPfbY/OnTp6/fH/vOyMjIXbp06ZK1a9f+OWnSpL9vvfXW9h988EHc/tj3geL1evd5Hz6fr9rranCklFKqTvnxxx+jevXq1S0lJSVt8ODBnbdv3+4C+PPPPyP69++f0rVr17S0tLTUxYsXR2RlZVn9+vVLSUtLS01JSUl77bXXGpfd3/Lly8O7dOnSvbCwUB588ME2H330UZNu3bqlPf/88006dOiQvmnTJjeA3++nffv2xY9DnXjiiZ27d++empyc3P3RRx9tHlz+5JNPNktKSkrv0aNH6o8//hgbXP7GG2/E9+zZs1tqampa//79U9avX+8GuPnmm9ucddZZHQ877LBuHTp0SH/ssceaA4wbNy5x3rx5sd26dUu77777Ws6aNSvuuOOOS/b7/SQmJvbYsWOHK7jvDh06pK9fv969adMm98knn9w5PT09NT09PfWLL76ocuK9/v37F9x2222bJk+e3BKgon1kZ2db5513XlKPHj1SU1NTi8/rpEmTmp1wwgmd+/bt27VDhw7pt9xyS+vqvaoVH+vbb7+NPuyww7qlpqam9e7du9vChQsjgsc6/vjjk4866qiU/v37d500aVKzk046qfMxxxzTpUOHDuljxoxpG9z3e++91+iwww7rlpaWlnrKKad0ysrKssBuwRo7dmxiWlpa6rRp05pUt6z1tslLKaXU/nP55bT780+i9+c+09PJnzaNGrd+jBo1quPjjz/+92mnnZZ74403trn99tvbTJs2bf1FF13U8dZbb90ycuTIzPz8fPH7/RIZGRn4+OOPVzVt2jSwefNm95FHHtntoosuyrSsPX/7R0ZGmjvvvHPTvHnzYl555ZW/AZYtWxb5wgsvNB0/fvy2Dz74oFFqampBmzZt9mhieP3119cmJCT4c3NzpXfv3mkXX3zxbo/HYz300ENt5s+fv7Rp06b+/v37d01PT88HGDx4cO7w4cOXWZbFxIkTm0+YMKHV888/vwFg6dKlUfPnz1+ak5Pj6t27d9qwYcOy7r///o2PPfZYwrfffrsK7O4wAJfLxUknnZT5+uuvN77hhht2fvPNNzGJiYlF7dq1851xxhkdb7755q0nn3xy7sqVK8NPPvnkLn/99dfiqs5v37598ydNmtQK4B//+Ee78vZx1113tT7uuOOy//vf/67dsWOHKyMjI3Xo0KHZAIsWLYr5448/FsfGxgZ69+6dduaZZ2Yde+yx+VUdt6Jj9erVq/DXX39dFhYWxvvvvx/3f//3f20///zz1QCLFy+OXrRo0eKEhAT/pEmTmi1ZsiR64cKFS6KiogLJycnpt95669aYmBjzwAMPtP7uu+9WNGrUKDBu3LhW//rXvxIeffTRzQDNmjXzLVmyZGlV5QulwZFSSqk6Y+fOna6cnBzXaaedlgtw1VVX7TzvvPM67d6929q6dWv4yJEjMwGio6MNYDwej9x4441tf/7551jLsti2bVv4hg0b3O3bt69WH8rYsWN3DB06NHn8+PHbpk2b1nzUqFE7ylvvP//5T8LHH3/cGGDLli1hixcvjty0aVPYUUcdlRMMps4555xdK1asiARYs2ZN+FlnndV2+/btYUVFRVa7du08wX2dcsopmbGxsSY2NtbXr1+/7O+//z6mSZMm/orKeNFFF+2aMGFCmxtuuGHn66+/3nTYsGG7AH744YdGK1eujAqul5ub68rKyrLi4+MDldXZmJILFCvax+zZsxt9/vnnjYNBlMfjkVWrVoUDDBgwILtVq1Z+gNNOO2337NmzY6sTHFV0rF27drkuuOCCjmvXro0UEeP1eiW4zjHHHJOdkJBQfG4GDBiQ3axZMz9AcnJy4erVqyN27drlWr16dWTfvn27AXi9XunTp09ucJuRI0furqpsZWlwpJRSir1p4akLpkyZ0nTnzp3uP/74Y2lERIRJTEzsUVBQUO2UkeTkZG/z5s19H374Ydzvv/8e8/777/+1atWqsNNPP70LwOWXX749LS2tcM6cOXHz5s1bFhcXF+jbt2/Xqo5x7bXXtr/hhhu2jBgxImvWrFlxEyZMaBN8TkRKrVv2cVknnHBC3hVXXBGxadMm92effdb4/vvv3wR2kLNgwYKlTqBYbb/++mt0cnJyYWX7MMbwzjvvrOrVq5cndPn//ve/mJqWP3Sf5R3r8ssvbz9w4MCcL7/8cvXy5cvDjz/++K7B56Kjo0sFeuHh4cXbulwu4/V6xRjDgAEDsj/66KM15R03Li6u0mCxPJpzpJRSqs5o1qyZv1GjRv7PPvssFuDFF19s1q9fv9wmTZoEWrVqVfTqq682BigoKJCcnBwrKyvL1bx5c29ERIT56KOP4jZt2hRe2f4bNWrkz83NLfXdd/nll2+/8sorO55xxhm73G43ycnJ3mXLli1ZtmzZkv/7v//bnpmZ6YqPj/fHxcUFfvvtt8iFCxfGABx77LF5c+fOjduyZYvL4/HIzJkzi3NacnJyXO3bt/cCTJ8+vVno8T799NPG+fn5smXLFtfPP/8cN2DAgLz4+Hh/bm6ui3JYlsUpp5ySefXVV7dLTk4uCLbaDBgwIPvBBx9sGVzvxx9/jCpv+1Bz586NeuSRR9pcc8012yrbx3HHHZf92GOPJQQCdlzxww8/FO/7f//7X6OtW7e6cnNz5ZNPPmk8cODAXKqhomNlZ2e72rZtWwQwZcqU5hVtX5FBgwblzZs3L/bPP/+McPZnLVq0KKKm+wmlwZFSSqmDprCw0EpISOgZvN17770JL7300prbb7+9bUpKStqiRYuiHnrooU0Ar7322pqnn366ZUpKSlpGRka39evXu6+88spdCxcujElJSUl7+eWXm3Xs2LGwsuOdcsopOStWrIgKJmQDXHjhhVn5+fmu0aNH7yxvm2HDhmX5fD7p1KlT99tuuy2xV69eeQAdOnTw3n777ZuOOuqo1IyMjG4pKSnFxx43btymCy+8sHP37t1TmzVrVqqLLzU1Nb9///5djzzyyNRbb711c1JSkrdv374FLpfLdO3aNe2+++5rWbYMI0aM2PXBBx80Pffcc4u7iKZOnbp+wYIFMSkpKWmdO3fuPnny5BbllX/evHmxwUv5r7766vaPPPLI32eeeWZOZft46KGHNvl8PunWrVtacnJy97vvvjsxuL+ePXvmDR06tHP37t27n3HGGbsr6lLr1atXWvB1vfLKK9tWdKzbb799y7333ts2NTU1rSZXlAW1adPGN2XKlLXDhw/vFHxv/PHHH5E13lEICe17rA8yMjLMvHnz9mrb2bNnM2jQoP1boINE61I3HSp1OVTqAVqXIBGZb4zJCF22cOHCtb169So3x6Yh+e6776JvuummdvPnz19e28e6+eab28TGxvonTJiwtbaPVRsmTZrULDShvT5buHBh8169eiWV91ytthyJyBARWS4iq0TkjnKe7yAiX4vIIhGZLSJty9uPUkopVRvuuuuuVsOHD+/8wAMPbDzYZVF1R60lZIuIC3gaGAxsAH4VkQ+NMUtCVnsUeMUY87KIHA88CFxSW2VSSimlQj3wwANbHnjggS0H6ngTJ07cdKCOVRuuv/76nUC53Y+Hktq8Wq0vsMoY8xeAiLwFnAmEBkdpwM3O/W+B92uxPEodUIW+QsZ/O56NORX/IG3fqD33HXcf4a5Kc0iVUkodQLUZHCVCqUtDNwBHlllnIXAO8CRwNhAnIs2MMaWiUhEZDYwGSEhIYPbs2XtVoNzc3L3etq7RutRNubm5fDv7WwpNIQ8ufZDvt39P68jW5V7qaoxhc+Fmfln5C7d1vRWXz4vbuBEELAvC9ulii31yqL0mWhelVE0c7HGObgUmi8go4DtgI7DHQFjGmKnAVLATsvc2IVETM+umQ60uvY7txc1f3sz327/n5hNuZtzR44ih/FH97/vuPh6c/SBpnZK5o93JNI5qRYxEQWE+dD0C5OBcUHqovSZaF6VUTdRmcLQRCJ1RuK2zrJgxZhN2yxEiEgsMM8Zk1mKZlKp1z/z6DNN/ns4lGZdwWb/LiCaaCCm/FejuY+5mRdYKJv88lQ6+MK5IH0GM5QYBfD4I0+42pZQ60GrzZ+mvQBcR6Sgi4cBw4MPQFUSkuUjxT+M7gWm1WB5VDwVMjQc2PeA8Pg+P/PAIN312E6+te43xn4/n+JTj+efJ/0REcFHuuG4AuMXN3afczaD2/blj/rO8sOwdZv09m1kbf2DW8o+YtWJWubc/tv5xAGuoVO25/fbbWyUnJ3dPSUlJ69atW9o333wTA3DBBRd0mD9/frXHqvnuu++iR40a1Q7sy81HjhzZviblCN1+1qxZcV9++WWVk7iGuvnmm9u0bNmyZ7du3dI6duzYfcSIEe39/gpnBAHg1VdfbVxVHYMT0Jb3XE3Pkaq+Wms5Msb4RORa4HPABUwzxiwWkQnAPGPMh8Ag4EERMdjdatfUVnnqk3yvjzCXRVg5EyeGCvh9ZGf9hdtYxDZqf0i0MhhjyDSZePweLvnvJXy18it6tO7BBT0uYFj6MFrElIxxZmHRWBpXe+j6/clv/GSZLP7c+ifD3xzO5pzNxc/1bNOT+8++n0IpRBDclfyZhRFGmCuMJ08Yx0XvX8f//TyxWse3xOKF815gaNehAMRLPG452L3kqrYUmIJK30f11VdffRXz+eefN/7jjz+WREVFmc2bN7s9Ho8AzJgxY11N9nXsscfmV2d+r/J4vd5S23/zzTdxsbGx/sGDB+fVZD9jxozZOmHChK1+v5++fft2/eSTT+LOOOOMnIrWf//99xv7fL6sPn36VDpwZUVqeo5U9dVqQoMx5hNjTIoxprMx5n5n2XgnMMIY844xpouzzpXGGE/le2wYdhQWke+r/BcHgN9fSP6mheRt/B0KKvz7q1d8+FjPet7/632+WvkVqQmprNy+kru/uJvUiamM/nA0mwOb2Wq2sp71+Kj5aKr7gwcPq/2rOef1c9hVsIt7h97L/FvmM/nwycwcNZPUiFTaWm3pIB0qDd5EhA7Sgc7Siu+GvMhPKeP5+rhJfDl4Ep8PfYGPrvhoj9uHl39Ieut0rpl5DYtzFrPerKeAggNYe3WgbTQbySTzYBdjv9u4cWNY06ZNfVFRUQagdevWvqSkJC9A3759u3733XfRANHR0b3/8Y9/tE1OTu7ev3//lG+//Ta6b9++Xdu2bdvj9ddfj4eKW1jeeOON+J49e3ZLTU1N69+/f8r69evdYLf0nHXWWR0PP/zwbuecc07H4PbLly8Pf+WVV1o899xzCd26dUv77LPPYhMTE3sEg7Zdu3ZZoY/L4/F4xOPxWMGRsR977LHm6enpqV27dk07+eSTO+fk5FhffvllzFdffdX47rvvbtutW7e0xYsXR/z5558R/fv3T+natWtaWlpa6uLFiyMA8vLyXEOGDOnUsWPH7kOHDu0YnNKj7Dm67rrrErt27ZrWq1evbsF6Ll68OKJXr17dUlJS0q6//vo20dHRvffTy3dIO/R+ihwCAhjKG7k8q8hLoc9Py6gIrKIiXGOuIbpTHHnnnojfk4eLZuXsrX4JEMCFixWbVwAwa9Qs8q185q2dx2VvXsZ7C9/jvYXvMevKWbRv1Z5ccmkiTarY6/6XZbL4ZfUv7MzbyZTzpnB0t6PpIl3IjsumU1inGu0rVmKhSIj5cSlHXTYB4mLhrZegVQq07VnuNolnJdJvSj9uefcWpo6YijfMa+cpqUPG7sBudrELgHzycZva/bi+/IPL2/257c/o/bnP9Jbp+dPOnFbhhLZnnXVW9oMPPtgmKSkpfcCAAdkXXnjhrtNOO22PeboKCgqsE044IXvKlCkbBg8e3Pnuu+9O/P7771csWLAg8rLLLus4YsSIrIqOMXjw4Nzhw4cvsyyLiRMnNp8wYUKr559/fgPAypUrI+fOnbssNjbWzJo1Kw6ga9euRSNHjtweOop1v379ct5+++34Sy65JHPatGlNTz311N0RERF7fEg/99xzCW+//XazTZs2hQ8cODCrf//+BQAjRozYfcstt+wAuP7669tMmjSp+bhx47adeOKJmaeffnrWZZddthugZ8+e3W699dYtI0eOzMzPzxe/3y9r1qwJX7p0adTvv//+V1JSkrdPnz7dvvzyy9iTTz651HkqKCiw+vXrl/vUU09tHDNmTNunnnqqxcMPP7z52muvbXf11Vdv+8c//rHr4YcfLnd6EbUnnVutjjHGYAC/gYAxBJwgKWAM2UVe8v12S4nf7WbzT1/hen4GBouAd69ak+scP34E4ed1P5PcIplG4Y2IdcfSt3Nf/rr7L24ZdAsAT//wNC5ceDg4jY0FFDB/7Xwi3BEck3wMQuW5RZUyAfAVwZwfnMcG/vkA+CquW1rzNP499N/MWz+PV+e+ShFFe3dsVWflkEO2ySaPPGbMm8G9X96L/elw6IiPjw/8+eefSyZPnryuRYsWvksvvbTzpEmT9viVFxYWZs4999xsgO7duxcMGDAgJyIiwvTt27dg48aNleYTrFmzJvyYY47pkpKSkjZp0qRWy5YtK55AdciQIZmxsbFVntTRo0dvD04e+9prrzUfPXp0uVOujBkzZuuyZcuWbN++fWF+fr41derUJgDz58+P6tOnT9eUlJS0d999t9nixYv3yBPavXu3tXXr1vCRI0dmAkRHR5vgbPI9evTI69y5s9flctG9e/f81atX71HnsLAwM3z48CyAPn365K1bty4c4Lfffou9/PLLdwFceeWVh/zgjfuLthzVMZ5AAF/AsLuoiOwiL5ZAi6gIthV48AUMLiecLQgU8lhfPxNf2UHu97/iO7E1YXtxPK83j0CgpGtKsAiPiNs/ldkLAQKs2bGGn9b+xNXHXo0LF02lKTkmBx8+/jHgH2R5spj28zTOXnU2J3Y5EZ/x7Zd8G2NMuUHGjvwdPPPLM+wq3MU1R1xDl2Zd8OBh6ZaldGvZjYArQGMa45K9DI58PjsgWrAQ+vWFwcfDhIdg7nxI6AyRURDaNecOwy1uhqQP4aNFH/HCjy9w2RGX0SSyCS5cpc+FCYC3CNaug7PPhr/L+REfGQkffwiH9S7ef6W8Hru8wXWtvay3KuY1XgKUvvjAg4cIInh34bs88OkDADTp0oTjOK5WylBZC09tcrvdnH766Tmnn356Ts+ePQteffXVZs4ozKHrGMvJwbQsi2Crjcvlwu/3V9pmeu2117a/4YYbtowYMSJr1qxZcRMmTGgTfC4mJqZaV3ycdNJJedddd13ErFmz4vx+vxxxxBGV5ghFRESYk046Kfu7776LGz169O7Ro0d3fOedd1b169evYNKkSc3mzJlTow/Z0FYql8uFz+fbo86h58jtdpe7jqo+DY7qGGPALUKU2/7CKfD58QXs34uxYW4KnKsfot3RDLrpcTbOvAj/1NfJPjqDKG9RjZOyt6+ZDf6iUl++zTudQHj4wQmQDIbXfnmNcFc45x9+PpZYRBJJnMQV/2q+9thr+f6v7xk3axxpY9MIRAboLJ33+di55LLGrClOfDXG8NEfH/HIl4+wK9/u3vhm3TfMHD2TdbvW8dvG3zir51m4xU0c+3C+8rNh/QZY9Cfcdj1ccA48+zyMHAuMhaZN4OF7YcCR4PVC2y644lvShCZcN/A6zp92Pm8sfIOL+15MBBEkS0jaRX4OLPoRLrkatu+A4cNKd7/5AzDtVXjnTYi3wOeFlpVc5BPww5o/wPjtoKttCjRO2Pu6KwImwGqzeo/gqNBfyMhpI1m8ZTEJcQn069SPjtLxIJWydixcuDDCsix69OjhAfjtt9+i2rZtu1+bQXNyclzt27f3AgRbf6oSFxfnz87OLhX1Dx8+fOfll1/e8ZZbbtlc0XZBgUCAH3/8Mfawww7LB8jPz7fat2/v9Xg88tZbbzVt3bq1FyA2NtafnZ1tATRp0iTQqlWroldffbXxJZdckllQUCD7I8A57LDDcqdPn97kqquu2j1t2rSm+7q/hkK71fYzbyBAntdHntdXbt5QVQym1JeXCAQMlNeafnLqabw5II7289Ygq9YR8NYsKdfnyWHZu6+ycvS1rLzqGr57exrGGHwHsovOV2R/4WbvhOyd7MrdxgeLPmBo+lCaxzbHwiJcwkmykuhodaSj1ZHuEd2555R72J67nRfnvIgHz16d67JyTS5u4ybSROL2u3n8q8e584M7CZgAUy6YwugBo1mxdQXPzX6Oc6acg9tyc+lRl9JaWtPIarT3B/bkwwLn0vwTBtk5R29Mg3hnn7t2w3V3wMq/7Vak3ExEhLZWW05teyq9Envx/P+eZ/vO7Xuei9wsuOFuWL8RnnoYnpwEU6eX3F58BTq0h8VLIboRRMXaA1BWxFdkB0bRjSA80n6s9okPHwECRBNNXm4eO3fv5L1573H0w0ezeMtiUlqk8NGYj3h26LP0jC8/B62+ys7Odo0cObJj586du6ekpKQtW7Ys6j//+c9+nXts3Lhxmy688MLO3bt3Tw0mSFdl2LBhmR9//HHjYEI2wBVXXLEzOzvbfcUVV+yqaLtgEndKSkr3QCDAbbfdtg3gjjvu2NS3b9/UjIyMbl26dCludRoxYsSuSZMmtUpNTU1bvHhxxGuvvbbm6aefbpmSkpKWkZFRnFS9L5566qn1Tz31VEJKSkraqlWrImNjY6u+2kch++NL5UDKyMgw8+bN26ttD8Tosrs9RWwv9CAIHWKjCXfVLP7M8/rYVughyuW0HPn9xIeHkVXkJcrlosDvJyk2mjlz5nB0/wye/u81/GPUK6w9sQedZ3xJeKPq/4pfMPl20m98mJwIIabIEOmDT0ZlcMyT/yWuUVKNyr3Xsncy+4efGNSxBXgL+df2zxj//UN8fNXHJCUk0cHqQIyUHm7EGMNSs5T7P76fNxa8wb2n38tdh99FmOxNx6Kt0FfIAwseYOH6hcxZNYesQju/88z0M3l46MMUWUXsyN7BcZPsLo3Y8Fj+deq/GJw+mCQrqbiMe/Ue27gSRl4JK1bB/76wpw4JtW07nHWh3fJz8QUweiRkHA+WRaEp5NNtnzJq+ii8fi/TR07n7MSz7XMRCMC5Z8PMD+GpR2DwsdAhHSLL5NyefTYsmGcf2+8Dv5/Z6zPLr0d+Nqx3AilPPsQ2hVZ1uzWjro8qnW/yWe1fzbINyxj99mgyCzIBEIRbjruFUX1HIWFCgiTwx3d/7HVdRGS+MSYjdNnChQvX9urVq9z8GVXaSy+91OSDDz5o/P7776852GWpiZycHCsmJiZgWRZTp05tMmPGjKZff/316oNdrrpg4cKFzXv16pVU3nParbafBYwh0nLhx+Dfq5YjSrcSOYnZFRnWeyjvHTWTCz//g5+H9sMXaY/EHH3+CDIuv9spU4DJn02g6/Mzicq3f+nHZRVw+M/rWNHKjfXRq3jDY9h48ShOnT6POSuPpkfG6TT916MQV8vdawE/WAIxjfDl+pjy28tcWZTKMfe9js94iSAOxA0pKXDTTWBZiAhu42b8kPGs272Oe2fdy+cLP6dHix57VYRMTyYfLf+IAl8BghDuDqdnm55cePiFnNvrXNyWmyKK6N24N5POm4TH4+GM7mcQ4Y4gn3ysfW2ADfjhjyVw7NF7BkYALVvAK1Ph1nHw4qvwwcdw5lngchNhDIPIYlF+P+asnkPWzOHMbtyRCFc4sduzOXzBJr4Z2Y/jzzzNDmzKyyfqewS8/z4s/BN6dofNG+n03HR4883S661eDVs2wzWXw+mn2lOb5OyCZokl3blffQX//W/l9Y2PhzvvhCYH/irDusiPn+e+f45nvnsGsMewujjjYq45+hpaxrUEIM/k6ThWB9Gll17a7ttvv42fNWvWyoNdlpr64Ycfom+44Yb2xhgaNWrknz59+tqDXab6QP/a9jNfwNjpOwZ2eYpIdEdVuU2oPQIhAX/AlNutBoLLCqPj/ROYfc1ddF+wFoDIIkP0l/cw5e/ZbMlIZsnmpVz77+/otwF2xpT02c1Oj6HRxHtpFRNJAD9NX3qSH666npSFm4j/cSrZv/5M3rQHiXE3olGrHhATX6O6VIvfR8AE2BTYzEvL3mTw95uZ8tEWiFqLiY6yAw9jYMdOWPEn3HETiEV0qyh2h+cz7tRxTPp2Eos2LmLV7lV7VQTx+0lv0onLup3BcSnH4W+TWPycx/kvjDAa0Ygzup2B13hLtVLtc3C0aaPdKtQjDQpy7WCp7NhIbZrDG1Pgi29h4rPwoT3YvADxGOIIcIGJIKfIh9+U/LB96Gi4s+NPzNv6E20btcEjm2hPh9L7vuoq+M9/4La74d3X4Mobab9kuZ3r5ApJu9juNDBcfSv07AntEiFnt31V3ba18Os8OH8UREbYSd4V2bUb/jcHXptqP27RHuKqCJQ8+bB5dXEieKbJIs/tozCxHW4Jo720PyiDge4LYwx/m7+Zu3EuU/83lY7NOvL0hU/TvklJzlce9hiEAQns/dWQap+9/PLL6yk9kXq9MWTIkNzly5cvOdjlqG80ONqPjLFbiwSItCwKAwH8xuCqwYe235g9vhd9xmCVs4+w8BhadD6BFp2OJzD/cvw+uys7a+t6th/dn+EPfc0rvb5m7FY45m/If/h2Go2+BuPM9t4XcLkjS325J/58Jr9u+JkJt57GszMXYcZNpPC+62hUkF07wZHXQ0AM88ffxrhXFtiLurQn+8UH2XF4FzpLZ9y4YMxYO0emXSKccyqtva1JiGhPt2bdOP7c4/HvOV9x9fh9uFb+DhHRCIKVW4Qxnfe4AksQeyoQU3r4AIPZ9+DodyffqGe6/eWfmAKRFcxcMOYwGH0DhFxhaIwfQwALiMOUOhcDtiyEV0/ih7BMTkvqT4Hk4Df+0lfWNWkMj/0LxtwCV1wDS5bz97nDaD/9xdItWTk58NADMOk5eOwpePI/4HbbSdzZO+GpKXa+1BczIe3wiuv79NNw253w4y+Q0cNu0aoyOCqwuwcXLgaXC8/wgbgTW4DPR3ZYAV68hFPOxQgBP2DA7wUEXHXnI8+Hj2yy+fiPj/EFfDx5/pMc2/TY8usBh+QI2UrVVfrXth9lFXnJ8/mJcbsQEQLGsDm/kLYx1Ws98jtjGZUKhAz4AoFygyOAsLCQL9FwO4E3umNLtn/wDhGXXMfVy3eCy8Wue0cQfcZpRMa2rvIL4uhOg1ny7yf5166ruefdr8ls2wpza7f9P8ZgUSFkbsO7eztnOIERwM63J+Jt1gRfVBQuaWy3ojw1Cf5eC/98EJo3wXVBJ1z7kGNUbNsq8AQg1jmP+fmwc1uFV2yV9+t9n4OjPxbbQUhaV8AHEdEQVv5EteWXiQrbFA5vdzSCsHLXGicQzseLt0w9xL4S7qF74Va7KzazV0/alw2Go+Lgzv+DHdvgrZlw160QGwHeQvh7I3zzHVx3FbRtb69bkbHXwEMPw0uvQ/8noKgaFwDMeAtuvhtiojFeL80++YzsNx4jLAmM25BDDs2knAuR1i2xE8xXLbC7ATv2rNG5rU0+fFhY/L37b9IS0ujUvBMRRGj3mVJ1gP4V7kd+Y4iwrOJAxhi7S8wYU60m/4AxBICokF/rYZbgCQSIkJp9AYd17srOmU/gjrZ/kReaAuI87mqPSTM45WTeuWUsr+x+lpFPvk4gphUy+PTyV+7WDVq1qlH5APD7MF4fyffeg8cFv028mtZDzyDSE8AdHkMzmpWct8gomPhvGHWd/SXpjoLktJofM9Tvv8Mdd4DHAwP6weMPQZM4+8u+Ai5ce1xyLfsSNgb89pVinTtCdDTk5ZTuytpH0WHRdG7WmS+Xf8nV/a8GN/ilTCubiN1te/45sHkrPPciOV27VrDDeLjwXHjtHXjtLRhzqd1y9OrbEB4G558NYVXMgxkdCxefD09Ogbffh/PPgqws+O03/AE/S3csxRfSMhaxeTtdb3+Y7MO6kDX9CRI3F2CdN5JGY+/ll1tO5+O133LNkdewPt9+3fI6t8fboqn9B7hhGb/n5EBWAhTmgdkBEVGE7coiZkXFebXt49vTNKrMVc+dO0O7dvZ9Y2DBArs1rTytW0PIOQyYAL9u/JUCXwHt49vTqUkne+obA2t2riG9dTpQfvCtlDrwNDjaj4rzjRwBnKlAKLk63xcIUOAv/eXqFiHSZZHr9e2RW2S3QNk5yzXhDouGogJ8zg7D/AGsmNZ75rJUIMKK4txuJ3HXdUto++B3HP/AY/DAY+Wv3CgOnpsMpwwp2b+IfSVTZZPn+n14X3+DLss3c8/FrRh74mACBXk088bjjuoEVvOQCoXbeSxP/weGXwlX7ec5in+cC5eNgTdftL/4fEX2McuwsIrHWzLGYImFVcPAtRSfFxYvt4Mze692C8d+9M/j/8nI/47kxpk38ui5j5JFFl7jJZpowiUckJI36A1j4fKL8G7MLn9nMfF2MHzCQHj1LbjsAti2BWbOgqGn2cFleBXBkQhcfRUsWAR3/5tAfh68OgNr7XpcQHo5myxtDv1PXknBh2fxyykv0OaJW2k25n6GjH6KIQCMLV53VyT0uxJWhLx9CMm46LAbfnoRWu8xSUUVXC4YfAKEh9vjUv32e+XrT52M57wzKTQebvr+X7z028sAxEfGs/iWxWCB1+9lQ+YGTks7DQur3uVNKXWo0uBoPzKYUm0I9vQfpeOdfJ+fLfmFhDlBg8EOfBJjothZWITxWuzYDc2dGXCEyq9Wq0hUVAsCSUcWH9xCcEU0r3yjEE2lKYVtMrjthHsYtPE0ztzdnAlHjCHSFU4LaYEr+AVeWAi3jIOLLoVuXWDKY/bVVT4fJB++52XjoX5bQPh/nmFWF2h9yaUEwiziWvTARRxElRk3yOWGdl0h0Q8/zIFffqaCLPXqsyzofRg0bwUz34XLxsJLb8Coc+3BExvt2U3jwlUSHO2PfKMli+1E5yOcHB2h2gFsdZ2Rega3Db6Nh798mG+WfsOJaSeyla20lba0kBZ7zsnmdlVehvAouOQC+Go2vPgGREVAfgFcfrH9OlWULxWqWSt4/N9w6TVY/3qUQGQ4d12eyC9mMxd0GULX+NLDA2R2a8s9EYXc8tV9zMidzxVnj2BLcnuufelK2scl0Kd5dzrFt6NpIJyMf73JgnfC+P6ZsRQ2i2f1Vj8d20UhPh/Nf1tJ7xffI8Lk8vODwylqtGdZPf4iJv/xJuEuN/866lriI2JpkRuJ++UZsHI5BPO1LjwHzjxjz3NljJ2Tdc1NeCLzeThyAS8teYuL+l5ElETx4twX+Xj9xxzd/mi2Z27Hb/wkNU1qsK1GItLnyiuv3Bqc72z8+PEJubm5rokTJ1ZrvKP169e7R44cmbRp06Zwn88nbdu29cyZM2fV2rVrw8aMGdPus88++6u6ZbnxxhvbDBo0KOess87K6du3b9dHH310/bHHHlvtgd9Ct58wYULLm266aUdwCpDqSExM7BETE+O3LItAIMD48eM3XXzxxZmVbXPHHXe0euihh7ZUts6wYcOSQudwC9qbc9RQaHBUgawiL/k+P86FZzQJDyPSXfGHV8AYPH6DO6SJp1GYmwJ/wB6UT4QdBR7yfH4iXa5S4x/len1szfdgiTD20gi++MTFxpxCLKskOKrp16XLHUGj+JpNgBoqQiKIiGlL745teXr4C1w641I2yrc8fu7jNHal4JKQ1oGjj4XHJ8KU6TD2Nnh5KsRFOAMEVhIcjboCv8C4s+L5uP0x+KMiiW9cyUjXcU43R3wLSErZ67qV66yzYdrLMHEydOsMrTtBORP5usVdHJMFCOxbkmxBLsx0Lns/pr9zJZbs95YjC4sRR4zgrXlv8eb8N9mStYU+HfrQPNEJlsUqE2eaPQOmUGHhcMRh0CoBnnkRIsLhqCPsnKkiT7ktbnuIjIFYe7DLnI9ncpfncybLIiaePZFT088n0UrcYxNjDI/8PIUH5kxiya6/2ZqzlZ86wn+vnMzJbU4mTpw8p55nEzHkDIacY0+5sX3A0bRoGg8fflKys1ee5ahTzoDmex4HwLVhOKe/cjrLPR/w4vkv0igyDfcFl8CmlfYYT2Ankif3KT+H75gTYMAxhF8znndHFnJmv8HcedKdtChowYtzX2TFxhWc1OEk/t71NwBJzRpucBQeHm4++eSTJps3b97SunXrag3SGOr2229PPP7447PvueeebQBz586NAkhKSvLW9Ev/iSee2OsBKH0+X6ntp0yZknDVVVftqklwBDBnzpwVrVu39i1cuDDilFNOSakqOJo0aVLrqoKjiuzNOWoodITsCuQU+Sjy+/EFAuR7fXj8lV8N5TcGnwmUujLNEsFy0jkCxpDt9eISO48olD1ViCHSZfHFJ/YH5F+r7HVEhPjwMESEwkJ79ogD7ZQup3D3kLv5ZuU3/PvTf+MzZT6/ElrBtVfCtKdh+So4YqA9onPm7vJ3CLBoEfy1lkf7w+HdziDC70eqylWpTe5w+Of/2fdH3wTry79qNwz7tcgnnwIpIGyvZrQDtm6FU0+DCf+B9m2hQzs7OKqFecosLNyWm3N6nMPcdXN56OuHOG/aeSzdsbRkJZGS+dKCQVpFwsLtUbKnPQ1+v91qdOWldv5UNaevWZX9N7/tXs7XBUvpH/s+k2UR4/pdz8ndT67wnIoIGYn2GIbv//E+P639ia4tu9K5VefSQeqRR8IzjxQ/bPG/H+CnuSXPfzML+vaG8IoTs49IPIJHzn6ExVsWc9vM2ygMFNpBkMEOioJjRlX0erVoydwHryArUMg3b4XxZNerCJMwEmITSGqSxG8bfgNg7a61ACQ0TWiwV6O5XC4zcuTI7Q888MAeI9guX748/KijjkpJSUlJ69evX8rKlSv3eINt2bIlrF27dsVDtR955JEFwW27dOnSHWDSpEnNTjzxxM79+/fvkpiY2OOBBx5oce+99yakpqam9erVq9vWrVtdYLewvPTSS3tcOjlixIj26enpqcnJyd1vuumm4rnZEhMTe4wdOzYxLS0tddq0aU2C2//73/9uuW3btrCBAwemHHnkkSlPPPFEs8svv7xdcLvHHnus+RVXXNGu7HFCZWZmuho1alT8xXPiiSd27t69e2pycnL3Rx99tDnA1VdfnejxeKxu3bqlDR06tCPA5MmTm6WkpKR17do17ayzzipugp0zZ05s7969u7Vt27ZHsI5lz9FJJ53U+ZhjjunSoUOH9DFjxrQNbvv44483T0pKSu/Ro0fq8OHDO4wcObKSOYYODQ3zr7EaDBDmJFf7DVQV+vsDBquCLxRj7MvxBcHtdKf5/SV5ty4RECE/pPF22nMuHphoByHBBO9brg5jxw43X3+2LzWruXAJ59w+57I1aytTfpzCt8u/LX0puDGI3wci9L0qhlE/FXL2l7OhXSe2xu0Zf4uBlrn2GZ1zbCL/aHUaPvxYcdXv9tvvXGHQphX85z64/Z+QcQwcNxAGD7YHn3RegygsUlzJdmuL34vlN3DHjfDmWwD083ohrBoB086ddtcj2K1GAJjKc7T2kjg5Ref3Pp8nvnsCsAcaPPP5M4mPtK9IE5+vpHvIBCjyQ9jvFdTDgPjtKP1f/SPZHG/xzI7x8DYgFqaKhPICbwHZntI5Tff2HMXIvpeSi58IqThoefyUx4mLi+PmY28mz5NHi7gWuMRFlIRcEeoOh2OOgtW/w4efMje+OUcO6gs7d0GYGxo1goI8+zWvgBs3x3Y9lvEnj+fez+6ly2NdCHeFl25hq6I5d3f+Lk4Z3ZL3ns2k6LaH2TZzGoTlMLDDMby7ZCZ+TwEvzX2JFjEtaBrVhNbSuvId1rbLL2/Hn39W0tS7F9LT85lW9YS2t91227YePXp0v/fee0u1gIwdO7b9iBEjdl533XU7n3jiiWZjx45t99VXX5Ua3fmaa67ZNmrUqE7PPvts/qBBg7LHjh27MykpaY+fkStWrIhauHDhkoKCAqtr167p99xzz8alS5cuueKKK9pNmTKl2fjx47dVVL6JEyduTEhI8Pt8Pvr379917ty5UcEgrFmzZr4lS5YsBfj888/jAe6+++5tzz77bEKwFSgrK8tKT09v7fF4NkRERJjXXnut+ZQpU9aVd6yBAwemGGNkw4YN4dOmTStu1Xn99dfXJiQk+HNzc6V3795pF1988e5nnnlm4/Tp01suW7ZsCcC8efMiH3300dY//fTTstatW/uCQR/A1q1bw+bNm7fs999/jzz77LOTy3axASxZsiR64cKFS6KiogLJycnpt95661a3282jjz7aesGCBUsaN24c6N+/f0r37t1rNldVPaTBUQUCJoDb6d4Q7OCmMnk+P9nZhk7tInlyahHnj3DCKWPnpuz2eIs/V6+6OIyfvreY9W0RSZ1K9nvTmJIP65emuIuDI4DVK4X3ZrgYfUMRrv14NVN1RBBBtERzy/G30DimMX/v/Lv0CgGDOz/XjgLbwsxj4K8FWzjs9x1IBeet45os5g5M4v4L/4+dm2MwMdHEhFdrTsjaER5hd5ecd5bdivPiqzB3Pnz9Lbw0DZ57DFongN+Hu02y3bW3dqk95s9Tz9sJygkt2ZmZS5vGsdU7Zs/usHkzDD/Hfux0v+5vwavpWjdqzTPnPsParLUc3fFo3l7wNoGA/T51Z2XarSAiiM/Ljnwhvk3j8ndowJWXi5gA3zl58YOd5YHISALhVbceNY1qSp+I1lgBP92bdiYxpiWFkZFESwQRVBwctW3UlrtPuZtoomke05wiU7Tn+sHXMuCHM0+lYOVGe3mzkKvPouPs3KkKhBNOLLFcfMTFhIWF8efGP6usU1kxHh+juw4lT74mbuJ02jfpCZbFk81juDgml6uWpbGxE4xNPpPI7BzCmlQSVHuLan5VRj3StGnTwHnnnbfzoYceahkVFVX8W/S3336L+fTTT1cDjB07dtd9993Xtuy2w4YNyx4wYMAfM2fOjP/ss8/i+/Tpk/bHH38sLrte//79c5o0aRJo0qRJIDY21n/eeedlAvTo0SN/0aJFlQaFL7/8ctPp06c39/l8sn379rCFCxdGBoOjkSNHVtJEbouPjw8cffTROTNmzIjv0aNHodfrlb59+5YbYAQDqsWLF0ecdNJJKaeeeuri+Pj4wH/+85+Ejz/+uDHYrWWLFy+ObNWqVV7otp9//nmjM844Y3ewezIhIaG45Wno0KGZLpeLPn36FO7cubPcN9uAAQOymzVr5gdITk4uXL16dcS2bdvcRx55ZE5wX2efffbuFStWHMRm/gOjwQdHhX5/ccKz3bIjuEUIQPGVIyIQCJR8yRf5A/hMgEiXC78xBIyhwOdj3Qr7dN74jzDOH+EMFCjgDRg8fj+RLotli4VZM+3gZvZXFqNGl3TXffiuvfz4k/x884WLZ59wMfZGP++8aXHdlfYXzsh/+GBvu3L2UriEF896/1D/h6q30UVVrxJs7529czZtkgbtVdn2G1cYdOhu3+/YEy64zA5W/nkXPPgIHHcmPP0YnDQQcjMhMhbemWkHRuecDpMmQmIXVsyeTZuazH21YwPscib5DgTAVb1uqZoIvcLulNRTyDN5tLPaMfS0oSUr/bXI/vJ1uSE/m9kbcxl0/An7vSz7quywCQazZ65O6GsJsG6X/ZrWgEtcdBT7HXrX4XdBJWNaVumRi6BtN3sk9F9/I37O/zgROHIjTPr3YK46Ygz5nqKKr1Tze2HTipL7taUaLTy16c4779x6+OGHpw0fPrzGc70lJCT4x4wZs2vMmDG7jjvuuOQvvvgitl+/fqUSqcPDw4s/xC3LIjIy0gTv+3y+CiPPZcuWhU+ePDlh/vz5S1u0aOEfNmxYUmFhYXETb3VzikaPHr3j/vvvb5WSklJ48cUXV1nH7t27e5o1a+ZdsGBBZF5enmvOnDlx8+bNWxYXFxfo27dv14KCgho1MwfrC1Q4UXfoOXK5XMbr9R66EXkVGnzO0bYCD1vyPWzN97CtoJDtBZ49utAEwR/Snp5ZVMSGvAIK/X62FXjYUVhEvs/PR+/awZExQiC4E2NPJutxBnJcuKDklK9cXvK++/JTe/k/H/By2z12i9GEcWF8/bnF/feUBENt2taviYLrNRG4biw8/6T9+Jpb4LnpsG0zzHwH7nnQvgR/wl2V5q9Uyh1uj7+Tlw35WRBRs+lmqkOc/0LtcZWdO8wZTdreoq4qW+5yg6O6xrLgogvgH5fCq1PxvP8K6755HneTJtz5z++Jfuo1wrIruSCqIBfysuzBLOvwa7OvEhIS/GecccbuN954o7h/vXfv3nkvvPBCE4ApU6Y0zcjI2GMAhg8//DAuJyfHAti9e7e1bt26iI4dOxaVXW9v7d692xUVFRVo2rSpf/369e7Zs2dXa6qAmJgYf1ZWVvEb9vjjj8/bvHlz+MyZM5tdccUVu6rafuPGje4NGzZEJCcnF2VmZrri4+P9cXFxgd9++y1y4cKFxZdZut1u4/F4BODkk0/O/uijj5ps2bLFBRDarba3BgwYkDd37ty47du3u7xeLx988EGDmBSxwbccGWMnQlsi5Pt8WE5LUCgrOL9Z8Tb2F06mx4s3EMBtWYS5LF54puR0/rVKSE6xr/oJDg4J8OciISra0KWrYVVIcDRzhv0ePvdCP81bwmvvFnHxsHCuujisOA1l/P0HIRu7oQuPgn4Z8N2ncM2t8Nhk+wbQNRmeewLcptIumkrFNIakkAlzKxv6YC8JUtxyFHy8x8CV7jDI2Qlej92FU0eVrct+GU7hQAiPBL/9o8f07oGYbeS9OhH3Df8mdvLrRM6aDWedV9KtOmAAnON0t/qK7IFCZ31Joz794IQTD04dDoBx48Ztefnll1sEHz/33HN/jxw5MunJJ59s1axZM98rr7yytuw2v/76a/RNN93U3uVyGWOMXHLJJTsGDhyYv3z58v3SDNuvX7+C9PT0/M6dO6e3bt26qE+fPtUaIevSSy/dMWTIkJSEhISiuXPnrgA466yzdi9atCi6RYsWFV7hM3DgwJRga9b48eM3tGvXzjds2LCsqVOntujUqVP3Tp06Ffbq1au4O23EiBHbU1NT09LT0/M//PDDNbfccsvmY445pptlWSY9PT3/3XffXbsv9e/YsaP3pptu2pyRkZEaHx/vS05OLoyPj9/L+ZrqD6moea2uysjIMPPmzdurbWfPns2gMl0ea3PyiHBmes/2+nALhLksvH5DtHPpvjEGTyBAh9hoRITN+QX4AqY40TrMErZuMxzRuWTMlInPeLnwUj/5Pj9hlkXAGCJcFucMCafIA527GN5+3cW7nxbR/9gAx/YJp1OyYfoMLzleH9FuF3dcH8Zr0+yA61+PeLnyaj8Ffj9JsdHMmTNnj7rUV+W9LnVGfjasXQwuy+72+vRr+PZ7aNYcrrwQWrSws+uT0iG6UZ2si8/4WGFWEO0Mq5BHHp2kU+kkZq/Hvjlm/7KgztUDwG/8LDPLiMH+W8s3+bSUljS3Kk7mrxOvSV4mrFsMLjcevOw02wl3cqXCX/+ImCkzcBU4QWmu87036iK47y57Xrmb7oSPv2LZzTfR7bGJe1UEEZlvjMkIXbZw4cK1vXr1qnE3lto7xx13XPKNN9649cwzz6xgaPW6KSsry4qPjw94vV5OPvnk5FGjRu0YOXJk5sEu175auHBh8169eiWV91w9+MlVe4xxRq92fq3Ful2EWy7E2CNWB4mTg+Q3wZGR7V+w4S6LcMsiYOCrT+wg5rP/eWiTaHj/HXv7cMvCG/Dbl/QbWLxI6N4zQFJnu99t2Cnh5OfB6hVCek97/35nAtt+A0o6+Dp2ql9B7CEjKg6Se0PHXtC5N1x7K7z9Lkx+GvqeYC9PPhyiqpmEfRBYWLhwke/8Zzn/lRLmJDEHb3VU2VavetGtBvY5Te4DHXthktLJTupIXlIyeUnJbLvrGjb/9T/YvMG+rVpmbzP9DcjLtVv11m+G3j3ZcsopB7ceaq/s2LHDlZSUlB4ZGRmob4ERwG233damW7duaSkpKd3bt2/vqWrspUNBg+5WM8X/swXHJQLIyoT164T0XiUB0Y7CIlpFRxIIuajIEsj3B/hgRgTNWxh6HmYYdKKfzz52YQy4nITscEvY8LeQnSV072k47sQAD0+w93HFRWEEAnbQZIzBJfbHf/ceJYXroMHRwSFS9XQYdZwlFl3oUtwdJci+TXlyEFliIUZKzVdYaliJukqs4veRZSwCJhyD3evjNwaRWLAa2+vGNoaMw2HeAlj+F3ROgkWL7cmBdXqReql58+b+tWvX1vySxzpi6tSpGw52GQ60+vkJuZ94A4aKQo5Lzw9ncP8IipyW7kiXhc/JOwqETBNiieDNcvPz/1yMGu1DBFLTDbt2CNu3lgzi6LaEPxfZW6X3DNCug2F9ViHh4YbZX9kf7j0OCxRPJ2KArmklpWvXQYMjtfcssXCJC5e46m1gFFR28t96kXMUomzeVLkjrb/8kh0I3ToO1jjD4Rx5OJgaDbZcHYFAIKARl2pwnPd9hX9Q9etTZT/L8foIVBAezf3BPjWDMuxfdxbgNQEK/X77V2vIusuX2o/69LX3ldbDPt+L/yh9ehcusBAxpKTZ+7FchpvuLBnLqG274FxrgrfM5LQRe3kxlFKHGguLPPLIN/l4xVvvgiMLiwCB4supyw2OOnSAsZfB6jVw5oX2ssMPA2u/N/b/uX379ngNkFRDEggEZPv27fFAha15DbtbzRjCyxmR+ItPSpatWW3xxScWJ50awBjKvdR/5XJ7/S7d7GdSu9sfekv/FI4bbK+zYT08+bCbLt0CuCMDuMTCGzCMud5PZCScP8JfXCYLwWPsx02aGg7wmI9K1WkJJOART3HuUWWDRtZFFhaRROLFS7jTteaWMh/FlgvGXgH5Hpj+ur2sQzvw7t9A0OfzXblly5YXtmzZkk4D/7GsGpQA8KfP57uyohUadHBU0YSuH7xjRyNnnevn/XdcfD7LDo6iXBYFzhxroQO2vfuWi/BwQxtnDssmTaFNonFajuz1n3vSPtXX3Oi3c5EsO9cgMhLGXF9yVWSw5SjY9bFgZckVREopiLPiiCPuYBdjr4kIkSaSAkoGSN5jaAXLsqc6mTDOvvn94MmDzft31oY+ffpsA4ZWuaJSDUyD/qVgnNyhDeth/i8lH05FRZDcNcCzL3s59ng/i353phERIWBKT6+0Ypnw608WllU6VzI1PcB7M1wsW2wvnP+LRb9jAlxwiR0IuSzZo0MvYAwF/oAzOa0zBlMkRNbvfGClVBmho5ZDecGRyw6IgqPJWpad1K2UOiAa9F+b/bEjHHdEBKcfF8E2Z8rDXTuhqTPNV49ehuVLpDgxG0omL7/zJjcD+9hN+o894yXgDCAZMIaOne2Vzj89HGNgzWohxel2Q5zJZMtER35jiHG7aBUdueeHpVLqkBGaVC5I+UMrRESVJGCbAIfy6NhK1TUNOjgyBma95yI3x/7QueOmMHKyYfUKi0Rnmo7U9ABer7B6hb1OmGUhAh4PTJ9a0it5/OlevAGD39jztbVsZW+/fZvw7BMusjKlOBcJwCrng67QHyDG7XK61fZsWVJKHRpcuPDipcgU4RNf+Unl7rCS4KioEML2/7x7SqnyNfjg6PWXXLjddhjy6YcuUlpHsnWL0O8Y+0Opc4r93Lq1TvKnyyLG7WbWTPvUHTUgwNuzioiIgJZREbSLjSLa7ebyq700ije43YbnJtlB1EmnOblFwXGSysRHLueyfyinmV0pdciIIopG0ogIiaAxjfe8Wg3sCXSD3WrGQKOKRwFXSu1fDToh2+s3/D7f4pIr/GzdInzyQcllYQOPtz+UWre2g6Otm0uClfx8mDrZTXSM4d1Pi7AsKPCXxDouEcIj4NZxPsb/Xxjbt9lBVOs2Jccu260WMAaXlCR6l9PrppQ6RMRascRSxajqLndJH74J2I+VUgdEg245WvsX5OYIPQ8zDBtut+oMPMHPMy8V0T7J/lBq3hIsy7B5U0lwdM9tbhb9ZtG0GcWTwkrx/5zAxoA75LPshttKxjPyG4NF6YajgLG77IKC040opRqosHAIlLQ2Y+mYHkodKA32p4gxJQFPuw6GowcGWL29kOgyk6K7XNAyAbZuLln26892ENO3X8mIR8H51sDOJzLAORf4uetmu5us/7El67osIcJl4QfyfT7nKjhDfFhYyToIfjQJU6kGKyLangzYGPB7NThS6gCq1eBIRIYATwIu4AVjzENlnm8PvAw0dta5wxjzSW2WKSiAnXgN0DrRbqIpGxgFtWpj2LTBDlJ274Id2+37D0z0lqwkJWGMPf2HIb4x/LWjkK2bhXAnlzI4urYl9vxQkW4XLSLtK95cVkkgFOmyyPX58AQCRLlc5Pt85Q5YqZQ6RMU0hs6Hlzyu53P8KVWf1Nq3rYi4gKeBU4A04EIRSSuz2t3A28aY3sBw4JnaKk9ZAWP45QcXbRJLLrsvKzi8f++MAD//YFFYCB++62L3TuGTOR7iG5dev2Qy2pIgJyoKkkImjTXYLUwuZ5LbcMsi3GXfXCHbNQoPIyk2hli3G3/AEGZZ+I1BM5GUaiAsCyKjS27640ipA6Y2/9r6AquMMX8ZY4qAt4Azy6xjgEbO/XhgUy2Wp5SAgR3bhLYdTIUTXWd5vXj8Afr0DVBUJKxdLaxbI0REGA7rUyZICXkoIhXmCxlwAiMhxu0mylX+SyAiuCwhzBJ71m6ECJeLSE3KVEoppWpVbX7TJgLrQx5vAI4ss869wBcich0QA5xYi+UpZowh3+dj53Y3Kd3sKMYXCOASKb5azBsIYIlFod9P9172so9muti0UWjVppyASkpyjsqLtYwxFAUMfmOIcH4BJkRX3UzuEsHjDxAf4aZ1dNTeVVgppZRS1XawmyEuBKYbYx4TkX7AqyKSbowpNberiIwGRgMkJCQwe/bsvTpYbm4us2fPxgD5HsPfa46lZ/dN/PnzKnzBS+md0MbvNP3YgzEaunQ5gokPxtElJZsm8X7+/Pn3UvsOYFjnBD0BAz4TKDXQo3EmC3CJIAgrq5lnbbC7ADchLA/ZJliXQ4HWpe45VOoBWhelVM3VZnC0EWgX8ritsyzUFcAQAGPMTyISCTQHtoWuZIyZCkwFyMjIMIMGDdqrAs2ePZtBgwaR7/Pz7c9FeDwuTjwjge5HNifX5yfSZRVfTp/r9WEJtImJYnN+IUPOjGDlo7ByRSOGX+Ij/ah+pfZd4PeTFBuNiJDv87G1wEOUq+TqEo8/QGyYm2aR+2eU22BdDgVal7rnUKkHaF2UUjVXmzlHvwJdRKSjiIRjJ1x/WGadv4ETAEQkFYgEttdimQC7JWb5Ervq3boHyPP7CbcsCvx+Ak6LkTgDMgaTpEeNLhmnqF2H0glFwSvQpLivrWQER78xZBZ58QYChFnVbC5SSiml1EFTa8GRMcYHXAt8DizFviptsYhMEJGhzmq3AFeJyELgTWCUMbU/9GHAGJYvFsLDDe07B4h2uWgTE0mU20Ug5Oj2QI12QNMmkeKBImNi7YCoeKJZSucZhd73G0OYJTSLDCc27GD3YiqllFKqKrX6be2MWfRJmWXjQ+4vAY6uzTKUJ2AMq5ZbdO5icLkhwuUizLIIE8FnghfbO7NlC8WtQA8+bs+XNuwCPwX+AJYztpEBIl2lB2gLYAdOxth5RmGWVeoSf6WUUkrVTQ2yKcNvDKtXWPQ63E6TdgWn/UCctGm7Wy3S7bIDGrFbiuIaCQ9MtLvXCvzQJjqK8HIuxXdbQoTlotDvxxLBJTo+iVJKKVVfNMhv7YJCWL9O6NzFgCkZtDH4r3Faj1pG2SNXlz1JfmNfkl9RS1CYZdEqOhIDFPkDxcGXUkoppeq+BtdyVOj3s2xlgEBASE4J2PM5FgdHUOgP4BYpNY6RiDgjW9uK/AHiw8IqDXpcAi0jIwgYg2UJ0W6dF0kppZSqDxpccLSzsIiVK+z7nVNMqTnRcHKMmkdFEBYSHQUnkg3yG0NsmDvk6rQ9iQhx4WEVPq+UUkqpuqnBBUcuETastYOapI6lu9VcYneJxZW5qswSe2DHYO6RyxIiKpj2QymllFL1W4MLjsCwY6uLyChDo3goDJRMGNsoPKzc1h4RnPGP7BYkt+iVZ0oppdShqsE1fwSA7duElgkl86MFp/mwQgZ9DBXpcuE3AbyBAAED2miklFJKHboa3te8gV07hWbNSx5X1QjUJCKc2LAwjLHnSHOVO7WsUkoppQ4FDS44CgBZmULjJk6KtVCtLjK3c8WaMdVbXymllFL1U4MLjoyBzN3QuHFwAdVqB7KwW41CL/1XSiml1KGnwSVkGwyZu4XGTQP2YI9SveDIZVl4AwbB4NbYSCmllDpkNbjgyO83ZO2Gxk3sxxZUOl5RULTbRYfYaMCeHkQppZRSh6YGFxzlZIMxQnxjg78aydhBlgjhOg+IUkopdchrcDlHmbvtAKdJE0OB30+Uq8HFh0oppZSqRIMNjho3tbvHmkeGH+QSKaWUUqouabDBUaN4U+18I6WUUko1HA0uOMrKtP+NivdhaWK1UkoppcpocMFRsOUovjG0jIw4uIVRSimlVJ3T4IKjgjz735hYCLcaXPWVUkopVYUGFx14PHbLUVSk5hsppZRSak8NLjgqLACXyxARroGRUkoppfbU4IIjj0eI0FYjpZRSSlWg4QVHhRAR0QArrpRSSqlqaXAxQmEhRESa6s02q5RSSqkGp8EFR55CITKqAVZcKaWUUtXS4GKEwgK7W02bjpRSSilVngYXHO3YJjRvaTQ0UkoppVS5qh0ciUiUiHStzcIcCFu3CK1aGyy9Wk0ppZRS5ahWcCQiZwC/A585jw8TkQ9rsVy1wh+AbZuFhNbmYBdFKaWUUnVUdVuO7gX6ApkAxpjfgY61UqJalJUVhs8ntGxl0IYjpZRSSpWnusGR1xiTVWZZvWt+2bUrHIAWCZpzpJRSSqnyuau53mIRuQhwiUgX4Hrgx9orVu0oKHABEBtnkIaXi66UUkqpaqhuhHAd0B3wAG8AWcCNtVSmWuPx2MFRZJR2qymllFKqfFW2HImIC/jYGHMcMK72i1R7PB47FoyM0lGOlFJKKVW+KluOjDF+ICAi8QegPLWqqDg40pwjpZRSSpWvujlHucAfIvIlkBdcaIy5vrKNRGQI8CTgAl4wxjxU5vnHgeOch9FAS2NM42qWqcYKnW61qEgQ7VdTSimlVDmqGxy959yqzemOexoYDGwAfhWRD40xS4LrGGNuCln/OqB3TY5RU8FutYgoDY6UUkopVb5qBUfGmJdFJBxIcRYtN8Z4q9isL7DKGPMXgIi8BZwJLKlg/QuBf1anPHvLo91qSimllKpCtYIjERkEvAysxc5lbicilxpjvqtks0RgfcjjDcCRFey/A/agkt9U8PxoYDRAQkICs2fPrk6x95CT08ouyJJf2LFSsOpxhJSbm7vX56Gu0brUPYdKPUDropSquep2qz0GnGSMWQ4gIinAm0Cf/VSO4cA7TvL3HowxU4GpABkZGWbQoEF7dZDnn1+H221I7deXlpERxIRVt/p1z+zZs9nb81DXaF3qnkOlHqB1UUrVXHXHOQoLBkYAxpgVQFgV22wE2oU8bussK89w7GCrVnmKLCKj7PuacqSUUkqp8lS36WSeiLwAvOY8HgHMq2KbX4EuItIROygaDlxUdiUR6QY0AX6qZln2mqfQRWSUAQOiWUdKKaWUKkd1W47GYidSX+/cljjLKmSM8QHXAp8DS4G3jTGLRWSCiAwNWXU48JYxptbnavN4SlqOlFJKKaXKU92WIzfwpDFmIhRfph9R1UbGmE+AT8osG1/m8b3VLMM+8xRZREWhw2MrpZRSqkLVbTn6Gghtc4kCvtr/xaldRUUW4eF2A5XmHCmllFKqPNUNjiKNMbnBB8796NopUu3x+yzcVaWRK6WUUqpBq25wlCcihwcfiEgGUFA7Rao9fr/gduMkZCullFJK7am6OUc3Av8VkU3O49bABbVSolrk9wuR9a69SymllFIHUqUtRyJyhIi0Msb8CnQDZgBe4DNgzQEo337l9wsut91qpJfyK6WUUqo8VXWrTQGKnPv9gLuwJ5PdjTNidX3i9wtul8FoXKSUUkqpClTVreYyxuxy7l8ATDXGvAu8KyK/12rJakGw5UgppZRSqiJVtRy5RCQYTpxA6Ylh612YUZyQjV7Kr5RSSqnyVRXgvAnMEZEd2FenfQ8gIslAVi2Xbb/z+bTlSCmllFKVqzRUMMbcLyJfY1+d9kXIFB8WcF1tF25/s3OOgFqfqEQppZRS9VWV7SjGmJ/LWbaidopTu/x+KR4EUnvVlFJKKVWe6g4CeUiwE7K12UgppZRSFWtwwZHbhdNspG1HSimllNpTwwqOAiUJ2RoaKaWUUqo8DSs4CrmUX6MjpZRSSpWnQQVHAb+2HCmllFKqcg0qOPL57OlD9FJ+pZRSSlWkQQVHxRPPirYcKaWUUqp8DS44cofZgZHo/CFKKaWUKkeDCY4CATDGHufIkgZTbaWUUkrVUIOJEnw++1+XC1zaaKSUUkqpCjS84MgNlgZHSimllKpAwwuOXODSbjWllFJKVaDBRAklLUdGW46UUkopVaEGExx5vfa/LhdYeqWaUkoppSrQYIKjUjlHB7coSimllKrDGkycEAyO3G6jYxwppZRSqkINLjiyr1bT4EgppZRS5WtwwZHbrROrKaWUUqpiDS44crl1XjWllFJKVawBBkeC9qoppZRSqiINLjhyWwbRtiOllFJKVaDBBEd+v/2vK+zglkMppZRSdVuDCY4CAftfEbRbTSmllFIVqtXgSESGiMhyEVklIndUsM75IrJERBaLyBu1VRbjXKRmWdqpppRSSqmKuWtrxyLiAp4GBgMbgF9F5ENjzJKQdboAdwJHG2N2i0jL2ipPsOXIZYFer6aUUkqpitRmy1FfYJUx5i9jTBHwFnBmmXWuAp42xuwGMMZsq63CFHerWRoaKaWUUqpitRkcJQLrQx5vcJaFSgFSROQHEflZRIbUVmGKW44050gppZRSlai1brUaHL8LMAhoC3wnIj2MMZmhK4nIaGA0QEJCArNnz67xgX77rTFwGJtWLOV/cdn1vvUoNzd3r85DXaR1qXsOlXqA1kUpVXO1GRxtBNqFPG7rLAu1AZhrjPECa0RkBXaw9GvoSsaYqcBUgIyMDDNo0KAaFybYctQ2rRvHHBuJ26rfF+rNnj2bvTkPdZHWpe45VOoBWhelVM3VZoTwK9BFRDqKSDgwHPiwzDrvY7caISLNsbvZ/qqNwoQmZIv2qymllFKqArUWHBljfMC1wOfAUuBtY8xiEZkgIkOd1T4HdorIEuBb4DZjzM7aKE8wOLI0IVsppZRSlajVnCNjzCfAJ2WWjQ+5b4CbnVutCg2OlFJKKaUq0mBCheLgSHQQSKWUUkpVrMEER8ERskVzjpRSSilViQYTHGm3mlJKKaWqo8GECqWnD1FKKaWUKl+DCRWKpw/RHjWllFJKVaLBBEfBnCPtVlNKKaVUZRpMqKA5R0oppZSqjgYTKhQHR66DWw6llFJK1W0NLjhyac6RUkoppSrR4IIjHeNIKaWUUpVpMMGRJmQrpZRSqjoaTKigOUdKKaWUqo6GFxw1mBorpZRSam80mFBBR8hWSimlVHU0mFChuOVI87GVUkopVYkGExwFE7JdmnOklFJKqUo0mOBIu9WUUkopVR0NJlTQ4EgppZRS1dFgQoWSq9U06UgppZRSFWswwVFxzpEGR0oppZSqRIMJjrRbTSmllFLV0WBCBR0hWymllFLV0eCCI205UkoppVRlGkyoEAyORDTnSCmllFIVazDBkQ4CqZRSSqnqaDDBUWIi9OiRSVRYg6myUkoppfaC+2AX4EC58EJo3fp3msYNOthFUUoppVQdps0oSimllFIhNDhSSimllAqhwZFSSimlVAgNjpRSSimlQmhwpJRSSikVQoMjpZRSSqkQGhwppZRSSoXQ4EgppZRSKkStBkciMkRElovIKhG5o5znR4nIdhH53bldWZvlUUoppZSqSq2NkC0iLuBpYDCwAfhVRD40xiwps+oMY8y1tVUOpZRSSqmaqM2Wo77AKmPMX8aYIuAt4MxaPJ5SSiml1D4TE5yufn/vWORcYIgx5krn8SXAkaGtRCIyCngQ2A6sAG4yxqwvZ1+jgdEACQkJfd566629KlNubi6xsbF7tW1do3Wpmw6Vuhwq9QCtS9Bxxx033xiTsZ+LpNQh6WBPPPsR8KYxxiMi/wBeBo4vu5IxZiowFSAjI8MMGjRorw42e/Zs9nbbukbrUjcdKnU5VOoBWhelVM3VZrfaRqBdyOO2zrJixpidxhiP8/AFoE8tlkcppZRSqkq1GRz9CnQRkY4iEg4MBz4MXUFEWoc8HAosrcXyKKWUUkpVqda61YwxPhG5FvgccAHTjDGLRWQCMM8Y8yFwvYgMBXzALmBUbZVHKaWUUqo6ajXnyBjzCfBJmWXjQ+7fCdxZm2VQSimllKoJHSFbKaWUUiqEBkdKKaWUUiE0OFJKKaWUCqHBkVJKKaVUCA2OlFJKKaVCaHCklFJKKRVCgyOllFJKqRAaHCmllFJKhdDgSCmllFIqhAZHSimllFIhNDhSSimllAqhwZFSSimlVAgNjpRSSimlQmhwpJRSSikVQoMjpZRSSqkQGhwppZRSSoUQY8zBLkONiMh2YN1ebt4c2LEfi3MwaV3qpkOlLodKPUDrEtTBGNNifxZGqUNVvQuO9oWIzDPGZBzscuwPWpe66VCpy6FSD9C6KKVqTrvVlFJKKaVCaHCklFJKKRWioQVHUw92AfYjrUvddKjU5VCpB2hdlFI11KByjpRSSimlqtLQWo6UUkoppSqlwZFSSimlVIgGExyJyBARWS4iq0TkjoNdnsqISDsR+VZElojIYhG5wVneVES+FJGVzr9NnOUiIpOcui0SkcMPbg32JCIuEflNRGY5jzuKyFynzDNEJNxZHuE8XuU8n3RQC16GiDQWkXdEZJmILBWRfvX1dRGRm5z3158i8qaIRNaX10VEponINhH5M2RZjV8HEbnUWX+liFxaR+rxiPP+WiQiM0Wkcchzdzr1WC4iJ4csrzefb0rVBw0iOBIRF/A0cAqQBlwoImkHt1SV8gG3GGPSgKOAa5zy3gF8bYzpAnztPAa7Xl2c22jg2QNf5CrdACwNefwf4HFjTDKwG7jCWX4FsNtZ/rizXl3yJPCZMaYb0Au7TvXudRGRROB6IMMYkw64gOHUn9dlOjCkzLIavQ4i0hT4J3Ak0Bf4ZzCgOoCms2c9vgTSjTE9gRXAnQDOZ8BwoLuzzTPOj4769vmmVJ3XIIIj7A++VcaYv4wxRcBbwJkHuUwVMsZsNsYscO7nYH8BJ2KX+WVntZeBs5z7ZwKvGNvPQGMRaX1gS10xEWkLnAa84DwW4HjgHWeVsnUJ1vEd4ARn/YNOROKBY4EXAYwxRcaYTOrp6wK4gSgRcQPRwGbqyetijPkO2FVmcU1fh5OBL40xu4wxu7GDkrKBSq0qrx7GmC+MMT7n4c9AW+f+mcBbxhiPMWYNsAr7s61efb4pVR80lOAoEVgf8niDs6zOc7ovegNzgQRjzGbnqS1AgnO/rtfvCeD/gIDzuBmQGfIFEFre4ro4z2c569cFHYHtwEtOF+ELIhJDPXxdjDEbgUeBv7GDoixgPvXzdQmq6etQZ1+fEJcDnzr363M9lKpXGkpwVC+JSCzwLnCjMSY79Dljj8FQ58dhEJHTgW3GmPkHuyz7gRs4HHjWGNMbyKOk6waoV69LE+zWhY5AGyCGA9xqUpvqy+tQGREZh93F/vrBLotSDU1DCY42Au1CHrd1ltVZIhKGHRi9box5z1m8Ndgt4/y7zVlel+t3NDBURNZiN/cfj52309jpzoHS5S2ui/N8PLDzQBa4EhuADcaYuc7jd7CDpfr4upwIrDHGbDfGeIH3sF+r+vi6BNX0daizr4+IjAJOB0aYksHo6l09lKqvGkpw9CvQxbkSJxw7qfHDg1ymCjm5HC8CS40xE0Oe+hAIXlFzKfBByPKRzlU5RwFZId0LB5Ux5k5jTFtjTBL2ef/GGDMC+BY411mtbF2CdTzXWb9OtAAYY7YA60Wkq7PoBGAJ9fB1we5OO0pEop33W7Au9e51CVHT1+Fz4CQRaeK0pJ3kLDuoRGQIdjf0UGNMfshTHwLDnSsHO2InmP9CPft8U6peMMY0iBtwKvaVH6uBcQe7PFWUdQB2l8Ai4Hfndip2jsfXwErgK6Cps75gX62yGvgD+wqkg16Pcuo1CJjl3O+E/cG+CvgvEOEsj3Qer3Ke73Swy12mDocB85zX5n2gSX19XYD7gGXAn8CrQER9eV2AN7FzpbzYLXpX7M3rgJ3Ts8q5XVZH6rEKO4co+Lf/XMj645x6LAdOCVlebz7f9Ka3+nDT6UOUUkoppUI0lG41pZRSSqlq0eBIKaWUUiqEBkdKKaWUUiE0OFJKKaWUCqHBkVJKKaVUCA2OlCpDRPwi8nvIbb/Nci4iSaEzsCullKp73FWvolSDU2CMOexgF0IppdTBoS1HSlWTiKwVkYdF5A8R+UVEkp3lSSLyjYgsEpGvRaS9szxBRGaKyELn1t/ZlUtEnheRxSLyhYhEHbRKKaWU2oMGR0rtKapMt9oFIc9lGWN6AJOBJ5xlTwEvG2N6Yk8SOslZPgmYY4zphT0H22JneRfgaWNMdyATGFartVFKKVUjOkK2UmWISK4xJrac5WuB440xfzkTA28xxjQTkR1Aa2OM11m+2RjTXES2A22NMZ6QfSQBXxpjujiPbwfCjDH/PgBVU0opVQ3acqRUzZgK7teEJ+S+H839U0qpOkWDI6Vq5oKQf39y7v+IPRM6wAjge+f+18BYABFxiUj8gSqkUkqpvae/WJXaU5SI/B7y+DNjTPBy/iYisgi79edCZ9l1wEsichuwHbjMWX4DMFVErsBuIRqLPQO7UkqpOkxzjpSqJifnKMMYs+Ngl0UppVTt0W41pZRSSqkQ2nKklFJKKRVCW46UUkoppUJocKSUUkopFUKDI6WUUkqpEBocKaWUUkqF0OBIKaWUUirE/wMuoj6yLaeZSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "fig,ax=plt.subplots()\n",
    "df['logEpoch']=np.log10(df['Epoch'])\n",
    "# sns.lineplot('Step', 'AttentionModelwFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'AttentionModelwoFeatWeights_val', data=att_model_df, ax=ax)\n",
    "# sns.lineplot('Step', 'DenseModel_val', data=att_model_df, ax=ax)\n",
    "\n",
    "def get_mov_ave(y, window_size=3, percentiles=(10,90)):\n",
    "    assert window_size%2 ==1\n",
    "    w=int(window_size/2)\n",
    "    out=[]\n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    l,u=percentiles[0],percentiles[1]\n",
    "    for i in range(w, len(y)-w):\n",
    "        out.append(np.average(y[i-w:i+w+1]))\n",
    "        lower.append(np.percentile(y[i-w:i+w+1],l))\n",
    "        upper.append(np.percentile(y[i-w:i+w+1],u))\n",
    "\n",
    "    while w>0:\n",
    "        w=w-1\n",
    "        win_size=w*2+1\n",
    "        out.insert(0, np.average(y[:win_size]))\n",
    "        lower.insert(0, np.percentile(y[:win_size], l))\n",
    "        upper.insert(0, np.percentile(y[:win_size], u))\n",
    "        out.append(np.average(y[len(y)-win_size:]))\n",
    "        lower.append(np.percentile(y[len(y)-win_size:], l))\n",
    "        upper.append(np.percentile(y[len(y)-win_size:], u))\n",
    "    return out, lower, upper\n",
    "\n",
    "def get_min_max(mov_ave, y):\n",
    "    assert len(mov_ave)==len(y)\n",
    "    mins=np.min(np.vstack([mov_ave, y]), axis=0)\n",
    "    maxs=np.max(np.vstack([mov_ave,y]), axis=0)\n",
    "    return mins, maxs\n",
    "\n",
    "colors1=[\"b\",\"g\",\"r\",\"y\",\"k\"]\n",
    "colors2=[\"powderblue\",\"palegreen\",\"lightsalmon\",\"bisque\",\"lightslategray\"]\n",
    "for idx, i in enumerate([\"LLDLwFW_valacc\",\n",
    "#           \"LLDLwoFW_valacc\", \n",
    "#           \"DenseModel_valacc\"\n",
    "#                          \"LLDLwFW_simBatched_valacc\",\n",
    "#                          \"LLDLwFW_NosimBatched_valacc\",\n",
    "                         \"LLDLwFW_simBatched_lr_0_001_valacc\",\n",
    "                         \"LLDLwFW_NosimBatched_lr_0_001_valacc\"\n",
    "         ]):\n",
    "    x_plot=df['Epoch']\n",
    "    y_plot=df[i]\n",
    "    mov_ave, lower, upper=get_mov_ave(y_plot, window_size=15)\n",
    "    plt.plot(x_plot, mov_ave, c=colors1[idx])\n",
    "    #mins,maxs=get_min_max(mov_ave, get_mov_ave(y_plot, window_size=3))\n",
    "    plt.fill_between(x_plot,lower, upper, color=colors2[idx], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim([0.45, 0.95])\n",
    "ax.legend([\"Locality-adaptive Deep Learner\", \n",
    "#            \"Similarity Batching\",\n",
    "#            \"No Similarity Batching\",\n",
    "           \"Similarity Batching\",\n",
    "           \"No Similarity Batching\"\n",
    "          ], \n",
    "          bbox_to_anchor=(1,1))\n",
    "ax.set_title(\"10-D Synthetic Data with cluster-specific noise\")\n",
    "plt.grid()\n",
    "# savefile=os.path.join(SynthDataFolder, \"SynthData_10dim_LocallyAdaptiveDeepLearner\")\n",
    "# plt.savefig(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
