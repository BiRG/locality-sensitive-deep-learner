# Locality Sensitive Deep Learner
Companion paper: Yap XH, Raymer M.   Toxicity Prediction using Locality-Sensitive Deep Learner. Comput. Toxicol. *(Under review)*

Locality-sensitive deep learner (LSDL) uses attention mechanism to learn locality of a chemical in a dataset. We hypothesize that toxicity data has a *locally-linear* data structure: local regions with linear feature-target relationship.  

Repository is oraganized as follows:
- Processed toxicity datasets (Tox21, AChEi, CoMPARA, AOT) using CDK and PaDEL descriptors and Morgan2 (ECFP2) fingerprints *(/data/processed)*
- python scripts with helper functions *(/0_code)*
- Synthetic (locally-linear) data generation *(/1_Notebooks/SynthData/SynthData_10dim_generate_dataset.py)*
- Synthetic (locally-linear) experiments *(1_Notebooks/SynthData/SynthData_10dim_clusternoise*)
- python scripts for each dataset (Dataset names: Tox21_CDKPaDEL, AChEi, CoMPARA, AOT_wFP) *(/1_Notebooks/{dataset_name})*. Note that several of these scripts will need to load trained tensorflow models. The trained models are too large to be included in git repository (>0.1-1GB per model depending on dataset size). Also please check file paths in code files because files have been moved around/re-organized and paths may be broken. 


For ***Tox21_CDKPaDEL*** (*/1_Notebooks/Tox21_CDKPaDEL/*), further preprocessing and training of COSA feature weights was applied in *DataProcessing.ipynb*. The python scripts *Tox21_experiments_{modelName}_singlelabel.py* were used to train models in a few variations: dense (feed-forward neural network), LS (Locality-sensitive model without feature weighting), LSwFW (Locality-sensitive model with COSA feature weighting), LSwFW_ones (Locality-sensitive model with naive feature weighting initialized to ones), xgboost (XGBoost).  

For ***AChEi*** (*/1_Notebooks/AChEi/*), further preprocessing and training of COSA feature weights was applied in *DataProcessing.ipynb*. The models were trained using *210503_AChEi_ExtendedDataset_allFeatures.py*. The combined model was evaluated in *Exploration/ExtendedDatasetAnalyses.ipynb*, under *1.2.2 Plots across all folds* and *1.3 Repeat analysis with humanOnly*.  
An additional model using fingerprints only (*Exploration/AChEi_smiles_humanOnly*) was trained and used to demonstrate the weighting of chemotypes/functional groups on Soman in the thesis and paper.  

For ***AOT_wFP*** (*/1_Notebooks/AOT_wFP*), *AOT_binary.py*, *AOT_multiclass.py*, *AOT_regression.py* were used to generate binary/multi-class/regression deep learners with naming convention similar to Tox21_CDKPaDEL (dense, LS, LSwFW, LSwFW_ones, xgboost).  
__XGBoost models__ are generated from the files *AOT_binary_xgb.py*, *AOT_multiclass_xgb.py*, and *AOT_regression.py*.   
__Combined models__ (Averaged predictions of LSDL with feed-forward neural network) were generated by 1) saving predictions of base classifiers (*Results/AOT_predict/*model*_AOT_*traintest*_predict)*; 2) Running (*GetCombinedModel.py)* to evaluate performance of combined model. This jupyter notebook also outputs predictions of combined model.  
__Stacking models__ are obtained by first tuning the XGBoost classifier with (*Stacking_tuning.py*), then training and evaluating the model(s) with (*Stacking.py*).  

For ***CoMPARA*** (*/1_Notebooks/CoMPARA*), only the binary targets were used. *210427_CoMPARA_binary.py* was used to train deep learners and xgboost. The same workflow as ***AOT_wFP*** was used: 1) Get predictions (saved in *Results/Predicts*) and evaluate combined models (*GetCombinedModel.py*).; 2) Tune Stacking classifier with (*Stacking_tuning.py*) and train Stacking classifier with (*Stacking.py*).  


## How about generation of COSA feature weights? 