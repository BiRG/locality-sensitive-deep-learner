# Locality Sensitive Deep Learner
Companion paper: Yap XH, Raymer M.   Toxicity Prediction using Locality-Sensitive Deep Learner. Comput. Toxicol. *(Under review)*

Locality-sensitive deep learner (LSDL) uses attention mechanism to learn locality of a chemical in a dataset. We hypothesize that toxicity data has a *locally-linear* data structure: local regions with linear feature-target relationship.  

Repository is oraganized as follows:
- Processed toxicity datasets (Tox21, AChEi, CoMPARA, AOT) using CDK and PaDEL descriptors and Morgan2 (ECFP2) fingerprints *(/data/processed)*
- python scripts with helper functions *(/0_code)*
- Synthetic (locally-linear) data generation *(/1_Notebooks/SynthData/SynthData_10dim_generate_dataset.py)*
- Synthetic (locally-linear) experiments *(1_Notebooks/SynthData/SynthData_10dim_clusternoise*)
- python scripts for each dataset (Dataset names: Tox21_CDKPaDEL, AChEi, CoMPARA, AOT_wFP) *(/1_Notebooks/{dataset_name})*. 

For ***AChEi***, further preprocessing was applied using /1_Notebooks/AChEi/DataProcessing.ipynb
For ***AOT_wFP***, */1_Notebooks/AOT_wFP/AOT_binary.py*, */1_Notebooks/AOT_wFP/AOT_multiclass.py*, */1_Notebooks/AOT_wFP/AOT_regression.py* were used to generate binary/multi-class/regression deep learners in a few variations: dense (feed-forward neural network), LS (Locality-sensitive model without feature weighting), LSwFW (Locality-sensitive model with COSA feature weighting), LSwFW_ones (Locality-sensitive model with naive feature weighting initialized to ones). 
__XGBoost models__ are generated from the files */1_Notebooks/AOT_wFP/AOT_binary_xgb.py*, */1_Notebooks/AOT_wFP/AOT_multiclass_xgb.py*, and */1_Notebooks/AOT_wFP/AOT_regression.py*. 
__Combined models__ (Averaged predictions of LSDL with feed-forward neural network) were generated by 1) saving predictions of base classifiers (*/1_Notebooks/AOT_wFP/Results/AOT_predict/*model*_AOT_*traintest*_predict)*; 2) Running (*/1_Notebooks/AOT_wFP/GetCombinedModel.ipynb)* to evaluate performance of combined model. This jupyter notebook also outputs predictions of combined model. 
__Stacking models__ are obtained by first tuning the XGBoost classifier with (*/1_Notebooks/AOT_wFP/Stacking_tuning.py*), then training and evaluating the model(s) with (*/1_Notebooks/AOT_wFP/Stacking.py*)

